"Document Title","Abstract","Chosen","Authors","Author Affiliations","Publication Year","Page","DOI","Link","Content type"
"""We Even Borrowed Money From Our Neighbor"": Understanding Mobile-Based Frauds Through Victims' Experiences","Mobile-based scams are on the rise in emerging markets. However, the awareness about these scams and ways to avoid them remains limited among mobile users. We present a qualitative analysis of the dynamics of mobile-based fraud (specifically, SMS and call-based fraud) in Pakistan. We interviewed 96 participants, including different stakeholders in the mobile financial ecosystem: 71 victims of mobile-based scams, seven non-victims, 15 mobile money agents, and three officials from regulatory agencies that investigate mobile-based fraud. Leveraging the perspectives from these stakeholders and analyzing mobile-based fraud with a four-step social-engineering attack framework, we make four concrete contributions: First, we identify the nuances as well as specific tactics, methods, and resources that fraudsters use to scam mobile users. Second, we look at other actors, beyond the victim and the adversary, involved or affected by fraud and their roles at each step of the fraud process. Third, we discuss victims' understanding of mobile fraud, their behavior post-realization, and their attitudes toward reporting fraud. Finally, we discuss possible points of intervention and offer design recommendations to thwart mobile fraud, including addressing the vulnerabilities discovered in the ecosystem, utilizing existing actors to mitigate the consequences of these attacks, and realigning the design of fraud reporting mechanisms with the sociocultural practices.","Yes","Razaq L,Ahmad T,Ibtasam S,Ramzan U,Mare S","","2021","","10.1145/3449115","https://doi-org.proxy.bnl.lu/10.1145/3449115","Journal Article"
"A SWOT Analysis of Mobile Electronic Banking: The Zimbabwe Case","Zimbabwe is presently undergoing a transformative shift from a prevalently cash-based economy, to one using mobile electronic payments. The cash economy had the unintended consequence of excluding a large portion of the population from financial services, particularly banking services. This shift is significant for the economy because it has enabled the informal sector to tap into banking services. The Zimbabwean informal sector has gradually emerged as a major employer owing to economic challenges that have shrunk the formal sector. This reality has motivated mobile telephony companies to introduce innovative financial products targeting this sector. In this paper we use the SWOT framework to analyse the mobile banking sector in Zimbabwe. Our investigation seeks to inform stakeholders about the sector's potential and to caution about weaknesses that impact on stability and growth. We also characterise the processes involved in mobile banking to enable easy comparison of offerings from different service providers.","No","Nyandoro A,Mahleko B","","2015","218–238","10.1504/IJEF.2015.070531","https://doi-org.proxy.bnl.lu/10.1504/IJEF.2015.070531","Journal Article"
"A Study of Static Analysis Tools to Detect Vulnerabilities of Branchless Banking Applications in Developing Countries","The ubiquity of smart phones and their prevalence among the underprivileged has enabled the delivery of financial services to previously unbanked through digital means. At the same time it has exposed the same people to security vulnerabilities of digital infrastructure. In this paper, we analyze 10 Android Digital Financial Services (DFS) applications using static analysis tools and present results to show that off-the-shelf static bug checking tools, can be useful in finding many critical security bugs in DFS applications. Our findings also show that DFS applications from developing countries have more vulnerabilities in application specific code compared with DFS applications from developed countries. However, we observe that general purpose static analysis tools have low specificity for DFS specific bugs, such as the vulnerabilities in the use of cryptography and networking, and there is a need to develop better bug detection tools.","Yes","Ibrar F,Saleem H,Castle S,Malik MZ","","2017","","10.1145/3136560.3136595","https://doi-org.proxy.bnl.lu/10.1145/3136560.3136595","Conference Paper"
"Adoption of Mobile Commerce Technology: An Involvement of Trust and Risk Concerns","This research extended the Technology Acceptance Model TAM with perceived trust and perceived risks security and privacy concerns constructs to identify the impact of these factors on Jordanian users' intentions to adopt mobile commerce m-commerce. An empirical test was used utilizing 132 responses from students in two public universities in Jordan. Results indicated that perceived trust, perceived usefulness, and perceived ease of use are major influencers of mobile commerce adoption. On the other hand, perceived risk factors security and privacy concerns were not significant in this relation. Discussion, conclusion and future work are stated at the end of this paper.","No","Abu-Shanab E,Ghaleb O","","2012","36–49","10.4018/jtd.2012040104","https://doi-org.proxy.bnl.lu/10.4018/jtd.2012040104","Journal Article"
"An Assessment of SMS Fraud in Pakistan","SMS fraud has become a growing concern for those working toward financial inclusion, however, it is often unclear how widespread such threats are in practice. This multi-method study investigates SMS fraud in Pakistan through identification and categorization of fraudulent messages as well as the impact on those who receive such messages. We collect fraudulent SMS messages by various means, including byway of a custom-built Android smartphone application. To complement this, we interview people exposed to SMS fraud and representatives of mobile network operators. Based on our analysis, lottery type fraud schemes dominate SMS fraud in Pakistan, and these schemes have the greatest impact on vulnerable low-income, rural populations. We offer a simple heuristic for fraud detection that has a high accuracy rate and is adaptable to evolving fraud schemes, and conclude with a recommendation for a fraud mitigation strategy to target fraudster call back numbers.","No","Pervaiz F,Nawaz RS,Ramzan MU,Usmani MZ,Mare S,Heimerl K,Kamiran F,Anderson R,Razaq L","","2019","195–205","10.1145/3314344.3332500","https://doi-org.proxy.bnl.lu/10.1145/3314344.3332500","Conference Paper"
"An Empirical Investigation on Acceptance of Mobile Payment System Services in Jordan: Extending UTAUT2 Model with Security and Privacy","Several developed and developing countries have launched a mobile payment system service, which is known in Jordan as Jordan Mobile Payment (JoMoPay) system to overcome the drawbacks of traditional payment system. The system supports payment transactions by utilising mobile phones applications. However, the acceptance of JoMoPay system in Jordan is still below the level of expectation. This study was undertaken to understand and explain the acceptance of JoMoPay system based on extending the unified theory of acceptance and use of technology (UTAUT2) model in the Jordanian context. The model was extended by considering two additional constructs namely; security and privacy. Utilising a self-reported survey, collected data was analysed using structural equation modelling (SEM) to test the research model. Five constructs were found to be the determinants of behavioural intention to use JoMoPay system, namely performance expectancy, social influence, price value, security and privacy. Together they account for 61.4% of the variance in behavioural intention. However, effort expectancy, facilitating condition and hedonic motivation did not have a significant impact on behavioural intention to use JoMoPay system and hence the related hypotheses were not supported. Lastly, conclusions, limitations and future research directions will be discussed further in the last section of the paper.","No","Al-Okaily M,Rahman MS,Ali A,Abu-Shanab E,Masa'deh R","","2023","123–152","10.1504/ijbis.2023.128306","https://doi-org.proxy.bnl.lu/10.1504/ijbis.2023.128306","Journal Article"
"Analysis of the Essential Factors Affecting of Intention to Use of Mobile Learning Applications: A Comparison between Universities Adopters and Non-Adopters","Although mobile learning systems offer several benefits for students, academic staff and universities, from easily access and learning anywhere and anytime, the use and acceptance of this new technology in Jordan still very low. However, acceptance of mobile learning by students is crucial to the success of mobile learning. The factors that affect the use and user acceptance of mobile learning are still controversial. Thus, this study mainly proposes an integrated model, with the aim of identifying the most influential factors that may encourage or impede students and universities in Jordan in moving towards acceptance and adoption of mobile learning applications. The proposed model was evaluated empirically with 1200 students from both two groups of universities that already used the mobile learning technology and non-adopters universities in Jordan. The model aims to examine the impact of 11 factors on the adoption of mobile learning applications that were categorised based on four fundamental constructs are: (i) technological factors (security, privacy, compatibility, relative advantage and trust), (ii) organizational factors (resistance to change and technology readiness), (iii) cultural factors and (iv) quality factors (quality of system, quality of content and quality of service). The key findings include: (1) resistance to change, security and privacy concerns still limit mobile learning acceptance and adoption in Jordanian universities; (2) some factors like compatibility, technology readiness, and culture were found to have a negative effect on the intention to use of the mobile learning; (3) five factors (relative advantage, trust, quality of system, quality of content and quality of service) were found to have a positive effect on the intention to use of the mobile learning; and (4) our research also found that the effect of these factors differed in universities that already used the mobile learning and non-adopters. Finally, it is expected that the findings of this research can assist university decision makers, mobile learning application providers and the research community in introducing better strategies for encouraging adoption and acceptance of this technology.","Yes","Almaiah MA,Al Mulhem A","","2019","1433–1468","10.1007/s10639-018-9840-1","https://doi-org.proxy.bnl.lu/10.1007/s10639-018-9840-1","Journal Article"
"Cybersecurity Analysis to Determine the Impact on the Social Area in Latin America and the Caribbean","This document presents an introduction to the events that occurred in Latin America and the Caribbean, where banks are compromised by cyber-attacks, the same case is also seen in Ecuador, where losses from these attacks would amount to $ 6 billion by 2021. Our goal is to provide an analysis that demonstrates the social impact that cybersecurity has in Latin America and the Caribbean and a way to measure cybersecurity to combat threats due to constant technological progress and the great privacy risks presented to the day with cyber systems. The deductive method was used, adopting and generating a set of activities to evaluate the Total Cybersecurity (TC) of the cyber systems and / or companies to have a control of the security that it has and the improvements that can be implemented to prevent or combat Possible cyber threats or vulnerabilities. It resulted in cyber-resilience activities and activities based on the main functions before, during and after a cyber-attack. These activities are evaluated by the frequency of use, allowing each activity to assign a value and in this way apply the formulas proposed and obtain the CT, achieving the percentage of cybersecurity that has been implemented and discovering the weaknesses of the systems that They must be strengthened. It was concluded that in certain countries of Latin America and the Caribbean they have very little interest in the development and expansion of cybersecurity in their lands, unlike the progress of cybersecurity in European countries.","No","Toapanta SM,Jaramillo JM,Gallegos LE","","2020","73–78","10.1145/3375900.3375911","https://doi-org.proxy.bnl.lu/10.1145/3375900.3375911","Conference Paper"
"Cybersecurity Awareness Based on Software and E-Mail Security with Statistical Analysis","The aim of this study is to discover the impact of software security and e-mail security on overall cybersecurity among the students of Imam Abdulrahman Bin Faisal University in Dammam. Another main purpose to conduct this study is to know the level of knowledge students have in the developing countries about the cybersecurity and how much are they mindful of cyber-attacks and the level of awareness among the university students. Two important hypotheses were studied to discover their importance in awareness of cybersecurity. One is software security, and the other is e-mail security. A total of 11 relevant questions were drafted, and then these questions were distributed among the university students, and around 390 responded to the questionnaires. Statistical analysis was performed on the responses using tools. Initial tests such as validity and reliability test, feasibility test of a variable, correlation test, multicollinearity test, multiple regression, and Heteroskedasticity test were conducted using SPSS. And furthermore, multiple linear regression model and coefficient of determination, hypothesis test, ANOVA test, and partial test were conducted using ANOVA. The outcome of the analysis is software security variable (X1) that has a significant and positive effect on cybersecurity awareness (p value ≤0.001, β = 0.192). This shows that having a thorough understanding of software security can raise cybersecurity awareness up to 19.2%. E-mail security variable (X2) has a significant and positive effect on cybersecurityawareness (p-value ≤0.000). This shows that having a thorough understanding of email security can raise cybersecurity awareness up to 31.3%. Software security (X1) and e-mail security (X2) variables simultaneously have a significant effect on cybersecurity awareness (p-value ≤0.000) with a correlation coefficient of 12.1% (R2 = 0.121). This shows that the independent variable used can explain the level of cybersecurity awareness up to 12.1%. Research results show that students are aware of software or application updates. Furthermore, students’ awareness of email security is also good.","Yes","Alqahtani MA,Kumar V","","2022","","10.1155/2022/6775980","https://doi-org.proxy.bnl.lu/10.1155/2022/6775980","Journal Article"
"Examining Consumer Adoption and Perception of Mobile Money in Ghana","This paper investigates the consumer perception of a new electronic financial service in Ghana, namely mobile money MM. We analyse the relationships among five MM-related constructs, which are perceived ease of use PEOU, perceived usefulness PU, perceived mobile money security PMMS, attitude ATT, and intention to use IU. Importantly, the impact of age, family income, and gender on the relationships among the five MM constructs has been studied using a multi-group analysis approach. We find that PEOU, PU, and PMMS are significant determinants of ATT in the MM market in Ghana when age, family income, gender are not considered. However, the relationships among the five constructs exhibit significant variations when age, family income, and gender are considered. We also find an evidence that the effects of age, family income, and gender on consumers' perception of, ATT towards, and intention of using MM are significant in Ghana. The results of this study provide more insights into the research on MM, thus helping the development of marketing strategies for the service.","No","","","2016","18–41","10.1504/IJEF.2016.083490","https://doi-org.proxy.bnl.lu/10.1504/IJEF.2016.083490","Journal Article"
"Exploiting Multi-Vendor Vulnerabilities as Back-Doors to Counter the Threat of Rogue Small Unmanned Aerial Systems","A recent trend for many malicious actors, such as: (1) terrorists in Iraq and Syria, (2) lone wolf domestic terrorists, (3) drug cartels, or (4) espionage-minded corporations, has been to use commercial-off-the-shelf (COTS) small unmanned aerial systems (sUAS) (i.e., drones) that can circumvent ground-based defenses to attack or spy on targets, to transport contraband, or to steal information. Because of the low cost of COTS sUAS and the prior success of these uses, this trend is increasing at an alarming rate, leading to the need to counter the malicious usage of sUAS (i.e., rogue sUAS). Researchers, the armed forces, and technologists have all proposed disparate solutions to this problem. There are no comprehensive and compact solutions capable of effectively tracking, identifying, and actively neutralizing the threats associated with rogue sUAS. Thus, we have developed a mobile cyber solution, using rigorous penetration testing across the top sUAS COTS vendors. Based on the market share of these top vendors, our approach is applicable to approximately 90% of all COTS sUAS. We demonstrate that hard-to-patch vulnerabilities (i.e., vulnerabilities that exist across all the top vendors of sUAS) can be used as back-doors to counter the threat of rouge sUAS. Our solution can be launched from a standard laptop or Android mobile device with an external antenna, and is capable of tracking, identifying, and disrupting all Parrot and 3DR sUAS, as well as almost all DJI sUAS (i.e., renders them incapable of video flight) within a 300-meter radius.","No","Watkins L,Ramos J,Snow G,Vallejo J,Robinson WH,Rubin AD,Ciocco J,Jedrzejewski F,Liu J,Li C","","2018","","10.1145/3215466.3215467","https://doi-org.proxy.bnl.lu/10.1145/3215466.3215467","Conference Paper"
"Exploring Technical Quality Factors That Enhance Mobile Learning Applications Services Using Data Mining Techniques","Mobile learning (m-learning) has become an increasingly attractive solution for schools and universities that utilize new technologies in their teaching and learning setting. This study investigates the technical factors affecting the development of m-learning applications services from students’ perspectives. It presents a model consisting of twelve technical factors, including content usefulness, scalability, security, functionality, accessibility, interface design, interactivity, reliability, availability, trust, responsiveness, and personalization. To evaluate the model, a questionnaire was designed and distributed to 151 students in Jerash University, Jordan. The results indicate that all technical factors have positive affects on learner satisfaction and overall m-learning applications services, however the data mining analysis revealed that security and scalability factors exert a major impact on student satisfaction with m-learning applications services. This study gives insight for the future of developing and design m-learning applications.","Yes","Abu-Al-Aish A","","2021","1–23","10.4018/IJICTE.20211001.oa14","https://doi-org.proxy.bnl.lu/10.4018/IJICTE.20211001.oa14","Journal Article"
"Exploring the Influence of Security/Privacy, Trialability, Output Quality and Anxiety on the Adoption of Mobile Decision Support Systems among Nurses: A Developing Country Context","Nursing staff need to be highly mobile in executing their routine work. Therefore, they may need to catch, deliver and/or receive critical information, orders or alerts via mobile devices at any point of care to help them take immediate decisions/actions or orders to accomplish their tasks quickly. This paper investigates the factors that affect the adoption of mobile decision support systems among nurses in Jordan. Experience and voluntariness as moderators in the proposed model were also investigated. The model was analysed and tested using WarpPLS 5.0 software. The findings of this study have demonstrated that perceived usefulness, perceived ease-of-use, security/privacy, trialability, output quality, and anxiety are important constructs in predicting and affecting intentional behaviour to adopt decision support systems among nurses in Jordan. The model has explained 65% of the variance in behavioural intention. Theoretical contributions and practical implications are outlined. Limitations and suggestions for future studies are discussed.","No","Jaradat MI","","2021","251–281","10.1504/ijmlo.2021.116508","https://doi-org.proxy.bnl.lu/10.1504/ijmlo.2021.116508","Journal Article"
"How Relevant Are Risk Perceptions, Effort, and Performance Expectancy in Mobile Banking Adoption?","This article provides a comprehensive overview of the adoption process using evidence from m-banking adoption in Pakistan. A survey design was used and 189 responses were received from across Pakistan and analyzed using Smart PLS application. Findings suggest that research on the effect of risk in the adoption process remains inconclusive. Contrarily, consumers have overcome many fears due to the usefulness, indispensability, high security features, and effort expended in the use of financial services delivered through m-banking. Perceived risk's PR direct influence was found to be generally weak. However, PR plays a major role in the pre-adoption process because it's weak and direct inhibiting influence become an ""enhancer"" in the association between effort expectancy EE and the three key TAM/UTAUT constructs [performance expectancy PE, attitude ATT, and adoption intention INT]. Most importantly, the role of EE as a strong driver of PE, ATT, INT, and its significant interaction with PR highlights the unique role that both risk and EE play in the adoption process.","Yes","Shaikh AA,Glavee-Geo R,Karjaluoto H","","2018","39–60","10.4018/IJEBR.2018040103","https://doi-org.proxy.bnl.lu/10.4018/IJEBR.2018040103","Journal Article"
"Let's Talk Money: Evaluating the Security Challenges of Mobile Money in the Developing World","Digital money drives modern economies, and the global adoption of mobile phones has enabled a wide range of digital financial services in the developing world. Where there is money, there must be security, yet prior work on mobile money has identified discouraging vulnerabilities in the current ecosystem. We begin by arguing that the situation is not as dire as it may seem---many reported issues can be resolved by security best practices and updated mobile software. To support this argument, we diagnose the problems from two directions: (1) a large-scale analysis of existing financial service products and (2) a series of interviews with 7 developers and designers in Africa and South America. We frame this assessment within a novel, systematic threat model. In our large-scale analysis, we evaluate 197 Android apps and take a deeper look at 71 products to assess specific organizational practices. We conclude that although attack vectors are present in many apps, service providers are generally making intentional, security-conscious decisions. The developer interviews support these findings, as most participants demonstrated technical competency and experience, and all worked within established organizations with regimented code review processes and dedicated security teams.","Yes","Castle S,Pervaiz F,Weld G,Roesner F,Anderson R","","2016","","10.1145/3001913.3001919","https://doi-org.proxy.bnl.lu/10.1145/3001913.3001919","Conference Paper"
"Malware Analysis through High-Level Behavior","Malware is becoming more and more stealthy to evade detection and analysis. Stealth techniques often involve code transformation, ranging from equivalent code substitution and junk code injection, to continuously transforming code using a polymorphic or a metamorphic engine. Evasion techniques have a great impact on signature-based malware detection, making it very costly and often unsuccessful.We propose to study a malware's network behavior during its execution. While malware may transform its code to evade analysis, we contend that its behavior must mostly remain the same to achieve the malware's ultimate purpose, such as sending spam, scanning for vulnerable hosts, etc. While live malware analysis is hard, we leverage our Fantasm platform on the Deter-Lab testbed to perform it safely and effectively. Based on observed network traffic we propose a behavior classification approach, which can help us interpret the malware's actions and its ultimate purpose at a high level. We then apply our approach to 999 diverse samples from the Georgia Tech Apiary project to understand current trends in malware behaviors.","No","Deng X,Mirkovic J","","2018","5","","","Conference Paper"
"No Smurfs: Revealing Fraud Chains in Mobile Money Transfers","Mobile Money Transfer (MMT) services provided by mobile network operators enable funds transfers made on mobile devices of end-users, using digital equivalent of cash (electronic money) without any bank accounts involved. MMT simplifies banking relationships and facilitates financial inclusion, and, therefore, is rapidly expanding all around the world, especially in developing countries. MMT systems are subject to the same controls as those required for financial institutions, including the detection of Money Laundering (ML) - a source of concern for MMT service providers. In this paper we focus on an often practiced ML technique known as micro-structuring of funds or smurfing and introduce a new method for detection of fraud chains in MMT systems. Whereas classical detection methods are based on machine learning and data mining, this work builds on Predictive Security Analysis at Runtime (PSA@R), a model-based approach for event-driven process analysis. We provide an extension to PSA@R which allows us to identify fraudsters in an MMT service monitoring network behavior of its end-users. We evaluate our method on simulated transaction logs, containing approximately 460,000 transactions for 10,000 end-users, and compare it with classical fraud detection approaches. With 99.81% precision and 90.18% recall, we achieve better recognition performance in comparison with the state of the art.","No","Zhdanova M,Repp J,Rieke R,Gaber C,Hemery B","","2014","11–20","10.1109/ARES.2014.10","https://doi-org.proxy.bnl.lu/10.1109/ARES.2014.10","Conference Paper"
"Practical Receipt Authentication for Branchless Banking","Although branchless banking systems have spread to different parts of the developing world, methods to ensure transactional security in these systems have seen slower adoption because of a variety of operational constraints. A basic requirement from such systems is the provision of secure and reliable receipts to users during transactions, and recent attacks have demonstrated that existing systems fall short of fulfilling this requirement in practice. In this paper, we propose a simple and practical protocol to enable users to authenticate transaction receipts in branchless banking systems. Our protocol makes novel use of missed calls (sent from users to the bank) to help distinguish real receipts from spoofed ones and can be implemented on any mobile phone, without software installation. Besides preventing spoofing attacks, the protocol enjoys significant advantages of usability, efficiency and cost, which make it a more practical choice than other schemes. We also discuss ways to use missed calls to mitigate man-in-the-middle attacks on branchless banking systems.","No","Panjwani S","","2013","","10.1145/2442882.2442886","https://doi-org.proxy.bnl.lu/10.1145/2442882.2442886","Conference Paper"
"The Adoption of Security Control Apps among Smartphone Users in Tanzania","Threats to mobile devices and smartphones, in particular, are on the rise, suggesting that data and information residing in the mobile device such as smartphones are in danger of being attacked. The current study employs an extended TBP as a theoretical framework to investigate the adoption of security control apps (i.e. antivirus) to safeguard against the attacks. A theoretical framework was tested using structural equation modelling (SEM) with data collected from 233 respondents. The study found that social influence, attitude and security awareness have an influence on the intention to adopt antivirus software while perceived behavioral control and individual risk propensity have no influence. Further security awareness has an influence on the attitude of smartphone users towards using antivirus software.","Yes","Koloseni D,Sedoyeka EM","","2019","1–18","10.4018/IJTD.2019100101","https://doi-org.proxy.bnl.lu/10.4018/IJTD.2019100101","Journal Article"
"ThinSIM-Based Attacks on Mobile Money Systems","Phone-based mobile money is becoming the dominant paradigm for financial services in the developing world. For example, mPesa has a cash flow of over thirty billion USD, equivalent to nearly half of Kenya's GDP. Inside of these markets, competitors have appeared who leverage ThinSIMS, small SIM-card add-ons, to provide alternative mobile money implementations. However, the security implications of ThinSIMs are not well understood.To resolve this, we explore the security of phone-based mobile money systems against attacks via the SIM interface, the 3GPP-defined interface between a SIM card and a phone. Using a ThinSIM to intercept and initiate communication over the SIM interface, we demonstrate that a malicious ThinSIM can steal a user's mPesa credentials and initiate transactions without the user's consent or knowledge. We also demonstrate a similar ThinSIM-based attack against USSD-based mobile money systems that allows for similar transactions without the user's knowledge or participation. Lastly, we propose and implement modifications to both STK and USSD-based mobile money systems to limit the impact of our discovered ThinSIM-based attacks.","No","Phipps R,Mare S,Ney P,Webster J,Heimerl K","","2018","","10.1145/3209811.3209817","https://doi-org.proxy.bnl.lu/10.1145/3209811.3209817","Conference Paper"
"Towards Cash-Less Economy: Examining Factors Influencing Intention to Use NFC-Based Mobile Payments","Recently, there has been speedy development of mobile technologies and an increase in diffusion of smartphones among young people. This has provided opportunities for innovative companies to create new payment solutions to their young customers. Although there has been a lot of coverage on consumer acceptance of mobile payments, only limited studies in Tanzania provide guidelines for NFC technology acceptance. This study aimed at examining factors influencing the acceptance of NFC technology in Tanzania using young customers (students). Current research modifies UTAUT framework based on existing literature to achieve the stated purpose. The snowball sampling technique was used to select 405 students from the IFM. SEM was employed in the analysis of collected data. The findings reveal that both security and trust are significant and positively affect adoption of NFC technology in Tanzania. Surprisingly, the results also indicated that the combination of social influence and security explains 84% of the trust. The implication, limitations, and future studies were also discussed.","No","Lashayo DM,Mhina JR","","2022","1–24","10.4018/IJMDWTFE.311432","https://doi-org.proxy.bnl.lu/10.4018/IJMDWTFE.311432","Journal Article"
"""If God Gives Me the Chance i Will Design My Own Phone"": Exploring Mobile Phone Repair and Postcolonial Approaches to Design in Rural Kenya","This article focuses on ""fundi wa simu,"" (mobile phone repairers) in rural Kenya and their ideas about mobile phone design. Our study design and analysis were guided by ideas from postcolonial computing; we use our qualitative findings, and outcomes from a drawing exercise, to show existing flaws in mobile phone design, and to explore how repairers' knowledge can lead to handsets that are better suited for rural Kenyans. Our argument is that, by engaging with repairers ""[on] their own terms,"" technologists can expand conversations around designing for the 'developing' world that go beyond building novel smartphone applications. In fact, such conversations can also include reimagining mobile phones, and supporting local repairers' efforts to manufacture them. We conclude by discussing ways to improve upon postcolonial approaches to technology design.","","Wyche S,Dillahunt TR,Simiyu N,Alaka S","","2015","463–473","10.1145/2750858.2804249","https://doi-org.proxy.bnl.lu/10.1145/2750858.2804249;http://dx.doi.org/10.1145/2750858.2804249","Conference Paper"
"A Case History of a Computer Media Event—Introducing a Supercomputer Center","I've been asked to tell you how Cornell attempted to explain to the rest of the world the establishment here of one of four national centers for advanced computing — the supercomputer facility formally known as the Center for Theory and Simulation in Science and Engineering and nicknamed the Theory Center. This is the center that was founded this spring with part of the 200 million dollars that the National Science Foundation is allocating in the federal government's supercomputer initiative. That's a polite way of saying, we want to “Pearl Harbor” the Japanese before they do it to us in yet another area of technology.In brief, the Cornell Theory Center will be receiving something in the neighborhood of 30 million dollars from the National Science Foundation and another 30 million from IBM, in equipment and support, over the next three years to build and operate a production supercomputer facility — a sort of jumbo jet of supercomputers — and to conduct research in experimental supercomputer configurations — a program that could be thought of as the X-15 of computing. The Theory Center is still seeking additional industrial support; another $100 million would be a nice round number. Even without the industrial support, this is the largest single research program at Cornell.I'd like to describe the preparation — the groundwork — that went into this public information effort, as much as two years in advance. We'll go into the gory detail of what went wrong in our announcement, and some of the things that went right, not so many thanks to us. We'll take a look at how the news media covered an event like this — in particular television news — and I'll tell you why the hardest part of our job, as public information practitioners, is still ahead us.Let's start with who am I and what am I doing at a conference of computer documentation people? In a way, we're in the same business. We're supposed to be explaining computers and computing to people. Your people — your public — can be assumed to be receptive to computing. Or at least they're using it. The general public includes lots of people like myself who are still on the fringes of the computer revolution. They've been involved in a few skirmishes, maybe not even wounded yet, but they're not sure whose side they're on. They know that “user friendly” isn't good enough. They're not ready to learn a new language to speak to a machine. “The damn things are in the U.S. of A. Let them learn to speak American”.Even the millions of folks who have bought personal computers share a healthy suspicion of computing. Big computers are the ones the IRS uses to lose your tax returns. Big computers are the ones in government weapons labs. Big computers still can't predict the weather. Big computers are the ones, when they make mistakes, you can't argue with.That has something to do with why the idea of super computing — large scale computing — is not so easy to sell. “Bigger is better” went out with tailfins on cars. Now, if you're going to be bigger, or bigger just to be faster, there had better be a good reason for it.We didn't realize all of this, however, when ken Wilson won the Nobel Prize for physics in 1982, and immediately began talking about building supercomputers. I guess we were just glad to hear a theoretical physicist talk about something besides “the deep and hitherto unperceived analogies between the phenomena revealed by phase transitions and certain aspects of elementary particle physics.”The public's first inkling that there would be something called a Theory Center began when Ken Wilson stood up at a press conference that October morning, about four hours after being notified he was a Nobel Prize winner, and said: “I'm working at the national policy level to get people to realize the importance of computers as they become very much more powerful than they are today.” He said that just one field alone—theoretical physics — needed computing support to the tune of $100 million a year. He said, “I hope the prestige of the prize will help me get people — not necessarily to give $100 million — but to look carefully at the problems I've been discussing and to see if we can't get them worked out.”And from that day on, Cornell began promoting Kenneth G. Wilson — and I'm not ashamed of that word, promotion — and capitalizing on his fame. After all, you're only the reigning Nobel Prize winner for 365 days, and then someone else's phone starts ringing off the hook.Now Wilson was already serving on government panels to advise on the future of large scale computing and he had been knocking on the doors of executive suites in big business and industry, trying to convince the movers and shakers that American industry needed supercomputers and that the computer industry wasn't going to make very many of them until there was a demonstrated market and the best showroom, if you will, for supercomputers would be the universities where potential customers could come and “kick the tires” of the latest models.Then suddenly, Nobel Prize winner Wilson was the most prominent member of those government panels. Receptionists would say, “Let me show you right in, Dr. Wilson.” We interviewed Wilson for a Cornell publication a month later and he said, “There is nothing that comes close to providing the kind of forum that the Nobel Prize provides. With the kinds of problems I'm dealing with, with the kinds of barriers I face, anything short of the Nobel Prize doesn't mean very much.”We took the text of that interview — which talked about new uses for computer modeling and simulation and some schemes for parallel processing — and we sent it to about a dozen key business writers and science writers and editors around the country with a note saying, “Keep your eye on this guy. He knows more about supercomputing than anyone else in the country.”Now we didn't know whether that was true at the time. We just sort of became convinced of it.In the meantime, Ken Wilson was stepping up his activities in behalf of supercomputers. He was visiting more industries and getting more involved in advising government policy. When a report or a recommendation came out, if his name wasn't on it, people would ask his opinion. When the Japanese moved a little closer to making some big advance, people would ask Ken Wilson what he thought the U.S. should do. And once you get cited in The New York Times as a “leading expert” then you are one, and everyone else wants to know what you think. He was invited to write lots of articles and give talks on supercomputers and “the Japanese challenge.” He became “Mr. Supercomputer.”We don't claim all the credit for his fame. A lot, maybe most, of the effort was on Wilson's part. We just did everything we could to keep him in the public eye. When he and IBM and some other industries and the National Bureau of Standards sponsored a conference on large scale computing in Washington, we promoted it, even though it had next to nothing to do with Cornell. He became one of about a dozen almost-celebrity professors at Cornell. The only person more quoted, day in and out, was Carl Sagan.After Wilson had convinced the Washington establishment and the people holding the purse strings to spend some big money on scientific supercomputing, he had to step back from the role of neutral adviser and apply for some of the money himself. And somewhere along the line, the Theory Center became the Theory and Simulation Center, and it was to be for engineering and not just science. Must be someone figured out that there's a reason why the Fortune 500 doesn't include companies called International Business Theories or General Theoretical Motors. The co-investigators in the proposal to the National Science Foundation were Wilson; Dr. Kenneth King, who is also a physicist by background and is the computer czar for Cornell; and Ravi Sudan, also a physicist and an engineer who runs a lab for plasma fusion studies.During the time the proposal to the federal government was being reviewed — for months — we couldn't say much about the Theory Center. It's considered bad form to discuss something you're certain you will get. And if you don't get it, you look really silly.So instead, we concentrated on one little phase of the Theory Center, one that was already going on. This was the so-called GIBBS Project, an attempt by Wilson and some of the computer scientists here to create an entirely new scientific programming language to replace FORTRAN. We asked the public relations firm that represents the College of Engineering, of which computer science is a part, to push the GIBBS Project and they tried. It got some attention in the trade press and in places Like Science magazine, not too bad for something that wasn't hatched yet. The Theory Center, itself, wasn't real for a long time either. The Cornell faculty had given its consent and so had the University Board of Trustees. But Cornell's President, Frank Rhodes, wouldn't allow it to be established until Wilson could show some evidence of funding. They had an office with a name on the door and some furniture and a couple of people, but they didn't exist as far as Cornell University was concerned. We took to calling them the Theoretical Theory Center.We also started planning how we would announce the center when it was funded, which everyone said it would be, except that was a secret. We started preparing with the National Science Foundation's public information people to make an announcement. They told us they were afraid of a leak, ahead of the official announcement, and it could come from Congress. We thought they meant congressmen from California or Illinois or someplace. Surely, no elected official from New York would engage in something as sleazy as pork barreling, then spill the beans. Remember, I told you something would go wrong…In our brainstorming sessions, Ken Wilson made a demand that caused some snickers and mumblings of “Boy, is he naive.” He wanted to create the impression in the public mind that all of upstate New York was the next up-and-coming high technology region in the country. That all the isolated high tech areas like Rochester and Schenectady and Syracuse could be working together, rather than in competition, and that they could be linked electronically, by the Digital Thruway. The next Silicon Valley! And he wanted that impression created and established before the Theory Center was established, so that it would seem to be another piece fitting into the high tech picture. So we tossed around some names. Everything new has to have a catchy name. If New York City was the Big Apple, upstate could be the Silicon Apple. Then someone pointed out that gallium arsenide was the next hot semiconductor material and maybe we should be the Gallium Arsenide Apple. But that sounded too much like something the wicked witch would give Snow White. We talked about how the state could become involved. We tried to point out that impressions of prosperity and high tech environments aren't created overnight. Nobody knew they loved New York until millions of dollars worth of jingles and bumper stickers and billboards told them so.I guess we sensed a few inferiority complexes showing in these men who were about to pull off an astounding achievement — to persuade the federal government and the biggest computer company in the world to risk tens of millions of dollars. I remember Ken King telling of a telephone call he had just received from an acquaintance at another university who said, “Congratulations, but you got the booby prize.” He meant that Cornell — although it hadn't been announced yet — would be the fourth last-minute center funded by the government, and that we had to team up with a company that didn't even make supercomputers to do it.We tried to point out that Cornell didn't need to apologize for being the odd man in or out or wherever, because we had the element of surprise on our side. Everyone would want to know why the government was designating a private university in the middle of nowhere as a national center. We said that a couple of times, then shut up, We thought we still had three months to prepare for the announcement.At one point, some thought was given to hiring the same public relations firm that represents the manufacturer of the array processors the Theory Center uses, Floating Point Systems, to represent Cornell as well. They talked a Lot about “building understanding” which is something that p.r. people are big on. “Building understanding” is p.r. shorthand for building understanding of my point of view and convincing you of it. The firm wanted $40,000 to make the announcement of the Theory Center, and that was just to the trade press. It occurred to us that for $40,000 we could parachute Ken Wilson to the roof of every one of the top 100 newspapers in the country to personally hand a news release to the editor. We told them we'd think about it. We thought we still had two months to prepare for an announcement, sometime in the middle of April.In the meantime, we began preparing background information on the supercomputer center. We did a story saying that supercomputing will benefit American business, that “the advanced power of supercomputing and the research discoveries it makes possible promise to improve the entire corporate production cycle, from conception of a product through manufacturing to distribution.”We did a story saying that the marriage of supercomputing and three-dimensional, real-time computer graphics would be the greatest advance in communication since cavemen started painting on walls.We prepared a background piece saying that “Cornell University is a promising Location for a national, advanced scientific computing center because of its experience in operating highly successful interdisciplinary centers for the benefit of the scientific research community.” And we took the opportunity to brag about the Cornell Manufacturing Engineering and Productivity Program (COMEPP) and the Cornell High Energy Synchrotron Source (CHESS) and the Materials Science Center and the National Research and Resource Facility for Submicron Structures (which spells NRRFSS) and the Cornell Biotechnology Institute and the Semiconductor Research Corporation Center of Excellence in Microscience and Technology (which doesn't spell anything).We did another story saying the research uses of the supercomputer will range from “the study of galaxies to subatomic particles, from the motion of drifting continents to the movement of toxic wastes.”We wrote a general news release on the announcement, Leaving blanks for the amount of money and the number of years and the actual date of the announcement. We thought we still had a month to get ready.We solicited statement of congratulations from New York Governor Mario Cuomo and from the congressional delegation from this part of the state and from IBM vice president Jack Keuhler.When we were writing our news releases, by the way, we had to be careful not to mention IBM in the same breath — or even the same paragraph — with the word supercomputers. That directive came down from on high at IBM. IBM was not in the supercomputer business. Never had been, never will be. We couldn't even say the 3084QX would be a building block of a supercomputer. IBM was just giving us $30 million because they like us.We prepared biographies of all key personnel involved — all the way from Cornell President Frink Rhodes, who doesn't know anything about computers but who is able, with a little prompting, to speak eloquently on any issue and thank people for giving us money — down through all the vice presidents of: the university and provosts to the principal investigators in the Theory Center grant to the people who will really run the facility.Then we sat back and waited. Until February 20th, a Wednesday, when the NSF told us the announcement would be made the following Monday morning, in Washington. That didn't bother us. We were ready. We decided to schedule not one, not two, but three simultaneous press conferences. We would send Ken Wilson to the NSF press conference in Washington, along with a couple people from our office to straighten his tie and tuck in his shirt tails. We sent President Rhodes and Vice Provost King and Professor Ravi Sudan to New York for a press conference at Cornell Medical College. And we kept one Cornell vice president and one provost and the executive director of Theory Center, Bill Schrader, and the head of Theorynet, Alison Brown, for a simultaneous press conference in Ithaca.When we announce a press conference, we are very cagey. We try not to give away very much of the story — just enough to entice people to turn out. There's a reason for this. If you give away the story and if it's worth anything, the news people — being in a very competitive business — will try to run with it, and spoil your announcement. It happens every time. So we said something Like: Cornell University, the National Science Foundation and a major manufacturer of computing equipment will announce the start of a $60 million cooperative research venture at 10:30 a.m. Monday, February 25, at the following locations: …. Then we swore everybody to secrecy, everybody who might get calls Late at night or even be likely to talk in their sleep. There was one exception to that: We lined up an interview with Ken Wilson and The New York Times for Monday morning, just preceding the scheduled announcement. Then we sat back and waited.Imagine our surprise, on Saturday morning, February 23, to start receiving calls from news media all over New York State: “Could someone comment on the D'Amato announcement?” The D'Amato announcement? They read from a press release: “Senator Alfonse M. D'Amato (R, NY) is pleased to announce that Cornell University will receive at least $30 million and possibly up to $60 million from the National Science Foundation and up to $35 million from International Business Machines Corp. to do fundamental research from America's next generation of supercomputers.” Senator D'Amato said the grants would make Cornell one of the leading institutions in the country.That surprised us a little. We thought we were already a Leading institution. We are among the top four or five or six research universities in the country, and our academic reputation isn't too shabby, either.It was obvious what Sen. D'Amato was up to. He serves on one or two committees that some time in the past had reviewed the NSF proposals, probably voted for an appropriation when it seemed that some of the money might go to his home state, and placed a note in his future file: Break this on a slow news day and take credit for it.We tried to persuade D'Amato and his staff to back off, to correct his misinformation, to join us in a joint announcement on Monday and to shut up in the meantime. No go. He said the NSF had given him the green light to make the announcement. The NSF was furious. They refused to confirm that Cornell would even get a nickel, they started an investigation to determine how the leak occurred, and they blamed Cornell for prompting Sen. D'Amato to jump the gun and spoil the announcement for the other three centers around the country. The congressmen in the House of Representatives who really had gone to bat for Cornell on this one weren't too happy either. But they knew that D'Amato had a reputation for this sort of thing.Of course the news was in the Sunday papers all around New York the next day. That kind of money, even if the figures are incorrect, gets people's attention. The stories said that Cornell officials refused to comment, except to say that Sen. D'Amato was mistaken, and that an announcement would be made on Monday. It looked like we had something to hide. Or at least that we were caught off guard.Which we weren't. We had even given Ken Wilson media training. We had put him in front of our own TV cameras. We had dry runs of press conferences. We asked him the toughest, the stupidest, the most repetitive questions we could think of. We tried to teach him to look at the camera, not to fidget or play with parts of his clothing, not to look to the heavens or into his pocket for answers. In short, to give the impression that every question he gets is the most perceptive and original he has ever heard, deserving of a sensitive, profound answer that he just thought of. We weren't trying to make a Carl Sagan of him, just to help him come across as the intelligent person that he really is.Then we packed everybody off to their respective press conferences. All in all, they went pretty well, considering that practically nobody came to the New York City press conference and that the University of Illinois beat the pants off us in the Washington conference. The problem at the NSF press conference wag Larry Smarr, the Illinois astrophysicist, who was savvy enough to jump up and answer questions that weren't directed to anybody in particular. (We made a note to train Wilson to do that the next time.) Larry Smarr told a little story that any of the supercomputer people could have told but he thought of it first, and it's been quoted everywhere since then. He said that supercomputers are so scarce in this country that in order to do his research he had to go to Germany to find time on a machine — a machine that was made in this country. No big deal, but it was the kind of anecdote that writers love and lots of them used it in their stories.We knew our homework was paying off, however, when we saw that Ken Wilson was quoted on the front page of The New York Times, even before they mentioned the other places that have supercomputer centers. Larry Smarr had a snappier quote, but it was in the second section of the paper, and besides, IBM was quoted as saying that Cornell's approach to building supercomputers was the only one IBM would consider exploring, not that IBM was particularly interested in making supercomputers, of course.You have before you copies of some of the newspaper and magazine clips that appeared over the next few days. There have been lots more since. I'd like to play for you some tapes from local television stations that covered the Ithaca press conference. They go from bad to worse. We in the public information business collect these things to try to figure out how the information that we thought was presented so clearly gets so screwed up on the six o'clock news. Later I'll play a segment from a public affairs show on a Local PBS station, and then a piece that one of the national networks did — a really first rate job. Those of you who live in major media centers will be educated on what small town television is like. Those of you from small towns can sympathize.","","Segelken R","","1986","146–160","10.1145/10563.10588","https://doi-org.proxy.bnl.lu/10.1145/10563.10588;http://dx.doi.org/10.1145/10563.10588","Conference Paper"
"A Case Study of an African E-Government/e-Governance Development","It is a widely held belief, that Information and Communication Technology (ICT) is a powerful and timely source of development aid. A development aid which could be misunderstood, especially if its limitations are not taken into consideration in its planning. When it comes to the use of ICTs for good governance, the literature has very little to say on successes and failures of e-Government applications resulting in e-Governance efficiency and effectiveness in developing and transitional countries.This paper studied Ghana's e-Government/e-Governance profile since the adoption of its ICT4AD Policy, 2003. The method used in this study was observation and content analysis of different government departmental websites and documents from development partners such as The World Bank and the United Nations amongst others. The most quoted source is the 2014 edition of the United Nations E-Government Survey, the latest in the research by the Division for Public Administration and Development Management (DPADM) of the United Nations Department of Economic and Social Affairs (DESA), as well as by many valued external experts, researchers and contributors from other organizations [34]. Another sampling used for this paper involved the choice of interviewing individuals who are most advantageously placed or in the best position to provide the information required.Findings indicated that there is a demand for online or e-Government services in Ghana; indeed, a handful of the Ghana Government departments are utilizing websites to provide certain government services to the citizens. However, since internet connectivity is not available to a majority of citizens, one can safely conclude that e-Government/e-Governance presence is somehow stunted. It is also glaringly clear that apart from infrastructural deficit (inadequate broadband connectivity), there is weakness in the enforcement of policy regime, and extremely weak ICT skills capability. It is therefore suggested that the Government of Ghana assists its citizens with available, accessible, and affordable internet services through capacity building, with a dynamic regulatory body and encouragement to use mobile technology instead of total reliance on computers.The value and implications of this study, since the author believes that it is the most up to date and comprehensive study of the country's level of ICT readiness for the delivery of government services on --line, suggest that an understanding of the current status of e-Government/e-Governance in Ghana can help policy makers recognise the importance of Ghana's future growth by pursuing ICT development of both public and private sector organisations with emphasis on mobile telephony.","","Awotwi J,Amega-Selorm C","","2015","49–58","10.1145/2846012.2846040","https://doi-org.proxy.bnl.lu/10.1145/2846012.2846040;http://dx.doi.org/10.1145/2846012.2846040","Conference Paper"
"A Comparative Study of Population-Based Optimization Algorithms for Downstream River Flow Forecasting by a Hybrid Neural Network Model","Population-based optimization algorithms have been successfully applied to hydrological forecasting recently owing to their powerful ability of global optimization. This paper investigates three algorithms, i.e. differential evolution (DE), artificial bee colony (ABC) and ant colony optimization (ACO), to determine the optimal one for forecasting downstream river flow. A hybrid neural network (HNN) model, which incorporates fuzzy pattern-recognition and a continuity equation into the artificial neural network, is proposed to forecast downstream river flow based on upstream river flows and areal precipitation. The optimization algorithm is employed to determine the premise parameters of the HNN model. Daily data from the Altamaha River basin of Georgia is applied in the forecasting analysis. Discussions on the forecasting performances, convergence speed and stability of various algorithms are presented. For completeness' sake, particle swarm optimization (PSO) is included as a benchmark case for the comparison of forecasting performances. Results show that the DE algorithm attains the best performance in generalization and forecasting. The forecasting accuracy of the DE algorithm is comparable to that of the PSO, and yet presents weak superiority over the ABC and ACO. The Diebold-Mariano (DM) test indicates that each pair of algorithms has no difference under the null hypothesis of equal forecasting accuracy. The DE and ACO algorithms are both favorable for searching parameters of the HNN model, including the recession coefficient and initial storage. Further analysis reveals the drawback of slow convergence and time-consumption of the ABC algorithm. The three algorithms present stability and reliability with respect to their control parameters on the whole. It can be concluded that the DE and ACO algorithms are considerably more adaptive in optimizing the forecasting problem for the HNN model. Comparison of performances of population-based optimization algorithms in forecasting downstream river flow.Differential evolution (DE), artificial bee colony and ant colony optimization (ACO).Particle swarm optimization is included as a benchmark comparison for forecasting performances.Hybrid neural network (HNN) model incorporating fuzzy pattern-recognition and continuity equation.DE and ACO algorithms are considerably more adaptive in optimizing the forecasting problem for the HNN model.","","Chen XY,Chau KW,Busari AO","","2015","258–268","10.1016/j.engappai.2015.09.010","https://doi-org.proxy.bnl.lu/10.1016/j.engappai.2015.09.010;http://dx.doi.org/10.1016/j.engappai.2015.09.010","Journal Article"
"A Comparative Study of Smartphone-User Security Perception and Preference towards Redesigned Security Notifications","In this paper, we conducted a survey of 206 smartphone users of different demographics in Japan and Tanzania, two countries with different security and privacy expectations, to analyse users' cybersecurity knowledge and attitudes. We studied password choices, smartphone lock behaviour, phishing awareness and attitudes towards public Wi-Fi. We also assessed the acceptability of our novel notification alert for smartphone OS security updates. We found that data privacy is equally important to the majority of participants, 70%, in both countries. However, most participants did not know the characteristics of a strong password for web applications despite being highly conscious of physical access security which was characterised by smartphone locking (78% of participants). We also found that phishing awareness in Tanzania is not satisfactory, with the majority of the participants, 78%, likely to open a link from an unknown email source, whereas in Japan only 32% are likely to do so. Participants in Japan were also slightly more likely to read terms and conditions when connecting to public Wi-Fi (36% vs. 27%). Our novel notification design which integrated security updates with other free information services seemed promising for increasing security awareness and update compliance. Participants were more willing to accept update notices that provided guidance on how-to to perform a required task than plain notices.","","Ndibwile JD,Luhanga ET,Fall D,Miyamoto D,Kadobayashi Y","","2018","","10.1145/3283458.3283486","https://doi-org.proxy.bnl.lu/10.1145/3283458.3283486;http://dx.doi.org/10.1145/3283458.3283486","Conference Paper"
"A Confidential Electronic Result Transfer Using a Hybrid XML Security Scheme","Over the years, XML technology has been a standard for data representation and data exchange in many areas of information technology particularly those with focus on XML-based description standards for data interchange. Most data exchange involves transfer of confidential information, so there is a logical need for a secured means of storing, transmitting and receiving confidential and sensitive information. The security threats imposed on electronic result transfer is overwhelming and hence, the need to have a secure system in place. To obtain a maximum security level from XML Security standards, there is a need to incorporate a hybrid system that combines the features of the needed security measures. This paper presents a hybrid XML schema (XML encryption and XML signature) to ensure confidentiality and non-reputability in exchanging electronic result. The application involves encrypting the XML file using the XML encryption and then digitally sign this document using the XML signature for confidentiality and non-reputability, integrity and authenticity. The XML Security schema presented here is then proposed for adoption in the University of Agriculture Abeokuta, Ogun State Nigeria.","","Onashoga SA,Sodiya AS","","2011","397–402","10.1109/ITNG.2011.77","https://doi-org.proxy.bnl.lu/10.1109/ITNG.2011.77;http://dx.doi.org/10.1109/ITNG.2011.77","Conference Paper"
"A Context-Aware Multi-Channel Messaging Framework for African Banks: Design and Implementation","Customers of Financial Service Institutions (FSIs) subscribe to different types of alerts occurring on their accounts. The Single Channel Messaging (SCM) model is predominantly used by most Banks in Africa. However, the number of supported platforms and messaging formats limits the SCM Model and in the case where FSIs make use of multiple channels, these are not integrated. In addition, SCM does not provide a way of distinguishing between communication channels based on urgency or priority of the messages which need to be delivered to the customers. Consequently, this research work investigated and reviewed the existing approaches, publicly available platforms, web and mobile applications used by FSIs for interacting with their clients. Based on this, we derived the technical requirements for the implementation of a model for Multi-Channel Messaging (MCM) that addresses the weaknesses of SCM. Further, in this paper we present the proposed framework for the MCM model. The model was implemented using the problem-centred approach of the Design Science Research Methodology to derive the requirements of the MCM system from the SCM system, we further used Use-Case evaluation method to analyse the outcome of the design.","","Salami O,Mtsweni J","","2019","224–230","10.1145/3305160.3305162","https://doi-org.proxy.bnl.lu/10.1145/3305160.3305162;http://dx.doi.org/10.1145/3305160.3305162","Conference Paper"
"A Crowd Sourced Pharmacovigilance Approach Using SMS-Based Asymmetric Encryption","With the explosive international growth in mobile phone adoption, there is an increasing number of text message-based applications providing mission-critical services to mobile phone owners. With such an unexpected leap in the mobile subscriber base, questions have arisen over the reliability of Short Message Service (SMS) as a communication channel in regions of high mobile teledensity growth. This paper provides insight on two points - the architecture of new SMS-based services and an examination of SMS reliability in low resource environments. This is achieved by providing research results detailing the design and implementation of a crowd sourced mobile-based authentication service using asymmetric encryption and data from an in-field view of the reliability of SMS messages using the SMS product authentication service described. A new Mobile Product Authentication (MPA) platform has been designed and implemented using cloud-based distributed computing (server virtualization) and a mobile network reliability server has been built to emulate a quad-SIM cell phone with 2 GB of RAM, 200 GB storage and 2.5 GHz dual-core processing power. To evaluate network throughput, response time and fault-tolerance, time-stamped SMS messages are sent from the network reliability server to the MPA platform on a round-trip flight through Nigeria’s largest mobile telecommunications company over varying time periods and network conditions.","","Gogo A,Cybenko G,Garmire E","","2010","226–231","10.1109/ICCGI.2010.36","https://doi-org.proxy.bnl.lu/10.1109/ICCGI.2010.36;http://dx.doi.org/10.1109/ICCGI.2010.36","Conference Paper"
"A Data Driven Pre-Cooling Framework for Energy Cost Optimization in Commercial Buildings","Commercial buildings consume significant amount of energy. Facility managers are increasingly grappling with the problem of reducing their buildings' peak power, overall energy consumption and energy bills. In this paper, we first develop an optimization framework -- based on a gray box model for zone thermal dynamics -- to determine a pre-cooling strategy that simultaneously shifts the peak power to low energy tariff regimes, and reduces both the peak power and overall energy consumption by exploiting the flexibility in a building's thermal comfort range. We then evaluate the efficacy of the pre-cooling optimization framework by applying it to building management system (BMS) data, spanning several days, obtained from a large commercial building located in northern Australia. The results from simulations show that optimal pre-cooling reduces peak power by over 50%, energy consumption by up to 30% and energy bills by up to 37%. Next, to enable ease of use of our framework, we also propose a shortest path based heuristic algorithm for solving the optimization problem and show that it has comparable performance with the optimal solution. Finally, we describe an application of the proposed optimization framework for developing countries to reduce the dependency on expensive fossil fuels, which are often used as a source for energy backup. We conclude by highlighting our real world deployment of the optimal pre-cooling framework on the IBM Bluemix cloud. Our pre-cooling methodology, based on the gray box optimization framework, incurs no capital expense and relies on data readily available from a BMS, thus enabling facility managers to take informed decisions for improving the energy and cost footprints of their buildings.","","Vishwanath A,Chandan V,Mendoza C,Blake C","","2017","157–167","10.1145/3077839.3077847","https://doi-org.proxy.bnl.lu/10.1145/3077839.3077847;http://dx.doi.org/10.1145/3077839.3077847","Conference Paper"
"A Decision Support System for Tuberculosis Prevalence in South Africa","Tuberculosis is one of the most prevalent diseases, which is a threat to the lives of many South Africans. The disease has been spreading at a high rate in the past years. World health organization reported that South Africa is amongst 22 countries most burdened by the disease that has around 80% of the total global Tuberculosis cases. Despite the fact that the South African government is undertaking Tuberculosis campaigns, there is still a challenge in the control of the spread of Tuberculosis. The lack of awareness and access to information further contributes to the high rate at which Tuberculosis is spreading. Therefore, we developed a decision support system for Tuberculosis prevalence in South Africa. We used Bayesian network to aggregate, analyse and mine data received from health department of Mpumalanga province. The data is stored in MySQL database. We used WampServer environment, which enabled us to develop a web application. The proposed model educates, informs, and prescribes measures to take when visiting a high prevalence location. We then tested the system developed with data from Mpumalanga provincial health department showing that males are more at risk with prevalence rate of 53%, 0–35 age group are the most affected at 50%, Ehlanzeni location in Mpumalanga province is the most affected at 47%, pulmonary Tuberculosis is the most prevalence at 90% and the survival rate is at 87%. We evaluated the model achieving a utility of 88.2%. We believe this utility can be improved with more training and accurate data.","","Razwiedani M,Kogeda OP","","2021","270–284","10.1007/978-3-030-86973-1_19","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-86973-1_19;http://dx.doi.org/10.1007/978-3-030-86973-1_19","Conference Paper"
"A Developing World Perspective on the Design of Wireless Enabled Humanitarian Relief Services","In the absence of adequate state support, societies in the developing world have long relied on community support for humanitarian relief. Such community networks provide a readily available platform for delivery of humanitarian relief services. Wireless technologies can play an important role in enabling humanitarian relief applications that strengthen these community networks by facilitating the flow of information amongst the community members. Nevertheless, given the welfare nature of the activity, these applications face some strict design constraints that emerge from the larger socio-political-economic landscape. This paper presents a systematic approach to unearth the requirements that these domains may impose on the design of wireless enabled information and communication oriented humanitarian relief services, wiHRS. We describe SEAM, a systems thinking inspired conceptual framework that provides the theoretical underpinnings of the modeling apparatus used in this paper. As an example, we demonstrate the relevance of this framework to the design of wiHRS by analyzing the economics of enhanced information flow in community networks and how this analysis can be exploited to reflect on the financial viability of such services by, say, soliciting support from financial risk management instruments like insurance schemes.","","Saxena A,Wegmann A","","2011","357–364","10.1145/2185216.2185312","https://doi-org.proxy.bnl.lu/10.1145/2185216.2185312;http://dx.doi.org/10.1145/2185216.2185312","Conference Paper"
"A Framework for Monitoring Movements of Pandemic Disease Patients Based on GPS Trajectory Datasets","The rapid spread of contagious diseases poses a colossal threat to human existence. Presently, the emergence of coronavirus COVID-19 which has rightly been declared a global pandemic resulting in so many deaths, confusion as well as huge economic losses is a challenge. It has been suggested by the World Health Organization (WHO) in conjunction with different Government authorities of the world and non-governmental organizations, that efforts to curtail the COVID-19 pandemic should rely principally on measures such as social distancing, identification of infected persons, tracing of possible contacts as well as effective isolation of such person(s) for subsequent medical treatment. The aim of this study is to provide a framework for monitoring Movements of Pandemic Disease Patients and predicting their next geographical locations given the recent trend of infected COVID-19 patients absconding from isolation centres as evidenced in the Nigerian case. The methodology for this study, proposes a system architecture incorporating GPS (Global Positioning System) and Assisted-GPS technologies for monitoring the geographical movements of COVID-19 patients and recording of their movement Trajectory Datasets on the assumption that they are assigned with GPS-enabled devices such as smartphones. Accordingly, fifteen (15) participants (patients) were selected for this study based on the criteria of residency and business activity location. The ensuing participants movements generated 157, 218 Trajectory datasets during a period of 3 weeks. With this dataset, mining of the movement trace, Stay Points (hot spots), relationships, and the prediction of the next probable geographical location of a COVID-19 patient was realized by the application of Artificial Intelligence (AI) and Data Mining techniques such as supervised Machine Learning (ML) algorithms (i.e., Multiple Linear Regression (MLR), k-Nearest Neighbor (kNN), Decision Tree Regression (DTR), Random Forest Regression (RFR), Gradient Boosting Regression (GBR), and eXtreme Gradient Boosting regression(XGBR) as well as density-based clustering methods (i.e., DBSCAN) for the computation of Stay Points (hot spots) of COVID-19 patient. The result of this study showed clearly that it is possible to determine the Stay Points (hot spots) of a COVID-19 patient. In addition, this study demonstrated the possibility of predicting the next probable geographical location of a COVID-19 patient. Correspondingly, Six Machine Learning models (i.e., MLR, kNN, DTR, RFR, GBR, and XGBR) were compared for efficiency, in determining the next probable location of a COVID-19 patient. The result showed that the DTR model performed better compared to other models (i.e., MLR, kNN, RFR, GBR, XGBR) based on four evaluation matrices (i.e., ACCURACY, MAE, MSE, and R2) used. It is recommended that less developed Countries consider adopting this framework as a policy initiative for implementation at this burgeoning phase of COVID-19 infection and beyond. The same applies to the developed Countries. There is indication that GPS Trajectory dataset and Machine Learning algorithms as applied in this paper, appear to possess the potential of performing optimally in a real-life situation of monitoring a COVID-19 patient. This paper is unique given its ability to predict the next probable location of a COVID-19 patient. In the review of extant literature, prediction of the next probable location of a COVID-19 patient was not in evidence using the same Machine Learning algorithms.","","Ugwoke PO,Bakpo FS,Udanor CN,Okoronkwo MC","","2022","1–28","10.1007/s11276-021-02819-4","https://doi-org.proxy.bnl.lu/10.1007/s11276-021-02819-4;http://dx.doi.org/10.1007/s11276-021-02819-4","Journal Article"
"A Framework for Predicting Adherence in Remote Health Monitoring Systems","Remote health monitoring (RHM) systems have shown potential effectiveness in disease management and prevention. In several studies RHM systems have been shown to reduce risk factors for cardiovascular disease (CVD) for a subset of the study participants. However, many RHM study participants fail to adhere to the prescribed study protocol or end up dropping from the study prior to its completion. In a recent Women's Heart Health study of 90 individuals in the community, we developed Wanda-CVD, an enhancement to our previous RHM system. Wanda-CVD is a smartphone-based RHM system designed to assist participants to reduce identified CVD risk factors by motivating participants through wireless coaching using feedback and prompts as social support. Many participants adhered to the study protocol, however, many did not completely adhere, and some even dropped prior to study completion. In this paper, we present a framework for analyzing baseline features to predict adherence to prescribed medical protocols that can be applied to other RHM systems. Such a prediction tool can aid study coordinators and clinicians in identifying participants who will need further study support, leading potentially to participants deriving maximal benefit from the RHM system, potentially saving healthcare costs, clinician and participant time and resources. We analyze key contextual features that predict with an accuracy of 85.2% which participants are more likely to adhere to the study protocol. Results from the Women's Heart Health study demonstrate that factors such as perceived health threat of heart disease, and perceived social support are among the factors that aid in predicting patient RHM protocol adherence in a group of African American women ages 25-45.","","Alshurafa N,Eastwood J,Pourhomayoun M,Liu JJ,Nyamathi S,Sarrafzadeh M","","2014","1–8","10.1145/2668883.2669586","https://doi-org.proxy.bnl.lu/10.1145/2668883.2669586;http://dx.doi.org/10.1145/2668883.2669586","Conference Paper"
"A Framework for User Characterization Based on Tweets Using Machine Learning Algorithms","Twitter having more than three billion users is one of the most commercial and popular social networking sites. Twitter permits its users to post short messages and update their status. Tweets can be seen instantly by the followers of the users and other people with no twitter accounts. So by far most of the substance posted on the twitter is publicly accessible. Enormous number of political actors used twitter, who are interested in seeking extreme motives like radicalization, mobilization and recruiting activities. Twitters is used by large number of extremist organizations for press releases, public declaration and provide confirmation or motivation of their attacks. There have been several works looking at identifying extremist content based on twitter data but user identification using tweets has not been focused enough because of publication barrier and unavailability of data. In this research, a model is proposed which characterize a user into extremist and non-extremist categories. In this approach, pre-processing is done using natural language processing techniques and feature selection is performed using bag of words model. TF-IDF and word length is applied to obtain vector or feature to measure the significance of obtained vector in the whole document. We performed a methodology using classification through NB (Multinomial naïve Bayes) naïve Bayes on crises related tweets and Kaggle dataset related to tweets published by several Islamic State of Iraq and Sham to validate our proposed model. In this paper, a novel method is discussed for user characterization based on tweets posted by them. Evaluation results show that our suggested method gives best retrieval accuracies for word length feature extraction approach.","","Zahra K,Azam F,Butt WH,Ilyas F","","2018","11–16","10.1145/3301326.3301373","https://doi-org.proxy.bnl.lu/10.1145/3301326.3301373;http://dx.doi.org/10.1145/3301326.3301373","Conference Paper"
"A Framework for Water Loss Management in Developing Countries under Fuzzy Environment","A multi-criteria decision analysis method for water loss management is proposed.The method integrates AHP and TOPSIS methods under fuzzy environment.It is applied to a real water distribution system in a developing country.The prevalent strategies were highly connected to the local conditions. Facing water scarcity conditions water utilities cannot longer tolerate inefficiencies in their water systems. To guarantee sustainable water management one central task is reducing water losses from the supply systems. There are numerous challenges in managing water losses, manifested in a variety of options, their complexities, multiple evaluation criteria, inherent uncertainties and the conflicting objectives and interests of different stakeholders. This study demonstrates the effectiveness of multi criteria decision analysis (MCDA) approaches for decision support in this complex topic. The study covers identifying the key options among a set of options that have been proposed within a framework of strategies to reduce water losses in water distribution systems of developing countries. The proposed methodology was initiated by developing a hierarchical structure of the decision problem that consists of four levels: Overall objective, main criteria, evaluation criteria and options. Different stakeholders were engaged in the process of structuring and evaluating the decision problem. An integrated methodology that combines fuzzy set theory with Analytic Hierarchy Process (AHP) and Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) methods was then employed. This methodology has the potential to transform qualitative data into equivalent quantitative measures. Fuzzy AHP was used to create weights for main and evaluation criteria, while Fuzzy TOPSIS was used to aid the ranking of options in terms of their potential to meet the overall objective based on the evaluations and preferences of decision makers. The results showed that pressure management and control strategy was the most prevalent one, followed by employing advanced techniques and establishment of district metered areas. Their dominance was highly connected to the local and boundary conditions of the case study. The sensitivity analysis results showed that strongest and weakest options were less sensitive to changes in weights of evaluation criteria, which could be attributed to the strong consensus in strengthening the best option and neglecting the worst option. This study emphasized the successful application of MCDA in dealing with complicated issues in the context of water loss management. It is anticipated that, the integration of this developed framework in the planning policies of water utilities in developing countries can help in conducting better control over water losses.","","Zyoud SH,Kaufmann LG,Shaheen H,Samhan S,Fuchs-Hanusch D","","2016","86–105","10.1016/j.eswa.2016.05.016","https://doi-org.proxy.bnl.lu/10.1016/j.eswa.2016.05.016;http://dx.doi.org/10.1016/j.eswa.2016.05.016","Journal Article"
"A Framework to Leverage Cloud for Modernization of Indian Agricultural Produce Marketing System","In India, Information and Communication technology (ICT) is being leveraged as a modernization tool in almost every sector of economy such as health, education, and transportation. But when we consider the agricultural scenario in the Indian context, we realise that the ICT remains to be exploited to accrue its invaluable benefits. In recent times, the Government of India has introduced several initiatives to promote the application of ICT in agriculture sector. But when we compare the scale of ICT application in Indian agriculture sector with other developing countries like China, Brazil, etc., we find that application of ICT in Indian agriculture is yet to be applied on a significant magnitude. In this paper, we propose a cloud deployment model ""Agri-Bridge"", which provides access to agricultural market related information to farmers facing market connectivity constraints and acute capital shortage. Also, this model will operate as a bridge between the farmers and consumers within the existing agricultural produce marketing chain. This model utilizes the existing Government services, Agricultural Produce Marketing Committee (APMC) databases, retail market sources besides leveraging cloud computing, mobile phone services and Internet services to provide a solution to the problem of lack of access to real-time market information to the farmers, hence modernising the Indian agricultural produce marketing system.","","Matharu GS,Mishra A,Chhikara P","","2014","","10.1145/2677855.2677862","https://doi-org.proxy.bnl.lu/10.1145/2677855.2677862;http://dx.doi.org/10.1145/2677855.2677862","Conference Paper"
"A Ground-Up Approach to MHealth in Nigeria","Mobile Health (mHealth) has been piloted in developing countries to transform the delivery of healthcare services. Despite this heightened focus on mHealth, the number of fully operational mHealth solutions implemented in these locations remains surprisingly low. To extend mHealth projects beyond pilot stage it is imperative that the primary end user is positively predisposed to engaging with the mHealth intervention. Through exploring initial perceptions, we can inform later stages of mHealth projects or develop interventions to convert attitudes into commitment or motivation to use mHealth. This qualitative exploratory study aims to understand end users, namely Primary Healthcare (PHC) workers, initial attitudes towards a mHealth project called IMPACT (usIng Mobile Phones for Assessing, Classifying and Treating sick children). We conducted a field study in Enugu State, Nigeria to understand end users perceptions of the relevance, benefits, threats and initial understanding of the technology influencing end users attitudes towards adoption of mHealth. The initial findings indicate that PHC workers expressed positive perceptions regarding the relevance and benefits associated with the IMPACT app. PHC workers focus on how the technology could support them to be more efficient and effective in their roles. However, they advocate the need for community wide education and training to eradicate negative perceptions or misgivings about the potential use of mHealth as part of a patients assessment.","","Kenny G,OConnor Y,Eze E,Ndibuagu E,Heavin C","","2017","809–816","10.1016/j.procs.2017.11.105","https://doi-org.proxy.bnl.lu/10.1016/j.procs.2017.11.105;http://dx.doi.org/10.1016/j.procs.2017.11.105","Journal Article"
"A High-Efficiency Data Distribution Algorithm in Distributed Storage","To improve the survivability of distributed storage systems, using the theory of similarity transformation of Jordan standard shape in theory of matrix, combining the method of Lagrange interpolation method, we design a safe and high-efficient data distributing algorithm with threshold scheme. This algorithm has higher efficiency, stronger security and survivability than reference [1]. It has important applications in the intensive data distributed storage system and some storage scenes which have very high expectations for survivability.","","Yang XY,Liu Z,Zhang W,Guo DT","","2009","627–630","10.1109/IAS.2009.225","https://doi-org.proxy.bnl.lu/10.1109/IAS.2009.225;http://dx.doi.org/10.1109/IAS.2009.225","Conference Paper"
"A High-Frequency Mobile Phone Data Collection Approach for Research in Social-Environmental Systems: Applications in Climate Variability and Food Security in Sub-Saharan Africa","","","Giroux SA,Kouper I,Estes LD,Schumacher J,Waldman K,Greenshields JT,Dickinson SL,Caylor KK,Evans TP","","2019","57–69","10.1016/j.envsoft.2019.05.011","https://doi-org.proxy.bnl.lu/10.1016/j.envsoft.2019.05.011;http://dx.doi.org/10.1016/j.envsoft.2019.05.011","Journal Article"
"A Methodological Tool for Asset Identification in Web Applications: Security Risk Assessment","Security risk assessment in Web Engineering is an emerging discipline, where security is given a special attention, allowing software engineers to develop high quality and secure Web-based applications. A preliminary study revealed that asset identification (and evaluation) is an essential phase in risk assessment practices. This phase represents a degree of complexity and is the primary activity in the assessment process. This work focuses on asset identification and contributes to security risk assessment, which is essential part of software security. Specifically, the research goal is to design a methodological tool (instrument) for asset identification in web applications for the purpose of risk assessment. The proposed tool helps identify assets with security risks in web applications. The tool involves direct observations and survey questionnaires as data collection techniques used for this work. The research methodology is based on qualitative and quantitative analysis of a case study that focused on web-based application for Student Opinion Survey Coordination (EOE) developed in Simón Bolívar University, Venezuela. The data analysis required the use of cross-case analysis supported by the software application MAXQDA2007, which helps identify assets according to categories, such as Environment, Software, Hardware, Information and Networks. Under this work, students, faculty, staff, and software developers at Simón Bolívar University have participated in this study.","","M. BD,Haddad HM,A. JE","","2009","413–418","10.1109/ICSEA.2009.66","https://doi-org.proxy.bnl.lu/10.1109/ICSEA.2009.66;http://dx.doi.org/10.1109/ICSEA.2009.66","Conference Paper"
"A Multi-Level Cyber-Security Reference Model In Support Of Vulnerability Analysis","This paper reports on the second engineering cycle of a reference model for end-to-end cyber-security by design in the electricity sector. In our previous work, we proposed a reference model that relies on the integrated consideration of two fragmented, but complementary, reference models: NISTIR 7628 and powerLang. To align these reference models, we rely on multi-level modeling, specifically on the Flexible Meta Modeling and Execution Language (FMMLx), and integrated modeling and programming. Within this paper, we strengthen the bottom-up design of the reference model’s application by integrating a semi-automated threat analysis. This enables the identification of possible points of improvement in the actual architecture design, as well as a future analysis of business-level impact of different threats. To demonstrate our approach, we rely on the well-studied Ukraine scenario from 2016.","","Hacks S,Kaczmarek-Heß M,de Kinderen S,Töpel D","","2022","19–35","10.1007/978-3-031-17604-3_2","https://doi-org.proxy.bnl.lu/10.1007/978-3-031-17604-3_2;http://dx.doi.org/10.1007/978-3-031-17604-3_2","Conference Paper"
"A Multiple-Control Fuzzy Vault","We introduce multiple-control fuzzy vaults allowing generalized threshold, compartmented and multilevel access structure. The presented schemes enable many useful applications employing multiple users and/or multiple locking sets. Introducing the original single control fuzzy vault of Juels and Sudan we identify several similarities and differences between their vault and secret sharing schemes which influence how best to obtain working generalizations. We design multiple-control fuzzy vaults suggesting applications using biometric credentials as locking and unlocking values.Furthermore we assess the security of our obtained generalizations for insider/ outsider attacks and examine the access-complexity for legitimate vault owners.","","Hirschbichler M,Boyd C,Boles W","","2008","36–47","10.1109/PST.2008.23","https://doi-org.proxy.bnl.lu/10.1109/PST.2008.23;http://dx.doi.org/10.1109/PST.2008.23","Conference Paper"
"A New Method in Volcano-Morphology to Investigate the Tectonic Constraints on the Volcanism, Case Study of Harrat Al Sham Volcanic Field, Arabia Plate: The Interest of GIS and Relational Database","The volcanic activity of Arabian plate offers an attractive example of intraplate volcanism constrained by a complex tectonic setting. Harrat Ash Shaam volcanic field (HASV) is a basaltic province, extends widely at Arabian plate (over 50 000 km2), covers south of Syria, northeast of Jordan, north of Saudi Arabia, and contains hundreds of well- preserved monogenic volcanic cones.Our method aims to identify those cones volcanic, calculate its morphological parameters (heights, slopes, surfaces, volumes...etc.), and study their correlation. The farther intention of this study is to investigate the consequence of the tectonic events on the volcanic activity by testing the relations between the volcano-morphological parameters and the structure of the lithosphere (basement and moho surfaces).The realization of these objectives is problematic and even impossible by using the traditional exploration methods. Thanks to the computing technology which offers a vast opportunity to develop a new digital method in order to achieve such complex geospatial study.We suggest the integration and the exploitation of following primary data (so called to be distinguished from the extracted data): 1) the remote sensing (RS) technology provides several satellite scenes (landsat7, ETM+), 2) digital elevation models (SRTM data), 3) Digital earth application (by Cornell University), latter source offers internet based open access system of interpretation of geophysical data as estimation of crustal thickness and depth to Moho, 4) several geological maps of the study area, 5) K-Ar ages.The main challenges of this work are: a) building up geospatial database, geo-referencing and managing the primary data of different sources at same platform, b) treating the primary data to extract advanced levels of data, c) sustain the principle of ""data independence"" in order to protect the root of data from confusion after the process of extraction, which is imperative during the results interpretation (e.g. it must be specified if the volume parameter has been mathematically extracted based on the surface or independently).This paper spotlights the role of GIS in our geospatial investigation, and explains techniques employed in our method: 1) processing the satellite images with the purpose of distinguish the cones volcanic at HASV (more than 800 cones have been detected), 2) using spatial analysis tools in order to obtain automatically the periphery and the virtual bases of each cones volcanic from the digital elevation model, and 3) using GIS platform as tools to manage multi sources- data efficiently.In addition to, we highlight the integration between GIS and Relational Database, that we redesigned the geospatial database and restructured the data tables according to the new defined objects (i.g. the volcanic cones). In addition we have been used SQL widely in order to extract the advanced data levels (e.g. the morphological parameters), and to develop an approach in order to protect data roots.On other hand, the facility of exporting and importing the geospatial data tables between GIS and Microsoft application permitted us to reproduce easily and quickly the results of our research in form of maps (by using mapping tools based on geo-statistical methods of GIS). Consequently we propose an example of data streaming characterized by a geo-database system growing up in two directions (rows and columns). Our suggestion based on an observation; that in this case study, the geospatial database grows throughout a ""looping process"" between input and output data (i.g. the output data turn out to be a new batch of input data inserts again to the system). The probability of this looping process seems to be high and relates to the number of the scientific questions under investigation using the geospatial database system.Our prospective of the future challenge is to enhance the update links between the primary and the extracted data levels with the aim of bridging the gap created by high rate data streaming, as well as we proposed to develop the approach of ""data independence"".This case study shows that the role of GIS and Relational Database in geospatial investigation is not only indispensable as tools to manage and manipulate multi sources data, but is also significant to answer composite scientific questions.That our results demonstrate different spatial density zones contain clusters of hundreds of cones volcanic, in addition to considerable spatial differentiations of the morphological parameters. Consequently, we linked those variations to the lithosphere structures.On other hand our results obtained by applying digital based-method to HASV are in agreement with our dating results (K-Ar ages) of the volcanic activity, and the petrologic evidences at the northern parts of HASV. That enhanced our understanding of the volcano-tectonic evolution of the study area and played key role to suggest a spatial-temporal model characterizes the tectonic alteration between the compression and the extension during the last 26 Ma.We expect the mentioned harmony between results (i.e. direct method and digital based- methods) could reflect an important advantage in comparing the volcanism of HASV and other terrestrial planets.Moreover our results suggest a huge tectonic constrain on the volumes of the volcanic activity; that is fundamental to manage the volcanic risks at active analog zones. Therefore, we concluded that the digital based- method is helpful for monitoring and predication the natural hazards at regional scales.In the light of the previous facts building up the digital earth and developing its management tools are the future duties.","","Kwatli MA,Gillot PY","","2010","","10.1145/1823854.1823908","https://doi-org.proxy.bnl.lu/10.1145/1823854.1823908;http://dx.doi.org/10.1145/1823854.1823908","Conference Paper"
"A Novel PCA–Whale Optimization-Based Deep Neural Network Model for Classification of Tomato Plant Diseases Using GPU","The human population is growing at a very rapid scale. With this progressive growth, it is extremely important to ensure that healthy food is available for the survival of the inhabitants of this planet. Also, the economy of developing countries is highly dependent on agricultural production. The overall economic balance gets affected if there is a variance in the demand and supply of food or agricultural products. Diseases in plants are a great threat to the yield of the crops thereby causing famines and economy slow down. Our present study focuses on applying machine learning model for classifying tomato disease image dataset to proactively take necessary steps to combat such agricultural crisis. In this work, the dataset is collected from publicly available plant–village dataset. The significant features are extracted from the dataset using the hybrid-principal component analysis–Whale optimization algorithm. Further the extracted data are fed into a deep neural network for classification of tomato diseases. The proposed model is then evaluated with the classical machine learning techniques to establish the superiority in terms of accuracy and loss rate metrics.","","Gadekallu TR,Rajput DS,Reddy MP,Lakshmanna K,Bhattacharya S,Singh S,Jolfaei A,Alazab M","","2021","1383–1396","10.1007/s11554-020-00987-8","https://doi-org.proxy.bnl.lu/10.1007/s11554-020-00987-8;http://dx.doi.org/10.1007/s11554-020-00987-8","Journal Article"
"A Pilot Study of the Challenges Associated with ELearning Developments in Saudi Universities","The ongoing developments in Information and Communication Technologies (ICTs) lead IT professionals of the academic environments worldwide to adjust the eLearning Management Systems of their universities' domains in this reality by adopting the new ideas and recommendations. As a direct consequence, the influence on teaching and learning environments is more than emphatic and the challenges revealing the all the more increasing need in utilizing modern learning applications, procedures, and policies more apparent than ever before. Nevertheless, their institutions remain teaching organizations with their core processes focused on the need for education and training of their student bodies often increasing in size, especially in the emerging economies and developing countries. The Middle East and especially the Gulf Council Countries' (GCC) higher education systems are no exception. Saudi Arabia in particular can be considered a special case in the GCC due to its numerous and rather crowded higher education institutions. In this research, a number of diverse types of administrative, technical, and general challenges and issues related to eLearning are covered in order to examine the current situation of eLearning progress in Saudi universities, investigate the obstacles preventing high rates of eLearning development, and discover what kind of learning procedures people of Saudi prefer to accommodate their educational preferences. A pre-tested questionnaire was used for the purpose of data collection. The data were gathered from students of these educational institutions in Saudi Arabia and from other individuals from all walks of life and of various employment statuses. This pilot research study suggested that the main reason behind the slow progress of eLearning in Saudi Arabia is the result of problems in the local telecommunications and other infrastructure, as noted by the survey participants, and far less the outcome of weaknesses of the established procedures and facilities available from the local eLearning institutions.","","Xanthidis D,Nikolaidis P","","2014","63–79","10.4018/ijtd.2014100105","https://doi-org.proxy.bnl.lu/10.4018/ijtd.2014100105;http://dx.doi.org/10.4018/ijtd.2014100105","Journal Article"
"A Polygonal Approximation for General 4-Contours Corresponding to Weakly Simple Curves","The paper proposes a polygonal approximation for closed 4-paths obtained from standard contour following under 4-connectivity. Those 4-contours generate weakly simple polygons in the Euclidean plane; in general, they are not digital Jordan curves. The proposed polygon is easy to calculate and useful for shape representation and data reduction. The paper presents a linear algorithm for determining the ordered list of polygon vertices which are pixels determined from the point list of the given 4-contour. The algorithm relies on local extremity and semi-local shortest path requirements, and it uses only simple operations of integer calculus. The resulting polygon approximates what would be a generalization of the minimal perimeter polygon. The latter is known from the literature for 4-contours only for restricted cases such as digital Jordan curves related to simple grid continua, or certain types of subsets of rectangular mosaics, where it has been applied to perimeter estimation and for convexity and concavity analysis. We apply the polygon proposed to approximate 4-contours corresponding to weakly simple curves of known perimeter and report on experiments of perimeter estimation.","","Villafuerte M,Wiederhold P","","2022","161–193","10.1007/s10851-021-01060-0","https://doi-org.proxy.bnl.lu/10.1007/s10851-021-01060-0;http://dx.doi.org/10.1007/s10851-021-01060-0","Journal Article"
"A Retrofit Design Science Methodology for Smart Metering Design in Developing Countries","Traditional meters present both the users and utilities providers with various challenges in developing countries. For instance utility providers must get access to their users' premises to be able to read these meters or check fraudulent connections. Users on the other hand have to wait for months or more before knowing their utility consumptions or join long queues to purchase credit for the post-payment and pre-payment meters respectively. This paper seeks to propose a design that retrofits traditional meters on site into smart meters by adding embedded units for communication and control. The study was conducted using a modified Design Science Methodology referred to as Retrofit Design Science Research Methodology (RDSRM). RDSRM argues that, the artifact in context (Smart Meter) has undergone evaluation and acceptance as critical for solving a defined problem and that there are enough literature to support its relevance. The traditional meters were studied and the proposed system was designed using General Packet Radio Service (GPRS) technology for communication, and Peripheral Interface Controller (PIC). Network based applications were developed to present both the consumers and the utilities with the ability to interact with the meters remotely. An attempt was made to address identified security issues of smart metering by using Message Digest 5 (MD5) Algorithm in the design. The system was evaluated based on smart metering requirements. The GPRS Retrofitted Smart Metering System (GRSMS) will reduce the cost of deploying smart meters.","","Azasoo JQ,Boateng KO","","2015","1–7","10.1109/ICCSA.2015.23","https://doi-org.proxy.bnl.lu/10.1109/ICCSA.2015.23;http://dx.doi.org/10.1109/ICCSA.2015.23","Conference Paper"
"A Review of Geospatial Information Technology for Natural Disaster Management in Developing Countries","Disasters are deadly and destructive events, particularly in developing countries where economic, social, political and cultural factors increase natural hazard vulnerability. The recent devastation of the Haiti earthquake on January 12th, 2010 was a prime example of the human toll a natural disaster can take in developing regions of the world. There is an imminent need to improve natural disaster management capacity in developing countries to reduce disaster impacts. Given that disasters are spatial phenomenon, the application of geospatial information technology GIT is essential to the natural disaster management process. However, in developing countries there are numerous barriers to the effective use of GIT, especially at the local level, including limited financial and human resources and a lack of critical spatial data required to support GIT use to improve disaster management related decision making processes. The results of a thorough literature review suggests that currently available free and open source GIT FOS GIT offers great potential to overcome some of these barriers. Thus, disaster management practitioners in developing countries could harness this potential in an attempt to reduce hazard vulnerability and improve disaster management capacity. The use of FOS GIT significantly reduces software costs and can help build local level GIT knowledge/technical skills that are required for successful GIT implementation.","","Herold S,Sawada MC","","2012","24–62","10.4018/jagr.2012040103","https://doi-org.proxy.bnl.lu/10.4018/jagr.2012040103;http://dx.doi.org/10.4018/jagr.2012040103","Journal Article"
"A Review of Mobile Cloud Computing in Education during the Covid-19 Pandemic in Jordan","The concept of mobile cloud computing (MCC) becomes a commonly recent trend because of the impact of the covid-19 pandemic on most vital sectors around the world. The educational sector has been affected by the covid-19 pandemic lockdowns. The paradigm shift in education strategies has greatly affected many groups in society related to the educational sector. This research study reviews the perceptions of using MCC on teachers, parents, and students during the covid-19 lockdowns period in Jordan. The objectives of the research are to study the educational environment from the MCC user’s viewpoint, the difficulties that the users face while using MCC in learning, and their concerns about using MCC since it becomes an inevitable solution. Moreover, this research highlights the extent to which users know and accept MCC that they use and its effects on their privacy. Questionnaire results concluded that over 60 % of the users used social media and over 50collaborative applications as a communication method through their smart mobile devices compared to users who relied on specialized e-learning educational platforms, computers, or televisions. About 50 % of the users agreed to learn MCC techniques if it is required especially if they have the opportunity to see someone using these techniques in front of them, although near 35 % of the users thought that MCC threats their privacy. Over 65 % of the users determined the most difficulty or fear is disconnecting communication, especially while performing online exams. In conclusion, this research suggested an MCC online/offline examination framework.","","Mizher MA,Mazhar AA,Mizher MA","","2022","187–193","10.1145/3489088.3489101","https://doi-org.proxy.bnl.lu/10.1145/3489088.3489101;http://dx.doi.org/10.1145/3489088.3489101","Conference Paper"
"A Scalable Blockchain Implementation Model for Nation-Wide Electronic Voting System","Blockchain technology adoption rate is fast growing as seen in cryptocurrency and distributed finance (DiFi) domains. It is also getting lots of attention in many other application areas including electronic voting(e-voting) systems. The electronic voting system is an interesting application use case for blockchain because it helps to solve critical problems within that space- the integrity of voting data, the secrecy of the ballot, and single point of failure. This is because of the characteristics that blockchain technology embodies. One of the challenges, however, is with the scalability of the blockchain network, how the blockchain technology can power the scalability of systems built on it. The aim of this paper, therefore, is to present a Blockchain Implementation Model that tackles scalability concerns for E-Voting System. This model can be adaptable in any national election, specifically, Nigeria’s national elections. The resulting model would present a scalable electronic voting framework by leveraging the security and integrity infrastructures that blockchain technology brings to bear.","","Apeh AJ,Ayo CK,Adebiyi A","","2021","84–100","10.1007/978-3-030-87013-3_7","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-87013-3_7;http://dx.doi.org/10.1007/978-3-030-87013-3_7","Conference Paper"
"A Sharable Cloud-Based Pancreaticoduodenectomy Collaborative Database for Physicians: Emphasis on Security and Clinical Rule Supporting","Background: Pancreaticoduodenectomy (PD) is a major operation with high complication rate. Thereafter, patients may develop morbidity because of the complex reconstruction and loss of pancreatic parenchyma. A well-designed database is very important to address both the short-term and long-term outcomes after PD. Objective: The objective of this research was to build an international PD database implemented with security and clinical rule supporting functions, which made the data-sharing easier and improve the accuracy of data. Methods: The proposed system is a cloud-based application. To fulfill its requirements, the system comprises four subsystems: a data management subsystem, a clinical rule supporting subsystem, a short message notification subsystem, and an information security subsystem. After completing the surgery, the physicians input the data retrospectively, which are analyzed to study factors associated with post-PD common complications (delayed gastric emptying and pancreatic fistula) to validate the clinical value of this system. Results: Currently, this database contains data from nearly 500 subjects. Five medical centers in Taiwan and two cancer centers in Mongolia are participating in this study. A data mining model of the decision tree analysis showed that elderly patients (>76 years) with pylorus-preserving PD (PPPD) have higher proportion of delayed gastric emptying. About the pancreatic fistula, the data mining model of the decision tree analysis revealed that cases with non-pancreaticogastrostomy (PG) reconstruction - body mass index (BMI)>29.65 or PG reconstruction - BMI>23.7 - non-classic PD have higher proportion of pancreatic fistula after PD. Conclusions: The proposed system allows medical staff to collect and store clinical data in a cloud, sharing the data with other physicians in a secure manner to achieve collaboration in research.","","Yu HJ,Lai HS,Chen KH,Chou HC,Wu JM,Dorjgochoo S,Mendjargal A,Altangerel E,Tien YW,Hsueh CW,Lai F","","2013","488–497","10.1016/j.cmpb.2013.04.019","https://doi-org.proxy.bnl.lu/10.1016/j.cmpb.2013.04.019;http://dx.doi.org/10.1016/j.cmpb.2013.04.019","Journal Article"
"A Study of Framework Development and Research of Jewelry Design, Based on Pattern Egyptian Culture (Lotus Flower) Used in Culture Product Design","Industrial design has played a crucial role in the integration of cultural elements into products and in increasing their cultural value in the competitive global marketplace. Nowadays there is a shortage of design studies and products that dealt with the Egyptian styles. Even though, the ancient Egyptian civilization is full of patterns and symbols that we can exploit, develop, and manufacture with different products. Lotus flower one of the most important symbol in the antient Egypt, it was associated with Egyptian gods because of the way in which the Lotus emerged from the water. The Ancient Egyptians believed that Lotuses were symbolic of creation, rebirth, strength. This article aims to clarify the true meaning of the Lotus flower pattern and how to transform this cultural feature into innovative jewelry designs under the framework of culture-oriented design. The main contribution of this work is to explore the old Egyptian styles and convert them into designs that are compatible with this era to spread the culture attractively. This process is done firstly through a detailed explanation of this pattern, this phase consists of cultural features, literature reviews, and concepts. Secondly, used some design programs such as Auto CAD and Render software to transform this pattern into jewelry designs. Finally, this paper establishes a cultural product jewelry design model that is meant to provide designers with valuable research that can be applied in many artistic fields like clothing design, fashion, decoration, and modern designs for this pattern.","","Ramadan E,Wu Y","","2021","630–645","10.1007/978-3-030-90328-2_43","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-90328-2_43;http://dx.doi.org/10.1007/978-3-030-90328-2_43","Conference Paper"
"A Study on Higher Order Differential Attack of KASUMI","This paper proposes novel calculuses of linearizing attack that can be applied to higher order differential attack. Higher order differential attack is a powerful and versatile attack on block ciphers. It can be roughly summarized as follows: (1) Derive an attack equation to estimate the key by using the higher order differential properties of the target cipher, (2) Determine the key by solving an attack equation. Linearizing attack is an effective method of solving attack equations. It linearizes an attack equation and determines the key by solving a system of linearized equations using approaches such as the Gauss-Jordan method. We enhance the derivation algorithm of the coefficient matrix for linearizing attack to reduce computational cost (fast calculus 1). Furthermore, we eliminate most of the unknown variables in the linearized equations by making the coefficient column vectors 0 (fast calculus 2). We apply these algorithms to an attack of the five-round variant of KASUMI and show that the attack complexity is equivalent to 228.9 chosen plaintexts and 231.2 KASUMI encryptions.","","Sugio N,Aono H,Hongo S,Kaneko T","","2007","14–21","10.1093/ietfec/e90-a.1.14","https://doi-org.proxy.bnl.lu/10.1093/ietfec/e90-a.1.14;http://dx.doi.org/10.1093/ietfec/e90-a.1.14","Journal Article"
"A Sub-Regional Information System for Monitoring and Managing PLHIV in Cross-Border Areas between Gambia, Senegal and Guinea Bissau: Information System for Managing PLHIV in Cross-Border Areas","Since aids appeared, it is of common knowledge that geographical spread of HIV is linked to human mobility [1]. However, this relationship between mobility and Aids is both complex and relatively unknown. The FEVE project (Frontiers and Vulnerability to HIV in West Africa), is implemented by ENDA to underline the causal process in order to achieve the UNAIDS 90-90-90 target [2]: by 2020, 90% of the people living with HIV know their HIV status, 90% of the people who know their HIV-positive status are accessing antiretroviral therapy and 90% of the people receiving antiretroviral therapy will have suppressed viral loads. However, as in most African countries, in Senegal health actors generate a large amount of information every day, such as consultation, hospitalization, monitoring infectious diseases, deaths, etc that is recorded in registers. That make difficult their exploitation. This difficulty is compounded when we interested in data related to infectious diseases such as HIV in cross-border areas. The high mobility of the population in these areas poses a great deal of problems in terms of treatment adherence as well as the search for those lost to follow-up. To overcome this problem, we propose a transboundary platform for the monitoring of People Living with HIV (PVVIH). This platform is a web and application which offers not only a sub-regional system of PLHIV management but also a system of communication and capacity building between actors.","","Dieng Y,Diop I,Faye Y,Malack CA","","2019","","10.1145/3361570.3361576","https://doi-org.proxy.bnl.lu/10.1145/3361570.3361576;http://dx.doi.org/10.1145/3361570.3361576","Conference Paper"
"A Survey of Software Estimation Techniques and Project Planning Practices","Paper provides in depth review of software and project estimation techniques existing in industry and literature, its strengths and weaknesses. Usage, popularity and applicability of such techniques are elaborated. In order to improve estimation accuracy, such knowledge is essential. Many estimation techniques, models, methodologies exists and applicable in different categories of projects. None of them gives 100% accuracy but proper use of them makes estimation process smoother and easier. Organizations should automate estimation procedures, customize available tools and calibrate estimation approaches as per their requirements. Proposed future work is to study factors involved in Software Engineering Approaches (Software Estimation in focus) for Offshore and Outsourced Software Development taking Pakistani IT Industry as a Case Study.","","Nasir M","","2006","305–310","10.1109/SNPD-SAWN.2006.11","https://doi-org.proxy.bnl.lu/10.1109/SNPD-SAWN.2006.11;http://dx.doi.org/10.1109/SNPD-SAWN.2006.11","Conference Paper"
"A Survey of Web Engineering Practice in Small Jordanian Web Development Firms","Web based-applications became increasingly important to all aspects of life, and most of these web applications projects run over time and budget. So there is a need to encourage practitioners to adopt best practices so as to improve the quality of the processes in use, and therefore achieve targets relating to time, budget and quality. The web development industry worldwide is dominated by a myriad of small firms. This presents a challenge in terms of determining the current practices of industry participants, and in devising improvement initiatives which are feasible for small firms. Currently, the level of adoption of best practice among web developers is unknown. To help improve the web industry, it is necessary to determine the current status of use of practices and techniques. The objective of this research is to understand the extent of web development practices currently in use. To achieve this objective, a survey of web engineering practice in small Jordanian firms was conducted. A detailed description of the survey procedures is provided in this paper. The results showed that there is a weakness in applying web engineering practices in small Jordanian web development firms.","","El Sheikh A,Tarawneh H","","2007","481–489","10.1145/1295014.1295023","https://doi-org.proxy.bnl.lu/10.1145/1295014.1295023;http://dx.doi.org/10.1145/1295014.1295023","Conference Paper"
"A Survey of Web Engineering Practice in Small Jordanian Web Development Firms","Web based-applications became increasingly important to all aspects of life, and most of these web applications projects run over time and budget. So there is a need to encourage practitioners to adopt best practices so as to improve the quality of the processes in use, and therefore achieve targets relating to time, budget and quality. The web development industry worldwide is dominated by a myriad of small firms. This presents a challenge in terms of determining the current practices of industry participants, and in devising improvement initiatives which are feasible for small firms. Currently, the level of adoption of best practice among web developers is unknown. To help improve the web industry, it is necessary to determine the current status of use of practices and techniques. The objective of this research is to understand the extent of web development practices currently in use. To achieve this objective, a survey of web engineering practice in small Jordanian firms was conducted. A detailed description of the survey procedures is provided in this paper. The results showed that there is a weakness in applying web engineering practices in small Jordanian web development firm.","","El Sheikh A,Tarawneh H","","2007","481–490","10.1145/1287624.1287692","https://doi-org.proxy.bnl.lu/10.1145/1287624.1287692;http://dx.doi.org/10.1145/1287624.1287692","Conference Paper"
"A Terrain Risk Assessment Method for Military Surveillance Applications for Mobile Assets","We developed a terrain risk assessment method for military surveillance.We developed the method for UAVs used for military combat operating posts.We modeled the terrain by calculating 5 risk factors using geographical parameters.We modeled high risk spots for methodical UAV surveillance plans.We tested the method using real-life scenario data provided by the sponsor. This study proposes an analytical and flexible terrain risk assessment method for military surveillance applications for mobile assets. Considering the risk as the degree of possibility of insurgent presence, the assessment method offers an efficient evaluation of risk in the surrounding terrain for military combat operating posts or observation posts. The method is designed for unmanned aerial vehicles as the surveillance assets of choice to improve the effectiveness of their use. Starting with the area map and geographical data, the target terrain is first digitized for space representation. Then the data of nine geographical parameters are used to formulate five contributing risk factors. These factors are incorporated in an analytical framework to generate a composite map with risk scores that reveal the potential high-risk spots in the terrain. The proposed method is also applied to a real-life case study of COP Kahler in Afghanistan, which was a target for insurgent attacks in 2008. The results confirm that when evaluated with the developed method, the region that the insurgents used to approach COP Kahler has high concentration of high-risk cells.","","Buyurgan N,Lehlou N","","2015","88–99","10.1016/j.cie.2015.06.025","https://doi-org.proxy.bnl.lu/10.1016/j.cie.2015.06.025;http://dx.doi.org/10.1016/j.cie.2015.06.025","Journal Article"
"A View from the Other Side: Understanding Mobile Phone Characteristics in the Developing World","Mobile devices are becoming increasingly dominant in the developing world. However, there is little insight into the characteristics of devices being used in such regions. Using a dataset of 0.5 million subscribers from one of the largest cellular operators in Pakistan, we analyze the characteristics of cell phones based on different features (e.g., CPU, memory, and cellular interface). We identify potential device-level bottlenecks for Internet access and analyze the security implications of the phones being used. To aid the analysis of cell phones, we propose abstractions (e.g., connectivity, capacity, and device security) and cluster phones based on these abstractions. Our analysis reveals interesting insights for improving mobile web performance.","","Ahmad S,Haamid AL,Qazi ZA,Zhou Z,Benson T,Qazi IA","","2016","319–325","10.1145/2987443.2987470","https://doi-org.proxy.bnl.lu/10.1145/2987443.2987470;http://dx.doi.org/10.1145/2987443.2987470","Conference Paper"
"A Virtual Reality Exposure Therapy Application for Iraq War Post Traumatic Stress Disorder","Post Traumatic Stress Disorder (PTSD) is reported to be caused by traumatic events that are outside the range of usual human experiences including (but not limited to) military combat, violent personal assault, being kidnapped or taken hostage and terrorist attacks. Initial data suggests that 1 out of 6 Iraq War veterans are exhibiting symptoms of depression, anxiety and PTSD. Virtual Reality (VR) exposure treatment has been used in previous treatments of PTSD patients with reports of positive outcomes. The aim of the current paper is to present the rationale, technical specifications, application features and user-centered design process for the development of a Virtual Iraq PTSD VR therapy application. The VR treatment environment is being created via the recycling of virtual graphic assets that were initially built for the U.S. Army-funded combat tactical simulation scenario and commercially successful X-Box game, Full Spectrum Warrior, in addition to other available and newly created assets. Thus far we have created a series of customizable virtual scenarios designed to represent relevant contexts for exposure therapy to be conducted in VR, including a city and desert road convoy environment. User-Centered tests with the application are currently underway at the Naval Medical Center-San Diego and within an Army Combat Stress Control Team in Iraq with clinical trials scheduled to commence in February 2006.","","Pair J,Allen B,Dautricourt M,Treskunov A,Liewer M,Graap K,Reger G","","2006","62–72","10.1109/VR.2006.23","https://doi-org.proxy.bnl.lu/10.1109/VR.2006.23;http://dx.doi.org/10.1109/VR.2006.23","Conference Paper"
"A Visual Analytics Framework for Spatiotemporal Trade Network Analysis","Economic globalization is increasing connectedness among regions of the world, creating complex interdependencies within various supply chains. Recent studies have indicated that changes and disruptions within such networks can serve as indicators for increased risks of violence and armed conflicts. This is especially true of countries that may not be able to compete for scarce commodities during supply shocks. Thus, network-induced vulnerability to supply disruption is typically exported from wealthier populations to disadvantaged populations. As such, researchers and stakeholders concerned with supply chains, political science, environmental studies, etc. need tools to explore the complex dynamics within global trade networks and how the structure of these networks relates to regional instability. However, the multivariate, spatiotemporal nature of the network structure creates a bottleneck in the extraction and analysis of correlations and anomalies for exploratory data analysis and hypothesis generation. Working closely with experts in political science and sustainability, we have developed a highly coordinated, multi-view framework that utilizes anomaly detection, network analytics, and spatiotemporal visualization methods for exploring the relationship between global trade networks and regional instability. Requirements for analysis and initial research questions to be investigated are elicited from domain experts, and a variety of visual encoding techniques for rapid assessment of analysis and correlations between trade goods, network patterns, and time series signatures are explored. We demonstrate the application of our framework through case studies focusing on armed conflicts in Africa, regional instability measures, and their relationship to international global trade.","","Wang H,Lu Y,Shutters ST,Steptoe M,Wang F,Landis S,Maciejewski R","","2019","331–341","10.1109/TVCG.2018.2864844","https://doi-org.proxy.bnl.lu/10.1109/TVCG.2018.2864844;http://dx.doi.org/10.1109/TVCG.2018.2864844","Journal Article"
"A Voice in the Crowd: Broader Implications for Crowdsourcing Translation during Crisis","Both international non-governmental organizations and government actors have embraced the technological union of humans and software, known as crowdsourcing, to manage the flood of information produced during recent crises. However, unlike a business solution, the task of translation is unique during a crisis situation; the costs are human, and the impact is social and political. This paper follows four crises in which different crowdsourcing applications were developed by a range of actors. In each instance, the design approach failed to incorporate the unique circumstances of the conflict context, resulting in a translation application that removed authorship, dissolved intentionality, and shed contextual markers from original sources. This flawed application prevented the original contributors from interacting with the information directly related to their own life-threatening situation, and the information it amassed formed an unsound basis for decision-making by international actors. The associated consequences during: post-earthquake Haiti 2010, Libya and Egypt 2011 and Somalia 2011/12 are intended to provoke process improvement among all stakeholders.","","Sutherlin G","","2013","397–409","10.1177/0165551512471593","https://doi-org.proxy.bnl.lu/10.1177/0165551512471593;http://dx.doi.org/10.1177/0165551512471593","Journal Article"
"Accelerating Public Service Delivery in India: Application of Internet of Things and Artificial Intelligence in Agriculture","The application of Information and Communication Technologies (ICTs) in the public sector can usher performance enhancement, productivity and social equity in public service delivery mechanisms. More specifically, emerging digital technologies including Artificial Intelligence (AI) can be employed for more effective retrieval and analysis of complex, real-time data that could also be captured and shared by devices supporting Internet of Things. Literature asserts that governments worldwide must adopt solutions offered by these emerging technologies to drive innovation in public service delivery mechanisms. Appreciating these claims, this study aims to explore the current and potential use of IoT and AI. Based on the related review of literature, the study puts forth a conceptual framework for creating an open and integrated national level agriculture stack (christened as KisanOne by the authors) so that developing countries like India can effectively espouse data driven approach in its agriculture sector. ""Kisan One"" combines varied aspects of a farmers' activities including weather forecast, soil health indices, seed procurement cycle, sowing cycles, details of fertilizers availability, crop prices, etc, in a unified national stack that is accessible to all the stakeholders using application programming interfaces (APIs). Needless to say, the proposed KisanOne is a utopian implementation where existing and contemporary digital initiatives get unified on a single platform.Datasets themselves have little intrinsic value sans any ability to extract meaning from it. Intelligent data analytics could be employed on real time datasets of KisanOne both for evidence based decision making as well as for malicious intent. This paper, therefore, attempts to offer an insight into such challenges as well as suggest policy recommendations that could strengthen existing regulatory mechanisms for effective implementation of IoT and AI in existing public service delivery schemes of India. The paper is divided into four broad sections. The first section builds the Background of the paper. The next section is divided into four subsections and in this section instance of Agriculture has been detailed with reference to its current scenario and prevailing solutions. India has started using technology in Agriculture to a great extent- some of these applications such as Kisan Suvidha2 mobile app, mKisan SMS Portal, Farmer's Portal, Soil Health Card, Fertilizer Monitoring System(FMS) software, Agrimarket App have been delineated in the study. A use case on transformation of agriculture sector using IoT and AI is also presented in one of the sub-sections. A National Level Integrated Agriculture Stack is also proposed in this paper. The subsequent section presents brief picture of key challenges of implementing IoT and AI in Agriculture sector followed by recommendations and Consulive Remarks. It is an innovative and descriptive study that primarily relies on secondary data gleaned from international/national journals, reports of Ministry of Electronics and Information Technology, Government of India and other online academic sources coupled with creative out-of-box thinking to propose the application of IoT and AI in varied public sectors with special emphasis on Agriculture.","","Malhotra C,Anand R","","2020","62–69","10.1145/3428502.3428510","https://doi-org.proxy.bnl.lu/10.1145/3428502.3428510;http://dx.doi.org/10.1145/3428502.3428510","Conference Paper"
"Accidental Infrastructure for Groundwater Monitoring in Africa","A data deficit in shallow groundwater monitoring in Africa exists despite one million handpumps being used by 200 million people every day. Recent advances with smart handpumps have provided accelerometry data sent automatically by SMS from transmitters inserted in handles to estimate hourly water usage. Exploiting the high-frequency noise in handpump accelerometry data, we model high-rate wave forms using robust machine learning techniques sensitive to the subtle interaction between pumping action and groundwater depth. We compare three methods for representing accelerometry data (wavelets, splines, Gaussian processes) with two systems for estimating groundwater depth (support vector regression, Gaussian process regression), and apply three systems to evaluate the results (held-out periods, held-out recordings, balanced datasets). Results indicate that the method using splines and support vector regression provides the lowest overall errors. We discuss further testing and the potential of using Africa's accidental infrastructure to harmonise groundwater monitoring systems with rural water-security goals. A data deficit exists in shallow groundwater monitoring in Africa.Our smart handpump has low-cost accelerometers mounted in the handle.We show that machine learning methods applied to the accelerometry can estimate aquifer depth.We demonstrate that we can use the accidental infrastructure of handpumps for estimating groundwater levels.","","Colchester FE,Marais HG,Thomson P,Hope R,Clifton DA","","2017","241–250","10.1016/j.envsoft.2017.01.026","https://doi-org.proxy.bnl.lu/10.1016/j.envsoft.2017.01.026;http://dx.doi.org/10.1016/j.envsoft.2017.01.026","Journal Article"
"Adaptability of Backcasting for Sustainable Development: A Case Study from Nepal","To cope with problems like climate change, lack of food security, and poverty, a more reasonable use of existing resources is needed. Hence, a transition towards a sustainable behavior in the industrial as well as the developing countries is of core importance. Transition management and backcasting are two methodologies that have been developed mainly in the Netherlands to achieve this behavioral change. This paper examines in a case study, in a small village in the mid-hills of Nepal, whether these methodologies are also applicable in a developing country. Moreover it analyzes which adjustments are needed to achieve good outcomes. First results show that this methodology seems to be appropriate to trigger a change in thinking towards long-term considerations amongst the small scale farmers. Long-range thinking and future envisioning can stimulate investments in technologies that tend to be sustainable and guarantee a more stable return in the long run. Compared to programs in Europe, instructors should adjust time frame and workshop design.","","Wieners E,Neuburger M,Schickhoff U","","2015","16–27","10.4018/ijabim.2015070102","https://doi-org.proxy.bnl.lu/10.4018/ijabim.2015070102;http://dx.doi.org/10.4018/ijabim.2015070102","Journal Article"
"Agent-Based Simulation of Local Soy Value Chains in Ghana","The assessment of changes in the relationships between supply chain agents is considered fundamental for market transformation. This paper reports on the application of a Value Chain Lab that supports the measurement of behavioral change in vertically structured supply-chain relationships. A participative gaming approach is used that enables to identify changes in mutual trust, transaction costs and risk behavior that result from value chain support and co-operation. The Value Chain Lab comprises value chain analysis, value chain games and multi-agent simulation. The paper describes the multi-agent simulation of a soy value chain in northern Ghana. The research was conducted in the context of the 2SCALE program, aiming to improve rural livelihoods and food and nutrition security in a number of African countries by developing agricultural supply chains including local smallholder farmers. The study confirms the positive effects of trust and loyalty in value chain relationships. Furthermore, it demonstrates the usefulness of agent-based simulations for exploring potential consequences of alternative interventions.","","Verwaart T,Dijkxhoorn Y,Plaisier C,van Wagenberg C","","2019","654–666","10.1007/978-3-030-30244-3_54","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-30244-3_54;http://dx.doi.org/10.1007/978-3-030-30244-3_54","Conference Paper"
"Algorithms for Enhancing Satellite Imagery to Discover Archaeological Finds Covered by Shadow","Very high-resolution (VHR) images proved to be an invaluable source of information even in the archaeological domain, but sometimes shadows hinder their full exploitation. To overcome such limitation, this research proposes a workflow able to analyze shadowed zones, by processing Pléiades and World-View 2 images. The case study is the archaeological site of Maltai, in the Iraqi Kurdistan Region, which presents shadowed areas to be detected. Applying de-shadowing workflow has been tested over multispectral and panchromatic images, with different invariant color spaces. The proposed methods exploit the techniques of automatic thresholding and spectral ratio in the detection of shadow regions. This approach shows a clustering of shadow pixels for an enhanced images visualization and proves its suitability for archaeological settings.","","Chiappini S,Di Stefano F,Malinverni ES,Pierdicca R","","2020","664–673","10.1007/978-3-030-58814-4_53","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-58814-4_53;http://dx.doi.org/10.1007/978-3-030-58814-4_53","Conference Paper"
"Aluminum Foil Satellite Dishes and a Millennium of Experience: Sustainability in the High Andes","This address will describe an ICT research project that is context specific and achieved economic and social turnarounds where other ICT projects have failed. The message for computer science educators and professionals is that desired impact has less to do with science and technology and more to do with understanding context and culture. Evaluating implementation options to advance educational and social needs is applying intelligence to technology. Technology without context is a chasm.Literature on contextual relevance such as Habermas, Friere, Husserl, Gadamer, Borgman, abounds. However the absence of minorities in our computer classes, the overarching business use of technology to automate historic processes and the obsession with development of new technologies in the abstract without considering their applications indicate that our profession is slow to grasp this.The ancient Incan culture, through the Quechuan people of Antabamba Peru, a remote indigenous society high in the Andean Mountains has over 700 years of proven social, environmental and economically sustainable practice. Until only 10 years ago Antabamba was a time capsule which was isolated from the world by several days walk from the nearest road. When the road was built in 1995 the multinational products, television, marketing and western philosophies of business practice soon followed. Within 10 years the population of Antabamba was worse off than in anytime in the previous 700 years and risked losing what the developed world is in search of, sustainable practice.Starting in 2003 the Unitec project spent a year learning what had underpinned this ancient culture. Yesterdays wireless technologies, internet, web design, No. 8 wire, aluminum foil satellite dishes and some basic tools were grounded in the traditional Incan methodologies of sharing, learning and understanding. Unparalleled results were achieved. Together with the local communities, the Unitec project developed a methodology called ""Community Centric Empowerment"" (CCE) which has been attributed by OSIPTEL, the Telecommunications Authority in Peru and the Latin American telecommunication council representative as the deciding factor that has separated this project from other ""telecenter"" projects in Latin America. Additional studies focusing on the ability of ICT to reduce poverty and exploitation in third world countries by FITEL, the Rural development wing of OSIPTEL in Peru, support the notion of the importance of how, rather than what, when it comes to ICT use for poverty reduction (Bossio 2005) (Newman 2006). These studies showed the usage patterns and impact of the Unitec project to be quite distinctive compared with any other poverty alleviation project using ICT.In keeping with the phenomenological methodology of the initial study, this address will describe the story of the Peruvian project to demonstrate to ICT educators and professionals that how we implement ICT is as important as what we implement, when social and economic sustainability are our objectives. It lays down a challenge to ICT educators and professionals to reconsider the priorities in our teachings and philosophies.","","Young A,Muller L","","2006","2","10.1145/1140124.1140126","https://doi-org.proxy.bnl.lu/10.1145/1140124.1140126;http://dx.doi.org/10.1145/1140124.1140126","Conference Paper"
"An Android-Based Application for Convenient Visitation at Windhoek Correctional Facility","A global outbreak of Coronavirus affected countries' economy, people's lives and businesses around the world due to lockdown restrictions imposed on everyday activities. Like elsewhere, logistics and visiting hours to correctional facilities in Namibia is no exception. Namibian correctional facilities are far located in remote areas, hence, visitation to these facilities tends to be cumbersome, time-consuming, costly and at times disappointing due to the lack of accurate and timely information. Also, the rate of imprisonment quadrupled due to unfortunate acts during the lockdown. In response to this challenges, authors of this paper developed an android-based application to support social distancing, help Namibians in locating their relatives and friends in Namibian rehabilitation centers and reduce recidivism while improving the morale and safety of inmates and workers amid the pandemic. This study adopted a mixed research methodology with a case study and an experimental as a research design. An Agile software development model has been used for the development of an application. Primary data were collected through open-ended questionnaires, direct observations in the prison and group interviews. The study has been also chiefly informed by related literature reviews, as secondary data. A simple random sampling technique has been used to select the respondents from a target population of thirty participants. The study concluded that the application developed was intelligent, innovative, helpful, easy and convenient to use. Mobile technology can drastically change how we can communicate. It has been recommended that the Ministry of Home Affairs, Safety and Security consider funding and fully implement this project in all thirteen correctional facilities across the country. As part of future work, a similar version of iOS is to be developed and possibly implement a remote and/or onsite Inmate video visitation.","","Haiduwa T,Hashiyana V,Samuel JN","","2020","","10.1145/3415088.3415127","https://doi-org.proxy.bnl.lu/10.1145/3415088.3415127;http://dx.doi.org/10.1145/3415088.3415127","Conference Paper"
"An Exploratory Study on Policy Transfer for SIM Card Registration in Malawi","Majority of African countries have adopted policies for mandatory Subscriber Identifiable Module SIM card registration to mitigate security threats to citizens and society. However, there are few countries that have not yet adopted the mandatory SIM card registration policies. This study investigated the means through which SIM card registration policy may be transferred in countries without the policy. The context of Malawi was analysed which represented an ideal case of an African country without mandatory SIM card registration policy. The findings showed that the mandatory SIM card registration policy may be transferred through: a voluntary transfer to address local challenges related to mobile technologies b coercive transfer in response to meet international agreements. However, lack of national identification documents for mobile phone users and delays in implementing legal framework affected the transfer of the mandatory SIM Card registration in Malawi. It will be necessary to consider of social, economic and political factors when adopting the mandatory SIM card registration policy.","","Makoza F","","2015","33–45","10.4018/IJTD.2015010102","https://doi-org.proxy.bnl.lu/10.4018/IJTD.2015010102;http://dx.doi.org/10.4018/IJTD.2015010102","Journal Article"
"An Improved Fast Correlation Attack on Stream Ciphers","At Crypto'2000, Johansson and Jönsson proposed a fast correlation attack on stream ciphers based on the Goldreich-Rubinfeld-Sudan algorithm. In this paper we show that a combination of their approach with techniques for substituting keystream and evaluating parity-checks gives us the most efficient fast correlation attack known so far. An application of the new algorithm results in the first-known near-practical key recovery attack on the shrinking generator with the parameters suggested by Krawczyk in 1994, which was verified in the 40-bit data LFSR case for which the only previously known efficient attacks were distinguishing attacks.","","Zhang B,Feng D","","2009","214–227","","https://doi-org.proxy.bnl.lu/10.1007/978-3-642-04159-4_14","Book Chapter"
"An Integrated Mobile Veld Fire Detection and Sharing Platform for Southern Africa","While there are clear efforts towards managing veld fires, it comes as a concern that in Southern Africa, the role of local communities in fire control has weakened and veld fires have grown to be a major threat. Current systems and technologies to share veld fire information have several challenges. These include; being unable to detect burning fires in the forests, poor to almost missing veld fire local alerting systems, and malfunctioning local veld firefighting communities. Against this background, a mobile veld fire detection and sharing application prototype was developed using a qualitative data approach and experimental design. Weather data and scientific models of different areas were used to create fire-danger indices based on forecasted weather data and weather station information on the ground. These were programmed into the system to trigger alerts for the veld fire prediction component. For the identification of already burning fires, this was linked to the MODIS system of firefighting stakeholders (EMA Zimbabwe). Results revealed that conditions that promote veld fires can be predicted and local residents can thus be warned instantly to avoid activities that cause fires. For already burning fires, the mobile application was able to instantly communicate to users registered to the system.","","Jere NR,Scott MS,Taruvinga A","","2017","","10.1145/3129416.3129439","https://doi-org.proxy.bnl.lu/10.1145/3129416.3129439;http://dx.doi.org/10.1145/3129416.3129439","Conference Paper"
"An Intelligent Handcrafted Feature Selection Using Archimedes Optimization Algorithm for Facial Analysis","Human facial analysis (HFA) has recently become an attractive topic for computer vision research due to technological progress and mobile applications. HFA explores several issues as gender recognition (GR), facial expression, age, and race recognition for automatically understanding social life. This study explores HFA from the angle of recognizing a person’s gender from their face. Several hard challenges are provoked, such as illumination, occlusion, facial emotions, quality, and angle of capture by cameras, making gender recognition more difficult for machines. The Archimedes optimization algorithm (AOA) was recently designed as a metaheuristic-based population optimization method, inspired by the Archimedes theory’s physical notion. Compared to other swarm algorithms in the realm of optimization, this method promotes a good balance between exploration and exploitation. The convergence area is increased By incorporating extra data into the solution, such as volume and density. Because of the preceding benefits of AOA and the fact that it has not been used to choose the best area of the face, we propose utilizing a wrapper feature selection technique, which is a real motivation in the field of computer vision and machine learning. The paper’s primary purpose is to automatically determine the optimal face area using AOA to recognize the gender of a human person categorized by two classes (Men and women). In this paper, the facial image is divided into several subregions (blocks), where each area provides a vector of characteristics using one method from handcrafted techniques as the local binary pattern (LBP), histogram-oriented gradient (HOG), or gray-level co-occurrence matrix (GLCM). Two experiments assess the proposed method (AOA): The first employs two benchmarking datasets: the Georgia Tech Face dataset (GT) and the Brazilian FEI dataset. The second experiment represents a more challenging large dataset that uses Gallagher’s uncontrolled dataset. The experimental results show the good performance of AOA compared to other recent and competitive optimizers for all datasets. In terms of accuracy, the AOA-based LBP outperforms the state-of-the-art deep convolutional neural network (CNN) with 96.08% for the Gallagher’s dataset.","","Neggaz I,Fizazi H","","2022","10435–10464","10.1007/s00500-022-06886-3","https://doi-org.proxy.bnl.lu/10.1007/s00500-022-06886-3;http://dx.doi.org/10.1007/s00500-022-06886-3","Journal Article"
"Analysis of Appropriate Standards to Solve Cybersecurity Problems in Public Organizations","The development of ICTs in the globalized world has forced countries to develop problems or implement affected problems because new vulnerabilities have always been presented every day, so not having implemented a standard security standard brings problems such as data theft, leaks, malicious software among others. The objective of this investigative work is to analyze the cybersecurity analyzes that are used in public organizations in the Republic of Ecuador, for this purpose, a search was made of the different national and international security controls in order to compare them and by their similarities determine the security guidelines that are used in public organizations and any that apply. The deductive and exploratory method was used for the development of this research, it resulted in the analysis of EGSI data and after analyzing the percentage of initial and final compliance, it was concluded that the cybersecurity sensors in public organizations were low and are currently can be considered as means, since even the assessment does not incorporate all the international security parameters.","","Toapanta SM,E. GS,Gallegos LE","","2020","14–19","10.1145/3404663.3404678","https://doi-org.proxy.bnl.lu/10.1145/3404663.3404678;http://dx.doi.org/10.1145/3404663.3404678","Conference Paper"
"Analysis of Cybersecurity Models Suitable to Apply in an Electoral Process in Ecuador","Were analyzed different cybersecurity proposals to protect information, such as models, prototypes, approaches, frameworks, algorithms and evaluations. The problem is the lack of application of cybersecurity to electoral processes in Ecuador. The objective is to make an appropriate cybersecurity model to apply in an electoral process in Ecuador. The quantitative, descriptive, deductive reasoning was used to analyze the reference documents. It turned out a Conceptual Cybersecurity Model, a Cybersecurity Algorithm and a General Risk Formula. It was concluded that the model strengthens information security in the electoral process and asset risk assessment prioritizes the attention of vulnerabilities.","","Toapanta SM,Armijos MA,Gallegos LE","","2020","84–90","10.1145/3375900.3375912","https://doi-org.proxy.bnl.lu/10.1145/3375900.3375912;http://dx.doi.org/10.1145/3375900.3375912","Conference Paper"
"Application of Remote Sensing in Estimating Maize Grain Yield in Heterogeneous African Agricultural Landscapes: A Review","Maize Zea mays L. is the second most commonly grown crop worldwide and number one staple food in Africa where it accounts for more than 50% of the energy requirements. However, despite its widespread cultivation and the significance of maize information in Africa, maize crop maps and yield forecasts are hardly available. Yet, systematic area, spatial distribution, and maize yield estimates are important in understanding and addressing food security in Africa. Objective monitoring of maize yield statisics in a systematic way is possible with remotely sensed data. However, absence of maize yield forecasts using remote sensing in Africa has been attributed to the cost of acquiring satellite imagery and the heterogeneity of agricultural landscapes. The recent advances in sensors technology and availability of free high-resolution spatial and temporal multispectral satellite images afford an opportunity to forecast maize yield as well as mapping its spatial distribution in near real-time basis. This review gives an overview of maize yield estimation using remotely sensed information and its potential application in a fragmented and highly granular agricultural landscapes in Africa, including inherent challenges and research needs. The review was motivated by challenges faced by researchers and national agricultural statistical services agents when forecasting maize yield using conventional ground-based survey methods. These problems include, but are not limited to, restricted accuracy, and cost and time spent resulting in missed opportunities in food security early warning systems and proper developmental interventions. We conclude that by picking multispectral sensors with high spatial, temporal, and spectral resolution, as well as appropriate classification techniques and accurate ground-truthing data, remote sensing can be a practical option for estimating maize grain yield and its spatio-temporal dynamics in heterogeneous African agricultural landscapes for designing appropriate developmental interventions and technological out scaling.","","Chivasa W,Mutanga O,Biradar C","","2017","6816–6845","","","Journal Article"
"Applications of Bayesian Belief Networks in Water Resource Management","Bayesian belief networks (BBNs) are probabilistic graphical models that can capture and integrate both quantitative and qualitative data, thus accommodating data-limited conditions. This paper systematically reviews applications of BBNs with respect to spatial factors, water domains, and the consideration of climate change impacts. The methods used for constructing and validating BBN models, and their applications in different forms of decision-making support are examined. Most reviewed publications originate from developed countries (70%), in temperate climate zones (42%), and focus mainly on water quality (42%). In 60% of the reviewed applications model validation was based on the expert or stakeholder evaluation and sensitivity analysis, and whilst in 27% model performance was not discussed. Most reviewed articles applied BBNs in strategic decision-making contexts (52%). Integrated modelling tools for addressing challenges of dynamically complex systems were also reviewed by analysing the strengths and weaknesses of BBNs, and integration of BBNs with other modelling tools. The application of BBNs to water resource management was rarely applied in developing countries and in tropical regions.Only 8% reviewed papers explored potential impacts of climate change on water resources.Only 11% and 6% of reviewed articles applied influence diagrams and Object-Oriented Bayesian Networks respectively.Most reviewed articles applied BBNs in strategic decision-making contexts (52%) for water resource management.Results from BBN models were rarely compared or tested against other modelling approaches to validate their performance.","","Phan TD,Smart JC,Capon SJ,Hadwen WL,Sahin O","","2016","98–111","10.1016/j.envsoft.2016.08.006","https://doi-org.proxy.bnl.lu/10.1016/j.envsoft.2016.08.006;http://dx.doi.org/10.1016/j.envsoft.2016.08.006","Journal Article"
"Appropriate Security Algorithms to Mitigate the Risks in a Database of the National Customs Service of Ecuador","Currently, the use of technological resources, within public and private institutions, has become essential, due to the need to modernize processes, high commercial needs and mandatory continuous improvement. A problem has been observed at the national level, in relation to the ease with which the databases of natural or legal persons are accessed, which has motivated them to provide the respective security measures. For this reason, a study has been carried out on the security measures of the database of the National Customs Service of Ecuador, with a quantitative methodology which allowed to know, objectively, what are the different security measures that must be implemented to improve the operations with the utmost care. In addition, a qualitative analysis of the revised texts was carried out to minimize the threats and vulnerabilities present in security systems. The objective of this study was to establish adequate security algorithms to mitigate risks in a database of the National Customs Service of Ecuador, which has been working, since 2007, on risk management, training personnel, following strategies international and implementing technological aspects to systematize the processes that until then were mainly carried out physically. The need for the institution to take care of its database was evident, applying HASH computer security measures that reduce or eliminate computer thefts, with encrypted algorithms, training of personnel throughout the process and articles of the law that allow the use of adequate mechanisms for the care and protection of information, as appropriate.","","Toapanta SM,Astudillo KL,Gallegos LE","","2020","89–95","10.1145/3404663.3404669","https://doi-org.proxy.bnl.lu/10.1145/3404663.3404669;http://dx.doi.org/10.1145/3404663.3404669","Conference Paper"
"Architectural Choices for MHealth Services in Finland and Cameroon","In the developed world health care sector has used for tens of years information systems in their daily activities. Soon after the Internet usage began to spread to the societies mid 1990'ies the sector began to ponder how to offer services over the web to patients. The USA and the EU began to discuss eHealth scenarios, and many services are now offered, including appointments to doctors and nurses, virtual doctors, and electronic prescriptions. Electronic patient records are widely utilized could also be retrieved by patients and other health care personnel, but due to technical, organizational and legal restrictions this is not yet reality. Mobile networks and high-end mobile terminals are as powerful as laptops were a few years ago and could be used to access and store pertinent health information. In this article we discuss architectural choices that would facilitate the usage of the collected personal health care information, and their pros and cons. We mainly base our findings on the situation in Finland. We contrast, though, the findings with the situation in Cameroon, where the ICT infrastructure is weak and the ICT infrastructure in the health care could more strongly rely on mobile networks and emerging smart terminals.","","Veijalainen J,Hara V,Bisong B","","2011","46–51","10.1109/MDM.2011.32","https://doi-org.proxy.bnl.lu/10.1109/MDM.2011.32;http://dx.doi.org/10.1109/MDM.2011.32","Conference Paper"
"Assessing the SMEs' Competitive Strategies on the Impact of Environmental Factors: A Quantitative SWOT Analysis Application","Strength, Weakness, Opportunity and Threat (SWOT) analysis is an established methodology for assisting the formulation of strategy. This paper proposes a new quantified SWOT analytic method incorporated with the vote-ranking method. The indices of SWOT are voted, weighted and quantified to assess the competitive strategy, from top to the bottom, meanwhile the total weighted scores method will be used to get the best strategy alternatives. The competitive strategies of the Taiwanese Small and Medium Enterprises (SMEs) in the Environmental Management Systems (EMS) are taken as a case study, where eighteen certificated ISO9000 or ISO14000 auditors (or lead auditors) are invited to establish a decision group. Under the impact of environmental factors, the results show that company's image and profitability is the most important strategy for SMEs within the global markets. Lastly, Taiwanese SMEs apperceive the significance of EMS and also recognize the importance to survive within the diversified competing market environment, whereas they need to build up its environmental management that has to suit the EMS specification and attention. The findings are also applicable for other developing countries within the global markets or barriers.","","Hai HL","","2008","1701–1710","","","Journal Article"
"Attributing Authors of Emirati Tweets","Electronic text Author Attribution (AA) is a well known stylometry problem that attempts to infer the identity of authors of disputed electronic texts by solely analyzing the texts. This is important for various applications such as forensics and market analysis. However, currently the state of the art in author identification has never been evaluated against Emirati social media electronic texts. This is partly due to the fact that no evaluation dataset exists that is suitable for evaluating author identification methods in the domain of Emirati social media electronic texts. This paper presents the first of such evaluations, along with the release of the Khonji-Iraqi Emirati Tweets author identification evaluation dataset with 30 authors (KIT30). Additionally, novel definitions of grams are introduced, namely compound grams, which demonstrate that decision models that make use of them can achieve higher classification accuracies than the alternative case when classical definitions of grams are followed. The findings also indicate that, when suitable data representation is used, the degradation in the classification accuracy, as the space of suspect authors increases, is not necessarily as sharp as previously reported in the literature. This suggests that AA problem solvers can be significantly more scalable as previously evaluated.","","Khonji M,Iraqi Y","","2018","206–212","10.1109/GLOCOM.2018.8647952","https://doi-org.proxy.bnl.lu/10.1109/GLOCOM.2018.8647952;http://dx.doi.org/10.1109/GLOCOM.2018.8647952","Conference Paper"
"Augmented Reality Based Smart City Services Using Secure IoT Infrastructure","This paper presents an application of Augmented Reality (AR) within a smart city service to be deployed in the domain of public transport in the city of Novi Sad in Serbia. The described solution is focused on providing a simple and efficient method to citizens for accessing important information such as bus arrival times, bus routes and tourist landmarks using smart phones and AR technology. The AR information is triggered by image and geo-location markers and the data is provided via secure IoT infrastructure. The IoT infrastructure is based on bus-mounted IoT devices which utilize secure CoAP software protocol to transmit the data to the associated cloud servers. Description of the complete end-to-end solution is presented, providing the overall system set-up, user experience aspects and the security of the overall system, focusing on the lightweight encryption used within the low-powered IoT devices.","","Pokric B,Krco S,Pokric M","","2014","803–808","10.1109/WAINA.2014.127","https://doi-org.proxy.bnl.lu/10.1109/WAINA.2014.127;http://dx.doi.org/10.1109/WAINA.2014.127","Conference Paper"
"Author Profiling on Bi-Lingual Tweets","The task of author profiling aims to distinguish the author’s profile traits from a given content. It has got potential applications in marketing, forensic analysis, fake profile detection, etc. In recent years, the usage of bi-lingual text has raised due to the global reach of social media tools as people prefer to use language that expresses their true feelings during online conversations and assessments. It has likewise impacted the use of bi-lingual (English and Roman-Urdu) text in the sub-continent (Pakistan, India, and Bangladesh) over social media. To develop and evaluate methods for bi-lingual author profiling, benchmark corpora are needed. The majority of previous efforts have focused on developing mono-lingual author profiling corpora for English and other languages. To fulfill this gap, this study aims to explore the problem of author profiling on bi-lingual data and presents a benchmark corpus of bi-lingual (English and Roman-Urdu) tweets. Our proposed corpus contains 339 author profiles and each profile is annotated with six different traits including age, gender, education level, province, language, and political party. As a secondary contribution, a range of deep learning methods, CNN, LSTM, Bi-LSTM, and GRU, are applied and compared on the three different bi-lingual corpora for age and gender identification, including our proposed corpus. Our extensive experimentation showed that the best results for both gender identification task (Accuracy = 0.882, F1-Measure = 0.839) and age identification (Accuracy = 0.735, F1-Measure = 0.739) are obtained using Bi-LSTM deep learning method. Our proposed bi-lingual tweets corpus is free and publicly available for research purposes.","","Ashraf MA,Nawab RM,Nie F,Pinto D,Singh V,Perez F","","2020","2379–2389","10.3233/JIFS-179898","https://doi-org.proxy.bnl.lu/10.3233/JIFS-179898;http://dx.doi.org/10.3233/JIFS-179898","Journal Article"
"Automated Generation of Counterterrorism Policies Using Multiexpert Input","The use of game theory to model conflict has been studied by several researchers, spearheaded by Schelling. Most of these efforts assume a single payoff matrix that captures players’ utilities under different assumptions about what the players will do. Our experience in counterterrorism applications is that experts disagree on these payoffs. We leverage Shapley’s notion of vector equilibria, which formulates games where there are multiple payoff matrices, but note that they are very hard to compute in practice. To effectively enumerate large numbers of equilibria with payoffs provided by multiple experts, we propose a novel combination of vector payoffs and well-supported ϵ-approximate equilibria. We develop bounds related to computation of these equilibria for some special cases and give a quasipolynomial time approximation scheme (QPTAS) for the general case when the number of players is small (which is true in many real-world applications). Leveraging this QPTAS, we give efficient algorithms to find such equilibria and experimental results showing that they work well on simulated data.We then built a policy recommendation engine based on vector equilibria, called PREVE. We use PREVE to model the terrorist group Lashkar-e-Taiba (LeT), responsible for the 2008 Mumbai attacks, as a five-player game. Specifically, we apply it to three payoff matrices provided by experts in India--Pakistan relations, analyze the equilibria generated by PREVE, and suggest counterterrorism policies that may reduce attacks by LeT. We briefly discuss these results and identify their strengths and weaknesses from a policy point of view.","","Sawant A,Dickerson JP,Hajiaghayi MT,Subrahmanian VS","","2015","","10.1145/2716328","https://doi-org.proxy.bnl.lu/10.1145/2716328;http://dx.doi.org/10.1145/2716328","Journal Article"
"Automatic Detection and Compression for Passive Acoustic Monitoring of the African Forest Elephant","In this work, we consider applying machine learning to the analysis and compression of audio signals in the context of monitoring elephants in sub-Saharan Africa. Earth's biodiversity is increasingly under threat by sources of anthropogenic change (e.g. resource extraction, land use change, and climate change) and surveying animal populations is critical for developing conservation strategies. However, manually monitoring tropical forests or deep oceans is intractable. For species that communicate acoustically, researchers have argued for placing audio recorders in the habitats as a cost-effective and non-invasive method, a strategy known as passive acoustic monitoring (PAM). In collaboration with conservation efforts, we construct a large labeled dataset of passive acoustic recordings of the African Forest Elephant via crowdsourcing, compromising thousands of hours of recordings in the wild. Using state-of-the-art techniques in artificial intelligence we improve upon previously proposed methods for passive acoustic monitoring for classification and segmentation. In real-time detection of elephant calls, network bandwidth quickly becomes a bottleneck and efficient ways to compress the data are needed. Most audio compression schemes are aimed at human listeners and are unsuitable for low-frequency elephant calls. To remedy this, we provide a novel end-to-end differentiable method for compression of audio signals that can be adapted to acoustic monitoring of any species and dramatically improves over näive coding strategies.","","Bjorck J,Rappazzo BH,Chen D,Bernstein R,Wrege PH,Gomes CP","","2019","","10.1609/aaai.v33i01.3301476","https://doi-org.proxy.bnl.lu/10.1609/aaai.v33i01.3301476;http://dx.doi.org/10.1609/aaai.v33i01.3301476","Conference Paper"
"Automatic Expandable Large-Scale Sentiment Lexicon of Modern Standard Arabic and Colloquial","In subjectivity and sentiment analysis (SSA), there are two main requirements are necessary to improve sentiment analysis effectively in any language and genres, first, high coverage sentiment lexicon - where entries are tagged with semantic orientation (positive, negative and neutral) - second, tagged corpora to train the sentiment classifier. Much of research has been conducted in this area during the last decade, but the need of building these resources is still ongoing, especially for morphologically-Rich language (MRL) such as Arabic. In this paper, we present an automatic expandable wide coverage polarity lexicon of Arabic sentiment words, this lexical resource explicitly devised for supporting Arabic sentiment classification and opinion mining applications. The lexicon is built using a seed of gold-standard Arabic sentiment words which are manually collected and annotated with semantic orientation (positive or negative), and automatically expanded with sentiment orientation detection of the new sentiment words by exploiting some lexical information such as part-of-speech (POS) tags and using synset aggregation techniques from free online Arabic lexicons, thesauruses. We report efforts to expand a manually-built our polarity lexicon using different types of data. Finally, we used various tagged data to evaluate the coverage and quality of our polarity lexicon, moreover, to evaluate the lexicon expansion and its effects on the sentiment analysis accuracy. Our data focus on modern standard Arabic (MSA) and Egyptian dialectal Arabic tweets and Arabic microblogs (hotel reservation, product reviews, and TV program comments).","","Ibrahim HS,Abdou SM,Gheith M","","2015","94–99","10.1109/ACLing.2015.20","https://doi-org.proxy.bnl.lu/10.1109/ACLing.2015.20;http://dx.doi.org/10.1109/ACLing.2015.20","Conference Paper"
"Batched Gauss-Jordan Elimination for Block-Jacobi Preconditioner Generation on GPUs","In this paper, we design and evaluate a routine for the efficient generation of block-Jacobi preconditioners on graphics processing units (GPUs). Concretely, to exploit the architecture of the graphics accelerator, we develop a batched Gauss-Jordan elimination CUDA kernel for matrix inversion that embeds an implicit pivoting technique and handles the entire inversion process in the GPU registers. In addition, we integrate extraction and insertion CUDA kernels to rapidly set up the block-Jacobi preconditioner.Our experiments compare the performance of our implementation against a sequence of batched routines from the MAGMA library realizing the inversion via the LU factorization with partial pivoting. Furthermore, we evaluate the costs of different strategies for the block-Jacobi extraction and insertion steps, using a variety of sparse matrices from the SuiteSparse matrix collection. Finally, we assess the efficiency of the complete block-Jacobi preconditioner generation in the context of an iterative solver applied to a set of computational science problems, and quantify its benefits over a scalar Jacobi preconditioner.","","Anzt H,Dongarra J,Flegar G,Quintana-Ortí ES","","2017","1–10","10.1145/3026937.3026940","https://doi-org.proxy.bnl.lu/10.1145/3026937.3026940;http://dx.doi.org/10.1145/3026937.3026940","Conference Paper"
"Beyond the Baseline: Establishing the Value in Mobile Phone Based Poverty Estimates","Within the remit of `Data for Development' there have been a number of promising recent works that investigate the use of mobile phone Call Detail Records (CDRs) to estimate the spatial distribution of poverty or socio-economic status. The methods being developed have the potential to offer immense value to organisations and agencies who currently struggle to identify the poorest parts of a country, due to the lack of reliable and up to date survey data in certain parts of the world. However, the results of this research have thus far only been presented in isolation rather than in comparison to any alternative approach or benchmark. Consequently, the true practical value of these methods remains unknown. Here, we seek to allay this shortcoming, by proposing two baseline poverty estimators grounded on concrete usage scenarios: one that exploits correlation with population density only, to be used when no poverty data exists at all; and one that also exploits spatial autocorrelation, to be used when poverty data has been collected for a few regions within a country. We then compare the predictive performance of these baseline models with models that also include features derived from CDRs, so to establish their real added value. We present extensive analysis of the performance of all these models on data acquired for two developing countries -- Senegal and Ivory Coast. Our results reveal that CDR-based models do provide more accurate estimates in most cases; however, the improvement is modest and more significant when estimating (extreme) poverty intensity rates rather than mean wealth.","","Smith-Clarke C,Capra L","","2016","425–434","10.1145/2872427.2883076","https://doi-org.proxy.bnl.lu/10.1145/2872427.2883076;http://dx.doi.org/10.1145/2872427.2883076","Conference Paper"
"Boosting Archimedes Optimization Algorithm Using Trigonometric Operators Based on Feature Selection for Facial Analysis","Due to technical advancements and the proliferation of mobile applications, facial analysis (FA) of humans has recently become an important area for computer vision research. FA investigates a variety of difficulties, including gender recognition, facial expression recognition, age and race recognition, with the goal of automatically comprehending social interactions. Due to the dimensional challenge posed by pre-trained CNN networks, the scientific community has developed numerous techniques inspired by biology, swarm intelligence theory, physics, and mathematical rules. This article presents a gender recognition system based on scAOA, that is a modified version of the Archimedes optimization algorithm (AOA). The latest variant (scAOA) enhances the exploitation stage by using trigonometric operators inspired by the sine cosine algorithm (SCA) in order to prevent local optima and to accelerate the convergence. The main purpose of this paper is to apply scAOA to select the relevant deep features provided by two pretrained models of CNN (AlexNet & ResNet) to recognize the gender of a human person categorized into two classes (men and women). Two datasets are used to evaluate the proposed approach (scAOA): the Brazilian FEI dataset and the Georgia Tech Face dataset (GT). In terms of accuracy, Fscore and statistical test, the comparison analysis demonstrates that scAOA outperforms other modern and competitive optimizers such as AOA, SCA, Ant lion optimizer (ALO), Salp swarm algorithm (SSA), Grey wolf optimizer (GWO), Simple genetic algorithm (SGA), Grasshopper optimization algorithm (GOA) and Particle swarm optimizer (PSO).","","Neggaz I,Neggaz N,Fizazi H","","2022","3903–3923","10.1007/s00521-022-07925-8","https://doi-org.proxy.bnl.lu/10.1007/s00521-022-07925-8;http://dx.doi.org/10.1007/s00521-022-07925-8","Journal Article"
"Botswana's Lab-In-A-Briefcase: A Position Paper","Detecting and managing communicable and non-communicable diseases in rural settings of Africa raises numerous structural, syntactical and semantic issues. Further, it has been observed that both Communicable Diseases (CDs) such as TB and Non-Communicable Diseases (NCDs), such as cancer, diabetes, cardiovascular diseases and chronic respiratory disease, are on the rise in sub-Saharan African countries and estimated to account for about 25% of deaths (Bloomfield et al., 2014) [8]. In Botswana, NCDs account for more than a third of all deaths in the country (WHO NCD country profile, 2014) [9]. For cash-poor part of Africa, this additional spend-requirement in healthcare is unfortunately substantial. One approach to reducing death related to CD/NCD is early detection and control through data collection and appropriate intervention. In sub-Saharan Africa countries, most of the population lives in rural areas where access to healthcare facilities is very limited. In such circumstances, a low-cost and mobile healthcare facility along with associated Information and Communication Technologies (ICT) would be of great assistance.This paper investigates the application of the ""lab-in-a-briefcase"" technology for the management of CDs/NCDs in Botswana and other SADC countries. The ""lab-in-a-briefcase is designed to provide a portable laboratory diagnosis toolkit with rapid results (about 15 minutes) that can be used in areas where access to laboratory or healthcare facility is limited and can be used with minimal training. It contains all the necessary tools and chemicals/reagents which are packaged in a briefcase form so that they can easily be carried. In addition, the Lab-in-a-briefcase employs mini-HPLC and smart camera, microphone, credit card-sized ECG and microscope so that a variety of tests can be performed quickly and efficiently in a portable manner.This paper details the design and deployment of ""Lab-in-a-briefcase"" and associated software tools at primary care health facilities so that diagnosis can be quickly carried out and the resulting medical records are automatically generated, converted into appropriate format and securely shared with different health information systems. The deployment of this system requires adaptation of the system in the context of the linguistic, legal, security, and other policy requirements of the participating countries. As part of the demonstration of the applicability, pilot studies will be extended to all participating African countries. Our end-objective is to develop a fully optioned prototype.","","Narasimhan VL","","2019","","10.1145/3290688.3290716","https://doi-org.proxy.bnl.lu/10.1145/3290688.3290716;http://dx.doi.org/10.1145/3290688.3290716","Conference Paper"
"Breast Cancer Prognosis from Patient Profiling by SFM","Breast cancer is the one of the common cancer types for woman society in Myanmar as well as in the world. Identifying recurrence and breast cancer patients profiling in terms of breast cancer recurrence-related data and breast cancer patient characteristics provide new insights into the complexity and causes of breast cancer recurrence. To estimate the probability of recurrence given the patient's symptoms, the statistical model is one of the current prognosis techniques. This approach offers reliable conclusions but lacks explanatory power in a human readable form, i.e. no obvious qualitative chain of inference to the conclusion. To address this issue, we investigate the exploitation of the frequent pattern as an underlying technique for this purpose. As a result, this approach can be very efficiently applied in this domain.","","Oo KM,Thein NL","","2006","129–133","","","Conference Paper"
"Business Optimization in Logistics and Performance through Technology Implementation in Developing Countries","While fast-growing countries in terms of technology like Japan, USA, South Korea, China, Finland, etc. are taking advantage of information and communication technology (ICT) to launch mobile apps, set up online payments and improve public security, public and private businesses also use it to improve economic development and problem-solving efficiency. That is not the case in developing countries where IT use is not considered when it comes to solving a problem because of its higher investment cost. This paper intends to highlight technology's role in business economic development, how it can solve problems, and the difference it can bring. We introduce GreenApp: a set of a mobile and a web application developed for a social waste management company in Madagascar called Greentsika, which has solved many of its monitoring issues and improved financial control and health. This technology improved the business by a factor of 7.14 as proven by computing the economic value created before and after application use.","","Rabefaritra KM,Rabevohitra FH,Andrianarimanana FH","","2019","226–231","10.1145/3322645.3322692","https://doi-org.proxy.bnl.lu/10.1145/3322645.3322692;http://dx.doi.org/10.1145/3322645.3322692","Conference Paper"
"Can AI Be for Good in the Midst of Cyber Attacks and Privacy Violations? A Position Paper","Artificial Intelligence (AI) is affecting every aspect of our lives from healthcare to finance to driving to managing the home. Sophisticated machine learning techniques with a focus on deep learning are being applied successfully to detect cancer, to make the best choices for investments, to determine the most suitable routes for driving as well as to efficiently manage the electricity in our homes. We expect AI to have even more influence as advances are made with technology as well as in learning, planning, reasoning and explainable systems. While these advances will greatly advance humanity, organizations such as the United Nations have embarked on initiatives such as ""AI for Good"" and we can expect to see more emphasis on applying AI for the good of humanity especially in developing countries. However, the question that needs to be answered is Can AI be for Good when when the AI techniques can be attacked and the AI techniques themselves can cause privacy violations? This position paper will provide an overview of this topic with protecting children and children's rights as an example.","","Thuraisingham BM","","2020","1–4","10.1145/3374664.3379334","https://doi-org.proxy.bnl.lu/10.1145/3374664.3379334;http://dx.doi.org/10.1145/3374664.3379334","Conference Paper"
"Can Phones Build Relationships? A Case Study of a Kenyan Wildlife Conservancy's Community Development","Wildlife conservancies across the globe are increasingly recognizing their need to support their surrounding communities to sustainably operate. Rapidly shifting environmental and sociopolitical climates increasingly stress existing resource and service provisions, forcing wildlife conservancies to co-manage with local communities shared resources like water, wildlife, soil, pollinators, and security. This work presents a case study in Laikipia, Kenya on Ol Pejeta Conservancy's use of text-based technologies to provide services and build relationships with the many widely-dispersed communities on its borders. Through technology deployments, staff interviews, and community focus groups, we investigate a potential role for basic mobile phone services, like SMS and USSD, to help conservancy personnel disseminate accurate and timely information, gather community feedback, address grievances, and improve accountability. Our findings show that communication with locals requires intense and ongoing effort from conservancy staff. Partially successful deployments of phone services provide a proof-of-concept for their utility in community relations but highlight particular design challenges for wildlife conservancies; having critical needs for broad inclusive engagement; clear, deliberate communication; and careful trust-building.","","Ziegler M,Wack M,Ingutia N,Muiruri I,Njogu N,Muriithi K,Njoroge W,Long J,Heimerl K","","2020","219–230","10.1145/3378393.3402279","https://doi-org.proxy.bnl.lu/10.1145/3378393.3402279;http://dx.doi.org/10.1145/3378393.3402279","Conference Paper"
"Capturing Smoker in Non-Smoking Room","In developing countries legal actions regarding violations of smokers in non-smoking areas are still weak. This will be very disturbing especially those who care for their own health. Eastern cultures are generally reluctant to treat smokers who violate the rules directly. Therefore, other methods are needed, such as creating a set of cigarette smoke detection systems that can warn smokers not to do it in a place that is forbidden to smoke. This device is expected to detect cigarette smoke, then at the same time take photos of suspected smokers as evidence of violations. Warnings will be carried out by authorized persons, if the alarm signal of cigarette smoke is not also heeded. The device consists of NodeMCU, MQ-2, piezo speakers, and ArduCAM OV2640. When the device detects cigarette smoke, it will push a beep sound, capture images of the room, and immediately send images to the Cloud database. A few moments later the mobile phone supervisor of the room will get a proof of the incident and immediately take an action to reprimand and arrest the perpetrators. The testing of cigarette smoke detection devices was carried out in a cardboard room with a volume of 50cm x 50cm x 75cm. Detection was carried out at 4 different points from the source of cigarette smoke each of 6 x experiments or 24 x experiments. It was found, that the speed of detection of cigarette smoke was achieved on average 14.4 seconds with the device located above the source of cigarette smoke (75cm).","","Hareva DH,Teguh S","","2020","102–106","10.1145/3369114.3369159","https://doi-org.proxy.bnl.lu/10.1145/3369114.3369159;http://dx.doi.org/10.1145/3369114.3369159","Conference Paper"
"Carrier Class High Density VoIP Media Gateway Using Hardware Software Distributed Architecture","This paper presents a system on chip (SOC) based high-density carrier class Voice over Internet Protocol (VoIP) media gateway. The design exploits three levels of parallelism namely HW/SWpartitioning, multiprocessing and instruction level parallelism. The system facilities the carrier class service providers to transform channels on PSTN network to IP network, enabling the consumers to enjoy several value added services, such as voice, data, fax and video all through a uniform network at lower cost. The SoC implements a high-density media gateway switch for carrier class VoIP applications. The solution is synthesized to operate at 266 MHz handling up to OC-3 data rate port density equivalent to 2016 simultaneous calls on a single chip and it can be cascaded to support OC-12 and OC-48 rate port density on single board in different configurations. On each channel the SoC supports up to 128 ms tail length G.168 compliant Line Echo Cancellation (LEC), voice activity detection (VAD), comfort noise generation (CNG) and discontinuous transmission (DTX), dual tone multi frequency (DTMF) detection and generation, variety of G.xxx voice codecs, V. 17 Fax and V.34 data modem standards and MPEG4 video compression/decompression algorithms. The solution is compared with the existing architectures and commercial products; it offers 3x to 10x cost, size, power and port density performance improvements with IP and PSTN internetworking support. The media gateway system based on the presented architecture has been used to develop IP-based automatic call distribution (ACD) by etel Pvt. Ltd and installed in Telephone Inquiry Exchange of Pakistan Telecom and its variants are being tested by Buraq Telecom for installation in their service network.","","Rahmatullah MM,Khan SA,Jamal H","","2007","1513–1520","10.1109/TCE.2007.4429246","https://doi-org.proxy.bnl.lu/10.1109/TCE.2007.4429246;http://dx.doi.org/10.1109/TCE.2007.4429246","Journal Article"
"Change Detection Analysis Using Sentinel-1 Satellite Data with SNAP and GEE Regarding Oil Spill in Venezuela","In Venezuela, according to a report by the National Aeronautics and Space Administration (NASA) dated September 2021, up to 50,000 oil spills at sea have been monitored in the 2010–2016-time frame. In the current two-year period, the situation does not seem to have changed: the state refinery of the Venezuelan oil company Petróleos de Venezuela, S.A. (PDVSA), located near El Palito (Carabobo), is estimated to have been responsible for nearly 100,000 barrels of oil spilled in just one year. The aforementioned spills, with the intensification of extraction, transport and storage operations, have given rise to a greater number of accidents resulting in uncontrolled dispersion of material, endangering local marine-coastal ecosystems. The one that took place in July 2020 stands out, reconstructed a posteriori using satellite images that have highlighted its geo-environmental impact. Remote sensing has played a fundamental role in identifying and monitoring the spread of hydrocarbons; in the present study, the same event was analysed using Sentinel-1 Synthetic Aperture Radar Image (SAR) Change Detection techniques. The use of the desktop software SeNtinel Application Platform (SNAP) of the European Space Agency (ESA) made it possible to quantify the ocean surface affected by the phenomenon under analysis; at the same time, an algorithm was formulated within the cloud platform Google Earth Engine (GEE) which confirmed the same outputs but more quickly and allowed the implementation of an algorithm that exploits the statistical concept of value of Otsu threshold. The results obtained were subsequently compared with other results extrapolated through automatic methodologies developed by ESA, which supported a better accuracy of the procedures used in this study.","","Caporusso G,Gallo C,Tarantino E","","2022","387–404","10.1007/978-3-031-10545-6_27","https://doi-org.proxy.bnl.lu/10.1007/978-3-031-10545-6_27;http://dx.doi.org/10.1007/978-3-031-10545-6_27","Conference Paper"
"Chinese Petroleum Corporations' International Oil Trade in Africa","In this paper, we focus on the international oil trade of Chinese petroleum corporations' in Africa. Initially, we are trying to understand the current oil reserves in Africa. Then the reasons and the situation of Chinese petroleum companies' international oil trade in Africa will be discussed. Afterwards, the weaknesses of Chinese petroleum enterprises' are investigated. Finally, a conclusion based on the research and recommendations that can not only help Chinese petroleum corporations but also apply to other similar corporations will be given.","","Long Z","","2012","279–283","","","Conference Paper"
"Choosing Small Sets of Policy-Relevant Scenarios by Combining Vulnerability and Diversity Approaches","Computer simulation models can generate large numbers of scenarios, far more than can be effectively utilized in most decision support applications. How can one best select a small number of scenarios to consider? One approach calls for choosing scenarios that illuminate vulnerabilities of proposed policies. Another calls for choosing scenarios that span a diverse range of futures. This paper joins these two approaches for the first time, proposing an optimization-based method for choosing a small number of relevant scenarios that combine both vulnerability and diversity. The paper applies the method to a real case involving climate resilient infrastructure for three African river basins (Volta, Orange and Zambezi). Introducing selection criteria in a stepwise manner helps examine how different criteria influence the choice of scenarios. The results suggest that combining vulnerability- and diversity-based criteria can provide a systematic and transparent method for scenario selection. Describes an optimization-based method for choosing a small number of scenarios.A combination of criteria related to vulnerability and diversity is used.The method is applied to a real case involving climate resilient infrastructure.","","Carlsen H,Lempert R,Wikman-Svahn P,Schweizer V","","2016","155–164","10.1016/j.envsoft.2016.06.011","https://doi-org.proxy.bnl.lu/10.1016/j.envsoft.2016.06.011;http://dx.doi.org/10.1016/j.envsoft.2016.06.011","Journal Article"
"Citizen Relationship and Grievance Management System CiR&GMS through Multi-Channel Access for e-Government Services: A Case from India","Citizens are demanding greater access to interaction with government through their preferred channels or devices. The private sector uses different channels for their services, citizens except same level of services from the public sector. Therefore public sector needs to focus on creating multiple delivery channels Traditional such as face to face, Telephone and Modern channels such as Website, E-mail, SMS, so that citizens can have 'channels of choice', depending on specific needs, demands and preferences in order to increase citizens' participation and satisfaction. For this reason, the paper's purpose is 1 To understand multi-channel architecture, Integration, Management and its Strengths & Weakness 2 To develop a frame work for Citizen Relationship and Grievance Management System CiR&GMS for a single view 3 By applying proposed framework, To identify what types of channels are providing to access public services at National, State and Local level governments in India as a case study 4 To find out challenges and issues in implementation of multi-channel service delivery. The key findings of the case study are: a There is no declining in providing traditional channels after introducing modern channels b Many departments are offering mixed channels c Usage of Mobile/SMS, Social media and Wi-Fi hotspots based channels are in initial stage d t-Government channel is not yet initiated in any department e Multi-channel integration and management is not yet initiated by many departments, these departments are managed channels as separate silos. The proposed framework may provide some guidance to the decision and policy makers in the public sector. However, such initiatives have many challenges to the developing countries like India.","","Rao VR","","2015","43–67","10.4018/ijesma.2015040103","https://doi-org.proxy.bnl.lu/10.4018/ijesma.2015040103;http://dx.doi.org/10.4018/ijesma.2015040103","Journal Article"
"Citizen-Centric E-Government Services in Namibia: Myth or Reality?","Citizen-centric e-government shifts the focus of electronic services delivery from a top-down approach to the end-users. In order to provide better services to the citizens, the Namibian government took the initiative to make services available online and established a national web portal. The Ministry of Home Affairs and Immigration is one of the first Ministries to have rolled out its e-government services to citizens and among others it has an interactive website where citizens can access information, downloadable application forms and a Short Message Service (SMS) notification system for National Identification Systems. Despite such initiatives, there are still challenges affecting the v by the Ministry of Home Affairs and Immigration. The findings include a lack of awareness of services, cost factors, inadequate accessibility, a need for full online services, trust and security considerations. Citizens preferred mobile online services and expressed willingness to embrace online services.","","Amukugo K,Peters A","","2016","193–197","10.1145/2998581.2998610","https://doi-org.proxy.bnl.lu/10.1145/2998581.2998610;http://dx.doi.org/10.1145/2998581.2998610","Conference Paper"
"Clear P-Wave Arrival of Weak Events and Automatic Onset Determination Using Wavelet Filter Banks","P-wave arrivals of many weak events cannot be precisely determined manually. Difference in power levels between noise and P-wave in wavelet detail of weak events enables us to determine P-wave arrival manually. Because of this power difference, automatic onset detection and picking algorithm is introduced using the same wavelet detail. Parameter settings are not needed as algorithm will work on data generated by either short or very broad band seismometers. Application of the proposed algorithm on data of three stations of Egyptian National Seismic Network (ENSN) in Cairo region shows a maximum standard deviation of 0.14 seconds of the corresponding manual picks.","","Hafez AG,Khan MT,Kohda T","","2010","715–723","10.1016/j.dsp.2009.10.002","https://doi-org.proxy.bnl.lu/10.1016/j.dsp.2009.10.002;http://dx.doi.org/10.1016/j.dsp.2009.10.002","Journal Article"
"Closing the Gender Profit Gap?","We examine the impact of providing access to mobile savings accounts and improving financial management skills on the performance of microenterprises in Mozambique. The effects are highly heterogeneous: Combining both types of support is associated with a large increase in both short- and long-term firm profits and in financial security for female microentrepreneurs. This allowed female-headed microenterprises, particularly those with a higher level of profits at baseline, to close the gender profit gap in performance and skills relative to their male counterparts. The main drivers of improved business performance are improved financial management practices (bookkeeping), an increase in accessible savings, and reduced transfers to friends and relatives. Providing access to mobile money as a tool to save and manage finances also increases long-term profits of female microentrepreneurs, particularly for those with higher profits at baseline. However, neither treatment has any impact on male-led enterprises. Uncovering this heterogeneity in impact across different types of microenterprises can help improve the targeting of these interventions in the future.This paper was accepted by Yan Chen, behavioral economics and decision analysis.Funding: This work was supported by the International Growth Centre and the U.S. Agency for International Development [Grant AIO-OAA-F-12-00015].Supplemental Material: The data files and Online Appendix are available at .","","Batista C,Sequeira S,Vicente PC","","2022","8553–8567","10.1287/mnsc.2022.4579","https://doi-org.proxy.bnl.lu/10.1287/mnsc.2022.4579;http://dx.doi.org/10.1287/mnsc.2022.4579","Journal Article"
"Code Generation for Embedded Heterogeneous Architectures on Android","The success of Android is based on its unified Java programming model that allows to write platform-independent programs for a variety of different target platforms. However, this comes at the cost of performance. As a consequence, Google introduced APIs that allow to write native applications and to exploit multiple cores as well as embedded GPUs for compute-intensive parts. This paper proposes code generation techniques in order to target the Renderscript and Filterscript APIs. Renderscript harnesses multi-core CPUs and unified shader GPUs, while the more restricted Filterscript also supports GPUs with earlier shader models. Our techniques focus on image processing applications and allow to target these APIs and OpenCL from a common description. We further supersede memory transfers by sharing the same memory region among different processing elements on HSA platforms. As reference, we use an embedded platform hosting a multi-core ARM CPU and an ARM Mali GPU. We show that our generated source code is faster than native implementations in OpenCV as well as the pre-implemented script intrinsics provided by Google for acceleration on the embedded GPU.","","Membarth R,Reiche O,Hannig F,Teich J","","2014","","","","Conference Paper"
"Comparative Analysis of Terrorists’ Objectives Hierarchies","To develop effective counterterrorism strategies, it is important to understand the capabilities and objectives of terrorist groups. Much of the understanding of these groups comes from intelligence collection and analysis of their capabilities. In contrast, the objectives of terrorists are less well understood. In this article, we describe a decision analysis methodology to identify and structure the objectives of terrorists based on the statements and writings of their leaders. This methodology was applied in three case studies, resulting in the three objectives hierarchies of al-Qaeda, Islamic State of Iraq and the Levant (ISIL), and Hezbollah. In this article, we propose a method to compare the three objectives hierarchies, highlight their key differences, and draw conclusions about effective counterterrorism strategies. We find that all three terrorist groups have a wide range of objectives going far beyond the objective of killing and terrorizing people in the non-Muslim world. Among the shared objectives are destroying Israel and expelling Western powers from the Middle East. All three groups share the ambition to become a leader in the Islamic world. Key distinctions are the territorial ambitions of ISIL and Hezbollah versus the large-scale attack objectives of al-Qaeda. Objectives specific to ISIL are the establishment of a caliphate in Iraq and Syria and the re-creation of the power of Sunni Islam. Hezbollah has unique objectives related to the establishment of a Palestine State and to maintain the relationship with and support of Iran and Syria. Al-Qaeda’s objectives remain focused on large-scale attacks in the West. We also note a recent shift to provide support for small-scale attacks in the West by both al-Qaeda and ISIL. Our method can be used for comparing objectives hierarchies of different organizations as well as for comparing objectives hierarchies over time of one organization.","","Siebert JU,von Winterfeldt D","","2020","97–114","10.1287/deca.2019.0400","https://doi-org.proxy.bnl.lu/10.1287/deca.2019.0400;http://dx.doi.org/10.1287/deca.2019.0400","Journal Article"
"Computational Challenges and Opportunities of Simulating Cosmic Ray Showers at Global Scale","Galactic cosmic rays are the high-energy particles that stream into our solar system from distant corners of our Galaxy and some low energy particles are from the Sun which are associated with solar flares. The Earth atmosphere serves as an ideal detector for the high energy cosmic rays which interact with the air molecule nuclei causing propagation of extensive air showers. In recent years, there are growing interests in the applications of the cosmic ray measurements which range from the space/earth weather monitoring, homeland security based on the cosmic ray muon tomography, radiation effects on health via air travel, etc. A simulation program (based on the GEANT4 software package developed at CERN) has been developed at Georgia State University for studying the cosmic ray showers in atmosphere. The results of this simulation study will provide unprecedented knowledge of the geo-position-dependent cosmic ray shower profiles and significantly enhance the applicability of the cosmic ray applications. In the paper, we present the computational challenges and the opportunities for carrying out the cosmic ray shower simulations at the global scale using various computing resources including XSEDE.","","Sarajlic O,He X,Sarajlic S,Wei TC","","2018","","10.1145/3219104.3229281","https://doi-org.proxy.bnl.lu/10.1145/3219104.3229281;http://dx.doi.org/10.1145/3219104.3229281","Conference Paper"
"Computing Enclosures for the Matrix Mittag–Leffler Function","We propose two algorithms for numerically calculating interval matrices including two-parameter matrix Mittag–Leffler (ML) functions. We first present an algorithm for computing enclosures for scalar ML functions. Then, the two proposed algorithms are developed by exploiting the scalar algorithm and verified block diagonalization. The first algorithm relies on a numerical spectral decomposition. The cost of this algorithm is only cubic plus that of the scalar algorithm if the second parameter is not too small. The second algorithm is based on a numerical Jordan decomposition, and can also be applied to defective matrices. The cost of this algorithm is quartic plus that of the scalar algorithm. A numerical experiment illustrates an application to a fractional differential equation.","","Miyajima S","","2021","","10.1007/s10915-021-01447-6","https://doi-org.proxy.bnl.lu/10.1007/s10915-021-01447-6;http://dx.doi.org/10.1007/s10915-021-01447-6","Journal Article"
"Concurrent, Performance-Based Methodology for Increasing the Accuracy and Certainty of Short-Term Neural Prediction Systems","Accurate prediction of the short time series with highly irregular behavior is a challenging task found in many areas of modern science. Such data fluctuations are not systematic and hardly predictable. In recent years, artificial neural networks have widely been exploited for those purposes. Although it is possible to model nonlinear behavior of short time series by using ANNs, very often they are not able to handle all events equally well. Therefore, alternative approaches have to be applied. In this study, a new, concurrent, performance-based methodology that combines best ANN topologies in order to decrease the forecasting errors and increase the forecasting certainty is proposed. The proposed approach is verified on three different data sets: the Serbian Gross National Income time series, the municipal traffic flow for a particular observation point, and the daily electric load consumption time series. It is shown that the method can significantly increase the forecasting accuracy of the individual networks, regardless of their topologies, which makes the methodology more applicable. For quantitative comparison of the accuracy of the proposed methodology with that of similar methodologies, a series of additional forecasting experiments that include a state-of-the-art ARIMA modelling and a combination of ANN and linear regression forecasting have been conducted.","","Milić M,Milojković J,Marković I,Nikolić P,Delic V","","2019","","10.1155/2019/9323482","https://doi-org.proxy.bnl.lu/10.1155/2019/9323482;http://dx.doi.org/10.1155/2019/9323482","Journal Article"
"Confronting Global Issues: A Multipurpose IR Simulation","This article describes an international relations simulation that focuses on threats of transnational insurgent organizations, the future of the Iraqi regime, and the effect of globalization on foreign policies. It contains both the Simulation Director's Guide and the Participant's Guide. The guides explain the steps taken to run the simulation and offer a description of the process. During the game, conflicting goal-directed participants, representing specific actors in the international system, must derive and achieve foreign policy goals given military and monetary constraints. The general rules and procedures apply to simulations involving myriad international processes and actors.","","Shellman SM,Turan K","","2006","98–123","10.1177/1046878105278924","https://doi-org.proxy.bnl.lu/10.1177/1046878105278924;http://dx.doi.org/10.1177/1046878105278924","Journal Article"
"Contributors","Ivo Adan (“Exact FCFS Matching Rates for Two Infinite Multitype Sequences”) is a full professor of manufacturing networks in the Department of Mechanical Engineering at the Eindhoven University of Technology. His current research focuses on the modeling, analysis, and design of manufacturing, warehousing, and healthcare systems, and more specifically, the analysis of multidimensional Markov processes and queueing models.Alper Atamtürk (“A Conic Integer Programming Approach to Stochastic Joint Location-Inventory Problems”) is a Chancellor's Professor in the Industrial Engineering and Operations Research Department at the University of California, Berkeley. His current research interests are in optimization, integer programming, optimization under uncertainty with applications to energy, finance, operations, cancer therapy, and defense. He was appointed a National Security Fellow by the United States Department of Defense in 2010.Rami Atar (“A Diffusion Regime with Nondegenerate Slowdown”) is a professor in the Department of Electrical Engineering, Technion, Israel. His research interests are in stochastic processes. These include asymptotic analysis of queueing and stochastic network models in diffusion and large deviation regimes, PDE techniques in stochastic control and differential games, filtering, and estimation.Derek Atkins (“A Simulation Optimization Approach to Long-Term Care Capacity Planning”) is a professor in the Sauder School of Business at the University of British Columbia, Canada. His research interests are in supply chains and healthcare operations. He was formerly director of the Centre for Operations Excellence at Sauder, which undertook a project for a local health authority that triggered the need for the paper presented in this issue. Gemma Berenguer (“A Conic Integer Programming Approach to Stochastic Joint Location-Inventory Problems”) is a Ph.D. candidate in the Industrial Engineering and Operations Research Department at the University of California, Berkeley. She is doing research on integrated supply chain design problems, nonprofit supply chain management problems, and the design of regulatory mechanisms for environmental policies.Ya Ping Fang (“Piecewise Linear Multicriteria Programs: The Continuous Case and Its Discontinuous Generalization”) is an associate professor in the Department of Mathematics at Sichuan University. His research interests are in the area of optimization problems, equilibrium problems, and variational inequalities.Michael C. Fu (“A New Stochastic Derivative Estimator for Discontinuous Payoff Functions with Application to Financial Derivatives”) is the Ralph J. Tyser Professor of Management Science in the Robert H. Smith School of Business at the University of Maryland. His research interests include simulation and applied probability modeling, particularly with applications toward manufacturing systems, supply chain management, and financial engineering. He is a Fellow of INFORMS and IEEE.David Gamarnik (“Belief Propagation for Min-Cost Network Flow: Convergence and Correctness”) is an associate professor of operations research at the Sloan School of Management at the Massachusetts Institute of Technology. His research interests include applied probability and stochastic processes, theory of random graphs and algorithms, combinatorial optimization, statistical learning theory, and various applications. He is a recipient of the Erlang Prize from the INFORMS Applied Probability Society, IBM Faculty Partnership Award, and several NSF-sponsored grants.Nir Halman (“Approximating the Nonlinear Newsvendor and Single-Item Stochastic Lot-Sizing Problems When Data Is Given by an Oracle”) is a lecturer of operations research in the school of business administration at the Hebrew University of Jerusalem. His research focuses on optimization methods that yield efficient algorithms in combinatorial optimization.Jonathan Kluberg (“Generalized Quantity Competition for Multiple Products and Loss of Efficiency”) is an investment analyst at High Vista Strategies.Yuri Levin (“Cargo Capacity Management with Allotments and Spot Market Demand”) is a Distinguished Professor of Operations Management at Queen's School of Business in Kingston, Ontario, Canada. His research interests include revenue management, dynamic pricing, numerical optimization, and machine learning applications.Qing Li (“On the Quasiconcavity of Lost-Sales Inventory Models with Fixed Costs”) is an associate professor at the School of Business and Management, Hong Kong University of Science and Technology. His research interests include supply chain management, marketing/operations interfaces, stochastic dynamic inventory models, and economics of waste. Steven I. Marcus (“A New Stochastic Derivative Estimator for Discontinuous Payoff Functions with Application to Financial Derivatives”) is a professor in the Department of Electrical and Computer Engineering and the Institute for Systems Research at the University of Maryland. His research focuses on stochastic control and estimation, with applications in manufacturing and telecommunication networks.Kaiwen Meng (“Piecewise Linear Multicriteria Programs: The Continuous Case and Its Discontinuous Generalization”) holds a Ph.D. degree (2011) in optimization and operations research from the Hong Kong Polytechnic University. His research interests are in the areas of variational analysis, optimization theory, and operations research. S. Michel (“A Column-Generation Based Tactical Planning Method for Inventory Routing”) is an assistant professor of operations research at Le Havre University. She is a member of the Laboratory of Applied Mathematics and the Logistics Engineering Institute and an associate member of the INRIA research team REALOPT. Her research projects concern sea ship and vehicle routing, as well as generic primal heuristics.Anton Molyboha (“Stochastic Optimization of Sensor Placement for Diver Detection”) is a quantitative analyst at Teza Technologies. He holds a Ph.D. degree in mathematics with concentration in stochastic systems (2009) from the Department of Mathematical Sciences at Stevens Institute of Technology.Mikhail Nediak (“Cargo Capacity Management with Allotments and Spot Market Demand”) is an assistant professor in the School of Business at Queen's University in Kingston, Ontario, Canada. His research focuses on new models in revenue management and dynamic pricing.Matthew Nelson (“A Simulation Optimization Approach to Long-Term Care Capacity Planning”) is a project lead in the Centre for Research in Healthcare Engineering at the University of Toronto. He received his master's degree from the Centre for Operations Excellence in the Sauder School of Business at the University of British Columbia. James B. Orlin (“Approximating the Nonlinear Newsvendor and Single-Item Stochastic Lot-Sizing Problems When Data Is Given by an Oracle”) is the Edward Pennell Brooks Professor of Operations Research in the Sloan School of Management at the Massachusetts Institute of Technology. His research focuses on optimization methods, especially in combinatorial and network optimization. He is a coauthor of Network Flows: Theory, Algorithms, and Applications (Prentice-Hall, 1993), for which he was awarded the Lanchester Prize in 1993. He is an INFORMS Fellow.Georgia Perakis (“Generalized Quantity Competition for Multiple Products and Loss of Efficiency”) is the William F. Pounds Professor at the Sloan School of Management at Massachusetts Institute of Technology.Dzung T. Phan (“Lagrangian Duality and Branch-and-Bound Algorithms for Optimal Power Flow”) is a research staff member in the Mathematical Sciences Department at IBM T. J. Watson Research Center, Yorktown Heights, New York, where he spent one year as a postdoctoral researcher. His research interests lie in the field of optimization theory and algorithms. Recently at IBM, he developed several numerical algorithms for optimization problems arising from power system analysis. Martin L. Puterman (“A Simulation Optimization Approach to Long-Term Care Capacity Planning”) is Advisory Board Professor of Operations in the Sauder School of Business at the University of British Columbia, Canada. He was founder and director of the Centre for Operations Excellence (in Sauder), the UBC Centre for Health Care Management, and the Biostatistical Consulting Service at BC Children's Hospital. He received the INFORMS Lanchester Prize for his book Markov Decision Processes: Discrete Stochastic Dynamic Programming (Wiley-Interscience, 2005). He is an INFORMS Fellow and recipient of the Canadian Operations Research Society (CORS) Award of Merit, the CORS Practice Prize, and the INFORMS case prize. Richard Ratliff (“Estimating Primary Demand for Substitutable Products from Sales Transaction Data”) is the Senior Research Scientist at Sabre Research. His primary focus is on applied research and development in travel revenue management. His work has included prototyping new technologies applicable to travel distribution, as well as major travel suppliers.Devavrat Shah (“Belief Propagation for Min-Cost Network Flow: Convergence and Correctness”) is a Jamieson career development associate professor in the Department of Electrical Engineering and Computer Science at Massachusetts Institute of Technology. He is a member of the Laboratory for Information and Decision Systems and Operations Research Center. His research focus is on theory of large complex networks and includes network algorithms, stochastic networks, network information theory, and large-scale statistical inference. He received the George B. Dantzig Dissertation Award from INFORMS in 2005, the ACM SIGMETRICS Rising Star Award in 2008, and the Erlang Prize from INFORMS in 2010.Zuo-Jun (Max) Shen (“A Conic Integer Programming Approach to Stochastic Joint Location-Inventory Problems”) is a Chancellors Professor of Industrial Engineering and Operations Research at the University of California, Berkeley. He has been active in the following research areas: integrated supply chain design and management, market mechanism design, marketing-operations management interface issues, and decision making with limited information. David Simchi-Levi (“Approximating the Nonlinear Newsvendor and Single-Item Stochastic Lot-Sizing Problems When Data Is Given by an Oracle”) is a professor of engineering systems at Massachusetts Institute of Technology. The work described in this paper is part of a larger research project that deals with effective supply chain and procurement strategies that improve supply chain performance.James E. Smith (“Technology Adoption with Uncertain Future Costs and Quality”) is J. B. Fuqua Professor of Business Administration at the Fuqua School of Business, Duke University. His research interests are primarily in decision analysis and focus on developing methods for formulating and solving dynamic decision problems and valuing risky investments. He is an INFORMS Fellow and past president of the Decision Analysis Society.Huseyin Topaloglu (“Cargo Capacity Management with Allotments and Spot Market Demand”) is an associate professor in the School of Operations Research and Information Engineering at Cornell University. His research interests include stochastic programming and optimal control with applications in revenue management, pricing, and inventory control.Canan Ulu (“Technology Adoption with Uncertain Future Costs and Quality”) is an assistant professor in the Department of Information, Risk, and Operations Management (IROM) at the McCombs School of Business, University of Texas at Austin. Her research interests include Bayesian learning in sequential decision problems and the impact of behavioral decision theory on decision analysis methods. F. Vanderbeck (“A Column-Generation Based Tactical Planning Method for Inventory Routing”) is a professor in the Department of Mathematics at the University of Bordeaux. He is a affiliated with the Institute of Mathematics of Bordeaux and the INRIA research center where he leads the research team REALOPT specializing in reformulation and algorithms for combinatorial optimization. His main activity is in decomposition approaches in integer programming with applications in routing and operation planning. He develops a branch-and-price platform named BAPCOD.Johan S. H. van Leeuwaarden (“Staffing Call Centers with Impatient Customers: Refinements to Many-Server Asymptotics”) is an associate professor of probability theory and stochastic networks at the Eindhoven University of Technology and a research fellow at the research institute EURANDOM. He received the INFORMS Telecommunication Dissertation Award (2008), a Veni Grant (2006--2009) from the Netherlands Organisation for Scientific Research, and a Starting Grant (2010--2015) from the European Research Council.Garrett van Ryzin (“Estimating Primary Demand for Substitutable Products from Sales Transaction Data”) is Paul M. Montrone Professor of Business and Chair of the Decision, Risk, and Operations Division at Columbia Business School. His research interests include revenue management, consumer behavior modeling, operations management, and stochastic optimization.Gustavo Vulcano (“Estimating Primary Demand for Substitutable Products from Sales Transaction Data”) is an associate professor at the Leonard N. Stern School of Business at New York University. His research interests are primarily in revenue management, including pricing mechanisms and capacity control. This paper is part of his current research on customer choice and strategic consumer behavior.Yongqiang Wang (“A New Stochastic Derivative Estimator for Discontinuous Payoff Functions with Application to Financial Derivatives”) is a research associate in the Department of Electrical and Computer Engineering and the Institute for Systems Research at the University of Maryland. He received the 2010 INFORMS Computing Society Student Paper Award and the 2010 Winter Simulation Best Student Paper Award. His research interests lie in the areas of simulation optimization, Markov decision process, and stochastic control, with applications toward supply chain management and financial engineering.Yehua Wei (“Belief Propagation for Min-Cost Network Flow: Convergence and Correctness”) is a Ph.D student in the Operations Research Center at the Massachusetts Institute of Technology. His research interests include the design of process flexibility and optimization of supply chains. He has also worked in the area of distributed algorithms, including belief propagation and divide and conquer algorithms.Gideon Weiss (“Exact FCFS Matching Rates for Two Infinite Multitype Sequences”) is a professor of statistics and operations research in the Department of Statistics at the University of Haifa, Israel. His current research focuses on scheduling and control of processing networks, with applications to manufacturing, communications, and service systems. In particular, he is studying fluid approximations to queueing networks, and simplex algorithms for continuous, infinite dimensional linear programs.Xiao Qi Yang (“Piecewise Linear Multicriteria Programs: The Continuous Case and Its Discontinuous Generalization”) is a professor in the Department of Applied Mathematics at the Hong Kong Polytechnic University. His research interests are in the areas of variational analysis, multicriteria optimization, and financial optimization.Peiwen Yu (“On the Quasiconcavity of Lost-Sales Inventory Models with Fixed Costs”) is a Ph.D. candidate in the School of Business and Management at the Hong Kong University of Science and Technology. His main research interests include inventory management and optimization. He received a B.S. degree in mathematics from the University of Science and Technology of China.Michael Zabarankin (“Stochastic Optimization of Sensor Placement for Diver Detection”) is an associate professor in the Department of Mathematical Sciences at Stevens Institute of Technology.Bo Zhang (“Staffing Call Centers with Impatient Customers: Refinements to Many-Server Asymptotics”) received his Ph.D. degree from Georgia Institute of Technology in 2011 and is a research staff member in the Business Analytics and Mathematical Sciences Department at the IBM T. J. Watson Research Center. He is broadly interested in decision making under uncertainty in various application domains, with an emphasis on stochastic modeling, analysis, and optimization. His research has won the first place in the 2010 INFORMS Nicholson Student Paper Competition and the Best Student Paper award at the 28th International Symposium on Computer Performance, Modeling, Measurements, and Evaluation.Yue Zhang (“A Simulation Optimization Approach to Long-Term Care Capacity Planning”) is an assistant professor of operations management in the College of Business and Innovation at the University of Toledo. His research interests include service and healthcare operations, location analysis and network design, logistics and transportation, and simulation optimization. The paper in this issue is part of his postdoctoral research at the Sauder School of Business, University of British Columbia. Bert Zwart (“Staffing Call Centers with Impatient Customers: Refinements to Many-Server Asymptotics”) is with the Center of Mathematics and Computer Science in Amsterdam, where he leads the Probability and Stochastic Networks Group. He is a professor at VU University Amsterdam. His honors include an IBM Faculty Award, the Erlang Prize, and VENI and VIDI awards from the Dutch Science Foundation.","","","","2012","501–504","10.1287/opre.1120.1076","https://doi-org.proxy.bnl.lu/10.1287/opre.1120.1076;http://dx.doi.org/10.1287/opre.1120.1076","Journal Article"
"Creating Password Security Using Spark Authentication Secret for Data Privacy and Protection","Most of the passwords created by individuals, business organisations and other institutions using other software application to ensure the privacy and protection of their data/information according to the research can be hacked by hackers which at the end cause a lot of financial loss and other disparities. In this paper we create password security system using Spark Technology for data privacy and protection. Secondly, we test the created password by selecting data from the various departments in Kumasi Technical University, Ghana, for the experiment to detect if the created password using Spark Technology can be hacked in order to have access to the data selected or not. The actual data selected for experiment are first and second semester examination results of 2016 academic. The password security system created is ""spark.authenticate.secret"" using Apache Spark Technology to guarantee data protection and privacy.","","Boachie E,Li C,Aduamoah M","","2018","402–406","10.1145/3291842.3291843","https://doi-org.proxy.bnl.lu/10.1145/3291842.3291843;http://dx.doi.org/10.1145/3291842.3291843","Conference Paper"
"Cryptographic Credit Control in Pre-Payment Metering Systems","Abstract: We describe the successful introduction of cryptology into a new application area-protecting prepayment electricity meters from token fraud. These meters are used by a number of utilities from Scotland to South Africa, and they present some interesting security challenges.","","Anderson RJ,Bezuidenhout SJ","","1995","15","","","Conference Paper"
"Customizable, Scalable and Reliable Community-Based Mobile Health Interventions","In pursuance of the Millennium Development Goals (MDGs) set by United Nations in 2000, both Community Based Participatory Research (CBPR) and Mobile Health (mHealth) have proved to be a great tool for advancements in patient monitoring, emergency care and community empowerment. Rapid proliferation of mobile telephony in low income, rural and underserved populations in the absence of other information and communication technology media have prompted the interests of researchers in public health sector. Exploiting mobile communication has resulted in formulation of a dependable and effective socio-technical ecosystem for public health. Whereas, involving academic researchers and community partners to collaborate and develop social and computational models, Community Based Participatory Research (CBPR) approach targets building communication, trust and capacity, with the final goal of increasing community participation in the research process. CBPR is a collaborative approach to research which equitably involves all partners in the research process for betterment of the targeted community. In this paper we present a conceptual and implementation architecture for conducting mHealth assisted community-based interventions. The framework allows CBPR partners to customize the system and design interventions around locale, technology, geographic, scale, and nonetheless social and cultural aspects. We also present the design of our planned intervention addressing prenatal monitoring of underserved populations in the Andean regions of Peru.","","Kaushik B,Brunette MJ,Fu X,Liu B","","2014","43–48","10.1145/2633651.2633659","https://doi-org.proxy.bnl.lu/10.1145/2633651.2633659;http://dx.doi.org/10.1145/2633651.2633659","Conference Paper"
"CyberBullet - Share Your Story: An Interactive Game for Stimulating Awareness on the Harm and Negative Effects of the Internet","Increased internet connectivity across the African continent through mobile phones not only opens numerous opportunities, but also increases cybercrimes such as online child abuse and sexual exploitation. Previous national studies have shown that Namibia has experienced a surge in cybercrimes, which leaves children vulnerable to predators. While a national reporting portal has been launched, children are less likely to report incidents of cyber bullying or online abuse. This study aimed at investigating how an interactive game-based approach can be used for preventing online child abuse and the study also creates a fully functional game prototype. We wanted to gain insight into the current online experiences in Namibia. After administering an online survey and conducting focus group interviews at a local high school, we then conducted two game design workshops with stakeholders namely students, teachers, parents, and game developers. We found that most girls liked storytelling games whereas boys were more drawn to action games. This led to the development of the game called CyberBullet - Share Your Story. The study contribution is in the application of game-based approach to sensitize and prevent children from becoming victims of online abuse.","","Mikka-Muntuumo J,Peters A,Jazri H","","2018","","10.1145/3283458.3283482","https://doi-org.proxy.bnl.lu/10.1145/3283458.3283482;http://dx.doi.org/10.1145/3283458.3283482","Conference Paper"
"Cybercrime Profiling: Decision-Tree Induction, Examining Perceptions of Internet Risk and Cybercrime Victimisation","The Internet can be a double-edged sword. While offering a range of benefits, it also provides an opportunity for criminals to extend their work to areas previously unimagined. Every country faces the same challenges regarding the fight against cybercrime and how to effectively promote security for its citizens and organisations. The main aim of this study is to introduce and apply a data-mining technique (decision-tree) to cybercrime profiling. This paper also aims to draw attention to the growing number of cybercrime victims, and the relationship between online behaviour and computer victimisation. This study used secondhand data collected for a study was carried out using Jordan a s a case study to investigate whether or not individuals effectively protect themselves against cybercrime, and to examine how perception of law influences actions towards incidents of cybercrime. In Jordan, cybercafe's have become culturally acceptable alternatives for individuals wishing to access the Internet in private, away from the prying eyes of society.","","Al-Nemrat A,Benzaid C","","2015","1380–1385","","","Conference Paper"
"Deep-Learning-Based Diagnosis of Cassava Leaf Diseases Using Vision Transformer","Viral diseases are major causes leading to the poor yields of cassava, which is the second-largest source of food carbohydrates in Africa. As symptoms of these diseases can usually be identified by inspecting cassava leafs, visual diagnosis of cassava leaf diseases is of significant importance in food security and agriculture development. Considering the shortage of qualified agricultural experts, automatic approaches for the image-based detection of cassava leaf diseases are in great demand. In this paper, on the basis of Vision Transformer, we propose a deep learning method to identify the type of viral disease in a cassava leaf image. The image dataset of cassava leaves is provided by the Makerere Artificial Intelligence Lab in a Kaggle competition, consisting of 4 subtypes of diseases and healthy cassava leaves. Our results show that Vision-Transformer-based model can effectively achieve an excellent performance regarding the classification of cassava leaf diseases. After applying the K-Fold cross validation technique, our model reaches a categorization accuracy 0.9002 on the private test set. This score ranks top 3% in the leaderboard, and can get a silver medal prize in the Kaggle competition. Our method can be applied for the identification of diseased plants, and potentially prevent the irreparable damage of crops.","","Zhuang L","","2022","74–79","10.1145/3508259.3508270","https://doi-org.proxy.bnl.lu/10.1145/3508259.3508270;http://dx.doi.org/10.1145/3508259.3508270","Conference Paper"
"Deploying PAWS: Field Optimization of the Protection Assistant for Wildlife Security","Poaching is a serious threat to the conservation of key species and whole ecosystems. While conducting foot patrols is the most commonly used approach in many countries to prevent poaching, such patrols often do not make the best use of limited patrolling resources. To remedy this situation, prior work introduced a novel emerging application called PAWS (Protection Assistant for Wildlife Security); PAWS was proposed as a game-theoretic (""security games"") decision aid to optimize the use of patrolling resources.This paper reports on PAWS's significant evolution from a proposed decision aid to a regularly deployed application, reporting on the lessons from the first tests in Africa in Spring 2014, through its continued evolution since then, to current regular use in Southeast Asia and plans for future worldwide deployment. In this process, we have worked closely with two NGOs (Panthera and Rimba) and incorporated extensive feedback from professional patrolling teams. We outline key technical advances that lead to PAWS's regular deployment: (i) incorporating complex topographic features, e.g., ridge-lines, in generating patrol routes; (ii) handling uncertainties in species distribution (game theoretic payoffs); (iii) ensuring scalability for patrolling large-scale conservation areas with fine-grained guidance; and (iv) handling complex patrol scheduling constraints.","","Fang F,Nguyen TH,Pickles R,Lam WY,Clements GR,An B,Singh A,Tambe M,Lemieux A","","2016","3966–3973","","","Conference Paper"
"Design and Capabilities of an Enhanced Naval Mine Warfare Simulation Framework","The Naval Surface Warfare Center, Panama City Division (NSWC PCD) designed and implemented a new tool, The Rapid Mine Simulation System Enterprise Architecture (RMSSEA), to support existing naval mine warfare simulations and to provide enhanced future mine warfare capabilities. RMSSEA supports existing physics-based models of Navy assets and threats in order to provide ship susceptibility and sweep effectiveness measures. The tool expands support for modeling of future systems, including maneuverable surface and underwater unmanned systems. Additionally, RMSSEA allows for simulations of distributed sensor and mobile warhead devices. The tool incorporates improved automation and visualization, which reduces simulation setup time and supports increased focus on results analysis.","","Floore TE,Gilman GH","","2011","2612–2618","","","Conference Paper"
"Detecting Voter Fraud in an Electronic Voting Context: An Analysis of the Unlimited Reelection Vote in Venezuela","Between December 2007 and February 2009, Venezuelans participated twice in constitutional referenda where the elimination of presidential term limits was one of the most salient proposals. Assuming voter preferences did not change significantly during that period, the 'repeated' character of these elections provide us with an excellent opportunity to apply forensic tools designed to detect anomalies and outliers in election returns in elections where electronic voting technologies were used. Similar tools were first applied by Myagkov et al. ([20], [21], [22], [23]) to the study of electoral fraud in Russia and Ukraine, and were effective in the isolation of potential cases of manipulation of electoral returns. The case of Venezuela is different because there exists no widespread agreement about the integrity or otherwise fraudulent nature of national elections, and because it is a nation where electronic voting technologies are used. Unless electoral fraud takes place in exactly the same manner in each election, an analysis of the 'flow of votes' between elections can be used to detect suspicious patterns in electoral returns. Although we do not find evidence of pervasive electoral fraud compared, for instance, to the Russian case, our analysis is useful to detect polling places or regions deviating considerably from the more general pattern.","","Levin I,Cohn GA,Ordeshook PC,Alvarez RM","","2009","4","","","Conference Paper"
"Determinant of Food Security on Upland Agriculture Households in Paletwa Township, Chin State of Myanmar","This study aims to determine food security on upland agriculture households in rural area. Food security is concerned with the first two main goals of Sustainable Development Goals, No Poverty and Zero Hunger. Myanmar is Food Insecure State that showing 14.2% that is 7.7 million of 51 million population. Chin state is least developing and Paletwa is poorest out of 324 townships. Research is applied by both qualitative and quantitative approaches. 3 Villages and 1 Quarter are chosen for qualitative method and 141upland agriculture households are selected for field survey using random sampling method. The data are analyzed by logistic regression in SPSS 17 to determine food security. Age, education, schooling years of household head, size, second occupation and no. of working people in households are socio-economic determinant and own food production and fruit access are food security determinant.","","Lwin S,Poungchompu S","","2017","44–53","10.4018/IJKSR.2017040104","https://doi-org.proxy.bnl.lu/10.4018/IJKSR.2017040104;http://dx.doi.org/10.4018/IJKSR.2017040104","Journal Article"
"Determining the Factors Affecting the Accuracy of Effort Estimates for Different Application and Task Types","An important asset in the skill set of any software project manager is the ability to somewhat accurately estimate the effort required to develop a software application. Acquiring this asset, however, requires a thorough understanding of the factors that may affect the accuracy of these estimates. This paper presents the results of an empirical study conducted to determine the causes of variation in the accuracy of effort estimations for different application and task types. A Pakistani software house that specializes in developing financial transaction processing applications is chosen for this empirical study. Actual and estimated values for software development effort are gathered and analyzed for four different types of applications--web-based, database, parallel processing, and telephony--each having six different types of tasks i.e. business-development, new features, usability, security, support, and performance. Over 1000 data points are considered. Analysis of the results reveals, for instance, that the effort for web-based applications is mostly underestimated while the effort for telephony applications is mostly overestimated. The underestimation in web-based applications is usually due to a failure to account for the learning curve associated with rapidly changing web technologies while the overestimation in telephony applications is usually due to a failure to account for the usage of third-party components.","","Bukhari S,Malik AA","","2012","41–45","10.1109/FIT.2012.16","https://doi-org.proxy.bnl.lu/10.1109/FIT.2012.16;http://dx.doi.org/10.1109/FIT.2012.16","Conference Paper"
"Deterministic Multikernel Extreme Learning Machine with Fuzzy Feature Extraction for Pattern Classification","In this paper a novel multikernel deterministic extreme learning machine (ELM) and its variants are developed for classification of non-linear problems. Over a decade ELM is proved to be efficacious learning algorithms, but due to the non-deterministic and single kernel dependent feature mapping proprietary, it cannot be efficiently applied to real time classification problems that require invariant output solution. We address this problem by analytically calculation of input and hidden layer parameters for achieving the deterministic solution and exploiting the data fusion proficiency of multiple kernel learning. This investigation originates a novel deterministic ELM with single layer architecture in which kernel function is aggregation of linear combination of disparate base kernels. The weight of kernels depends upon perspicacity of problem and is empirically calculated. To further enhance the performance we utilize the capabilities of fuzzy set to find the pixel-wise coalition of face images with different classes. This handles the uncertainty involved in face recognition under varying environment condition. The pixel-wise membership value extracts the unseen information from images up to significant extent. The validity of the proposed approach is tested extensively on diverse set of face databases: databases with and without illumination variations and discrete types of kernels. The proposed algorithms achieve 100% recognition rate for Yale database, when seven and eight images per identity are considered for training. Also, the superior recognition rate is achieved for AT & T, Georgia Tech and AR databases, when compared with contemporary methods that prove the efficacy of proposed approaches in uncontrolled conditions significantly.","","Ahuja B,Vishwakarma VP","","2021","32423–32447","10.1007/s11042-021-11097-3","https://doi-org.proxy.bnl.lu/10.1007/s11042-021-11097-3;http://dx.doi.org/10.1007/s11042-021-11097-3","Journal Article"
"Developing Electricity Forecast Web Tool for Kosovo Market","In this paper is presented a web tool for electricity forecast for Kosovo market for the upcoming ten years. The input data i.e. electricity generation capacities, demand and consume are taken from the document ""Kosovo Energy Strategy 2009-2018"" compiled by Ministry of Energy of Kosovo and approved by the Kosovo Assembly. The web tool enables different settings for national electricity grid, divided in seven electricity consume regions, five interconnection lines and using domestic generation capacities, using existing power plants and those planed to be built until 2018. It enables different scenarios, such as increasing/decreasing electricity demand in different regions, energy import/export and increasing/decreasing generation capacities. The developed web tool was tested especially against boundary condition such as heavy increased/decreased energy consumption, i.e. beyond the planned economic growth of the country and the delay of starting time of new generation capacities. For these boundary conditions are proposed extra measures to be considered in order to fulfill the security of energy supply criteria. This web application is developed using latest ASP.NET platform, C# as programming language and Microsoft SQL as database server. The web tool shall server as unique tool for governmental decision makers and to contribute inputs to future policy and management decision-making in the energy sector.","","Rexha B,Ahmeti A,Ahmedi L,Komoni V","","2011","55–64","","","Journal Article"
"Development and Characteristics of African Satellite Augmentation System (ASAS) Network","This paper reports on an African Satellite Augmentation System (ASAS) Space and Ground Segments as an integration part of Global Satellite Augmentation System (GSAS) for enhanced Traffic Control and Management (TCM) globally at sea, on the ground (road and railway vehicles) and in the air. The ASAS network can be used as solely systems for covering and providing TCM and Safety and Security service for entire African Continent and Middle East region, according to the International Maritime Organization (IMO), its Global Maritime Distress and Safety System (GMDSS) and International Civil Aviation Organization (ICAO) recommendations and requirements. Since 1995 few commercial Regional Satellite Augmentation System (RSAS) networks have been projected and developed to utilize Communication, Navigation and Surveillance (CNS) service for Maritime Traffic Control (MTC), Land Traffic Control (LTC) and Air Traffic Control (ATC), including for improved Safety and Security in all transportation systems. The proposed Space Segment of Geostationary Earth Orbit (GEO) constellation and Ground Segment of ASAS network are discussed, and areas examined where further investigations are needed. Specific issues related to these challenges are concluded and a set of solutions is proposed to maximize the availability of ASAS network capacity to the user applications.","","Ilcev DS","","2013","121–137","10.1007/s11235-011-9464-x","https://doi-org.proxy.bnl.lu/10.1007/s11235-011-9464-x;http://dx.doi.org/10.1007/s11235-011-9464-x","Journal Article"
"Development and Design of a Unified Remote Video Surveillance System for Homes, Using Free Software Tools","In this article we present the design and implementation of a prototype for video surveillance that allows to manage IP cameras from different manufacturers through a single application implemented with free software tools and free hardware. Several currently existing applications work with proprietary applications and IP cameras from the same manufacturer, however, in this article we demonstrate that management is more efficient through our unique system that allows generating remote alerts through SMS messages and notifications by electronic mail after the activation of a sensor. Our article describes the existing problems in residential security systems, applied to the case of the City of Cuenca-Ecuador, as well as the technical development of the system in relation to server configuration, client equipment and an Android application developed in IONIC Framework. Finally, we describe the results of the different connectivity tests of the system generating events through the internet cloud, to determine performance and connectivity times in a real operating environment.","","Abril B,Jara JD,Cuzco P,Gallegos P","","2020","","10.1145/3387168.3387194","https://doi-org.proxy.bnl.lu/10.1145/3387168.3387194;http://dx.doi.org/10.1145/3387168.3387194","Conference Paper"
"Development of Hepatitis Disease Detection System by Exploiting Sparsity in Linear Support Vector Machine to Improve Strength of AdaBoost Ensemble Model","Hepatitis disease is a deadliest disease. The management and diagnosis of hepatitis disease is expensive and requires high level of human expertise which poses challenges for the health care system in underdeveloped and developing countries. Hence, development of automated methods for accurate prediction of hepatitis disease is inevitable. In this paper, we develop a diagnostic system which hybridizes a linear support vector machine (SVM) model with adaptive boosting (AdaBoost) model. We exploit sparsity in linear SVM that is caused by L1 regularization. The sparse L1-regularized SVM is capable of eliminating redundant or irrelevant features from feature space. After filtering features through the sparse linear SVM, the output of the SVM is applied to the AdaBoost ensemble model which is used for classification purposes. Two types of numerical experiments are performed on the clinical features of hepatitis disease collected from UCI machine learning repository. In the first experiment, only conventional AdaBoost model is used, while in the second experiment, a feature vector is applied to the sparse linear SVM before its application to the AdaBoost model. Simulation results demonstrate that the strength of a conventional AdaBoost model is enhanced by 6.39% by the proposed method, and its time complexity is also reduced. In addition, the proposed method shows better performance than many previously developed methods for hepatitis disease prediction.","","Akbar W,Wu WP,Saleem S,Farhan M,Saleem MA,Javeed A,Ali L,Bashir AK","","2020","","10.1155/2020/8870240","https://doi-org.proxy.bnl.lu/10.1155/2020/8870240;http://dx.doi.org/10.1155/2020/8870240","Journal Article"
"Development of SWIM Registry for Air Traffic Management with the Blockchain Support","System Wide Information Management (SWIM) including SWIM Registry for Air Traffic Management (ATM) has been successfully developed and applied in Europe and United States. The most developing countries have just started to study the employment of SWIM concept, which its establishment is required prior to the development of SWIM Registry. In this paper, we introduce the experience of the development of SWIM Registry Brazil, which comprises the study of the architecture, components, services and data accessing. In order to encourage consumers and providers to participate in the SWIM community, we developed a prototype of SWIM Registry Demonstration for the Brazilian ATM society. We propose a model based on Blockchain for managing services currently provided by Brazilian ATM in order to certificate operations which are performed by consumers, authorities and involved stakeholders. The proposed model is expected to provide services for SWIM Registry with integrity, efficiency, security and authenticity, which are fundamental for the proper operation of Brazilian aviation system.","","Bonomo IS,Barbosa IR,Monteiro L,Bassetto C,de Barros Barreto A,Borges VR,Weigang L","","2018","3544–3549","10.1109/ITSC.2018.8569223","https://doi-org.proxy.bnl.lu/10.1109/ITSC.2018.8569223;http://dx.doi.org/10.1109/ITSC.2018.8569223","Conference Paper"
"Digital Apartheid: An Ethnographic Account of Racialised Hci in Cape Town Hip-Hop","We describe findings from a 15-month ethnography of hip-hop performers in Cape Town, South Africa. Mobile communications and social media are hugely important to the development of these performers' careers, opening access to collaborators, production tools, audiences and distribution channels. This group go to extraordinary lengths to gain and maintain access to these technologies, often by exploiting their social capital through musical and ethnic networks. We document that even after nearly twenty years of democracy, a ridged separation along racial lines persists, which can be seen in all areas of life including access to and proficiency in digital technologies. We illustrate how hip-hop performers harness these divisions both on and offline in order to distinguish themselves from other artists. Our research raises a number of implications for post-colonial computing, highlighting difficulties related to discontinuous access, and how international preconceptions of identity and authenticity emerge as a consequence of the increased use of communication technology.","","Pritchard GW,Vines J","","2013","2537–2546","10.1145/2470654.2481350","https://doi-org.proxy.bnl.lu/10.1145/2470654.2481350;http://dx.doi.org/10.1145/2470654.2481350","Conference Paper"
"Digital Competencies for Developing and Managing Digital Libraries","PurposeThe purpose of this study was to explore the essential digital competencies for developing and managing digital libraries. The study identified useful training programs for university librarians to acquire digital competencies. It examined their digital competencies for developing and managing digital libraries in universities of Pakistan. This study also evaluates their digital knowledge in applying security measures to protect digital contents.Design/methodology/approachThe quantitative research method was used to conduct this study. Research questions and hypothesis were developed to achieve the objectives. In-depth review of related literature was conducted to draft a list of essential digital competencies for developing and managing digital libraries. It was circulated among the panel of experts to get their valuable feedback to make a final list of digital competencies for developing and managing digital libraries. A questionnaire was developed to measure the status of digital competencies of university librarians in Pakistan. It was pre-tested on 20 respondents before applying to the whole population. SPSS software was used to analyze data. Descriptive and inferential statistics were applied to achieve results.FindingsThe findings of the study showed that digital competencies for developing and managing digital libraries fall into three main categories: digital competencies for developing digital libraries; digital competencies for managing digital libraries; and digital competencies to protect digital contents. The results revealed that training programs offered by Higher Education Commission HEC, library associations, library schools, in-house trainings, use of online tutorials and trainings offered by skilled professionals are highly important and useful for university librarians to acquire digital competencies. The study concluded that the university librarians working in HEC recognized universities in Punjab province possess basic level of digital competencies for developing and managing digital libraries. Their digital competencies vary on the basis of their university type, i.e. public and private sector.Research limitations/implicationsThis study measures digital competencies of university librarians in Pakistan. The study has practical implications for librarians, library schools, library associations, university libraries and HEC.Practical implicationsThis study has practical implications for librarians, information professionals, libraries and library schools. The results are useful for librarians to get knowledge of digital competencies which are essential for developing and managing digital libraries and protecting digital contents. They can develop their digital competencies in identified areas. This study has identified useful training programs for university librarians for acquiring digital competencies. The university librarians should use these programs to gain needed digital skills.Social implicationsLibrarians can get knowledge of digital competencies for developing and managing digital libraries to face the challenges of digital age.Originality/valueIn contrast to previous research work on investigating computer skills, information and communication technology skills, technological skills and general digital skills, this study particularly identifies the essential digital competencies for developing and managing digital libraries. It helps library and information science schools, library associations, training groups and university libraries to offer adequate training opportunities in identified areas to meet the challenges of the digital age.","","","","2017","573–597","10.1108/EL-06-2016-0133","https://doi-org.proxy.bnl.lu/10.1108/EL-06-2016-0133;http://dx.doi.org/10.1108/EL-06-2016-0133","Journal Article"
"DyadChurn: Customer Churn Prediction Using Strong Social Ties","The increase in mobile phone subscriptions in recent years, has led to near market saturation in the telecom industry. As a result, it has become harder for telecom providers to acquire new customers, and the need for retaining existing ones has become of paramount importance. Because of fierce competition between different telecom providers and because the ease of which customers can move from one provider to another, all telecom service providers suffer from customer churn. In this paper, we propose a dyadic based churn prediction model, DyadChurn, where customer churn is modeled through social influence that propagates in the telecom network over strong social ties. We propose a novel method for evaluating social tie strength between telecom customers. We then, incorporate strong social ties in an influence propagation model to predict the set of future potential churners. The evaluation of the proposed dyadic based churn prediction model has been done using a real dataset, from one of the largest telecom companies in Egypt. The experimental results showed that the ""length of calls"" between customers is the most effective attribute in predicting social influence that result in churning. The results also showed that strong social ties (as opposed to weak ties) were the most effective ties in determining churn. Using strong social ties only enhanced the prediction accuracy (in terms of the lift curve) by more than 20%, when compared to a diffusion model.","","Abd-Allah MN,El-Beltagy SR,Salah A","","2017","253–263","10.1145/3105831.3105832","https://doi-org.proxy.bnl.lu/10.1145/3105831.3105832;http://dx.doi.org/10.1145/3105831.3105832","Conference Paper"
"Dynamic Data Driven Transportation Systems","Congestion-induced delays and pollution in modern transportation systems remain formidable impediments to the sustainable growth of our cities. Next generation Intelligent Transportation Systems (ITS) will attack these problems by relying on extensive in-vehicle sensing, crowd-sourced data, ubiquitous computing, and communications to augment existing infrastructure-based deployments. Advances in wireless networking and mobile computing have made it possible to create dynamic, data driven application systems (DDDAS) that address many challenges in modern transportation systems. We outline a vision for future dynamic data-driven transportation systems, and focus on the effectiveness of an approach to real-time management based on online simulations. The online simulations are embedded in the traffic network where distributed simulators perform the modeling task individually but project the future states collectively. A real-time data driven arterial simulation methodology is proposed to assist such computations that are performed over a testbed in the midtown area of Atlanta, Georgia. Field results are presented that provide evidence to validate the proposed approach.","","Suh W,Henclewood D,Guin A,Guensler R,Hunter M,Fujimoto R","","2017","25253–25269","10.1007/s11042-016-4318-x","https://doi-org.proxy.bnl.lu/10.1007/s11042-016-4318-x;http://dx.doi.org/10.1007/s11042-016-4318-x","Journal Article"
"Dynamic Security Analysis of Power Systems by a Sampling-Based Algorithm","Dynamic security analysis is an important problem of power systems on ensuring safe operation and stable power supply even when certain faults occur. No matter if such faults are caused by vulnerabilities of system components, physical attacks, or cyber-attacks that are more related to cyber-security, they eventually affect the physical stability of a power system. Examples of the loss of physical stability include the Northeast Blackout of 2003 in North America and the 2015 system-wide blackout in Ukraine. The nonlinear hybrid nature, that is, nonlinear continuous dynamics integrated with discrete switching, and the high degree of freedom property of power system dynamics make it challenging to conduct the dynamic security analysis. In this article, we use the hybrid automaton model to describe the dynamics of a power system and mainly deal with the index-1 differential-algebraic equation models regarding the continuous dynamics in different discrete states. The analysis problem is formulated as a reachability problem of the associated hybrid model. A sampling-based algorithm is then proposed by integrating modeling and randomized simulation of the hybrid dynamics to search for a feasible execution connecting an initial state of the post-fault system and a target set in the desired operation mode. The proposed method enables the use of existing power system simulators for the synthesis of discrete switching and control strategies through randomized simulation. The effectiveness and performance of the proposed approach are demonstrated with an application to the dynamic security analysis of the New England 39-bus benchmark power system exhibiting hybrid dynamics. In addition to evaluating the dynamic security, the proposed method searches for a feasible strategy to ensure the dynamic security of the system in the face of disruptions.","","Wu Q,Koo TJ,Susuki Y","","2018","","10.1145/3208093","https://doi-org.proxy.bnl.lu/10.1145/3208093;http://dx.doi.org/10.1145/3208093","Journal Article"
"E-Government Initiatives in Ethiopia","E-Government, considered to be a narrower concept than e-Governance, offers a great potential and opportunity for developing countries to improve their governance and citizen satisfaction. E-Government reduces costs, increases transparency and citizen participation in decision-making processes, strengthens accountability, improves service delivery, etc. In the process of setting up e-Government initiatives and to become successful, there are some prime issues for developing countries to assess and to research. In developing nations where capital is a major scarcity, failing to be successful in the implementation of information communication technology (ICT) initiatives can have a great impact. In case of faller, the leadership commitment, which is already low in some countries, could be greatly affected.This will cause major obstacles to get some other ICT project's approved. ICT is a capital intensive (for example in infrastructure and application development) and requires qualified human resources. Apart from this, the globalization and dynamism associated with the field are making the realization of e-Government in particular in developing countries more challenging. Implementing e-Government principles and functions require a range of standards, guidelines, rules, policies and legislative changes which do not exist in most developing countries. These all add up to the challenges in e-Government implementation. The following are also potential threats in implementing e-Government: low level working culture, high resistance, weak private sector, low level collaboration/partnership between private and public sectors, etc.In this case study, I will assess the potential of e-Government projects and initiatives for developing countries by taking the case of the Federal Democratic Republic of Ethiopia. The opportunities will be widely discussed by taking practical examples. I will also identify and analyze major challenges that may be encountered in implementing e-Government initiatives based on my practical experience in Ethiopia.","","Belachew M","","2010","49–54","10.1145/1930321.1930332","https://doi-org.proxy.bnl.lu/10.1145/1930321.1930332;http://dx.doi.org/10.1145/1930321.1930332","Conference Paper"
"Earthquake Risk to Inca's Historical Constructions in Machupicchu","The citadel of Machupicchu is probably the most famous Inca heritage site in Peru. Considering the seismically active region, this research is an attempt to perform a seismic risk analysis of the heritage structures at Machupicchu. A systematic approach is adopted for this purpose. Characteristic seismicity of the region, where these historical constructions are located, is discussed based on the seismic hazard analysis. Evaluation of the vulnerability of the structures under the prevalent earthquake hazard is another important aspect essential for risk analysis. As a first step to proper understanding of the seismic behavior of these heritage structures, typical elements of Inca construction are studied by simple analytical models to verify basic aspects of structural integrity. The possibility that peak ground acceleration corresponding to even relatively low hazard may produce instability in some structural components like gable walls was noted. In view of this preliminary result, attempt was made to identify the dynamic characteristics of typical buildings units from more detailed investigation. This forms part of the outcome from the field study program, which included microtremor measurement of free field as well as typical constructions, planned and undertaken by the authors. The results of the microtremor measurements are utilized to estimate the dynamic characteristics of the Inca stone structures. That is, the analytical results are compared with the measurements to calibrate the analytical model. Since microtremor measurements involve very small displacements, the characteristics of stones structures thus obtained correspond to elastic behavior applicable to small strain condition. Based on this scheme, an approach has been proposed to evaluate the seismic behavior and hence the seismic vulnerability of these structures. The procedure also permits identification of the probable mode of failure of the structures concerned.","","Cuadra C,Karkee MB,Tokeshi K","","2008","336–345","10.1016/j.advengsoft.2007.01.002","https://doi-org.proxy.bnl.lu/10.1016/j.advengsoft.2007.01.002;http://dx.doi.org/10.1016/j.advengsoft.2007.01.002","Journal Article"
"Editorial Message: Special Track on Web and E-Business Applications","The World WideWeb has become the standard computing platform for the development of new-generation information systems. A new tide of Web-based e-business applications (such as corporate portals, network-based supply chains and market places, etc.) is driving the need for a more open, flexible and distributed infrastructure, together with appropriate development methodologies and theoretical settings. Today's web applications involve skills from many different areas of computer science, including databases, AI and agent based applications, programming languages and algorithms, distributed computing, information retrieval, semantic modeling, etc. For this reason we proposed a track on Web and E-business applications based on the following main topics: data models for the World Wide Web, Web data management, languages for the World Wide Web and XML, E- business and Web services, transactions on the World Wide Web, security and integrity issues for the WWW, query systems for the World Wide Web, management and storage of Web information, information retrieval and search engines for the Web, Web semantics, data integration over the World Wide Web, data-intensive applications on the World Wide Web, Web architectures.We received 30 submissions, which were extensively reviewed for originality, significance, technical soundness and clarity of presentation. The submitted papers covered most of the proposed topics. The number of submissions distributed on each continent has been the following: 16 from Europe (53%), 9 from North America (30%), 3 from Asia (10%), 1 from Africa (3%) and 1 from Australia (3%). 12 papers corresponding to the 40% of the submitted papers have been selected for presentation at the conference, with the following distribution: 7 from Europe, 3 from America, 1 from Asia and 1 from Australia.","","Comai S,Tanca L","","2002","1086–1087","10.1145/508791.509005","https://doi-org.proxy.bnl.lu/10.1145/508791.509005;http://dx.doi.org/10.1145/508791.509005","Conference Paper"
"Efficient Architecture for Controlled Accurate Computation Using AVX","Several applications have problems with the representation of the real numbers because of its drawbacks like the propagation and the accumulation of errors. These numbers have a fixed length format representation that provides a large dynamic range, but on the other hand it causes truncation of some parts of the numbers in case of a number that needs to be represented by a long stream of bits. Researchers suggested many solutions for these errors, one of these solutions is the Multi-Number (MN) system. MN system represents the real number as a vector of floating-point numbers with controlled accuracy by adjusting the length of the vector to accumulate the non-overlapping real number sequences. MN system main drawback is the MN computations that are iterative and time consuming, making it unsuitable for real time applications. In this work, the Single Instruction Multiple Data (SIMD) model supported in modern CPUs is exploited to accelerate the MN Computations. The basic arithmetic operation algorithms had been adjusted to make use of the SIMD architecture and support both single and double precision operations. The new architecture maintains the same accuracy of the original one, when was implemented for both single and double precision. Also, in this paper the normal Gaussian Jordan Elimination algorithm was proposed and used to get the inverse of the Hilbert Matrix, as an example of ill-conditioned matrices, instead of using iterative and time-consuming methods. The accuracy of the operations was proved by getting the inverse of the Hilbert Matrix and verify that the multiplication of the inverse and the original matrix producing the unity matrix. Hilbert Matrix inverse execution time was accelerated and achieved a speedup 3x, compared to the original NM operations. In addition to the previous, the accelerated MN system version was used to solve the polynomial regression problem.","","Osman DM,Sobh MA,Bahaa-Eldin AM,Zaki AM","","2018","121–125","10.1145/3220267.3220292","https://doi-org.proxy.bnl.lu/10.1145/3220267.3220292;http://dx.doi.org/10.1145/3220267.3220292","Conference Paper"
"Electric Signal Synchronization as a Behavioural Strategy to Generate Social Attention in Small Groups of Mormyrid Weakly Electric Fish and a Mobile Fish Robot","African weakly electric fish communicate at night by constantly emitting and perceiving brief electrical signals (electric organ discharges, EOD) at variable inter-discharge intervals (IDI). While the waveform of single EODs contains information about the sender’s identity, the variable IDI patterns convey information about its current motivational and behavioural state. Pairs of fish can synchronize their EODs to each other via echo responses, and we have previously formulated a ‘social attention hypothesis’ stating that fish use echo responses to address specific individuals and establish brief dyadic communication frameworks within a group. Here, we employed a mobile fish robot to investigate the behaviour of small groups of up to four Mormyrus rume and characterized the social situations during which synchronizations occurred. An EOD-emitting robot reliably evoked social following behaviour, which was strongest in smaller groups and declined with increasing group size. We did not find significant differences in motor behaviour of M. rume with either an interactive playback (echo response) or a random control playback by the robot. Still, the robot reliably elicited mutual synchronizations with other fish. Synchronizations mostly occurred during relatively close social interactions, usually when the fish that initiated synchronization approached either the robot or another fish from a distance. The results support our social attention hypothesis and suggest that electric signal synchronization might facilitate the exchange of social information during a wide range of social behaviours from aggressive territorial displays to shoaling and even cooperative hunting in some mormyrids.","","Worm M,Landgraf T,von der Emde G","","2021","599–613","10.1007/s00422-021-00892-8","https://doi-org.proxy.bnl.lu/10.1007/s00422-021-00892-8;http://dx.doi.org/10.1007/s00422-021-00892-8","Journal Article"
"Electronic Payment Adoption in the Banking Sector of Low-Income Countries","Banks in low-income countries are launching e-banking services such as Internet banking, SMS banking, ATM banking, card banking, point of sales PoS and mobile banking. Among these planned services, ATM is the most matured service in many private and state owned banks in Ethiopia. ATM is a recent phenomenon in low-income countries ;, and is still being introduced in financial sectors in low-income countries Angeli, 2008; making investigation of factors of ICT technology adoption in low income countries timely. The authors test context specific applicability of UTAUT Unified Theory of Acceptance and Use of Technology model. The authors' analysis of primary data suggests general applicability of the modified UTAUT model in explaining factors and antecedents of technology adoption but also identifies significant differences in the moderating factors of gender and age. Depending on whether they are above or below the age of 30, Ethiopian consumers of banking services exhibit highly differentiated levels of service credibility and technology risk acceptance towards ATM banking. This suggests that banking services sector in low income countries may like to clearly delineate and appropriately differentiate their awareness and reach-out strategies to their customers who belong to one or the other age group. Furthermore, women in this study are found to perceive themselves as more susceptible to fraud and other security risks in ATM banking, suggesting that special design considerations be incorporated in the way locations of ATMs are selected and in the way ATM technology features are accessed to ally such fears. The authors' work also shows research directions where other scholars may investigate an otherwise much diffused technology adoption in the low income countries of the world.","","Alemu T,Bandyopadhyay T,Negash S","","2015","27–47","","","Journal Article"
"Eliciting Local Spatial Knowledge for Community-Based Disaster Risk Management: Working with Cybertracker in Georgian Caucasus","CyberTracker CT participatory field data collection software is used as an element of Participatory GIS for acquiring, geo-referencing, storing and transferring local spatial knowledge. It has been developed initially for animal tracking, ecological surveys and conservation management activities, but has extended into the social environment for health and welfare surveys, and it is being applied to social data collection about hazards, vulnerability and coping mechanisms in disaster risk management. This article provides a critical guide of CyberTracker under field conditions with representative participation. The practical experiences informing this critical review of field operations come from employing CyberTracker with staff of NGOs and local government agencies in a workshop in two hazard-prone communities in the Caucasus Mountains of Georgia.","","Spanu V,McCall MK","","2013","45–59","","","Journal Article"
"Empirical Study of Barriers to Electronic Commerce Adoption by Small and Medium Scale Businesses in Nigeria","Electronic commerce (E-commerce) is a technological innovation that enables small to medium enterprises (SMEs) to compete on the same level with their larger counterparts. And it has the potential to improve efficiency and productivity in many areas and, therefore, has received significant attention in many countries of the world. A thorough analysis of the impact of the internet and e-commerce across firms, industries and economies is necessary to separate hype from reality. However, several researchers have called for the investigation of the association between the perceptions of e-commerce and the barriers to its adoption in developing countries. It is however on record that SMEs the world over are faced with significant challenges that compromise their ability to function and to contribute optimally to the respective economies where they operate. This study was conducted in three states of Nigeria (Lagos, Abuja and Enugu states) with the use of interviews to gather relevant data; the aim of which was to understand the challenges which serve as barriers to E-Commerce adoption by small and medium scale enterprises in the Nigerian context. Findings indicates that small and medium scale online present is at best unknown. The most common e-Commerce applications used by most SMEs include but not limited to the use of e-mails for communication purposes and a simple website for basic product information — information contained are usually outdated as most of these websites are hardly updated. Findings revealed, among others, that lack of and total absence of a regulatory framework on e-Commerce security, as well as technical skills, and basic infrastructures are some of the barriers to electronic commerce adoption. The findings however, provide a constructive insight to financial practitioners, governments as well as other stakeholders on the need to give e-commerce a place in all aspects of e-commerce activities.","","Agwu EM,Murray PJ","","2015","1–19","","","Journal Article"
"Empirical Study of Barriers to Electronic Commerce Uptake by SMEs in Developing Economies","Electronic commerce E-commerce is a technological innovation that enables small to medium enterprises SMEs to compete on the same level with their larger counterparts. And it has the potential to improve efficiency and productivity in many areas and, therefore, has received significant attention in many countries of the world. A thorough analysis of the impact of the internet and e-commerce across firms, industries and economies is necessary to separate hype from reality. However, several researchers have called for the investigation of the association between the perceptions of e-commerce and the barriers to its adoption in developing countries. It is however on record that SMEs the world over are faced with significant challenges that compromise their ability to function and to contribute optimally to the respective economies where they operate. This study was conducted in three states of Nigeria Lagos, Abuja and Enugu states with the use of interviews to gather relevant data; the aim of which was to understand the challenges which serve as barriers to E-Commerce adoption by small and medium scale enterprises in the Nigerian context. Findings indicates that small and medium scale online present is at best unknown. The most common e-Commerce applications used by most SMEs include but not limited to the use of e-mails for communication purposes and a simple website for basic product information-information contained are usually outdated as most of these websites are hardly updated. Findings revealed, among others, that lack of and total absence of a regulatory framework on e-Commerce security, as well as technical skills, and basic infrastructures are some of the barriers to electronic commerce adoption. The findings however, provide a constructive insight to financial practitioners, governments as well as other stakeholders on the need to give e-commerce a place in all aspects of e-commerce activities.","","Agwu EM,Murray PJ","","2015","1–19","","","Journal Article"
"Employee Perceptions of BYOD in South Africa: Employers Are Turning a Blind Eye?","As mobile Information and Communication Technologies (ICTs) become greater entrenched in society and with the nature of work changing, more and more international organizations are embracing and/or considering formalizing the phenomenon of 'Bring Your Own Device' (BYOD). The gist of BYOD is the use of privately owned devices and software to access and work with organizational resources. There is however little that is known about the degree to which organizations in South Africa are embracing the BYOD phenomenon. In this paper, we explored how employees in organizations in South Africa perceive the use of their privately owned devices for work. The results from 61 employees suggest that there is a strong awareness of the BYOD concept among employees. Employees also appear to believe that although their employers are aware of the use of privately owned devices for work, the employers are reluctant to formally create BYOD organizational strategies. The findings suggest that the laxity of employers in South Africa to deal with the BYOD phenomenon as an issue of strategic importance could result in considerable security challenges for organizational data.","","Twinomurinzi H,Mawela T","","2014","126–131","10.1145/2664591.2664607","https://doi-org.proxy.bnl.lu/10.1145/2664591.2664607;http://dx.doi.org/10.1145/2664591.2664607","Conference Paper"
"Energy Efficiency of Encryption Schemes Applied to Wireless Sensor Networks","In this paper, we focus on the energy efficiency of secure communication in wireless sensor networks (WSNs). Our research considers link layer security of WSNs, investigating both the ciphers and the cryptographic implementation schemes, including aspects such as the cipher mode of operation and the establishment of initialization vectors (IVs). We evaluate the computational energy efficiency of different symmetric key ciphers considering both the algorithm characteristics and the effect of channel quality on cipher synchronization. Results show that the computational energy cost of block ciphers is less than that of stream ciphers when data are encrypted and transmitted through a noisy channel. We further investigate different factors affecting the communication energy cost of link layer cryptographic schemes, such as the size of payload, the mode of operation applied to a cipher, the distribution of the IV, and the quality of the communication channel. A comprehensive performance comparison of different cryptographic schemes is undertaken by developing an energy analysis model of secure data transmission at the link layer. This model is constructed considering various factors affecting both the computational cost and communication cost, and its appropriateness is verified by simulation results. In conclusion, we recommend using a block cipher instead of a stream cipher to encrypt data for WSN applications and using a cipher feedback scheme for the cipher operation, thereby achieving energy efficiency without compromising the security in WSNs. Copyright © 2011 John Wiley & Sons, Ltd.(This study is based on “An analysis of link layer encryption schemes in wireless sensor networks” by X. Zhang, H. M. Heys, and C. Li, which appeared in the Proceedings of IEEE International Conference on Communications (ICC 2010), Cape Town, South Africa, May 2010, and “Energy efficiency of symmetric key cryptographic algorithms in wireless sensor networks” by X. Zhang, H. M. Heys, and C. Li, which appeared in the Proceedings of Biennial Symposium on Communications (QBSC 2010), Kingston, Canada, May 2010. ©2010 IEEE.)","","Zhang X,Heys HM,Li C","","2012","789–808","10.1002/sec.375","https://doi-org.proxy.bnl.lu/10.1002/sec.375;http://dx.doi.org/10.1002/sec.375","Journal Article"
"Engaging High School Students in Cameroon with Exam Practice Quizzes via SMS and WhatsApp","We created a quiz-based intervention to help secondary school students in Cameroon with exam practice. We sent regularly-spaced, multiple-choice questions to students' own mobile devices and examined factors which influenced quiz participation. These quizzes were delivered via either SMS or WhatsApp per each student's preference. We conducted a 3-week deployment with 546 students at 3 schools during their month of independent study prior to their graduating exam. We found that participation rates were heavily impacted by trust in the intervening organization and perceptions of personal security in the socio-technical environment. Parents also played a key gate-keeping role on students' digital activities. We describe how this role - along with different perceptions of smartphones versus basic phones - may manifest in lower participation rates among WhatsApp-based users as compared to SMS. Finally, we discuss design implications for future educational interventions that target students' personal cellphones outside of the classroom.","","Poon A,Giroux S,Eloundou-Enyegue P,Guimbretiere F,Dell N","","2019","1–13","10.1145/3290605.3300712","https://doi-org.proxy.bnl.lu/10.1145/3290605.3300712;http://dx.doi.org/10.1145/3290605.3300712","Conference Paper"
"Enhancing E/M-Government Synergy in Kenya: Citizens’ Perspectives on the Driving Factors for M-Government Diffusion","This research investigated the driving factors of mobile government diffusion as antecedents that expand the specificity and explanatory power of traditional technology adoption models in mobile contexts. A robust conceptual model for evaluating the adoption of electronic and mobile government services is proposed. Focusing on the first component of the model, namely, the drivers of m-government diffusion, five innovation attributes that influence the decision to adopt m-government were examined. Following a qualitative approach based on grounded theory, 91 mobile phone users were interviewed using a questionnaire. Five attributes of diffusion of innovation were investigated: relative advantage, complexity, compatibility, trialability, and observability. The qualitative data obtained was coded and analyzed for theme frequency distribution. The driving factors that emerged from the themes were: accessibility, efficiency, connectivity and time-saving (dominant factors); convenience, user-friendly, features and service provider (moderate factors), and cost and security (minor factors). Future research should consider how the key driving factors for m-government diffusion can be leveraged to facilitate greater adoption of and synergy between e- and m-government. Empirical validation of the conceptual model is recommended to confirm its appropriateness in enhancing the adoption of electronic and mobile government services in Sub-Saharan Africa.","","Wakhu SM,Fuyuan X,Kakonge JO","","2020","121–137","10.1007/978-3-030-50350-5_11","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-50350-5_11;http://dx.doi.org/10.1007/978-3-030-50350-5_11","Conference Paper"
"Enterprise Grade Cloud Computing","Cloud computing and the as-a-service paradigm have gained a lot of interest recently. The separation of service provider from infrastructure provider has made it much easier for new services to be established online quickly and with low financial risk, and to scale those services as demand dictates. They can be built to run directly on top of infrastructure such as Amazon EC2 [1], on application platforms such as Google App Engine [3], or within higher level platforms such as FaceBook [2] or force.com [6], with increasing levels of ease of development and task specialization.It is clear why a startup company might be attracted to the cloud computing model. Equipment is very costly to purchase and can only be amortized over a period of years. Using someone else's infrastructure on a pay-per-use basis converts this fixed cost into a variable cost based on actual consumption; reducing initial investment and risk. Also the demand for online services can be very variable and poor response due to overload can risk losing customers. So the ability to scale the use of cloud compute power also mitigates the risk of failure.The arguments for an established enterprise are not the same. Such a business would have a well understood compute capacity and multi-year investment lifecycles. As the financial risk becomes less significant other issues come into play such as security, legislation, and dependence on the provider. Exactly where data resides is important as it will be accountable to the local legal system, especially where the main line of business is concerned. Security requirements may not be compatible with those offered by existing infrastructure providers.In reality enterprises already use a mix of services, some in-house, some contracted out. They may use a pay-per-use model to access outsourced payroll, travel arrangement, or even legal services. These may be provided by a cloud computing platform and integrated with further services such as credit card payment and courier distributors.For in-house services there may still be a cost advantage in using someone else's infrastructure -- if they are big enough. Studies have shown that the proportional cost of building and running data centers with tens of thousands of machines is significantly lower than one with just a few hundred. Where an enterprise does retain its own internal systems for IT or its main line of business, it is likely to be interested in using a private cloud; its own internal infrastructure and services managed in just the same way as an external cloud provider would do. But they may also be interested expanding out to external clouds to accommodate peak demands. An enterprise is likely to straddle the line between self-owned, on-premises compute facilities and third party cloud infrastructure.The future will bring a world of services interacting securely and running across multiple infrastructures, scaling and distributing as required. These considerations provide drivers for cloud computing research, both at service level and infrastructure level.At HP Labs we have been investigating service provision in a shared compute infrastructure for more than a decade. Past prototypes include SoftUDC [5], Frame Factory/SE3D, and the HP Utility Rendering Service [4] used by DreamWorks to create the Shrek and Madagascar movies among others. During the course of this work we have addressed a variety of challenges. How can clients with low bandwidth connectivity interact effectively with a service that involves very large volumes of data? How can independent services operate, flex and scale within the same shared infrastructure yet achieve sufficient isolation at the data and service levels? How can data and services be managed across multiple geographically distributed data centers?In addition to the technical challenges we also experienced client behaviors during these trials that have both motivated the use of cloud computing for individual users, but at the same time challenged the economics of the whole paradigm.Our current research addresses the challenges of enterprise-grade cloud computing, starting with the question: what would cloud computing need to provide for enterprises and enterprise service providers? In this talk we discuss our view of cloud computing and what we are doing to address the challenges of this new paradigm.","","Murray P","","2009","1","10.1145/1518691.1518692","https://doi-org.proxy.bnl.lu/10.1145/1518691.1518692;http://dx.doi.org/10.1145/1518691.1518692","Conference Paper"
"Equivalences Among Polarity Algorithms","The concept of polarity is pervasive in natural language. It relates syntax, semantics and pragmatics narrowly (Giannakidou, in: Maienborn, von Heusinger, Portner (eds.), Semantics: an international handbook of natural language meaning, De Gruyter Mouton, Berlin, 2011; Israel in The grammar of polarity: pragmatics, sensitivity, and the logic of scales, Cambridge studies in linguistics, Cambridge University Press, Cambridge, 2014), it refers to items of many syntactic categories such as nouns, verbs and adverbs. Neutral polarity items appear in affirmative and negative sentences, negative polarity items cannot appear in affirmative sentences, and positive polarity items cannot appear in negative sentences. A way of reasoning in Natural Language is through Natural Logic (van Benthem in Essays in logical semantics, vol. 29 of Studies in linguistics and philosophy, Reidel, Dordrecht, 1986; Language in action: categories, lambdas, and dynamic logic, vol. 130 of Studies in logic, Elsevier, Amsterdam, 1991). This logic is based on the concept of polarity in order to make the meaning of a sentence weaker o stronger without changing its truth value. There exist many proposals to compute polarity in the Natural Logic context, the most widely known are the ones by: van Benthem (1986, 1991), Sánchez-Valencia (Studies on natural logic and categorial grammar, Ph.D. thesis, Universiteit van Amsterdam, 1991), Dowty (Proceedings of the 4th conference on semantics and theoretical linguistics, Cornel University, CLC Publications, Rochester, 1994), and van Eijck (in: ten Cate, Zeevat (eds.), 6th international Tbilisi symposium on logic, language, and computation, Batumi, Georgia, Springer, 2007). If Natural Logic is going to be used, as an inferential mechanism between text fragments, in Natural Language Processing applications such as text summarization, question answering, and information extraction, it is a priority to know what the existing relationship among the aforementioned algorithms is; for example, to implement the most general. We show in this paper the equivalence among the analyzed algorithms, filling a gap in Natural Logic research, particularly in computing polarity, and the soundness of their algorithms.","","Lavalle-Martínez JJ,Montes-Y-Gómez M,Villaseñor-Pineda L,Jiménez-Salazar H,Bárcenas-Patiño IE","","2018","371–395","10.1007/s11225-017-9743-y","https://doi-org.proxy.bnl.lu/10.1007/s11225-017-9743-y;http://dx.doi.org/10.1007/s11225-017-9743-y","Journal Article"
"Estimating Performance Efficiency of Mining and Extracting Sectors Using DEA Models: The Case of Jordan","In this study, we estimated the performance efficiency of the Jordanian mining and extracting sector based on Data Envelopment Analysis (DEA). The utilized dataset includes 6 out of 15 corporations that reflect around 90% of the total market capitalization under the mining and extracting sector in the Amman Stock Exchange (ASE). The sample consists of 126 observations from 2000 to 2020. It should be noted that estimating the efficiency of the sector based on time series for each company is not mentioned in the literature review. Therefore, we applied BCC (Banker–Charnes–Cooper) models to estimate performance efficiency and compared between input and output models under DEA. We also estimated the average performance efficiency of the sector to detect weaknesses/strengths among companies. The market capitalization and the operating revenue are used to evaluate the companies’ performance. In addition to the performance variables as output to the DEA models, the current assets, non-current assets, operating expenses, and general administrative expenses are also used as input variables under the DEA models. This study also examined the effect of Gross Domestic Product (GDP) growth and Return on Assets (ROA) on performance efficiency scores for BCC models. In the results, we found that there are differences in performance efficiency across time series in each company based on dynamic BCC models. It is observed that the performance efficiency of NAST Company is better than the other companies based on BCC (Input/output). The GDP growth and ROA reveal the effect on efficiency performance under BCC models. The proposed model can be used to improve the performance efficiency of companies in stock exchange markets.","","Jaber JJ,Beldjilali F,Shehadeh AA,Hamadneh NN,Saleh M,Tahir M,Al Wadi S,Zhou Y","","2022","","10.1155/2022/3688381","https://doi-org.proxy.bnl.lu/10.1155/2022/3688381;http://dx.doi.org/10.1155/2022/3688381","Journal Article"
"Estimation of Evapotranspiration Using Fused Remote Sensing Image Data and Energy Balance Model for Improving Water Management in Arid Area","Remote sensing has proved to be very useful in the investigation of vegetation and hydrological monitoring, especially when studying vast areas. In this paper, the complement between two optical remote sensing data (Landsat TM and NOAA- AVHRR) and a Digital Elevation Model (DEM) is used to estimate hydrological parameters based on derived surface reflectance. These parameters which are used in the Modified Soil Energy Balance Algorithm for Land (M-SEBAL) model have been used to estimate net radiation, soil heat flux, sensible heat flux and evapotranspiration (ET) for Sana’a Basin in Yemen. The area is known for arid and semi-arid weather conditions with undulating topography. Image data from AVHRR on-board NOAA satellites with a large areal coverage, good temporal and spectral resolution are found to be very useful in generating some parameters required for the above process. However, the data have poor spatial resolution. On the other hand, image data from the Thematic Mapper on-board the Landsat satellite, with a high spatial and spectral resolution should be able to provide values for the parameters involved, but the area coverage is significantly reduced. This study has been carried out, using a data fusion technique in order to exploit the respective advantages of these two disparate sources of image data. A general framework is then proposed to generate ET maps for arid and semi-arid regions. This is achieved by means of multi-temporal, multi-resolution remote sensing data. Taking into account topographic effects, an attempt has also been made to incorporate DEM information for estimating the net radiation of the areas involved. An application for computing a daily ET map over Sana’a Basin, Yemen is presented. As a result, a daily ET map generated from meteorological observations was compared with estimated ET data simulated from remote sensing data. In conclusion, data from both remote sensing sources give reasonable values with the result from the TM being better than those obtained from the AVHRR. This is attributed to the differences in spatial resolution, in which TM data is higher than AVHRR. The fusion of the two shows improves spatial detail whilst maintaining the spectral signature close to the original.","","Almhab A,Busu I","","2009","529–533","10.1109/ICCET.2009.228","https://doi-org.proxy.bnl.lu/10.1109/ICCET.2009.228;http://dx.doi.org/10.1109/ICCET.2009.228","Conference Paper"
"European Union's Green Smart Directive or How Resource-Conscious Smart Systems Saved the World","In the 2020s, the devastating effects of anthropogenic climate change became unmistakable. Floods, storms, the mass extinction of flora and fauna, the threats of further pandemics, as well as Russia's war with Ukraine made it necessary for Europeans to act immediately. While the public was still wrangling about the best way to become more resource-conscious, in 2026 the European Union passed a directive that bound “smart”, artificial-intelligence-infused technologies to the goal of reducing resource consumption by law – the Green Smart directive. The present paper traces the impact of Green Smart in three everyday domains: laundry, mobility, and gardening. It shows that Green Smart led to a “decentering” of the human with beneficial effects on the planet as well as individual wellbeing. Upon release of the directive, smart systems immediately installed policies of CO2 avoidance and resource-saving, which had been discussed for centuries already, but had never actually been implemented. While this was accompanied by fierce debates about “freedom” and the “enslavement” of humanity by technology, in everyday life, the policies led to an almost instant reduction in resource consumption. New and adapted everyday practices appeared quickly, and many of them changed people's lives clearly for the better. In general, humanity's attitude toward technology changed profoundly. Instead of expecting technology to be a mere tool, always under the immediate control of people and to be used for whatever people saw fit, technology became understood as a powerful “other”, with its own needs and goals – even if those were designed by humans themselves. Instead of using technology, people started to cooperate and negotiate with technology about better ways of living.","","Hassenzahl M,Dörrenbächer J,Laschke M,Sadeghian S","","2022","","10.1145/3546155.3547277","https://doi-org.proxy.bnl.lu/10.1145/3546155.3547277;http://dx.doi.org/10.1145/3546155.3547277","Conference Paper"
"Evaluating Digital Economy in the Covid-19 Pandemic Era: A Review","The development of the digital economy in Indonesia is increasing, including Micro, Small, and Medium Enterprises (MSMEs). The digital platform is a solution for MSMEs under threat due to the impact of the Covid-19 pandemic. Indonesia's government collaboration with private sectors has initiated some efforts to recover the national economy. These efforts included developing digital platforms such as e-commerce platforms, digital wallets, and various applications that support the distribution of goods and services that business actors have widely used. The digital platforms that MSMEs have widely used need to be further evaluated for their impact on business processes and economic recovery. This paper performed a bibliometric analysis and delivered a narrative review on developing a digital platform that can be used by MSMEs. The narrative reviews reveal some findings: 1) the digital platforms can used by MSME players, and 2) the method's effectiveness in evaluating the social impact of implementing digital platforms. Furthermore, we pointed the highlight of the digital platform for MSMEs development in Indonesia. In comparison, we also exemplified the situation in Nigeria as a benchmark. As a result, this study proposes a method that can be adopted to evaluate the social impact of implementing digital platforms by MSME players. In the next stage, we consider evaluating the social impact of digital platforms implementation by MSME players.","","Kushadiani SK,Nugroho B,Mardian S,Muhammad-Bello B,Hermawan A","","2021","80–85","10.1145/3479645.3479653","https://doi-org.proxy.bnl.lu/10.1145/3479645.3479653;http://dx.doi.org/10.1145/3479645.3479653","Conference Paper"
"Evaluation and Comparison of Satellite-Based Rainfall Products in Burkina Faso, West Africa","The performance of seven operational high-resolution satellite-based rainfall products – Africa Rainfall Estimate Climatology ARC 2.0, Climate Hazards Group InfraRed Precipitation with Stations CHIRPS, Precipitation Estimation from Remotely Sensed Information using Artificial Neural Networks PERSIANN, African Rainfall Estimation RFE 2.0, Tropical Applications of Meteorology using SATellite TAMSAT, African Rainfall Climatology and Time-series TARCAT, and Tropical Rainfall Measuring Mission TRMM daily and monthly estimates – was investigated for Burkina Faso. These were compared to ground data for 2001–2014 on a point-to-pixel basis at daily to annual time steps. Continuous statistics was used to assess their performance in estimating and reproducing rainfall amounts, and categorical statistics to evaluate rain detection capabilities. The north–south gradient of rainfall was captured by all products, which generally detected heavy rainfall events, but showed low correlation for rainfall amounts. At daily scale they performed poorly. As the time step increased, the performance improved. All except TARCAT provided excellent scores for Bias and Nash–Sutcliffe Efficiency coefficients, and overestimated rainfall amounts at the annual scale. RFE performed the best, whereas TARCAT was the weakest. Choice of product depends on the specific application: ARC, RFE, and TARCAT for drought monitoring, and PERSIANN, CHIRPS, and TRMM daily for flood monitoring in Burkina Faso.","","Dembélé M,Zwart SJ","","2016","3995–4014","10.1080/01431161.2016.1207258","https://doi-org.proxy.bnl.lu/10.1080/01431161.2016.1207258;http://dx.doi.org/10.1080/01431161.2016.1207258","Journal Article"
"Evaluation of User Experience and Cognitive Load of a Gamified Cognitive Training Application for Children with Learning Disabilities","This study presents a gamified application for children with learning disabilities, designed to train and improve working memory. The application takes the form of a treasure hunt, and is designed according to a framework incorporating guidelines derived from accessibility, usability and cognitive load theory, and from gamification techniques. The aim is to exploit working memory capacity, motivate and engage the child in working memory training activities. The main focus of this study is the evaluation of the user experience and the cognitive load level of this gamified application. A sample of 12 Egyptian children with learning disabilities completed a five-week training period using the application, followed by an evaluation process. The evaluation took the form of a simple usability survey, an unstructured observation, and a cognitive load measurement scale. The purpose was to evaluate the children's perceived experience and assess the level of cognitive load experienced in each of the activities. The results revealed that all the children enjoyed playing the gamified application, were eager to participate in the daily training, and the cognitive load experienced during the training was found to be generally appropriate - although some areas for improvement were identified. Finally, the experiments identified a correlation between user experience, cognitive load and training performance.","","Shaban A,Pearson E","","2020","","10.1145/3371300.3383341","https://doi-org.proxy.bnl.lu/10.1145/3371300.3383341;http://dx.doi.org/10.1145/3371300.3383341","Conference Paper"
"Examining the Influence of Mobile Store Features on User E-Satisfaction: Extending UTAUT2 with Personalization, Responsiveness, and Perceived Security and Privacy","Despite the rapid growth in mobile stores (e.g., Apple Store, Google Play), scholarly research in this area is still in the early stages. In particular, there is a need for more empirical analysis of how the main features of these new systems shape the customer experience. This study aims to empirically identify and validate the key factors shaping users’ satisfaction toward mobile stores. The conceptual model was proposed based on a group of the main factors from the extended Unified Theory of Acceptance and Use of Technology (UTAUT2), mobile interactivity, and perceived security and privacy. The empirical analysis was conducted in Jordan by collecting data from a convenience sample of users of mobile stores. Structural equation modelling was applied to test the current study’s model. The results support the significant impact of performance expectancy, price value, hedonic motivation, personalization, responsiveness, and perceived security and privacy on user satisfaction. Discussion of the main limitations and future research directions are also provided.","","Alalwan AA,Baabdullah AM,Rana NP,Dwivedi YK,Kizgin H","","2019","50–61","10.1007/978-3-030-29374-1_5","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-29374-1_5;http://dx.doi.org/10.1007/978-3-030-29374-1_5","Conference Paper"
"Experiences in Implementing an Experimental Wide-Area GMPLS Network","In this article, we describe our experiences in implementing an experimental wide-area GMPLS network called CHEETAH (circuit-switched end-to-end transport architecture). The key concept is to add a complementary end-to-end circuit based service with dynamic call-by-call bandwidth sharing to the connectionless service already available to end hosts via the Internet. The current CHEETAH experimental network consists of off-the-shelf GMPLS-capable SONET switches (with Ethernet interfaces) deployed at three locations, Research Triangle Park, North Carolina, Atlanta, Georgia, and Oak Ridge, Tennessee. We describe our solutions to various problems relating to control-plane design, IP addressing and control-plane security. We designed and implemented a CHEETAH software package to run on Linux end hosts connected to the CHEETAH network. Among other functions, this software package includes an RSVP-TE module to enable end users and applications to dynamically initiate requests for dedicated end-to-end circuits and receive/respond to requests for circuits. We present measurements for typical end-to-end circuit setup delays across this network. For example, end-to-end circuit setup delay from a Linux end host in NC to a host in Atlanta is 166 ms","","Zhu X,Zheng X,Veeraraghavan M","","2007","82–92","10.1109/TWC.2007.026906","https://doi-org.proxy.bnl.lu/10.1109/TWC.2007.026906;http://dx.doi.org/10.1109/TWC.2007.026906","Journal Article"
"Experimental Application of Machine Learning on Financial Inclusion Data for Governance in Eswatini","An objectives of good governance is to increase capital base of small scale businesses (SSB) in order to encourage more investments and hence increase employment rate. Embracing good financial inclusion (FI) schemes in a country helps to ensure that entrepreneurs of SSB have access to financial services and hence meet their needs. In this paper we studied FI scheme in Kingdom of Eswatini with the view to establish the extent to which SSB have access to funds in running their businesses such that they could satisfy the target population and meet their desired goals. We got FI dataset for Eswatini for 2018 from Finscope database. Finscope 2018 dataset contains 1385 attributes with 2928 records. This study extracted attributes based on payment channel, registered/unregistered business, usage of commercial banks/insurance/mobile money and source of income for households from the Finscope database. We identified lot of missing data and hence replaced them using Mode method of preprocessing module in WEKA. We split the datasets and carried out cross validation on it. Training data is 80% of the datasets and 20% was used for testing. We carefully classified FI for selected parameters for Hhohho, Manzini, Shiselweni and Lubombo regions of Eswatini using Logistic regression with 80% for training and 10 fold cross-validation. The best 10 fold cross-validation recall rate for Manzini region using support vector machine (SVM) is 69.4% and 63.4% using logistic regression. These results show that veracity of FI dataset is weak and this is due to large number of missing data.","","Akinnuwesi BA,Fashoto SG,Metfula AS,Akinnuwesi AN","","2020","414–425","10.1007/978-3-030-45002-1_36","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-45002-1_36;http://dx.doi.org/10.1007/978-3-030-45002-1_36","Conference Paper"
"Exploiting Activation Sparsity for Fast CNN Inference on Mobile GPUs","Over the past several years, the need for on-device deep learning has been rapidly increasing, and efficient CNN inference on mobile platforms has been actively researched. Sparsity exploitation has been one of the most active research themes, but the studies mostly focus on weight sparsity by weight pruning. Activation sparsity, on the contrary, requires compression at runtime for every input tensor. Hence, the research on activation sparsity mainly targets NPUs that can efficiently process this with their own hardware logic. In this paper, we observe that it is difficult to accelerate CNN inference on mobile GPUs with natural activation sparsity and that the widely used CSR-based sparse convolution is not sufficiently effective due to the compression overhead. We propose several novel sparsification methods that can boost activation sparsity without harming accuracy. In particular, we selectively sparsify some layers with an extremely high sparsity and adopt sparse convolution or dense convolution depending on the layers. Further, we present an efficient sparse convolution method without compression and demonstrate that it can be faster than the CSR implementation. With ResNet-50, we achieved 1.88 speedup compared to TFLite on a Mali-G76 GPU.","","Oh C,So J,Kim S,Yi Y","","2021","","10.1145/3477008","https://doi-org.proxy.bnl.lu/10.1145/3477008;http://dx.doi.org/10.1145/3477008","Journal Article"
"Exploiting Mobile Phone Data for Multi-Category Land Use Classification in Africa","In the context of Smart Africa Initiative, we present a method to infer multiple land use in Africa. Such information is usually scarce in developing countries due to the constrained resources. Timely land use information is a critical input to smart urban planning that improves efficiency for the public to access to resources. The mobile phone usage is almost universal, which creates a valuable data source for land use inference. In this paper, we demonstrate that the temporal mobile phone call pattern and call network features can be combined to infer ten-category land use including residential, commercial-industrial/office, commercial-business/retail/leisure, high- and low- density commercial, high- and low- density residential, mixed land use areas as well as commercial and residential hubs of the city. In low income countries where land use surveys are rare, our approach create an alternative for measuring land use.","","Mao H,Thakur G,Bhaduri B","","2016","","10.1145/3007540.3007549","https://doi-org.proxy.bnl.lu/10.1145/3007540.3007549;http://dx.doi.org/10.1145/3007540.3007549","Conference Paper"
"Exploring Entrepreneurial Activities in Marginalized Widows: A Case from Rural Sri Lanka","In some developing countries, widows are looked down upon and are often considered inauspicious especially in rural regions. Some societies even consider them and their issues invisible. This paper presents findings from a qualitative study focused on understanding how technology could facilitate entrepreneurial and DIY activities of widows from rural Sri Lanka. We conducted semi-structured interviews and field observations with thirteen widows from low socio-economic backgrounds, who were involved in various small-scale entrepreneurial activities. Our findings showed three central aspects associated with their entrepreneurial activities which can be supported through technology: initial stages of entrepreneurship, balancing work with life, and dealing with exploitations. This paper explores how gender inequality in a social context affects marginalized women in rural Sri Lanka in conducting their entrepreneurial efforts. In particular, we highlight resilient practices that the participants apply to support their entrepreneurial activities. With an ""assets-based approach"" we conclude by providing implications for policymakers, media, and HCI practitioners to support this inbuilt resilience by leveraging their current assets.","","Rathnayake UA,Halloluwa T,Bandara P,Narasinghe M,Vyas D","","2021","","10.1145/3449216","https://doi-org.proxy.bnl.lu/10.1145/3449216;http://dx.doi.org/10.1145/3449216","Journal Article"
"Exploring and Analysing the African Web Ecosystem","It is well known that internet infrastructure deployment is progressing at a rapid pace in the African continent. A flurry of recent research has quantified this, highlighting the expansion of its underlying connectivity network. However, improving the infrastructure is not useful without appropriately provisioned services to exploit it. This article measures the availability and utilisation of web infrastructure in Africa. Whereas others have explored web infrastructure in developed regions, we shed light on practices in developing regions. To achieve this, we apply a comprehensive measurement methodology to collect data from a variety of sources. We first focus on Google to reveal that its content infrastructure in Africa is, indeed, expanding. That said, we find that much of its web content is still served from the US and Europe, despite being the most popular website in many African countries. We repeat the same analysis across a number of other regionally popular websites to find that even top African websites prefer to host their content abroad. To explore the reasons for this, we evaluate some of the major bottlenecks facing content delivery networks (CDNs) in Africa. Amongst other factors, we find a lack of peering between the networks hosting our probes, preventing the sharing of CDN servers, as well as poorly configured DNS resolvers. Finally, our mapping of middleboxes in the region reveals that there is a greater presence of transparent proxies in Africa than in Europe or the US. We conclude the work with a number of suggestions for alleviating the issues observed.","","Fanou R,Tyson G,Fernandes EL,Francois P,Valera F,Sathiaseelan A","","2018","","10.1145/3213897","https://doi-org.proxy.bnl.lu/10.1145/3213897;http://dx.doi.org/10.1145/3213897","Journal Article"
"Facing the Archaeological Looting in Peru by Using Very High Resolution Satellite Imagery and Local Spatial Autocorrelation Statistics","In many countries of Southern America, Asia and Middle East clandestine excavations affect more than other man-made and natural risks archaeological heritage. Direct and aerial surveillance are not always suitable for protection and monitoring sites of cultural interest. This favoured the use of Very high resolution satellite data for the detection of looting pits.This paper is focused on results we obtained from ongoing research focused on the use of VHR satellite images and spatial autocorrelation statistics, such as Moran's I, Geary's C, and Getis-Ord Local Gi index, for the identification and monitoring of looting.A time series of satellite images (QuickBird-2 and World-View-1) has been exploited to analyze and monitor archaeological looting in Cahuachi, a large Ceremonial Centre built by the Nasca Civilization in Southern Peru. The spatial autocorrelation statistics enabled us to extract spatial anomalies linked to illegal excavations and to recognize and quantitatively characterize looting patterns over the years.The results obtained encourage the application of satellite by means of cluster analysis techniques for the monitoring of archaeological sites.","","Lasaponara R,Masini N","","2010","254–261","10.1007/978-3-642-12156-2_19","https://doi-org.proxy.bnl.lu/10.1007/978-3-642-12156-2_19;http://dx.doi.org/10.1007/978-3-642-12156-2_19","Conference Paper"
"Factors Affecting Internet Banking Adoption among Internal and External Customers: A Case of Pakistan","This study investigates the determinants which attract the customers to adopt internet banking in Pakistan by employing internal and external customers, on the sample size of 210 for internal and 151 for external respondents through using the survey research instrument questionnaire. The confirmatory factor analysis with multiple regressions technique has been applied. The result of regression analysis shows that perceived usefulness PU, information of internet banking INF, perceived risk PR, security and privacy SP shows more influence to increase the intention of external customers to adopt internet banking services while government support GS provide more influence for the internal customers in adoption of internet banking services. This study proves that external customers can be more emphasised, if they believe in convenience in adopting the services. It is recommended that banks should take some consideration to apply internet banking by delivering the information in an easiest way, provide more usefulness and benefits and also minimise the fraud as providing more security and privacy. This will help the bank to increase their profit by reducing its cost, time saving and retain more potential users.","","Raza SA,Hanif N","","2013","82–96","10.1504/IJEF.2013.051746","https://doi-org.proxy.bnl.lu/10.1504/IJEF.2013.051746;http://dx.doi.org/10.1504/IJEF.2013.051746","Journal Article"
"Filter List Generation for Underserved Regions","Filter lists play a large and growing role in protecting and assisting web users. The vast majority of popular filter lists are crowd-sourced, where a large number of people manually label resources related to undesirable web resources (e.g. ads, trackers, paywall libraries), so that they can be blocked by browsers and extensions. Because only a small percentage of web users participate in the generation of filter lists, a crowd-sourcing strategy works well for blocking either uncommon resources that appear on “popular” websites, or resources that appear on a large number of “unpopular” websites. A crowd-sourcing strategy will perform poorly for parts of the web with small “crowds”, such as regions of the web serving languages with (relatively) few speakers. This work addresses this problem through the combination of two novel techniques: (i) deep browser instrumentation that allows for the accurate generation of request chains, in a way that is robust in situations that confuse existing measurement techniques, and (ii) an ad classifier that uniquely combines perceptual and page-context features to remain accurate across multiple languages. We apply our unique two-step filter list generation pipeline to three regions of the web that currently have poorly maintained filter lists: Sri Lanka, Hungary, and Albania. We generate new filter lists that complement existing filter lists. Our complementary lists block an additional 3,349 of ad and ad-related resources (1,771 unique) when applied to 6,475 pages targeting these three regions. We hope that this work can be part of an increased effort at ensuring that the security, privacy, and performance benefits of web resource blocking can be shared with all users, and not only those in dominant linguistic or economic regions.","","Sjösten A,Snyder P,Pastor A,Papadopoulos P,Livshits B","","2020","1682–1692","10.1145/3366423.3380239","https://doi-org.proxy.bnl.lu/10.1145/3366423.3380239;http://dx.doi.org/10.1145/3366423.3380239","Conference Paper"
"Fire Emergency Evacuation Simulation Based on Integrated Fire-Evacuation Model with Discrete Design Method","Emergency evacuation under fire condition in a mass transit station is a great concern especially in developing countries. The interaction between fire and human is very important in the analysis of emergency evacuation under fire condition. An integrated fire-human model, FDS+Evac, is widely used to solve numerically the simultaneous fire and evacuation processes. However, when the simulation runs increase, the simulation time and cost will increase dramatically. The use of discrete design method (DDM) to reduce the simulation time and cost in fire emergency evacuation simulations is proposed. The method is applied to an underground subway station to study the influence of different factors on fire emergency evacuation. The grid resolution is analyzed to determine an appropriate grid size that will optimize the solution accuracy and time. Different fire locations, heat release rates, occupant loadings, ventilation conditions and material properties are considered under fire condition in the underground subway station. It shows that the heat release rate has a weak influence on fire emergency evacuation, but the fire location, occupant loading, ventilation condition and material property have a great influence on fire emergency evacuation. Furthermore, the five parameters have a coupled function on fire emergency evacuation.","","Yang P,Li C,Chen D","","2013","101–111","10.1016/j.advengsoft.2013.06.007","https://doi-org.proxy.bnl.lu/10.1016/j.advengsoft.2013.06.007;http://dx.doi.org/10.1016/j.advengsoft.2013.06.007","Journal Article"
"FlashPatch: Spreading Software Updates over Flash Drives in Under-Connected Regions","Computers in developing regions often lack the Internet connectivity and network bandwidth necessary to consistently download and apply software updates and security patches. However, even unconnected computers contract viruses and malware through the sharing of USB flash drives and other removable media. This paper introduces FlashPatch, a system for distributing software updates to computers in such areas by having software updates ""piggy-back"" on the existing flow of flash drives in rural regions. FlashPatch requires no changes in user behavior once the software has been installed. We implemented a proof-of-concept FlashPatch prototype and evaluated it in a field trial in Ghana. We present data on the prevalence and spread of viruses at our study site and offer experimental evidence of FlashPatch's effectiveness from a nine-month field trial. We found that FlashPatch provided additional antivirus protection to 30% of the machines in our study without imposing any tangible burdens on the system owners.","","Corrigan-Gibbs H,Chen J","","2014","1–10","10.1145/2674377.2674384","https://doi-org.proxy.bnl.lu/10.1145/2674377.2674384;http://dx.doi.org/10.1145/2674377.2674384","Conference Paper"
"Flipping 419 Cybercrime Scams: Targeting the Weak and the Vulnerable","Most of cyberscam-related studies focus on threats perpetrated against the Western society, with a particular attention to the USA and Europe. Regrettably, no research has been done on scams targeting African countries, especially Nigeria, where the notorious and (in)famous 419 advanced-fee scam, targeted towards other countries, originated. How- ever, as we know, cybercrime is a global problem affecting all parties. In this study, we investigate a form of advance fee fraud scam unique to Nigeria and targeted at Nigerians, but unknown to the Western world. For the study, we rely substantially on almost two years worth of data harvested from an on-line discussion forum used by criminals. We complement this dataset with recent data from three other active forums to consolidate and generalize the research. We apply machine learning to the data to understand the criminals' modus operandi. We show that the criminals exploit the socio-political and economic problems prevalent in the country to craft various fraud schemes to defraud vulnerable groups such as secondary school students and unemployed graduates. The result of our research can help potential victims and policy makers to develop measures to counter the activities of these criminal groups.","","Mba G,Onaolapo J,Stringhini G,Cavallaro L","","2017","1301–1310","10.1145/3041021.3053892","https://doi-org.proxy.bnl.lu/10.1145/3041021.3053892;http://dx.doi.org/10.1145/3041021.3053892","Conference Paper"
"Flowtag: A Collaborative Attack-Analysis, Reporting, and Sharing Tool for Security Researchers","Current tools for forensic analysis require many hours to understand novel attacks, causing reports to be terse and untimely. We apply visual filtering and tagging of flows in a novel way to address the current limitations of post-attack analysis, reporting, and sharing. We discuss the benefits of visual filtering and tagging of network flows and introduce FlowTag as our prototype tool for Honeynet researchers. We argue that online collaborative analysis benefits security researchers by organizing attacks, collaborating on analysis, forming attack databases for trend analysis, and in promoting new security research areas. Lastly, we show three attacks on the Georgia Tech Honeynet and describe the analysis process using FlowTag.","","Lee CP,Copeland JA","","2006","103–108","10.1145/1179576.1179597","https://doi-org.proxy.bnl.lu/10.1145/1179576.1179597;http://dx.doi.org/10.1145/1179576.1179597","Conference Paper"
"Focus on Authors","Sreekumar R. Bhaskaran (“Consumer Mental Accounts and Implications to Selling Base Products and Add-ons”) is an assistant professor of operations management at the Cox School of Business, Southern Methodist University. He has a B.E. in mechanical engineering from the Indian Institute of Technology Madras, an MBA in operations and marketing from the Indian Institute of Management Calcutta, and a Ph.D. in supply chain and operations management from the McCombs School of Business, University of Texas at Austin. His primary research interests include new product development, supply chain management, and marketing and operation interfaces. His work has previously appeared in Management Science, Marketing Science, and Production and Operations Management.Dondeena Bradley (“Further Examining the Impact of the NLEA on Nutrition”) is the Vice President, Global R&D and Nutrition Ventures, at PepsiCo, where she is responsible for designing new solutions that target the special needs of consumers with diverse health and nutrition challenges. Prior to joining PepsiCo in 2007, she held numerous roles in the areas of strategy, nutrition, and health with Johnson & Johnson, Mars Inc., the Stepan Company, and the Campbell Soup Company. She received her Ph.D. in food science from The Ohio State University, her M.S. in nutrition from Purdue University, and her B.S. from Anderson University.Dipankar Chakravarti (“Bidding Behavior in Descending and Ascending Auctions”) is a professor of marketing at the Johns Hopkins Carey Business School, where he served as Vice Dean, Programs, and is also a professor emeritus at the University of Colorado, Boulder, where he was the Ortloff Professor of Business. He holds a Ph.D. in industrial administration from Carnegie Mellon University and has taught previously at the University of Arizona, Duke, and University of Florida. His current research examines marketing and consumer behavior issues in emerging economies, with a focus on the psychology of consumption in poverty and development. His research on consumer and managerial decision making in marketing contexts has been published in the field's leading scholarly journals and received several significant academic recognitions. Among his other contributions to the marketing field are two sons---one a practitioner and the other an academic; he also has three grandsons who he hopes will also publish in Marketing Science one day.Amar Cheema (“Bidding Behavior in Descending and Ascending Auctions”) is an associate professor of marketing at the McIntire School of Commerce, University of Virginia. He received his Ph.D. from the University of Colorado, Boulder. His research interests include auctions and online purchase behavior, pricing and promotion effects, behavioral decision theory, and word-of-mouth influences.Lesley Chiou (“How Does the Use of Trademarks by Third-Party Sellers Affect Online Search?”) is an associate professor of economics at Occidental College. She received her Ph.D. in economics from the Massachusetts Institute of Technology. She is interested in industrial organization and applied econometrics, and her research focuses on online advertising and competition in the retail sector.Martijn G. de Jong (“State-Dependence Effects in Surveys”) holds a Chair in Marketing Research at the Erasmus School of Economics, Erasmus University, and is a Tinbergen Research Fellow. He has a B.Sc. and M.Sc. in econometrics from Erasmus University and a Ph.D. in marketing from Tilburg University. He is mainly interested in consumer preference measurement; often his research is cross-cultural in nature, relying on large-scale data sets. He received several major research grants, including an NWO (Netherlands Organization for Scientific Research) innovation grant. His awards include the J. C. Ruigrok Prize (awarded once every four years to the most productive young scholar in the Economic Sciences in the Netherlands) and the Christiaan Huygens Science Award (presented by HRH Princess Máxima of the Netherlands; awarded once every five years to a young economist in the Netherlands).Sanjiv Erat (“Consumer Mental Accounts and Implications to Selling Base Products and Add-ons”) is an assistant professor of innovation, technology, and operations management at the Rady School of Management, University of California, San Diego. He has a B.E. in computer science from the Indian Institute of Technology Madras and a Ph.D. in operations management from the College of Management, Georgia Institute of Technology. His primary research interests include new product development, marketing and operation interfaces, and behavioral economics. His work has previously appeared in Management Science.Rosellina Ferraro (“Unintended Nutrition Consequences: Firm Responses to the Nutrition Labeling and Education Act”; “From Consumer Information Regulation to Nutrition Competition: A Response”) is an associate professor of marketing at the Robert H. Smith School of Business, University of Maryland. Her research focuses on consumer behavior---specifically, on the effects of social influence on choice and preference and the effects of external threats on consumption behavior. Her work has been published in the Journal of Consumer Research, Journal of Marketing, and Journal of Consumer Psychology. She serves on the editorial review board for the Journal of Consumer Research and was named a 2011 MSI Young Scholar.Joel Huber (“Unintended Nutrition Consequences: Firm Responses to the Nutrition Labeling and Education Act”; “From Consumer Information Regulation to Nutrition Competition: A Response”) is the Alan D. Schwartz Professor of Business Administration at the Fuqua School of Business at Duke University. He has a B.A. from Princeton University and an MBA and Ph.D. from the Wharton School of the University of Pennsylvania. His research centers on ways relatively minor changes in the competitive context can have a large impact on market choice and the impact of this context dependency on appropriate ways to measure value. Recent work has focused on valuation of environmental changes, insurance programs, and health systems. He has been an associate editor for the Journal of Consumer Research for 12 years and the editor of Journal of Marketing Research for 3 years.Sanjay Jain (“Self-Control and Incentives: An Analysis of Multiperiod Quota Plans”) is a professor and the JCPenney Chair of Marketing and Retailing Studies at the Mays Business School, Texas A&M University. His research interests are in the areas of competitive strategy, behavioral economics, and experimental game theory. His research has been published in the Journal of Marketing Research, Management Science, and Marketing Science. He is an associate editor for Management Science and serves on the editorial boards of the Journal of Marketing Research and Marketing Science.Kevin Lane Keller (“Economic and Behavioral Perspectives on Brand Extension”) is the E. B. Osborn Professor of Marketing at the Tuck School of Business at Dartmouth College. His academic resume includes degrees from Cornell, Duke, and Carnegie Mellon universities, award-winning research, and faculty positions at the University of California at Berkeley, Stanford, and the University of North Carolina. His textbook, Strategic Brand Management, has been adopted at the top business schools and leading firms around the world. He is also the coauthor (with Philip Kotler) of the all-time best-selling introductory marketing textbook, Marketing Management.Donald R. Lehmann (“State-Dependence Effects in Surveys”) is the George E. Warren Professor of Business at the Columbia Business School. He has a B.S. in mathematics from Union College, Schenectady, NY, and an MSIA and Ph.D. from the Krannert School of Purdue University. His research interests include individual and group choice and decision making, empirical generalizations and meta-analysis, the introduction and adoption of new products and innovations, and measuring the value of marketing assets such as brands and customers. He has published numerous journal articles and six books. He was the founding editor of Marketing Letters; has served on the editorial boards of the Journal of Consumer Research, the Journal of Marketing, the Journal of Marketing Research, Management Science, and Marketing Science; and has served as executive director of the Marketing Science Institute and as president of the Association for Consumer Research.Christine Moorman (“Unintended Nutrition Consequences: Firm Responses to the Nutrition Labeling and Education Act”; “From Consumer Information Regulation to Nutrition Competition: A Response”) is the T. Austin Finch, Sr. Professor of Business Administration at the Fuqua School of Business, Duke University. She has published research on consumers, managers, and organization learning and the use of information in a range of marketing strategy and public policy contexts. Founder of the CMO Survey, author of the book Strategy from the Outside In: Profiting from Customer Value (recipient of the 2011 Berry Book Prize), and winner of the Paul D. Converse award, she has also served as a trustee for the Marketing Science Institute and on the Board of Directors of the American Marketing Association.Sridhar Moorthy (“Can Brand Extension Signal Product Quality?”; “On Brand Extension as a Signal of Product Quality: A Reply to Keller and Wernerfelt”) is the Manny Rotman Professor of Marketing at the Rotman School of Management, University of Toronto. He received his Ph.D. from Stanford University, and he has taught previously at the University of Rochester, Yale School of Management, INSEAD, the University of California at Los Angeles, the Wharton School, and the Indian School of Business. His current research focuses on branding, advertising, and retailing issues; previous work published here and in other journals has examined the relationship between advertising and product quality, product differentiation in a competitive environment, and price-matching guarantees in retailing. He is coeditor of Quantitative Marketing and Economics, associate editor of Management Science, and a member of the editorial board of Journal of Marketing Research. He is a coauthor (with Philip Kotler and Gary Lilien) of Marketing Models (Prentice-Hall 1992).Oded Netzer (“State-Dependence Effects in Surveys”) is the Phillip H. Geier Jr. Associate Professor of Business at Columbia University. He received an M.Sc. in statistics and a Ph.D. in business, both from Stanford University, and he also holds a B.Sc. in industrial engineering and management from the Technion (Israel Institute of Technology). His research interests focus on modeling customer relationships, preference measurement methods, and modeling various aspects of choice behavior, including how choices change over time, contexts, and customers. His research has appeared in the top academic journals. He is the recipient of the John D. C. Little, Frank M. Bass, and Society of Consumer Psychology Best Competitive Paper awards.Janis K. Pappalardo (“Are Unintended Effects of the Marketing Regulations Unexpected?”) is the Assistant Director for Consumer Protection in the Bureau of Economics at the Federal Trade Commission. She majored in economics at Catholic University and received her Ph.D. from Cornell University in 1986, with a primary focus in consumer economics and secondary fields in statistics and industrial organization. Research that she coauthored on health claims regulation earned her two outstanding article awards from the Journal of Public Policy and Marketing. Her research on mortgage disclosures, coauthored with James Lacko, has been published in the American Economic Review (Papers and Proceedings) and has been cited in congressional testimony and newspapers such as the Washington Post, USA Today, and the Wall Street Journal. She currently serves on the editorial boards of the Journal of Public Policy and Marketing and the Journal of Consumer Affairs.Brian T. Ratchford (“Suggestions for Further Research on Firm Responses to NLEA and Other Disclosure Laws”) is the Charles and Nancy Davidson Professor of Marketing, University of Texas at Dallas. He has MBA and Ph.D. degrees from the University of Rochester. His research interests are in economics applied to the study of consumer behavior, information economics, marketing productivity, marketing research, and electronic commerce. He has published over 80 articles in marketing and related fields. He was the Editor of Marketing Science (from 1998 to 2002); is currently an associate editor of the Journal of Consumer Research; serves on the editorial review boards of the Journal of Marketing Research, Journal of Marketing, Journal of Retailing, Journal of Interactive Marketing, Journal of Public Policy and Marketing, and Journal of Service Research; and serves on the advisory editorial board of Marketing Science.Atanu R. Sinha (“Bidding Behavior in Descending and Ascending Auctions”) is an associate professor of marketing at the Leeds School of Business, University of Colorado, Boulder. His research interests include, among others, pricing, theoretical and empirical models of auctions, negotiations, social media, online two-sided markets, and loyalty programs.Catherine Tucker (“How Does the Use of Trademarks by Third-Party Sellers Affect Online Search?”) is currently the Douglas Drane Career Development Professor in IT and Management and an associate professor of marketing at the MIT Sloan School of Management, and she is a faculty research fellow at the National Bureau of Economic Research. She received her Ph.D. in economics from Stanford University. She specializes in understanding how the huge amounts of data generated by the information and communication technology revolution can better guide marketing and advertising decisions. She has also done substantial research into how healthcare information technology is transforming the healthcare sector. She also focuses on the privacy concerns that such data raise and how firms and policy makers can best address these; she received a National Science Foundation CAREER award for her work on digital privacy.Birger Wernerfelt (“On Brand Extension as a Signal of Product Quality”) is the JC Penney Professor of Management at the MIT Sloan School of Management. He has taught marketing, strategy, and economics, and he has published in all three areas.","","","","2012","870–872","10.1287/mksc.1120.0741","https://doi-org.proxy.bnl.lu/10.1287/mksc.1120.0741;http://dx.doi.org/10.1287/mksc.1120.0741","Journal Article"
"Food System Resilience and Sustainability in Cambodia","Cambodia is witnessing a “Goldilocks moment” in demographic change concurrent with shifts in land use, hydrology, and climate. These trends interact and affect food production, food costs, and food security. Drivers of these trends are typically examined separately with interacting factors considered along disciplinary margins. While science models to explore these interacting effects have been proposed, there remains an applied research gap in integrating these pieces and assessing interdisciplinary opportunities for developing food security solutions. Developed following a request from USAID to elucidate food security conditions in Cambodia, here the authors present their geospatial synthesis of the biophysical and socioeconomic drivers of current food security risk, as well as explore future trends for those conditions. The overall structure shows several interlocking or mutually reinforcing trends in systems that point towards a significant intensification of food insecurity in the near future. They offer an assessment of future targets for food systems innovation.","","Messina J,Suepa T,Snapp S,Olson J,Nejadhashemi AP,Murray S,Moore N,Frake A,Fan P,Adhikari U","","2022","1–23","10.4018/ijagr.2017070104","https://doi-org.proxy.bnl.lu/10.4018/ijagr.2017070104;http://dx.doi.org/10.4018/ijagr.2017070104","Journal Article"
"Forecasting Spot Prices of Agricultural Commodities in India: Application of Deep‐Learning Models","Food price fluctuations can impact both producers and consumers. Forecasting the prices of the agricultural commodities is of prime concern not only to the government but also to farmers and agribusiness firms. In developing countries like India, management of food security needs competent and efficient forecasting of food prices. With the availability of data, recent innovation in deep‐learning models provides a feasible solution to accurately forecast the prices. In this study, we examine the superiority of these models using the daily spot prices of five major commodities traded on the National Commodity and Derivatives Exchange: cotton seed, castor seed, rape mustard seed, soybean seed, and guar seed. The results were obtained from the application of the traditional univariate autoregressive integrated moving average model and deep‐learning techniques like the time‐delay neural network (TDNN) and long short‐term memory (LSTM) network. The empirical results indicate that the LSTM model is indeed suitable for the financial domain and captures the directional movement of the spot price changes with high accuracy compared with the TDNN and other linear models. Accuracy of the performance of these models has been compared using out‐of‐sample performance measure. The overall objective of this paper is to demonstrate the utility of spot price forecasting for farmers and traders in offering them the best predictions of the price movements. Our results provide a possibility of developing pricing models that can help in fairly regulating agricultural commodity prices.","","R L M,Mishra AK","","2021","72–83","10.1002/isaf.1487","https://doi-org.proxy.bnl.lu/10.1002/isaf.1487;http://dx.doi.org/10.1002/isaf.1487","Journal Article"
"Fraud Detection in the Distributed Graph Database","Over the last few decades, graphs have become increasingly important in many applications and domains for managing Big data. Big data analysis in a graph database is described as an analysis of exponentially increasing massive interconnected data concerning time. However, analyzing big connected data in social networks and synthetic identity detection is challenging. In previous approaches, fraud detection has been done on the complete graph data, which is a time-consuming process and will create bottlenecks while query execution. To overcome the issue, this paper proposes a new fraud detection technique to unveil synthetic identities involved in the Panama Paper leak dataset (unprecedented leak of 11.5 m data from the database of the world’s fourth-biggest offshore law arm, Mossack Fonseca) using a Node rank-based fraud detection algorithm by integrating distributed data profiling techniques on a minimized graph by minimizing the least influential nodes. The proposed model is verified on the three nodes cluster to improve data scalability, reduce the query execution time by an average of 30–36% and finally reduce the fraud detection time by 18.2%.","","Srivastava S,Singh AK","","2022","515–537","10.1007/s10586-022-03540-3","https://doi-org.proxy.bnl.lu/10.1007/s10586-022-03540-3;http://dx.doi.org/10.1007/s10586-022-03540-3","Journal Article"
"Free For All","—Editorial by Martin K. Starr, Editor-in-Chief, Management Science: Application—Letters to the Editor –“To the Editor” by Eugene P. Saxby, Management Science Department, Security First National Bank, Los Angeles–“To the Editor” by Ray Radosevich, The University of Kansas–“To the Editor” by Geoffrey P. E. Clarkson, Manchester Business School, University of Manchester, England–“To the Editor” by Thomas H. Naylor, Duke University–“To the Editor” by Peter J. Kolesar, Columbia University–“To the Editor” by Al Kahl, College of Business, University of Georgia, Athens, Georgia.","","","","1968","B-545–B-552","10.1287/mnsc.14.10.545","https://doi-org.proxy.bnl.lu/10.1287/mnsc.14.10.545;http://dx.doi.org/10.1287/mnsc.14.10.545","Journal Article"
"Front Matter","In the great digital era, we are witnessing many rapid scientific and technological developments in human-centered, seamless computing environments, interfaces, devices, and systems with applications ranging from business and communication to entertainment and learning. These developments are collectively best characterized as Active Media Technology (AMT), a new area of intelligent information technology and computer science that emphasizes the proactive, seamless roles of interfaces and systems as well as new media in all aspects of digital life. An AMT based computer system offers services that enable the rapid design, implementation, deploying and support of customized solutions.The first International Conference on Active Media Technology (AMT01) was held in Hong Kong in 2001, the second International Conference on Active Media Technology (AMT03) was held in Chongqing, China in May 29--31 of 2004, and the third International Conference on Active Media Technology (AMT05) was held in Kagawa, Japan in May 2005. The 4th International Conference on Active Media Technology (AMT06) follows the success of AMT01, AMT03 and AMT05.AMT06 is the leading International Conference focusing on Active Media Technology. It aims to bring together researchers from diverse areas, such as Web intelligence, data mining, intelligent agents, smart information use, networking and intelligent interface. It also encourages collaborative research in these areas to provide best services for enabling the rapid design, implementation, deploying and support of customized solutions.The conference includes the following topics:• Active Computer Systems and Intelligent Interfaces• Adaptive Web Systems and Information Foraging Agents• Web mining, Wisdom Web and Web Intelligence• E-Commerce and Web Services• Data Mining, Ontology Mining and Data Reasoning• Network, Mobile and Wireless Security• Entertainment and Social Applications of Active Media• Agent-Based Software Engineering and Multi-Agent Systems• Digital City and Digital Interactivity• Machine Learning and Human-Centred Robotics• Multi-Modal Processing, Detection, Recognition, and Expression Analysis• Personalized, Pervasive, and Ubiquitous Systems and their Interfaces• Smart Digital Media• Evaluation of Active Media and AMT Based SystemsAMT06 is sponsored by the IEEE Systems, Man, and Cybernetics Society and Queensland University of Technology. It attracted 123 submissions from 19 countries and regions: Algeria, Australia, China, Canada, England, Finland, France, Hong Kong, India, Japan, Korea, New Zealand, Pakistan, Poland, Republic of Korea, Taiwan, United Arab Emirates, United Kingdom, and United States of America. The review process was rigorous. Each paper was reviewed by two reviewers at least, and most of them reviewed by three reviewers.The Program Committee accepted 39 regular papers (the approximate acceptance rate is 32%), 33 short papers (the approximate acceptance rate is 39%) and 9 industry/demonstration papers.We would like to thank the members of Program Committee and Organization Committee and reviewers who contributed to the success of this conference.Yuefeng Li, Mark Looi and Ning Zhong, 17 March 2006","","","","2006","i–xvi","","","Conference Paper"
"Front Matter","In the summer of 1956, John McCarthy organized the famous Dartmouth Conference which is now commonly viewed as the founding event for the field of Artificial Intelligence. During the last 50 years, AI has seen a tremendous development and is now a well-established scientific discipline all over the world. Also in Europe AI is in excellent shape, as witnessed by the large number of high quality submissions we received. About 600 papers and posters were registered for ECAI-06, out of which 550 were actually reviewed (501 paper submissions and 49 poster submissions). The program committee decided to accept 131 full papers, which amounts to an acceptance rate of 26.1%, and 75 posters (authors of full papers had the possibility to opt for acceptance as poster in case of rejectance as full paper).We received submissions from 43 different countries, and accepted papers from 25 countries. The following table shows the number of submissions and accepted papers per country, based on the contact author affiliation:Algeria 5 0Australia 19 9Austria 9 5Belgium 4 2Brazil 12 0Bulgaria 1 0Canada 13 4China 4 0Cyprus 1 0Czechia 4 0Egypt 1 0Estonia 2 0France 111 46Finland 3 2Germany 47 19Greece 15 4Hungary 1 0India 1 0Iran 5 1Ireland 14 9Israel 8 2Italy 83 36Japan 9 1Luxemburg 5 3Mexico 2 0Netherlands 26 12New Zealand 3 0Pakistan 1 0Poland 3 0Portugal 1 0Romania 4 1Russia 3 0Singapore 4 4Spain 32 5Slovenia 2 2Slovakia 3 3Sweden 5 5Switzerland 5 3Thailand 2 0Turkey 3 0UK 49 22USA 22 5Venezuela 1 1It is also interesting to look at the areas of the submitted and accepted papers/posters. We show both absolute numbers and percentage. The area information is based on the first two key words chosen by the authors:# submitted % # accepted %Case-Based Reasoning 10.5 1.9 0.5 0.2Cognitive Modelling 33.5 6.1 13 6.3Constraints & Search 54.5 10.0 26 12.6Distributed AI/Agents 107 19.6 36.5 17.7KR & Reasoning 141.5 25.9 55.5 26.9Machine Learning 83 15.2 29 14.1Model-Based Reasoning 32 5.9 8 3.9Natural Language 21.5 3.9 7.5 3.6Perception/Vision 6 1.1 2 1.0Planning and Scheduling 27 4.9 12 5.8Robotics 12.5 2.3 5 2.4PAIS 18 3.3 11 5.3In comparison with ECAI 2004, we see a strong increase in the relative number of submissions from Distributed AI/Agents and Cognitive Modelling. Knowledge Representation & Reasoning is traditionally strong in Europe and remains the biggest area of ECAI-06. One reason the figures for Case-Based Reasoning are rather low is that much of the high quality work in this area has found its way into prestigious applications and is thus represented under the heading of PAIS.The ECAI-06 best paper award, sponsored by Elsevier, goes to a machine learning paper:A Real Generalization of Discrete AdaBoost, by Richard Nock and Frank NielsenCongratulations! The best poster award, sponsored by IOS Press, will be decided after the poster sessions in Riva. The 10 best papers are invited to a fast track of the Artificial Intelligence Journal.A conference of the size of ECAI needs a lot of support from many people. At this point we would like to thank all those who helped to make ECAI-06 a tremendous success: the poster, workshop, PAIS and area chairs faced a heavy workload and they all did an excellent job. The PC members and additional reviewers came up with timely, high quality reviews and made the life of the PC chair as easy as it can be. Thanks also to Alex Nittka who ran the conference management software, to the PC chair's great relief. We also want to thank the many people involved in the local organization of the conference: there would be no conference without you.Our very special thanks go to a person who is no longer with us. Rob Milne, chair of ECAI-06 until he died of a heart attack close to the summit of Mount Everest on June 5th, 2005. He shaped this conference from the beginning, and we did our best to organize ECAI-06 in his spirit.June 2006, Gerhard Brewka, Silvia Coradeschi, Anna Perini, Paolo Traverso","","","","2006","i–xxvi","","","Conference Paper"
"Front Matter","This festschrift celebrates the life of a remarkable man.Rob Milne died while climbing Mount Everest early on 5th June 2005 Nepal Time. He was 48. He is survived by his wife Val and his two children Alex and Rosemary.His untimely death was a tragedy, but Rob packed 96 years of living into his 48 years of life. In any one of his three “careers” ---as a hi-tech entrepreneur, as an AI researcher and as a mountaineer ---his achievements would have been enough for most ordinary mortals. But Rob combined world-class success in all of them. This book covers all these facets of his life. Each chapter has been contributed by one or more of his close collaborators as their tribute to Rob and to his legacy.Rob's ascent of Everest was to have been the culmination of a lifetime's ambition to climb the highest summits in each of the world's seven continents. Everest was the last of these seven summits. He was only 400 metres from the top when he died from a sudden and massive heart attack. He had been an ambitious and successful mountaineer since his childhood in Colorado. As Val, said in a radio interview, “Rob died at the top, doing what he loved”. This was true not just of his mountaineering, but in all the spheres of his life.I first met Rob in 1978 in Boston, Massachusetts. He was just finishing his undergraduate degree at MIT and had applied to be a PhD student at Edinburgh under my supervision. I was visiting MIT that Summer, so we met to discuss his research project. I was quickly introduced to his climbing expertise. He showed me how to climb a vertical brick wall using the gaps in the bricks as hand and foot holds. He invited me to try; I declined. He came to Edinburgh that Autumn to work on machine understanding of mechanics problems written in English as part of our Mecho project: one of the first non-US expert systems. In 1980, Rob initiated his project to conquer the seven summits by climbing Denali (Mt McKinley) in Alaska. I remember getting vertigo just by reading his subsequent article in our University Bulletin. Rob met Val at Edinburgh, and they married in 1981.Climbing Denali required determination and persistence. Rob exhibited these qualities in everything he did, which is why he achieved so much. But it wasn't always the best approach. When it came to his PhD viva, Rob somehow got the misconception that to concede to his examiners on any point, however minor, would destroy his chances. He, therefore, fought every step of the way. The viva lasted eight hours! He obtained his PhD in 1983.In 1982Rob returned to the USAwhere he worked first at the Wright-Paterson Airforce Base and then at the Pentagon. At the Pentagon, he introduced AI research into the US Army by founding the Army AI Center, in which he was the Chief AI scientist. Returning to Scotland in 1986, he founded Intelligent Applications: one of the first non-US expert system companies. After experimenting with various AI products, IA focused on turbine monitoring with its 'Tiger' product.Most entrepreneurs running innovative, hi-tech companies have little time for extracurricular activity, but Rob found time both for his mountaineering and his AI research. He continued to publish in the top journals and conferences, authoring over 75 papers on knowledge-based systems, data-mining, qualitative reasoning, etc. He was a popular speaker, giving many invited talks and tutorials at major conferences. He acted as a bridge between academia and industry, for instance, frequently talking to academics on the technology transfer process.Rob was a natural leader; he tirelessly and selflessly gave his time to help organise the activities in which he was involved. For instance, in both the British and European AI communities, he regularly served on conference committees, having been chair of both the British Computer Society's Specialist Group on AI Conference and of the European Conference on Artificial Intelligence. He was an officer of both organisations, including being the President of ECCAI 2000-04. He was also the inspiration behind bringing IJCAI-05 to Edinburgh, being the Local Arrangements Chair until his death. Rob played a key part in setting up the European Network of Excellence MONET (Model Based and Qualitative Systems), and in a second phase its Task Group BRIDGE (Bridging AI and Control Engineering model based diagnosis approaches) that focused on diagnosis.Rob played an active role in the Scottish Software Federation (which merged to form ScotlandIS in 2000): the industry bodies for IT and software companies in Scotland. Rob was a director of each organisation 1997--2002. He was a mentor to a number of start-up companies and guided other entrepreneurs in their efforts to establish successful businesses. In recognition of his academic and industrial achievements, he was elected a Fellow of the Royal Society of Edinburgh in 2003. He was also active in Scottish Mountaineering Club, being Convener of the publications sub-committee and co-authoring a book on the Corbetts (the 219 Scottish hills between 2500ft and 3000ft high). In 1997, Rob became only the 1860th person to have climbed all the Munros (the 284 Scottish mountains over 3000ft high). He was a keen winter climber, helping to establish a number of high-grade new climbs throughout Scotland.Rob summed up his attitude to life in a radio interview, by saying that it was important to wake up every morning with an exciting challenge in mind. He always set himself ambitious goals then attained them by persistence and determination. Ambition, persistence and determination are qualities sometimes associated with people who are difficult to get on with. Not so Rob. He was one of the most pleasant and easy-going people it has been my pleasure to work with. We already miss him.Alan Bundy, May 25, 2006","","","","2006","i–vii","","","Conference Paper"
"Front Matter","These proceedings contain the final versions of the papers presented at the 7th International Workshop on Finite-State Methods and Natural Language Processing, FSMNLP 2008. The workshop was held in Ispra, Italy, on September 11--12, 2008. The event was the seventh instance in the series of FSMNLP workshops, and the third that was arranged as a stand-alone event. In 2008 FSMNLP was merged with the FASTAR workshop.The aim of the FSMNLP workshops is to bring together members of the research and industrial community working on finite-state based models in language technology, computational linguistics, web mining, linguistics, and cognitive science on one hand, and, on related theory and methods in fields such as computer science and mathematics, on the other. Thus, the workshop series is a forum for researchers and practitioners working on applications as well as theoretical and implementation aspects. The special theme of FSMNLP 2008 centered around high performance finite-state devices in large-scale natural language text processing systems and applications.In the context of FSMNLP 2008, we received in total 37 submisions, of which 13 were selected as regular papers, 6 as short papers and 1 as demo paper. The acceptance rate for regular papers was 46,4%. Most of the papers were evaluated by at least four Programme Committee members, with the help of external reviewers. Only 15% of the papers were reviewed by three reviewers. In addition to the submitted papers, four lectures were given by invited speakers. The invited speakers and the authors of the papers represented (at least) Croatia, Finland, France, Gemany, Italy, Luxembourg, Netherlands, Portugal, Puerto Rico, Sweden, U.K., and the USA.We would like to thank all workshop participants for their contributions and lively interaction during the two days. The presented papers covered a range of interesting NLP applications, including machine learning and translation, logic, computational phonology, morphology and semantics, data mining, information extraction and disambiguation, as well as programming, optimization and compression of finite-state networks. The applied methods included weighted algorithms, kernels, and tree automata. In addition, relevant aspects of software engineering, standardization, and European funding programmes were discussed.We are greatly indebted to the members of the Programme Committee and the external referees for reviewing the papers and maintaining the high standard of the FSMNLP workshops. The members of the Programme Committee of FSMNLP 2008 were Cyril Allauzen (Google Research, New York, USA), Francisco Casacuberta (Instituto Tecnologico De Informática, Valencia, Spain), Jean-Marc Champarnaud (Université de Rouen, France), Maxime Crochemore (Department of Computer Science, King's College London, U.K.), Jan Daciuk (Gdańsk University of Technology, Poland), Karin Haenelt (Fraunhofer Gesellschaft and University of Heidelberg, Germany), Thomas Hanneforth (University of Potsdam, Germany), Colin de la Higuera (Jean Monnet University, Saint-Etienne, France), André Kempe (Yahoo Search Technologies, Paris, France), Derrick Kourie (Dept. of Computer Science, University of Pretoria, South Africa), Andras Kornai (Budapest Institute of Technology, Hungary and MetaCarta, Cambridge, USA), Marcus Kracht (Univeristy of California, Los Angeles, USA), Hans-Ulrich Krieger (DFKI GmbH, Saarbrücken, Germany), Eric Laporte (Université de Marne-la-Vallée, France), Stoyan Mihov (Bulgarian Academy of Sciences, Sofia, Bulgaria), Herman Ney (RWTH Aachen University, Germany), Kemal Oflazer (Sabanci University, Turkey), Jakub Piskorski (Joint Research Center of the European Commission, Italy), Michael Riley (Google Research, New York, USA), Strahil Ristov (Ruder Boskovic Institute, Zagreb, Croatia), Wojciech Rytter (Warsaw University, Poland), Jacques Sakarovitch (Ecole nationale supérieure des Télécommunications, Paris, France), Max Silberztein (Université de Franche-Comté, France), Wojciech Skut (Google Research, Mountain View, USA), Bruce Watson (Dept. of Computer Science, University of Pretoria, South Africa) (PC co-chair), Shuly Wintner (University of Haifa, Israel), Atro Voutilainen (Connexor Oy, Finland), Anssi Yli-Jyrä (University of Helsinki and CSC --IT Center for Science, Espoo, Finland) (PC co-chair), Sheng Yu (University of Western Ontario, Canada), and Lynette van Zijl (Stellenbosch University, South Africa). The external reviewers were Marco Almeida, Marie-Pierre Beal, Oliver Bender, Jan Bungeroth, Pascal Caron, Loek Cleophas, Matthieu Constant, Stefan Hahn, Christopher Kermorvant, Sylvain Lombardy, Patrick Marty, Evgeny Matusov, Takuya Nakamura, Ernest Ketcha Ngassam, Jyrki Niemi, Sébastien Paumier, Maciej Pilichowski, Adam Przepiórkowski, Magnus Steinby, Yael Sygal, David Vilar, Hsu-Chun Yen, Francois Yvon, Artur Zaroda, and Djelloul Ziadi.FSMNLP 2008 was organised by the Institute for the Protection and Security of the Citizen of the Joint Research Centre (JRC) of the European Commission in Ispra, Italy, in cooperation with the host of the next FSMNLP event, the FASTAR group of the University of Pretoria in South Africa. The Organizing Committee in 2008 had five JRC representatives: Regina Corradini, Daniela Negri, Jakub Piskorski (OC chair), Hristo Tanev, and Vanni Zavarella, and two members from the Department of Computer Science, University of Pretoria, South Africa: Derrick Kourie and Bruce Watson. A complementary role in long-term planning and coordination was played by the Steering Committee: Lauri Karttunen (Palo Alto Research Center, USA and Stanford University, USA) Kimmo Koskenniemi (University of Helsinki, Finland), Kemal Oflazer (Sabanci University, Turkey) and Anssi Yli-Jyrä (University of Helsinki and CSC --IT Centre for Science, Espoo).The current year's event is pivotal to the series of FSMNLP workshops since it starts the tradition of organizing the workshops on a yearly basis. Locations for successive events, including FSMNLP 2008 in Ispra and FSMNLP 2009 in Pretoria were proposed already in FSMNLP 2007 in Potsdam. The success of FSMNLP 2008 indicates that there is a growing and wide interdisciplinary community with shared interest in finite-state methods and natural language processing. Therefore, we are looking forward to the FSMNLP 2009 that is to be held in Pretoria, South Africa next year!In October 2008Jakub Piskorski, Bruce Watson, Anssi Yli-Jyrä","","","","2009","i–viii","","","Conference Paper"
"Fusing Open Source Intelligence and Handheld Situational Awareness: Benghazi Case Study","This paper reports the results and findings of a historical analysis of open source intelligence (OSINT) information (namely Twitter data) surrounding the events of the September 11, 2012 attack on the US Diplomatic mission in Benghazi, Libya. In addition to this historical analysis, two prototype capabilities were combined for a table top exercise to explore the effectiveness of using OSINT combined with a context aware handheld situational awareness framework and application to better inform potential responders as the events unfolded. Our experience shows that the ability to model sentiment, trends, and monitor keywords in streaming social media, coupled with the ability to share that information to edge operators can increase their ability to effectively respond to contingency operations as they unfold.","","Boleng J,Novakouski M,Cahill G,Simanta S,Morris E","","2014","1421–1426","10.1109/MILCOM.2014.158","https://doi-org.proxy.bnl.lu/10.1109/MILCOM.2014.158;http://dx.doi.org/10.1109/MILCOM.2014.158","Conference Paper"
"GADSA: Decision Support App for Antibiotics Prescribing in Nigeria","GADSA (Gamified Antimicrobial Stewardship Decision Support App) is a decision support tool to improve evidence-based prescribing, designed to be used at the point-of-care to help clinicians comply with guidelines in their everyday practice. The app represents a novel cross-platform, mobile decision support tool, integrating principles from serious games and gamification, to improve compliance with prescription guidelines of Surgical Antibiotic Prophylaxis (SAP) in Nigeria. This paper focuses on the decision support component of the mobile application, integrating the World Health Organisation and Sanford guidelines for SAP prescriptions.","","Birjovanu G,Wood C,Olufemi O,Ogunsola F,Okonji P,Kpokiri E,Luedtke S,Shallcross L,Soriano D,Lefevre CE,Hayward A,Molnar A,NCube F,Wiseman S,Kostkova P","","2019","9–10","10.1145/3357729.3357734","https://doi-org.proxy.bnl.lu/10.1145/3357729.3357734;http://dx.doi.org/10.1145/3357729.3357734","Conference Paper"
"GAPs: Geospatial Abduction Problems","There are many applications where we observe various phenomena in space (e.g., locations of victims of a serial killer), and where we want to infer “partner” locations (e.g., the location where the killer lives) that are geospatially related to the observed phenomena. In this article, we define geospatial abduction problems (GAPs for short). We analyze the complexity of GAPs, develop exact and approximate algorithms (often with approximation guarantees) for these problems together with analyses of these algorithms, and develop a prototype implementation of our GAP framework. We demonstrate accuracy of our algorithms on a real world data set consisting of insurgent IED (improvised explosive device) attacks against U.S. forces in Iraq (the observations were the locations of the attacks, while the “partner” locations we were trying to infer were the locations of IED weapons caches).","","Shakarian P,Subrahmanian VS,Sapino ML","","2011","","10.1145/2036264.2036271","https://doi-org.proxy.bnl.lu/10.1145/2036264.2036271;http://dx.doi.org/10.1145/2036264.2036271","Journal Article"
"GPRS Security as a QoS in the Telecommunication Industry Case of Vodafone Egypt","The changes taking place in the world today are largely due to the developments and evolution in a number of industries; one of which is information and communication technology. Focusing on communications solutions with an emphasis on business applications, it is obvious to claim that business applications that are being deployed with 2.5G wireless networks fall into two general categories: (a) horizontal applications ''mobile office'' such as electronic mailing, voice communications, Internet access, short messaging and personal information management (PIM) tools and (b) vertical applications ''sales force automation''(SFA) and field force automation (FFA), fleet management, government communications and public safety, telemetry and remote monitoring, point-of-sale as well as financial services. The new generation of wireless devices being introduced to the market for 2.5G global system for mobile communications (GSM) and general packet radio service (GPRS) services is designed to support these applications, with features ranging from small standard keyboards to high resolutions rich colored screens. The impressive growth of cellular mobile telephony as well as the number of Internet users promises an exciting potential for a market that combines both innovations. The general packet radio service (GPRS) is a new non-voice value-added service that allows information to be sent and received across a mobile telephone network. Users of GPRS benefit from shorter access time and higher data rates. It is important to note that the standard GPRS network itself does not offer a reasonably secure solution for providing mobile access to a corporate local area network (LAN). Although, the air interface ciphering and the GPRS authentication process are secured, the IP traffic is unencrypted all the way from the serving GPRS support node (SGSN) to the corporate LAN gateway. The most feasible solution for secure remote connections would be to use an end-to-end virtual private network (VPN) solution from the mobile station (MS) to the corporate LAN gateway where the traffic is encrypted for the whole connection and the user can slip to the Internet from the nearest access point. It is important to separate the user traffic from the control traffic to guarantee high level of security with a minor impact on quality of service (QoS) which means providing consistent and predictable data delivery service that can lead to customer application requirement satisfaction. However, to achieve that security has to be looked at as the key player in the new GSM data networks when deploying GPRS. This paper demonstrates the case of Vodafone Egypt, one of the mobile operators, in deploying GPRS networks while focusing on exploring the business opportunities and motivating factors to implement GPRS. Moreover, the paper proposes solutions on how to create secure connections over GPRS networks while proposing a security policy for Vodafone Egypt.","","Kamel S,Wahba K","","2004","5–27","10.1016/j.ijinfomgt.2003.12.004","https://doi-org.proxy.bnl.lu/10.1016/j.ijinfomgt.2003.12.004;http://dx.doi.org/10.1016/j.ijinfomgt.2003.12.004","Journal Article"
"Generalized Jordan Sets in the Theory of Singular Partial Differential-Operator Equations","We apply the generalized Jordan sets techniques to reduce partial differential-operator equations with the Fredholm operator in the main expression to regular problems. In addition this techniques has been exploited to prove a theorem of existence and uniqueness of a singular initial problem, as well as to construct the left and right regularizators of singular operators in Banach spaces and to construct fundamental operators in the theory of generalized solutions of singular equations.","","Falaleev MV,Romanova OA,Sidorov NA","","2003","523–532","","","Conference Paper"
"Generation of High-Resolution Mosaic for Photo-Realistic Texture-Mapping of Cultural Heritage 3D Models","The work investigates the problem of how information contained in different overlapping images of a scene can be combined to produce larger images of higher quality. The resulted images can be used for different applications like forensic image analysis, computer animation, special effects, 3D model texture mapping or panorama mosaic. In our case, high-resolution image mosaics of mural frescos are required for the texturing of a 3D model that will be used in a movie production. We developed a novel method for the derivation of a high quality mosaic using multi-resolution and multi-temporal images acquired from arbitrary positions and cameras. This method named 'constrained mesh-wise affine transformation' allows for seamless enhancement of the scene in the areas where higher resolution images are available. In this paper, we also discuss alternative procedures for the texture mapping of a 3D model using existing multi-resolution and multi-temporal imagery. The work has been done within a project aimed at a virtual and physical reconstruction of the destroyed Buddha statues of Bamiyan, Afghanistan.","","Remondino F,Niederoest J","","2004","85–92","","","Conference Paper"
"Genres of Spam: Expectations and Deceptions","This paper is a pilot study that explores how the concept of genre can be applied to the massive set of digital documents known as 'spam'. The authors studied 300 spam messages collected over 15 weeks from a university email system. Messages were coded based on content, form and specific features as well as on the manifest relationship to existing genres of communication. The paper argues that spam is not a single genre but many genres. For the most part, the genres evoked in spam are adaptations of print to Internet, including information artifacts, pamphlets, business cards, order forms, bulletins, advertisements, and ""Nigerian letters"". With spam, however, the concept of genre operates at several levels. Often, there is a contradiction between the manifest genre and the underlying purposes. The paper concludes that spam exploits genre by conforming to known forms while at the same time breaching those norms.","","Cukier WL,Cody S,Nesselroth EJ","","2006","51.1","10.1109/HICSS.2006.195","https://doi-org.proxy.bnl.lu/10.1109/HICSS.2006.195;http://dx.doi.org/10.1109/HICSS.2006.195","Conference Paper"
"German Typographers vs. German Grammar: Decomposition of Wikipedia Category Labels into Attribute-Value Pairs","Given an instance (Julieta Pinto), most methods for open-domain information extraction focus on acquiring knowledge in the form of either class labels (Costa Rican short story writers, Women novelists) referring to concepts to which the instance belongs; or facts (nationality: Costa Rica) connecting the instance (Julieta Pinto) to other instances or concepts (Costa Rica), where the fact and the other instance often take the form of an attribute (nationality) and a value (Costa Rica) respectively. From extraction through internal representation and storage, class labels and facts are treated as if they carved out disconnected slices within the larger space of factual knowledge. This paper argues that class labels and facts pertaining to an instance exist in symbiosis rather than as a dichotomy. A constituent (Costa Rican) within a class label (Costa Rican short story writers) of an instance may be indicative of a fact (nationality: Costa Rica) applicable to the instance and vice-versa. As an illustration of the relationship between class labels and facts, the paper introduces an open-domain method for the better understanding of the semantics of class labels in one of the larger and most widely-used repositories of knowledge, namely the categories in the Wikipedia category network. The method exploits the category network to associate constituents (Costa Rican) within names of Wikipedia categories, with attributes (nationality) that explain their role.","","Paşca M","","2017","315–324","10.1145/3018661.3018662","https://doi-org.proxy.bnl.lu/10.1145/3018661.3018662;http://dx.doi.org/10.1145/3018661.3018662","Conference Paper"
"Global Variation in Attack Encounters and Hosting","Countries vary greatly in the extent to which their computers encounter and host attacks. Empirically identifying factors behind such variation can provide a sound basis for policies to reduce attacks worldwide. However, the main current approach to identify these factors consists of expert opinions with limited empirical validation. In this work, we empirically test hypotheses regarding social and technological factors behind such international variation. We use Symantec's Intrusion Prevention System (IPS) telemetry data collected from around 10 million Symantec customers worldwide.We find that web attacks and fake applications are most prominent in Western Europe and North America. Our results indicate a relationship between countries' wealth and technological sophistication and attack exposure, indicating that attackers probably target developed countries to maximize their profits. Moreover, Eastern Europe hosts disproportionate quantities of attacks. Our statistical analysis reveals a relationship between attack hosting and the combined effect of widespread corruption and computing resources. Surprisingly, China is not among the top 10 attack hosting countries and Africa hosts the smallest quantities of attacks. Our work has important policy implications.","","Mezzour G,Carley KM,Carley LR","","2017","62–73","10.1145/3055305.3055306","https://doi-org.proxy.bnl.lu/10.1145/3055305.3055306;http://dx.doi.org/10.1145/3055305.3055306","Conference Paper"
"Grey Markov Model Forecast in Economic System under Incomplete Information and Its Application on Foreign Direct Investment","Foreign direct investment (FDI) plays an extraordinary role in developing countries and its fluctuations reflect the changes of influencing factors during time, and therefore the models to simulate and forecast the trends are of great significance. Model GM (1, 1) is used in this paper to overcome the problems of small sample size and poor data. In the pre-procession of the raw data, two sequences are generated from weakening operator and from logarithm process respectively, and the simulation results show that the model constructed from the logarithm sequence has better simulation accuracy. Then Markov Chain is introduced to original model to get more accurate forecast results, which indicate the growing trend of FDI inflows in the following three years. The grey system models applied in economic areas are proved to have accurate simulation and convincing results.","","Wang Y,Chen C","","2011","117–120","10.1109/ICIII.2011.175","https://doi-org.proxy.bnl.lu/10.1109/ICIII.2011.175;http://dx.doi.org/10.1109/ICIII.2011.175","Conference Paper"
"Group Profiling for Understanding Social Structures","The prolific use of participatory Web and social networking sites is reshaping the ways in which people interact with one another. It has become a vital part of human social life in both the developed and developing world. People sharing certain similarities or affiliates tend to form communities within social media. At the same time, they participate in various online activities: content sharing, tagging, posting status updates, etc. These diverse activities leave behind traces of their social life, providing clues to understand changing social structures. A large body of existing work focuses on extracting cohesive groups based on network topology. But little attention is paid to understanding the changing social structures. In order to help explain the formation of a group, we explore different group-profiling strategies to construct descriptions of a group. This research can assist network navigation, visualization, and analysis, as well as monitoring and tracking the ebbs and tides of different groups in evolving networks. By exploiting information collected from real-world social media sites, extensive experiments are conducted to evaluate group-profiling results. The pros and cons of different group-profiling strategies are analyzed with concrete examples. We also show some potential applications based on group profiling. Interesting findings with discussions are reported.","","Tang L,Wang X,Liu H","","2011","","10.1145/2036264.2036279","https://doi-org.proxy.bnl.lu/10.1145/2036264.2036279;http://dx.doi.org/10.1145/2036264.2036279","Journal Article"
"Group-Based Password Characteristics Analysis","In this article, we analyze password characteristics from the perspective of user groups in different countries and web-based services. We collect a dataset from the Chinese railway website www.12306.cn. which contains data from four provinces, Hubei, Zhejiang, Inner Mongolia and Xinjiang. Additionally, we select datasets from two English based Internet applications, Faithwrit-er and Facebook. We analyze these six datasets based on several common indicators, including popular passwords, password structure and letter distribution. The analysis results show that there are remarkable differences in different user groups. The experiments show that geographical factors (embodied in the native language) and types of website services play a significant role in password creation. We further evaluate the security of these passwords by employing two state-of-the-art password cracking techniques. The attack results show that datasets of different provinces and different types of website services have different password strength. To the best of our knowledge, this is the first time passwords are analyzed based on different user groups.","","He D,Zhou B,Yu H,Cheng Y,Chan S,Zhang M,Guizani N","","2021","311–317","10.1109/MNET.011.2000354","https://doi-org.proxy.bnl.lu/10.1109/MNET.011.2000354;http://dx.doi.org/10.1109/MNET.011.2000354","Journal Article"
"HIPAA and QMS Based Architectural Requirements to Cope with the OCR Audit Program","The United States legislation known as the Health Insurance Portability and Accountability Act of 1996 (HIPAA) is aimed at strengthening patient rights, increasing efficiency and decreasing administrative costs in the healthcare industry. Under HIPAA all Covered Entities are required to ensure compliance with certain privacy and security rules concerned with protecting private patient health information. Building upon the objectives of HIPAA, the American Recovery and Reinvestment Act (ARRA) of 2009, in Section 13411 of the Health Information Technology for Economic and Clinical Health (HITECH) Act, required the Department of Health and Human Services (HHS) to conduct periodic audits of Covered Entities against HIPAA Security Rule. This paper presents and evaluates a new approach which might be used by Covered Entities to achieve compliance with HIPAA by adopting the ISO 9001 guidelines. A United States based Healthcare IT Company (UHITC) with a backup office in Pakistan was taken as a case study for this approach. UHITC develops software for mobile devices along with providing third party medical billing services. In connection with its achieving ISO 9001 certification since 2004, UHITC had already developed a company-wide quality audit protocol based on the ISO 9001 standard. For purposes of conforming the ISO standards to the HIPAA audit protocol in a streamlined fashion, UHITC examined the HIPAA requirements to determine whether the existing protocol could be tailored to achieve HIPAA compliance. In order to accomplish this evaluation, the two standards were compared by cross-mapping their components. The comparison revealed that the controls mentioned in the ISO 9001 guideline meet or exceed the HIPAA Security Rule for 36% of the implementation requirements. UHITC was also able to increase customer satisfaction by achieving compliance with HIPAA Security Rule using a quality management system (QMS) model. At the next level, Compliance Attributes (CA) were derived from these requirements and classified as architectural and non-architectural in nature. A new approach to define compliance oriented software architecture using compliance tactic was also proposed.","","Gardazi SU,Shahid AA,Salimbene C","","2012","246–253","10.1109/MUSIC.2012.50","https://doi-org.proxy.bnl.lu/10.1109/MUSIC.2012.50;http://dx.doi.org/10.1109/MUSIC.2012.50","Conference Paper"
"Harnessing Nigeria's Investment in Satellite Technology for Sustainable Agriculture and Food Security","This paper examines the relevance of satellite technology in promoting and sustaining agricultural development and food security in Africa and Nigeria in particular. Some of the common problems facing agricultural development in Nigeria and Africa as a whole are discussed. The authors justify the relevance of Nigeria's investment in satellite technology for improving agricultural production in Nigeria and Africa as a whole. The paper also presents selected applications of NigeriaSat-1 in sustainable agriculture and food security as embarked on by the government of Nigeria through the National Space Research and Development Agency. Policy recommendations were made to further boost agricultural production and food security in Africa and particularly Nigeria.","","Opeyemi ZA,Akinyede JO","","2012","63–72","10.4018/jagr.2012010106","https://doi-org.proxy.bnl.lu/10.4018/jagr.2012010106;http://dx.doi.org/10.4018/jagr.2012010106","Journal Article"
"Healthcare Providers’ Perspective about the Use of Telemedicine in Egypt: A National Survey","Incorporation of telemedicine in general clinical practice is becoming a compelling need nowadays in the context of COVID-19 pandemic and its consequent burdens on the healthcare systems. Though telemedicine appears to be appealing and carries a lot of advantages, yet it is still faced by many challenges and barriers especially in developing countries. Our aim was to explore the impression of healthcare providers about telemedicine and its applicability in clinical practice in Egypt. A cross-sectional study was conducted among healthcare providers from different Egyptian governorates through a web-based survey. The survey gathered information about demographic, socioeconomic features of the enrolled healthcare participants; their knowledge, previous experience, impression about telemedicine, advantages of telemedicine over traditional medical services, barriers that may face telemedicine, and additional services that can be provided by telemedicine were also explored. Our study enrolled 642 healthcare providers from all over Egypt, 43.77% were females, of which 55.5% were physicians, 27.3% were nurses, 6.1% were technicians, 7.6% were administrative clerks, and 3.6% were medical directors. Sixty-four percent of participants reported that they have never used telemedicine. Smartphones were the most commonly used mean in the group who used telemedicine (65%), and smartphone applications were the favorable telemedicine service for about 50% of participants. Participants assumed that the use of telemedicine might not have a negative effect on the doctor-patient relationship but raised some concerns regarding the privacy and security of patients’ data. Despite the fact that telemedicine appears to be appealing and widely accepted by healthcare providers, yet still, its implementation is confronted by some obstacles. Precise organizational guidelines need to be developed to clearly figure out the exact role of each healthcare provider to minimize their doubtfulness about telemedicine and to facilitate its adoption.","","Alboraie M,Abdalgaber M,Youssef N,Moaz I,Abdeen N,Abosheaishaa HM,Shokry MT,El-Raey F,Asfour SS,Abdeldayem WA,Hassan AA,Mahran EE,Tag-Adeen M,Elshaarawy O,Radwan MI,Altonbary A,Fouad Y,Tsiknakis M","","2022","","10.1155/2022/3811068","https://doi-org.proxy.bnl.lu/10.1155/2022/3811068;http://dx.doi.org/10.1155/2022/3811068","Journal Article"
"Heritage Building Information Modelling (HBIM) as a Tool for Heritage Conservation: Observations and Reflections on Data Collection, Management and Use in Research in a Middle Eastern Context","The rich architectural and urban heritage of Jordan is under continuing threat not only through means of physical attack but also physical disaster, increasing urbanization and a diminishing value from multiple stakeholders such as owners and users. This research study explores the potential of digital technologies in documenting and preserving urban architectural heritage in Jordan. Data was collected from diverse stakeholders on heritage conservation in Jordan. The findings evidence that Building Information Modelling (BIM) has the potential to create a classification system for heritage buildings under threat and set forth the application of legislation and regulations about heritage . The study demonstrated that the collection of data information needs to be understood through the context of cultural sensitivity. Lack of awareness in the value of cultural heritage from local communities exacerbates the diminishing efforts in preserving cultural assets. In collecting information for the documentation of this heritage, this study categorizes the challenges of preserving urban heritage as either hierarchical or cultural. The collection, management and storing of data for digital heritage requires an awareness of the issues of time and the power structures that are involved in their collection and upon which they have a profound effect.","","Aburamadan R,Moustaka A,Trillo C,Makore BC,Udeaja C,Gyau Baffour Awuah K","","2021","3–14","10.1007/978-3-030-77411-0_1","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-77411-0_1;http://dx.doi.org/10.1007/978-3-030-77411-0_1","Conference Paper"
"High Performance Java Card Operating System","Due to the fast evolving of trusted computing environments and internet-of-things an eager need has been established for open platforms which support interchangeable technologies to co-exist without threatening system's security. Certainly, future embedded applications will need high performance operating systems to support the intensive-computing algorithms required for satisfying acceptable response and secure the application inside the vulnerable open environment, hence, new inevitable requirements for embedded operating systems have arisen including hard real-time response, support for native applications, system openness and system scalability. This paper introduces a new design for secure and open smart card operating system, called ESCOS (Egypt Smart Card Operating System), based on the prevalent Java Card technology. The new design provides competitive characteristics in the main three factors of judging smart card platforms, namely, system security, supported technology and system response. In addition, ESCOS is designed to have high degree of modularity and re-configurability to meet fast-changing business needs and diverse hardware platforms.","","Eletriby MR,Sobh M,Eldin AM,Fahmy HM","","2014","30–39","10.1109/SERE.2014.16","https://doi-org.proxy.bnl.lu/10.1109/SERE.2014.16;http://dx.doi.org/10.1109/SERE.2014.16","Conference Paper"
"Home Edge Computing Architecture for Smart and Sustainable Agriculture and Breeding","Challenges of today and tomorrow in developing countries to ensure sustainable food security for their populations require smart agriculture and breeding. This necessarily depends on water control, soil erosion, livestock management, and so on. At the same time, Internet of Things (IoT) represents the latest evolution of the Internet and can significantly improve the ability to collect, analyze and retrieve data that we can then transform into information, knowledge and finally knowing. In the context of ensuring smart and sustainable agriculture, the importance of IoT seems obvious. Note that, IoT has implications for bandwidth, latency and processing speeds, given the huge amount of data to collect. Edge computing and Systems are one of the emerging solutions to reduce latency and improve bandwidth utilization for real-time applications and services. Thus, to achieve these aims, we propose, in this paper, a new three-tier architecture (3-TIER) for smart agriculture. It is based on that of Home Edge Computing allowing us to achieve ultra-low latency. This architecture will also allow us to effectively solve the problems related to agriculture and livestock breeding, but also to be able to resolve considerably the conflicts between farmers and herders. This proposal will be followed by an experimental validation of HEC architecture using the EdgeCloudSim simulator.","","Babou CS,Sane BO,Diane I,Niang I","","2019","","10.1145/3320326.3320377","https://doi-org.proxy.bnl.lu/10.1145/3320326.3320377;http://dx.doi.org/10.1145/3320326.3320377","Conference Paper"
"How Advances in Semiconductor Technologies Have Adversely Affected Electrical and Electronics Installations in Africa","This paper presents findings obtained in the Zambian national instrumentation surveys and highlights the little understood adverse effects that advances in semiconductor technology have on electrical and electronic instrumentation applied in all sectors in most African countries in particular Zambia. These effects have been occasioned by the lack of compliance to revised international installation and protection standards, poor power quality and poor planning compounded in many cases by severe weather conditions. These adverse impacts have been mainly caused by very high transistor integration in semiconductor (ICs). This has meant that electrical environment of yester year now requires vast improvements for the newer low dielectric strength component based equipment to operate reliably and safely. This paper finally describes good installation practices in power conditioning, earthing, bonding, surge and lightning protection solutions.","","Namukolo S,Musonda E","","2018","86–94","10.4108/eai.20-6-2017.2270803","https://doi-org.proxy.bnl.lu/10.4108/eai.20-6-2017.2270803;http://dx.doi.org/10.4108/eai.20-6-2017.2270803","Conference Paper"
"How to Define Value on Data under Blockchain Driven Open Data System for E-Government","Many interesting news and activities are going on in the field of blockchain (sometimes called, Distributed Ledger Technology) related technologies like cryptocurrency, Initial Coin Offering (ICO), Internet of Things (IoT), Big Data, Artificial Intelligence (AI, mostly Deep Learning). Not only developing countries but also developed countries need to be concerned about applying blockchain technology to their e-government system. Blockchain technology has brought a very deep innovation over conventional Client Server Trusted Third Party intermediary system to pure peer-to-peer (P2P) based smart contract system. This smart contract based peer-to-peer system allow participants to share data which was not possible under Client Server Trusted Third Party system due to architectural monopoly nature of Client Server. Smart contract concept brought logical conditions to share data among participants but it does not provide any definition about data value. This peer-to-peer based data sharing can be practically possible only under definition of value on data shared. If this definition is vague, then it will be very difficult to share data among participants. Also if this definition is clear, data sharing participants can get much benefit from this data sharing. This data sharing will be only effective from blockchain based architecture.","","Park JS,Kim YS,Choi CH,Shim J","","2018","670–672","10.1145/3209415.3209436","https://doi-org.proxy.bnl.lu/10.1145/3209415.3209436;http://dx.doi.org/10.1145/3209415.3209436","Conference Paper"
"ICT Supported Extension Services in Conservation Agriculture Information Access for Small Holder Farmers in Laikipia County, Kenya","This paper examines how Information Communication Technologies (ICTs) are used in the Conservation Agriculture (CA) knowledge pathways. It discusses the parallel knowledge pathways smallholder farmers' use to access conservation agriculture information. The objective of this study is to develop an effective dissemination model that exploits the use of ICTs in existing pathways in order to improve Conservation Agriculture knowledge flows. Design, Methodology and Approach: A total of one hundred and twenty-five respondents were interviewed, with a purposively selected sample of 110 CA farmers interviewed using semi-structured questionnaires. Using the snowball method, 15 key informant interviews were conducted with Policy makers and ICT service providers. 69% of the respondents were female and 51% male. The focus of the study was on the different ICTs used in the CA knowledge pathways, the dissemination pathways, institutional and socio-economic factors. Data was analyzed manually and using SSPS ver. 21. Preliminary findings indicate that a variety of knowledge pathways exist through which farmers can access CA knowledge. Four different kinds of ICT led models were identified, Government ICT led models, Government-NGO led models, Government-NGO-Private Sector ICT led model and NGO ICT led models. However the study notes a lack of harmonization and weak linkages between institutions in the utilization of the existing ICT models, utilization of the ICTs access and ownership at the household level and harmonization of the CA messages. Furthermore, even though there was 100% mobile phones ownership, 94% radio, 64% television, 10% Laptop and 9% Computer (desktop) access and ownership among the respondents, farmers and a large number of the extension staff lacked the skills to fully exploit the use of these tools to access CA knowledge. Implication: New emerging and existing communication technologies have a very high potential to improve agricultural knowledge flows if taken advantage of by the ""change agents"" in the diffusion process of new innovations. New online technologies known as Web 2.0 and ‘social media’ are slowly emerging as platforms for collaboration, sharing of product and market information. Open chain models of village information centres also provide numerous economic opportunities, and do also network communities while providing public/private services. The opportunity of using real time communication tools has been greatly embraced especially by the youthful farmers and the advantage of these new emerging tools is their unique attributes, similar to the traditional oral cultures of communication seen in the African social systems where one can see, hold a discussion, get immediate feedback and use the written media to convey messages. The high percentage of ownership and accessibility of ICTs among the survey population also offers the potential to fully exploit ICTs in the improvement of the CA knowledge pathways and agricultural information provision.","","Cox AJ,Sseguya H","","2015","1–6","10.1109/ISTAS.2015.7439408","https://doi-org.proxy.bnl.lu/10.1109/ISTAS.2015.7439408;http://dx.doi.org/10.1109/ISTAS.2015.7439408","Conference Paper"
"ICT for Human Development in South Pacific","The author worked past year as Professor & Head of School of Computing, Information and Mathematical Sciences and Director of Japan Pacific ICT Centre at the University of South Pacific. The South Pacific Region has many problems related to environmental and economic issues. The University of the South Pacific (USP) is an ideal platform for provision of development of Human Resources and enhancement of Human Security in the Pacific. Current dynamic Internet developments and continuous demand for the ubiquitous connectivity combined with the next generation of networks contributes towards creation the future cyberspace infrastructures worldwide. Implementation of the cyberspace in the government and corporate infrastructures, contributes towards creation of new paradigm in the decision making processes. Decisions that are currently governed by the human intelligence knowledge and intuition may be influenced by the cyber-data and processes. Future cyberspace will ultimately impact the decision making processes by government, corporate, industrial and academic institutions worldwide. Main objective of ICT Development is to build human-resource for ICT capacity development all across developing countries in the south pacific while “bridging the digital divide”. Main Goal was to provide the south pacific region with appropriate resources to take the lead role in driving the Pacific through Human Resource Development Programs. Specific Goal is to focus on developing and strengthening ICT skills applicable at the e-services level. The author discusses the development of new Japan Pacific Information Communications Technologies (ICT) Centre at the University of the South Pacific and ICT for Human Development and Security in the South Pacific Region. The main objective is to accommodate increasing demand for ICT-related education and training in the region and to accelerate research and development activities in the Pacific. The ICT Centre will play a facilitator role for ICT related education, Training; and Research and Development for the Pacific. In conclusion the author promotes discussion on the role of the role of the ICT in the South Pacific Region. The author opens discussion on ICT's social and ethical impact in the south pacific region in the context of governance vs. privacy.","","Babulak E","","2010","621–624","10.1109/MINES.2010.229","https://doi-org.proxy.bnl.lu/10.1109/MINES.2010.229;http://dx.doi.org/10.1109/MINES.2010.229","Conference Paper"
"ICT for the Prevention of Avian Influenza","This paper intends to point out some problem of telemetry for wild birds and future technical expectations to prevent Avian Influenza. The ITU-D(International Telecommunications Union, Development Sector ) SG2(Study Group) Q14(Question) Rapporteur's Meeting hosted by the Ministry of Internal Affairs and Communications of Japan started in Tokyo on July 3-4, 2008. The Q14 deals with application of information and telecommunication technologies in health care. Meeting participants discussed the application of the information and communications technologies to help resolve some issues related to the improvement of access to medical treatment of people living in rural and remote areas of developing countries. The participants have also raised the question about the threat of avian influenza and what could be done with the ultimate goal of preventing and containing this disease. There were considerable deliberation on this emerging disease threat. Therefore, it was recommended that the ITU has to initiate the discussion at appropriate international level on how to set up the Integrated Information and Communications Network for Avian Influenza by using advanced information and telecommunication technologies for tracking of migratory birds. The participants concur in adopting the results of their work as the Statement of Appeal.","","Nakajima I,Androuchko L,Juzoji H,Tomioka Y,Kitano T","","2009","124–129","","","Conference Paper"
"IPM-Model: AI and Metaheuristic-Enabled Face Recognition Using Image Partial Matching for Multimedia Forensics Investigation with Genetic Algorithm","The rapid enhancement in the development of information technology has driven the development of human facial image recognition. Recently, facial recognition has been successfully applied in several distinct domains with the help of computing and information technology. This kind of application plays a significant role in the process of digital forensics investigation, recognizing the patterns of a human face based on the partial matching of images that would be in 24-bit color image format, including the spacing of the eyes, the bridging of the nose, the contour of the lips, ears, and chin. In this paper, we have proposed and implemented an image recognition model based on principal component analysis, genetic algorithms, and neural networks, in which PCA reduces the dimension of the benchmark dataset, while genetic algorithms and neural nets optimize the searching patterns of image matching and provide highly efficient output with a minimal amount of time. Through the experiment results on the human facial images dataset of the Georgia Institute of Technology, the overall match showed that the proposed model can achieve the recognition of human face images with an accuracy rate of 93.7%. Moreover, this model helps to examine, analyze, and detect individuals by partial matching with reidentification in the procedure of forensics investigation. The experimental result shows the robustness of the proposed model in terms of efficiency compared to other state-of-the-art methods.","","Khan AA,Shaikh AA,Shaikh ZA,Laghari AA,Karim S","","2022","23533–23549","10.1007/s11042-022-12398-x","https://doi-org.proxy.bnl.lu/10.1007/s11042-022-12398-x;http://dx.doi.org/10.1007/s11042-022-12398-x","Journal Article"
"IT Enabled Counter Terrorism Infrastructure: Issues and Challenges","In the post 11 September 2001, terrorism has been an immediate and most serious threat to the free world because of its real and potential damage to the infrastructure, economy and people. In response to the 11 September 2001 terrorist attacks, developed and developing countries, such as USA and Pakistan, have emerged as front line states in the fight against terrorism with the following objectives: (1) prevent future terrorist attacks, (2) reduce the nations vulnerability and (3) minimise the damage and recovery from attacks that occur. In order to achieve these objectives, we require new approaches to intelligence and information gathering and its analysis through the use of information technology. In this paper, we attempt to identify (1) the areas where IT can contribute in accomplishing these three strategic security objectives, (2) the unique IT problems and challenges in counter terrorism applications where such applications are being used and developed such as in USA and (3) lessons learned for developing countries such as Pakistan, so that an IT counter terrorism infrastructure can be established with minimum cost in terms of time and money.","","Ahsan S","","2007","117–124","10.1504/IJESDF.2007.013597","https://doi-org.proxy.bnl.lu/10.1504/IJESDF.2007.013597;http://dx.doi.org/10.1504/IJESDF.2007.013597","Journal Article"
"Identification of Ditches and Furrows Using Remote Sensing: Application to Sediment Modelling in the Tana Watershed, Kenya","Ridge-tillage is an agricultural practice where crops are planted on elevated ridges, with furrows in-between. Ridge-tillage has been shown to significantly reduce erosion from croplands, but data on the presence of ridge-tillage is sparse and challenging to collect at the landscape scale. Thus, water quality models often do not account for ridge-tillage in a spatially-explicit manner, potentially overlooking the important impacts of this practice. We have developed a novel method that exploits the spectral, radiometric and linearity shape characteristics to identify both drainage ditches and ridge-tillage furrows using remote sensing of 0.5 m satellite data. We applied the method to the Sasumua watershed in Kenya, where we had false positives in only 3% of randomly selected polygons, and we detected the majority of ditches in 59% of randomly selected polygons. We then assessed the potential value of including these data in sediment modelling, showing that representing these practices could reduce sediment export in the study area by roughly 80%. Being able to readily identify the presence of ditches and furrows could enable the development of more accurate water quality models, and help identify priority areas for intervention to improve water quality and possibly crop yields through changing agricultural practices or policies.","","Ayana EK,Fisher JR,Hamel P,Boucher TM","","2017","4611–4630","10.1080/01431161.2017.1327125","https://doi-org.proxy.bnl.lu/10.1080/01431161.2017.1327125;http://dx.doi.org/10.1080/01431161.2017.1327125","Journal Article"
"Identifying the Implied: Findings from Three Differentiated Replications on the Use of Security Requirements Templates","Identifying security requirements early on can lay the foundation for secure software development. Security requirements are often implied by existing functional requirements but are mostly left unspecified. The Security Discoverer (SD) process automatically identifies security implications of individual requirements sentences and suggests applicable security requirements templates. The objective of this research is to support requirements analysts in identifying security requirements by automating the suggestion of security requirements templates that are implied by existing functional requirements. We conducted a controlled experiment in a graduate-level security class at North Carolina State University (NCSU) to evaluate the SD process in eliciting implied security requirements in 2014. We have subsequently conducted three differentiated replications to evaluate the generalizability and applicability of the initial findings. The replications were conducted across three countries at the University of Trento, NCSU, and the University of Costa Rica. We evaluated the responses of the 205 total participants in terms of quality, coverage, relevance and efficiency. We also develop shared insights regarding the impact of context factors such as time, motivation and support, on the study outcomes and provide lessons learned in conducting the replications. Treatment group, using the SD process, performed significantly better than the control group (at p-value <0.05) in terms of the coverage of the identified security requirements and efficiency of the requirements elicitation process in two of the three replications, supporting the findings of the original study. Participants in the treatment group identified 84 % more security requirements in the oracle as compared to the control group on average. Overall, 80 % of the 111 participants in the treatment group were favorable towards the use of templates in identifying security requirements. Our qualitative findings indicate that participants may be able to differentiate between relevant and extraneous templates suggestions and be more inclined to fill in the templates with additional support. Security requirements templates capture the security knowledge of multiple experts and can support the security requirements elicitation process when automatically suggested, making the implied security requirements more evident. However, individual participants may still miss out on identifying a number of security requirements due to empirical constraints as well as potential limitations on knowledge and security expertise.","","Riaz M,King J,Slankas J,Williams L,Massacci F,Quesada-López C,Jenkins M","","2017","2127–2178","10.1007/s10664-016-9481-1","https://doi-org.proxy.bnl.lu/10.1007/s10664-016-9481-1;http://dx.doi.org/10.1007/s10664-016-9481-1","Journal Article"
"Image Fusion for Enhanced Forest Structural Assessment","This research explores the potential benefits of fusing active and passive medium-resolution satellite-borne sensor data for forest structural assessment. Image fusion was applied as a means of retaining disparate data features relevant to modelling and mapping of forest structural attributes in even-aged (4-11 years) Eucalyptus plantations, located in the southern KwaZulu-Natal midlands of South Africa. Remote-sensing data used in this research included the visible and near-infrared bands of the Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER), as well as a fine-beam (6.25 m resolution) Radarsat-1 image. Both datasets were collected during the spring of 2006 and fused using a modified discrete wavelet transformation. Spatially referenced forest-inventory data were also collected during this time, with 122 plots enumerated in 38 plantation compartments. Empirical relationships (ordinary and multiple regression) were used to test whether fused data sources produced superior statistical models. Secondary objectives of the article included exploring the roles of texture, derived from grey-level co-occurrence matrices, and scale in terms of forest modelling at the plot and extended plot levels (Voroni diagrams). Results indicate that single bands from both the optical and Synthetic Aperture Radar (SAR) datasets were not adept at modelling basal area and merchantable timber volume with adjusted R2 (coefficient of determination) values < 0.3. An optimized multiple-regression approach (adjusted R2) improved results based on mean, range and standard deviation statistics when compared to single bands, but were still not suitable for operational forest applications (basal area: R2 = 0.55, volume: R2 = 0.59). No significant difference was found between fused and non-fused datasets; however, optical and fused datasets produced superior models when compared to SAR results. Investigations into potential benefits of using textural indices and varied scales also returned inconclusive results. Findings indicate that the spatial resolutions of both sensors are inappropriate for plantation forest assessment. The frequency of the C-band Radarsat-1 data is, for instance, unable to penetrate the canopy and interact with the woody structures below canopy, leading to weak statistical models. The lack of variability in both the optical and SAR data lead to unconvincing results in the fused imagery, where, in some cases, the adjusted R2 results were worse than the single-dataset approach. It was concluded that future research should focus on high-spatial-resolution optical and Light Detection and Ranging (LiDAR) data and the development of automated and semi-automated forest-inventory procedures.","","Roberts JW,Van Aardt JA,Ahmed FB","","2011","243–266","10.1080/01431160903463684","https://doi-org.proxy.bnl.lu/10.1080/01431160903463684;http://dx.doi.org/10.1080/01431160903463684","Journal Article"
"Impact of Digital Marketing on Consumers' Impulsive Online Buying Tendencies With Intervening Effect of Gender and Education: B2C Emerging Promotional Tools","We are living in the digital age where consumers have become more elegant, and their buying intention is radically transforming from traditional to online buying behavior. This study investigates the impact of digital marketing (DM) tools on consumers' online impulsive buying tendencies (OBIT), i.e., effective (AD) and cognitive tendencies (CD) with intervening role of the gender (GDR) and education-level (EL). Four hundred surveys were randomly distributed to online shoppers in Pakistan. SEM was applied to test the proposed relationships and findings revealed a positive association between DM and consumers' OBIT. The comprehensive examination affirmed the positive interrelationships of sub-dimensions of DM on consumers' OBIT, i.e., AD and CD. It is further revealed that GDR and EL did not moderate the relationships between DM and OBIT. This study furnishes insights on how advertisers can exploit such platforms to achieve OBIT and creating effective relationships in today's digital age. This study demonstrates certain directions for academicians and practitioners.","","Waheed A,Wang D,Sarwar-A Alam MD","","2019","44–59","10.4018/IJEIS.2019070103","https://doi-org.proxy.bnl.lu/10.4018/IJEIS.2019070103;http://dx.doi.org/10.4018/IJEIS.2019070103","Journal Article"
"Implementing Data Security in Student Lifecycle Management System at the University of Prishtina","In this paper is presented a novel approach for fulfilling the data security criteria in a Student Lifecycle Management System at the University of Prishtina. The four main criteria of data security such as: privacy, authentication, integrity and non-repudiation are fulfilled through carefully selected security policies. Student data privacy is achieved using the Secure Socket Layer protocol for web communication with web server. Each user, being student, academic or administrative staff is provided with unique user name and initial password in the Student Lifecycle Management System. Data integrity and non-repudiation are fulfilled using digital signatures. The novelty of implemented solution is based on extending the subject name in X.509 digital certificates and using this certificate for securing student grades, which is in full compliance with the Kosovo Law on Information Society. Public Key Infrastructure and X.509 digital certificates have been established as the most trustworthy methods for assuring data security criteria in modern software applications. Security policy enforces that digital certificate and its associated private key shall be stored in a smart card. Access to private key stored in a smart card is protected by Personal Identification Number, known only by smart card holder. This implementation was installed at the Faculty of Electrical and Computer Engineering and has successfully passed a six semester testing period and students were, for the first time in the history of the University of Prishtina, able to apply online to take an exam.","","Rexha B,Lajqi H,Limani M","","2010","965–974","","","Journal Article"
"Important Role of the Hall Effect Measurement System in a Modified Course of Materials in Electrical Engineering","The course ldquoMaterials in Electrical Engineeringrdquo is a core course in the Mechatronics curriculum at the Faculty of Technical Sciences, University of Novi Sad, Serbia. In the past, this course was comprehensive and mainly theory-based. Teaching methods used in this course had not been changed for many years, and were mainly based on a traditional approach. They were therefore often outdated, and boring for students. In addition, the lack of modern materials characterization equipment was a significant weakness of the course in its early stages. This paper presents the main aspects of the modified course, which features a greater inclusion of modern equipment in its teaching methodology; in particular it introduces the Hall effect measurement system as an indispensable characterization technique in education, research and in the semiconductor industry. This paper also describes how students can be taught to use the Hall effect measurement system to determine the structural and electrical characteristics of different materials. Finally, students' feedback and observations on the modified course and the applied teaching methodology are discussed.","","Stojanovic G,Savic S,Zivanov L","","2009","297–304","10.1109/TE.2008.928206","https://doi-org.proxy.bnl.lu/10.1109/TE.2008.928206;http://dx.doi.org/10.1109/TE.2008.928206","Journal Article"
"Improved List Decoding of Generalized Reed-Solomon and Alternant Codes over Galois Rings","We present a two-stage list decoder comprising an errors-only Guruswami-Sudan (GS) decoder and an errors-and-erasures GS decoder as component decoders in the first and second stage, respectively. The two stages are coupled via a post-processor which selects a codeword from the output list of the first component decoder, from which erasure locations are obtained for the second stage. When applied to a generalized Reed-Solomon (RS) code over a Galois ring R that maps into a generalized RS code of the same length n and minimum (Hamming) distance d over the corresponding residue field, the proposed decoder exploits the presence of zero divisors in R to correct s errors where w=lceiln-radic(n(n-d))-1rceil<sleslceiln- radic((n-w)(n-d))-1rceil with a probability determined by s, w, and the ratio of the number of nontrivial zero divisors to the number of units in the code alphabet. Focusing primarily on alternant codes over Zopf(2l), an important class of subring subcodes of generalized RS codes over GR(2l,a), we demonstrate that the GS decoding radius w can be exceeded by a substantial margin with significant probability","","Armand MA","","2005","728–733","10.1109/TIT.2004.840901","https://doi-org.proxy.bnl.lu/10.1109/TIT.2004.840901;http://dx.doi.org/10.1109/TIT.2004.840901","Journal Article"
"Improved Meet-in-the-Middle Attacks on Reduced-Round Kalyna-128/256 and Kalyna-256/512","Kalyna is an SPN-based block cipher that was selected during the Ukrainian National Public Cryptographic Competition (2007---2010) and its slight modification was approved as the new encryption standard of Ukraine. In this paper, we focus on the key-recovery attacks on reduced-round Kalyna-128/256 and Kalyna-256/512 with the meet-in-the-middle method. The differential enumeration technique and key-dependent sieve technique which are popular to analyze AES are used to attack them. Using the key-dependent sieve technique to improve the complexity is not an easy task, we should build some tables to achieve this. Since the encryption procedure of Kalyna employs pre- and post-whitening operations using addition modulo $$2^64$$264 applied on the state columns independently, we carefully study the propagation of this operation and propose an addition plaintext structure to solve this. For Kalyna-128/256, we propose a 6-round distinguisher, and achieve a 9-round (out of total 14-round) attack. For Kalyna-256/512, we propose a 7-round distinguisher, then achieve an 11-round (out of total 18-round) attack. As far as we know, these are currently the best results on Kalyna-128/256 and Kalyna-256/512.","","Lin L,Wu W","","2018","721–741","10.1007/s10623-017-0353-5","https://doi-org.proxy.bnl.lu/10.1007/s10623-017-0353-5;http://dx.doi.org/10.1007/s10623-017-0353-5","Journal Article"
"Improving Security Awareness in the Government Sector","The increasing use of internet and smart mobile devices for accessing, storing and generating sensitive e-government data makes them an attractive attack vector for cyber-criminals. New technology adoption typically requires specialized training and awareness campaigns where people acquire new skills, learn about best practices and potential pitfalls of adoption. In this paper, we present results from a survey in Pakistan to help understand the level of cyber security awareness and understanding in the Government sector. The goal of the survey is to help identify at-risk demographics, problems, risks and key areas of concern that need to be addressed through customized education material and trainings. We then discuss design strategies to reduce the security and privacy risk faced by mobile device users of Government departments.","","Amjad HA,Naeem U,Zaffar MA,Zaffar MF,Choo KK","","2016","1–7","10.1145/2912160.2912186","https://doi-org.proxy.bnl.lu/10.1145/2912160.2912186;http://dx.doi.org/10.1145/2912160.2912186","Conference Paper"
"Inconsistent Requirements: An Argumentation View","In this article, we present a logical framework for reasoning about inconsistent requirements in the context of multi-viewpoint requirements engineering process. In order to analyse the sources of inconsistencies and to reason with inconsistent requirements, we present an argumentation view of the requirements. Intuitively, argumentation is a tool for reasoning with inconsistent knowledge: requirements are defined in terms of arguments (a conclusion with its support); then, a class of acceptable arguments is built (arguments with no counterarguments). We propose to characterize different classes of requirements which are ordered: from weakly confident to strongly confident (i.e. consistent). In the paper, we present inference rules to build intra and inter-viewpoint reasoning. Inference rules are issued from the classes of requirements. We show how this work is useful for the requirements engineers to analyse inconsistent fragments of requirements.A Multi-Agent System to the Common Management of a Renewable Resource: Application to Water Sharing M. Le Bars a,b and J.M. Attonaty b a LAMSADE laboratory Université Paris-Dauphine 75775 Paris Cedex 16. France. bINRA Station d'économie rurale, BP 01 78850 Grignon France. lebarsm@aol.com;attonaty@grigon.inra.fr Abstract. Water sharing has become an important problem in France. A lot of negotiations are taking place at a local level between farmers, water suppliers, public services and environmentalists to allocate water resources between users. The problem is to share water with respect of different criteria like economic (global output) ethical (disparities between actors) environmental (water savings). Different approaches have been already taken using linear programming or game theory, but they are always based on the hypothesis that decision-makers are completely rational, take into account few players and are often monoperiodic. We suggest that an Agent-Based Modelling (ABM) built with a Multi-Agent approach could help negotiations between different players by showing the consequences of water allocation rules and taking in consideration the players 'respective attitudes and their ability to change their behaviour. In this paper we will first present the model structure with the different types of agents modelled, how the model runs over a number of years and the first results of simulations. Keywords. Distributed Artificial Intelligence; Multi-Agent Systems Title: A new hybrid method for solving constraint optimization problems in anytime contexts Authors: Samir Loudni and Patrice Boizumault Affiliation: Ecole Des Mines de Nantes Abstract: In this paper, we present a new hybrid method for solving constraint optimization problems in anytime contexts. We use the Valued Constraint Satisfaction Problem (VCSP) framework to model numerous discrete optimization problems. Our method (VNS/LDS+CP) combines a Variable Neighborhood Search (VNS) scheme with Limited Discrepancy Search (LDS) using Constraint Propagation (CP) to evaluate cost and legality of moves made by VNS. Our experimental results on real-word problem instances demonstrate that our method clearly outperforms both LNS/CP/GR (another hybrid method which also relies on the VCSP framework) and other standard local search methods as Simulated-Annealing. This confirm the benefit of the use, in a local search, of the LDS partial search with constraint propagation. keywords: Anytime Problems, Constraint-Satisfaction, Constraint-Optimization, Local Search Methods, Hybrid Methods. Using Software Agents to avoid Collisions among Multiple Robots Markus Jäger Corporate Technology, Information and Communications Siemens AG 81739 Munich, Germany markus.jaeger@mchp.siemens.de AI Algorithms Collaborative Software Agents Cooperating Robots This paper describes a method where collaborative software agents are used to coordinate the independently planned trajectories of multiple mobile robots to avoid collisions and deadlocks among them. Whenever the distance between two robots drops below a certain value, the agents exchange information about the planned trajectories of the robots and determine whether they are in danger of a collision. If a possible collision is detected, the agents monitor the robots movements and, if necessary, insert idle times between certain segments of the trajectories in order to avoid the collision. Deadlocks among two or more robots occur if a number of robots block each other in a way such that none of them is able to continue along its trajectory without causing a collision. These deadlocks are reliably detected by the agents. After a deadlock is detected, alternative trajectories for each of the involved robots are successively planned until the deadlock is resolved. The agents use a combination of three fully distributed algorithms to reliably solve the task. They do not use any global synchronization. ----------- Authors Affiliations: - Cooperating Software Agents - Cooperating Robots - Collision Avoidance among multiple Robots - Area Partitioning - Area Coverage The title : Successive Search Method for Valued Constraint Satisfaction and Optimization Problems. Authors Names : Mohamed TOUNSI and Philippe DAVID Email Adresses : mohamed.tounsi@emn.fr and philippe.david@emn.fr Affiliation : Computer Science Department, Ecole des Mines de Nantes , 4 Rue Alfred Kastler 44307 Nantes, FRANCE. Abstract : In this paper we introduce a new method based on Russian Doll Search (RDS) for solving optimization problems expressed as Valued Constraint Satisfaction Problems (VCSPs). The RDS method solves problems of size n (where n is the number of variables) by replacing one search by n successive searches on nested subproblems using the results of each search to produce a better lower bound. The main idea of our method is to introduce the variables through the successive searches not one by one but by sets of k variables. We present two variants of our method: the first one where the number k is fixed, noted kfRDS; the second one, kvRDS, where k can be variable. Finally, we show that our method improves RDS on daily management of an earth observation satellite. Keywords : Constraint Satisfaction, VCSP, Optimization Problems. B-Course: A Web Service for Bayesian Data Analysis Petri Myllymaki, Tomi Silander, Henry Tirri, Pekka Uronen Complex Systems Computation Group (CoSCo) P.O.Box 26, Department of Computer Science FIN-00014 University of Helsinki, Finland URL: http://www.cs.Helsinki.FI/research/cosco/ B-Course (http://b-course.cs.helsinki.fi) is a free web-based online data analysis tool, which allows the users to analyze their data for multivariate probabilistic dependencies. These dependencies are represented as Bayesian network models. In addition to this, B-Course also offers facilities for inferring certain type of causal dependencies from the data. The software uses a novel ""tutorial style"" user-friendly interface which intertwines the steps in the data analysis with support material that gives an informal introduction to the Bayesian approach adopted. Although the analysis methods, modeling assumptions and restrictions are totally transparent to the user, this transparency is not achieved at the expense of analysis power: with the restrictions stated in the support material, B-Course is a powerful analysis tool exploiting several theoretically elaborate results developed recently in the fields of Bayesian and causal modeling. B-Course can be used with most web-browsers (even Lynx), and the facilities include features such as automatic missing data handling and discretization, a flexible graphical interface for probabilistic inference on the constructed Bayesian network models (for Java enabled browsers), automatic pretty-printed layout for the networks, exportation of the models, and analysis of the importance of the derived dependencies. In this paper we discuss both the theoretical design principles underlying the B-Course tool, and the pragmatic methods adopted in the implementation of the software. Artificial Neural Networks in Hydrological Watershed Modeling: Surface Flow Contribution from the Ungaged Parts of a Catchment Richard Chibanga1, Jean Berlamont2 and Joos Vandewalle3 1PhD student in the Civil Eng. Dept. and 2Prof. Civil Eng. Dept., and Head of Hydraulics Laboratory, 3 Prof. Head of Electrical Engineering Dept - SISTA/COSIC, Katholieke Universiteit, Kasteelpark Arenberg 40, 3001 Heverlee (Leuven), Belgium Abstract Watershed modeling is often faced with the difficulty of determining the flow contribution from the ungaged sections of the catchment. Where the main concern is making accurate streamflow forecasts at specific watershed locations, it is cost-effective and efficient to implement a simple system theoretic model. In this paper Artificial Neural Networks (ANNs) are used as system theoretic models to model the ungaged flows. Using data from the Kafue River sub-catchment in Zambia and a simple reservoir routing model, an estimate of the flow contribution from the ungaged sections is derived. Inputs: rainfall, evaporation, previous-time-step flow are fed to a series of Feedforward-Backpropagation ANNs with target-output the current derived flow. Selected best- performing ANNs are compared with Autoregressive Moving Average models with exogenous inputs (ARMAX) and they give accurate and more robust forecasts over long term than the best performing ARMAXs thereby making ANNs a viable alternative in time-series forecasting. Keywords: semi conceptual-system theoretic; Artificial neural networks; subsystem; tributary-runoff; forecasting; mapping. Title: Generation of Propagation Rules for Intentionally Defined Constraints Authors: Slim Abdennadher Computer Science Department, University of Munich Oettingenstr. 67, 80538 Munich, Germany Slim.Abdennadher@informatik.uni-muenchen.de Christophe Rigotti Laboratoire d'Ingenierie des Systemes d'Information Batiment 501, INSA Lyon, 69621 Villeurbanne Cedex, France Christophe.Rigotti@insa-lyon.fr Abstract: A general approach to implement propagation and simplification of constraints consists of applying rules over these constraints. However, a difficulty that arises frequently when writing a constraint solver is to determine the constraint propagation algorithm. In previous work, different methods for automatic generation of propagation rules for constraints defined over finite domains have been proposed. In this paper, we present a method for generating propagation rules for constraint predicates defined by means of a constraint logic program. Keywords: Constraint solving, Machine learning, Rule-based programming Title : ""Data Flow Coherence Criteria in ILP Tools"" Authors : Smaranda Muresan Department of Computer Science, Columbia University, New York, USA smara@cs.columbia.edu Tudor Muresan Department of Computer Science, Technical Univ. of Cluj-Napoca, Cluj-Napoca, Romania tmuresan@cs.utcluj.ro Rodica Potolea Department of Computer Science, Technical Univ. of Cluj-Napoca, Cluj-Napoca, Romania potolea@cs.utcluj.ro Keywords : Inductive Logic Programming, Automatic Program Generation, Data Flow Coherence Criteria, Pruning the Search Space Abstract: In this paper we present a new method that uses data-flow coherence criteria in definite logic program generation. We outline three main advantages of these criteria supported by our results: i) drastically pruning the search space (around 90%), ii) reducing the set of positive examples and reducing or even removing the need for the set of negative examples, and iii) allowing the induction of predicates that are difficult or even impossible to generate by other methods. Besides these criteria, the approach takes into consideration the program termination condition for recursive predicates. The paper outlines some theoretical issues and implementation aspects of our system for automatic logic program induction. Title: An Expert Recommendation System using Concept-based Relevance Discernment Authors: Takashi Yukawa NTT Corporation NTT Communication Science Laboratories 2-4 Hikaridai, Seika-cho, Kyoto, Japan yukawa@cslab.kecl.ntt.co.jp Kaname Kasahara NTT Corporation NTT Communication Science Laboratories 2-4 Hikaridai, Seika-cho, Kyoto, Japan kaname@cslab.kecl.ntt.co.jp Tsuneaki Kato The University of Tokyo Graduate School of Arts and Science Dept. of Language and Information Science 3-1-8 Komaba, Meguro-ku, Tokyo, Japan kato@boz.c.u-tokyo.ac.jp Toshiro Kita NTT Communications Corporation Solution Business Division Yamato Seimei Bldg. 1-1-7, Uchisaiwai-cho Chiyoda-ku, Tokyo, Japan toshiro.kita@ntt.com Keywords: information retrieval, recommendation system, vector space model, concept base, knowledge management Abstract: An expert recommendation system using concept-based relevance discernment is proposed. This system processes the description of a technical topic as input and then finds engineers who have a high level of expertise in that area. The technique employed is an extended vector space model that locates both technical topics and engineers in the same multi-dimensional space, and then calculates their relevance. This system can also retrieve engineers or documents that are related to a field matching a given engineer's technical interests. Such a system can be expected to play the role of a person's professional network, and be a valuable tool for knowledge management among several organizations. Paper Title: Combinatorial Optimization through Statistical Instance-Based Learning Keywords: constructive search, heuristics, optimization, instance-based learning Authors: Orestis Telelis, Panagiotis Stamatopoulos Department of Informatics and Telecommunications University of Athens 157 84 Athens, Greece telelis,takis@di.uoa.gr Abstract: Different successful heuristic approaches have been proposed for solving combinatorial optimization problems. Commonly, each of them is specialized to serve a different purpose or address specific difficulties. However, most combinatorial problems that model real world applications have a priori well known measurable properties. Embedded machine learning methods may aid towards the recognition and utilization of these properties for the achievement of satisfactory solutions. In this paper, we present a heuristic methodology which employs the instance-based machine learning paradigm. This methodology can be adequately configured for several types of optimization problems which are known to have certain properties. Experimental results are discussed concerning two well known problems, namely the knapsack problem and the set partitioning problem. These results show that the proposed approach is able to find significantly better solutions compared to intuitive search methods based on heuristics which are usually applied to the specific problems. TITLE: Interleaved Backtracking in Distributed Constraint Networks > AUTHOR: Youssef Hamadi > AFFILIATION: Hewlett Packards Labs Filton road, Stoke Gifford, > Bristol BS34 8QZ, United Kingdom > EMAIL: yh@hplb.hpl.hp.com > > > Abstract > The adaptation of software technology to distributed > environments is an important challenge today. In this > work we combine parallel and distributed search. By > this way we add the potential speed up of a parallel > exploration in the processing of distributed problems. > This paper extends DIBT, a distributed search proce > dure operating in distributed constraint networks [6]. > The extension is twofold. First the procedure is up > dated to face delayed information problems upcoming > in heterogeneous systems. Second, the search is ex > tended to simultaneously explore independent parts of > a distributed search tree. By this way we introduce > parallelism into distributed search, which brings to In > terleaved Distributed Intelligent BackTracking (IDIBT). > Our results show that 1) insoluble problems do not > greatly degrade performance over DIBT and 2) super > linear speed up can be achieved when the distribution > of solution is nonuniform. > > Keywords: Distributed Constraint Satisfaction, Distributed AI, > Collaborative Software Agents, Search","","Perrussel L,Charrel PJ","","2001","79","","","Conference Paper"
"Informal Interactive Bring Your Own Device Strategising Practices of South African Small and Medium Enterprises","The purpose of this study is two-fold: firstly, to identify factors affecting BYOD adoption in South African SMEs and secondly understand strategies SMEs engage in with regard to BYOD. Following an interpretive approach, and interviews as a means of data collection; the findings show that SMEs are consciously aware of BYOD but are not eager to formalise their strategy. Instead, SMEs engage in informal interactive strategising despite their concerns of cost, security and privacy. SMEs did not view BYOD as a cost saving approach but rather as a double end sword that brought privacy and security concerns; unintended consequence; and no improvement in productivity. Further findings show how SMEs, specifically employees advocated the need for a policy prescribing how mobile devices should be used and in so doing perpetuating the interactive strategising. External factors such as changing laws and regulation were perceived as barriers towards a formalised BYOD strategy.","","","","2018","257–295","","","Journal Article"
"Information Security Education and Self-Perception of Privacy Protection Risk in Mobile Web in Obstetrics Students from Peru","The objective of the study was to determine the information security education topics developed in the training of obstetrics students and their relationship with the self-perception of privacy protection risk in mobile web during the COVID-19 pandemic at the Santiago Antúnez of Mayolo National University (UNASAM) (Huaraz-Peru). A correlational cross-sectional investigation was developed, with 164 obstetric students. The information was collected through a questionnaire applied online between November and December 2020, having determined its validity and reliability. The Chi squared statistical test (p < 0.05) was used, while the information processing was carried out using the SPSS program. It was determined that 61.6% of obstetric students perceived a high risk in the protection of their privacy in mobile web during the development of their activities in the academic cycle 2020-I. Likewise, it was evidenced that the majority of students stated that they had not developed the topics consulted with regard to information security education during their virtual studies in obstetric, especially with regard to the recommendations for the use of passwords (83.5%), privacy protection strategies (81.1%) and data management through the creation of backups (79.9%), showing a statistically significant relationship with the self-perception of privacy protection risk in mobile web (p < 0.05). It was concluded that the low development of information security education topics in the training of obstetric students is related to the self-perception of high risk in the privacy protection in mobile web during the COVID-19 pandemic.","","Olaza-Maguiña AF,De La Cruz-Ramirez YM","","2021","32–43","10.1007/978-3-030-83164-6_3","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-83164-6_3;http://dx.doi.org/10.1007/978-3-030-83164-6_3","Conference Paper"
"Information Spreading Forensics via Sequential Dependent Snapshots","Mining the characteristics of information spreading in networks is crucial in communication studies, network security management, epidemic investigations, etc. Previous works are restrictive because they mainly focused on the information source detection using either a single observation, or multiple but independent observations of the underlying network while assuming a homogeneous information spreading rate. We conduct a theoretical and experimental study on information spreading, and propose a new and novel estimation framework to estimate 1 information spreading rates, 2 start time of the information source, and 3 the location of information source by utilizing multiple sequential and dependent snapshots where information can spread at heterogeneous rates. Our framework generalizes the current state-of-the-art rumor centrality [1] and the union rumor centrality [2]. Furthermore, we allow heterogeneous information spreading rates at different branches of a network. Our framework provides conditional maximum likelihood estimators for the above three metrics and is more accurate than rumor centrality and Jordan center in both synthetic networks and real-world networks. Applying our framework to the Twitter’s retweet networks, we can accurately determine who made the initial tweet and at what time the tweet was sent. Furthermore, we also validate that the rates of information spreading are indeed heterogeneous among different parts of a retweet network.","","Cai K,Xie H,Lui JC","","2018","478–491","10.1109/TNET.2018.2791412","https://doi-org.proxy.bnl.lu/10.1109/TNET.2018.2791412;http://dx.doi.org/10.1109/TNET.2018.2791412","Journal Article"
"Infrastructure Resilience for Climate Adaptation","Developing and maintaining resilient transportation infrastructure is a key strategy for meeting several UN sustainable development goals in the face of climate change-driven extreme flooding events. We present a framework for performing data-driven vulnerability analysis for flooding on existing transportation networks, and use this analysis to inform decision-making about investments for climate adaptation. We apply this approach to study the potential impacts of severe flooding on regional mobility in Senegal, using a combination of flood hazard maps and a travel demand model based on call detail record data. We use the estimated number of infeasible trips as a direct measure of flooding-induced mobility impacts, as well as an objective for minimizing these impacts. We then compare three alternative road network upgrade strategies to assess the extent to which each strategy would preserve network functionality under a given flooding scenario. We illustrate that strategies driven solely by travel demand can lead to underinvestment in roads that are at risk of flooding, while solely focusing on repairing flooded road segments neglects the criticality of those repairs to mobility. For example, in a 100 year flooding scenario with a fixed budget, our strategy that considers both flooding and mobility data can achieve a 53% reduction in the number of infeasible trips, while a strategy that just considers flooding data achieves only a 38% reduction for the same cost. Our framework can be applied more broadly to integrate information from a variety of sources about climate hazards and potential human impacts to make better informed decisions about investments in critical infrastructure systems.","","Gupta A,Robinson C,Dilkina B","","2018","","10.1145/3209811.3209859","https://doi-org.proxy.bnl.lu/10.1145/3209811.3209859;http://dx.doi.org/10.1145/3209811.3209859","Conference Paper"
"Insider Perspectives of Human-Computer Interaction for Development Research: Opportunities and Challenges","Human-Computer Interaction (HCI) research has gained traction in Africa in recent years. Researchers and designers have exploited the opportunities created by advances in mobile technology and increasing access to internet services in the communities to develop and deploy user-centered digital solutions targeting African audience and for solving Africa's problems. However, only a few researches have investigated the potential opportunities and challenges that face the adoption of HCI projects and mobile technology among indigenous people, especially in Biafra land in Nigeria. Therefore, the goal of this paper is to present an insider perspective of our lived experiences in conducting HCI4D and mobile technology research, the methodological and practical challenges, and design opportunities for advancing social and culturally-sensitive HCI research and mobile application designs in the Global South.","","Samuel Nkwo M,Orji R,Ugah J","","2021","131–135","10.1145/3448696.3448709","https://doi-org.proxy.bnl.lu/10.1145/3448696.3448709;http://dx.doi.org/10.1145/3448696.3448709","Conference Paper"
"Institutions and Consumers","This study on evaluation of the affirmation of ordinary consumer interest in the digital mobile telecommunications market in Nigeria situates within the broader perspective of the public interest and in the context of policy failure (what happens after adopting policy?). It focuses on aspects of compliance, monitoring, and enforcement of policy objective relating to ordinary consumer interest, areas that receive inadequate attention in policy literature.The study is conducted using the new institutional economics framework. It adapts and extends the Saleth and Dinar (1999) institution decomposition model to deconstruct the mobile institution into four major components: policy, law, administration and enforcement for analytical purposes. Using document analysis, supplemented by semi-structured interviews, the study provides insights into how the regulatory framework engages with the ordinary consumer and the implications this has for the delivery of the policy objective of protecting ordinary consumer interest.The main findings reveal that (1) due to weak institutional structures, the regulator and mobile service providers do not hold ordinary consumer's interest at levels consistent with policy and law (2) there is no special intervention to make basic mobile services accessible and affordable for low-income ordinary consumers and (3) the pervasive violation of consumer interest persists due to laxity in enforcement of existing rules.The public interest in telecommunications policy has so far benefitted mobile companies in Nigeria rather than ordinary consumers. The existing policy failure, as discussed in this case study, can provide inspiration for rethinking the place of the ordinary consumer. Pervasive violation of consumer interest persist due to laxity in rules enforcement.There is no intervention to make mobile service affordable for ordinary consumer.Ranking investment over affordability results in high transaction cost for consumer.The Commission is not consumer focused; she is hampered by conflict of interest.","","Onyeajuwa MK","","2017","642–650","10.1016/j.telpol.2017.05.004","https://doi-org.proxy.bnl.lu/10.1016/j.telpol.2017.05.004;http://dx.doi.org/10.1016/j.telpol.2017.05.004","Journal Article"
"Integrated Security Framework for Low Cost RFID Tags","Radio Frequency Identification (RFID) systems are becoming more popular today because of the wide area of applications. It is being used in several industries such as the transport industry, sports, medical and government institutions. Its advantages such as the capacity to store more information than other identification technologies as well as the ease with which data can be read (since it doesn't require line of sight and human intervention), have sparked its widespread use and implementation in the various industries.The most widely used class of RFID tags is the class 1 tag because it offers identification functionality at low cost. Class 1 tags have limited computational power and memory resources. Due to these limitations, common authentication protocols such as AES cannot be implemented on the class 1 tags. As these tags provide essential implementation capabilities for development countries such as South Africa, it is vital that researchers focus on providing adequate security solutions. Taking into account the information security needs and performance limitations of the class 1 tags, we present a lightweight protocol based on the Hopper and Blum's human authentication protocol.","","Muwanguzi M,Biermann E","","2010","201–208","10.1145/1899503.1899526","https://doi-org.proxy.bnl.lu/10.1145/1899503.1899526;http://dx.doi.org/10.1145/1899503.1899526","Conference Paper"
"Integrating MDA and SOA for Improving Telemedicine Services","Telemedicine supports the geographic distribution and continuity of medical services.Model Driven Architecture (MDA) or the separation of functional and technical needs.Service Oriented Architecture (SOA) for interoperable exchanges among applications.Combined use of MDA SOA for more scalable and sustainable services in telemedicine.Reverse engineering in the RAFT application for its modernization and improvement. Through telemedicine, the health sector has seized the opportunity offered by development of information and communications technology (ICT) such as the business or industrial sectors, but ICTs are constantly evolving. To benefit from technological progress it is necessary to adapt the computer applications to these technologies, however this operation is costly to health facilities especially in developing countries. In terms of scientific research, this observation explains the development of model-driven engineering of computer systems such as the Model Driven Architecture (MDA) approach. MDA is a computer design approach for the development of computer systems that considers separately the functional needs of technical needs of an application. MDA mainly uses the models and their transformations whose traces allow MDA to capitalize expertise in terms of technology and to ensure some rapid modernization of applications to new technologies which results in a significant productivity gain. Today there is a huge requirement worldwide in the interoperable services, in particular with regard to their valuable contribution to the collaboration ability of remote information technology systems. Service Oriented Architecture (SOA) is an interesting architectural pattern in which software components contribute to the collaboration and sharing of services. In this way, the principles of SOA are intended to ensure interoperability between heterogeneous and distributed applications. Web services are at the heart of SOA, which splits functions into different services, accessible over a computer network that enables users to associate and reuse them in the exploitation of applications. Health applications have a strong need to communicate with the remote institutions in order to provide the most relevant services to patients and to collaborate with other medical partners to solve complex tasks. For this purpose, the proposed research work shows how the paradigms of SOA and MDA can be configured to implement medical software applications on an e-health platform. The case study concerns the Telemedicine in French-speaking Africa (RAFT) project in which the joint use of MDA and SOA facilitates knowledge combination and reuse in the management of applications supporting a medical collaborative work environment.","","Traore BB,Kamsu-Foguem B,Tangara F","","2016","733–741","10.1016/j.tele.2015.11.009","https://doi-org.proxy.bnl.lu/10.1016/j.tele.2015.11.009;http://dx.doi.org/10.1016/j.tele.2015.11.009","Journal Article"
"Integrating Value Modeling and Legal Risk Management: An IT Case Study","Companies need to be able to demonstrate compliance with rules and regulations, especially start-ups who typically do not have the legal expertise to identify, assess and address legal risks of initial business ideas, nor do they have the resources to hire such expertise. Tools could help them identify and deal with legal risk at an early stage. Existing research in BPM focuses on compliance verification of a consolidated business model by checking the ability of a company to comply with the standards. The challenge is to apply a ‘continuous improvement’ by steering the business on values. Moreover, legal choices typically sit at the strategic level, and not only at the operational level. In this paper, we therefore propose an approach to handle legal risks as part of business model development. The approach makes use of Continuous Business Model Planning method, a value-driven modeling approach for strategic planning, and legal argumentation. The suitability and potential usefulness of the approach is illustrated by a study of the Kenyan court case Lipisha & BitPesa vs. Safaricom.","","Muthuri R,Capecchi S,Sulis E,Amantea IA,Boella G","","2022","27–55","10.1007/s10257-021-00543-2","https://doi-org.proxy.bnl.lu/10.1007/s10257-021-00543-2;http://dx.doi.org/10.1007/s10257-021-00543-2","Journal Article"
"Integrating Web 2.0 into an Academic Library in Tanzania","Purpose - This paper aims to demonstrate work undertaken by Muhimbili University of Health and Allied Sciences MUHAS Library in an effort to integrate Web 2.0 technologies in its functions to enhance the quality of its services in Tanzania. Design/methodology/approach - The study conducted an exploratory questionnaire survey to assess user requirements among undergraduate medical students at MUHAS, developed Library 2.0 services, conducted training and created awareness. Findings - The paper shows that Web 2.0 technologies can be implemented effectively according to university goals, user's needs, deployment of user friendly tools, and capacity building among librarians and users. Students positively supported the adoption of Library 2.0 services at MUHAS. Library 2.0 services improved the quality of MUHAS library services, despite various challenges related to infrastructure, awareness, literacy, inadequate staff, security and ownership of Web 2.0 services. Research limitations/implications - The study findings may not be widely replicated because this article is based on a case study of the integration of Web 2.0 technologies into the library functions of MUHAS. This study did not examine the use of Library 2.0 applications among library users such as faculty and students which could illuminate further the case study. Practical implications - Most academic libraries in Africa have not yet adopted Web 2.0 technologies to improve their services. The user preferences, technology adoption, and challenges faced from the present study can help other libraries to plan and integrate their Library 2.0 technologies in their services. Originality/value - MUHAS Library offers a practical example of how Web 2.0 services can be adopted to enhance the quality of academic library services in an African context. This paper is of significance to academic libraries that are still considering their options with regard to the application of Web 2.0 technologies.","","Tandi Lwoga E","","2014","183–202","10.1108/EL-06-2012-0058","https://doi-org.proxy.bnl.lu/10.1108/EL-06-2012-0058;http://dx.doi.org/10.1108/EL-06-2012-0058","Journal Article"
"Inter-Organizational Study of Access Control Security Measures","This study assesses the level of implementation and management of access control security measures among organizations. A survey was conducted and 233 responses were received from 56 organizations drawn from 5 major industry sectors of Ghana. This study focuses on the four access control clauses, namely access control policy, user access management, user responsibility and accountability, and system and application access control, which were adopted from ISO/IEC27002 international information systems security management standard. Overall, the results show that the organizations' level of implementation and management of access control measures were approximately 66.6% Level 3-well defined, indicating that access control measures were documented, approved, and implemented organization-wide. Moreover, the results show significant differences in the implementation and management of access control measures among the organizations. For all the access control measures, the financial and health care institutions outperform educational institutions and government public services.","","Yaokumah W,Okai ES","","2018","60–79","10.4018/IJTHI.2018010104","https://doi-org.proxy.bnl.lu/10.4018/IJTHI.2018010104;http://dx.doi.org/10.4018/IJTHI.2018010104","Journal Article"
"Interaction Patterns and ICT Use to Support the Livelihoods of Microenterprises","This paper reports on the nature of interaction patterns and use of Information and Communication Technologies (ICT) to support the livelihood of microenterprises. The study focused on the case of South Africa where Small, Micro and Medium Enterprises (SMMEs) act as a means for addressing unemployment and poverty. The study used qualitative data to understand the interaction patterns and how ICT such as computers, mobile phones and internet are used to support the livelihoods of microenterprises. The findings showed that vertical and horizontal interactions supported the flow of information and sharing of knowledge used in decisions for reducing vulnerabilities in the livelihoods of microenterprises. ICT were improving the interactions that supported the livelihoods of microenterprises. The study recommends use of existing social networks for microenterprises when designing interventions for supporting microenterprises.","","Makoza F,Chigona W","","2014","20–40","10.4018/ijictrda.2014010102","https://doi-org.proxy.bnl.lu/10.4018/ijictrda.2014010102;http://dx.doi.org/10.4018/ijictrda.2014010102","Journal Article"
"Interoperability in the Heterogeneous Cloud Environment: A Survey of Recent User-Centric Approaches","Cloud computing provides users the ability to access shared, online computing resources. However, providers often offer their own proprietary applications, interfaces, APIs and infrastructures, resulting in a heterogeneous cloud environment. This heterogeneous environment makes it difficult for users to change cloud service providers; exploring capabilities to support the automated migration from one provider to another is an active, open research area. Many standards bodies (IEEE, NIST, DMTF and SNIA), industry (middleware) and academia have been pursuing approaches to reduce the impact of vendor lock-in by investigating the cloud migration problem at the level of the VM. However, the migration downtime, decoupling VM from underlying systems and security of live channels remain open issues. This paper focuses on analysing recently proposed live, cloud migration approaches for VMs at the infrastructure level in the cloud architecture. The analysis reveals issues with flexibility, performance, and security of the approaches, including additional loads to the CPU and disk I/O drivers of the physical machine where the VM initially resides. The next steps of this research are to develop and evaluate a new approach LibZam (Libya Zamzem) that will work towards addressing the identified limitations.","","Mansour I,Sahandi R,Cooper K,Warman A","","2016","","10.1145/2896387.2896447","https://doi-org.proxy.bnl.lu/10.1145/2896387.2896447;http://dx.doi.org/10.1145/2896387.2896447","Conference Paper"
"Introduction to Global Health IT Strategies and Applications Minitrack","The global proliferation of information and communication technologies, along with improved mobile computing accessibility, enhanced security and cloud-based data exchanges have germinated interests in those seeking to apply existing and emerging information technologies to address health issues throughout diverse regions of the world. This minitrack will examine similarities and differences in how regions as diverse as North America, Africa, Asia and the Middle-East apply technology for improving health and healthcare systems. The focus will be on emerging trends for applying innovative health IT solutions to improve general population and community health care across the globe, including low-cost, mobile and other emerging health technological applications.","","Tan J,Dohan MS,Patrick S","","2014","2570","10.1109/HICSS.2014.323","https://doi-org.proxy.bnl.lu/10.1109/HICSS.2014.323;http://dx.doi.org/10.1109/HICSS.2014.323","Conference Paper"
"Introduction to Special Section on Probabilistic Proof Systems","The study of probabilistically verifiable proofs originated in the mid 1980s with the introduction of Interactive Proof Systems (IPs). The primary focus of research in this area in the '80s has been twofold: the role of zero-knowledge interactive proofs within cryptographic protocols, and characterizing which languages are efficiently interactively provable. In the 1990s, the focus of research on the topic shifted. Extensions of the interactive proof model, such as Multiprover Interactive Proofs (MIPs) and Probabilistically Checkable Proofs (PCPs), were considered with the intention of expanding our notion of what should be considered efficiently verifiable. In addition, researchers have taken a closer look at the exact resources (and tradeoffs amongst them) needed to verify a proof using various proof systems. This culminated in the important discovery that it is possible to verify NP statements (with a constant error probability) by only examining a constant number of bits of a PCP and using logarithmic amount of randomness. Perhaps, however, the most dramatic development has been the connection which was found between probabilistically verifiable proofs and proving hardness of approximation for optimization problems. It has been shown that a large variety of optimization versions of NP-hard problems (e.g., the maximum size of a clique in a graph, the minimum number of colors necessary to color a graph, and the maximum number of clauses satisfiable in a CNF formula) are not only NP-hard to solve exactly but also NP-hard to approximate in a very strong sense. The tools to establish hardness of approximation came directly from results on MIPs and PCPs. Indeed, almost every improvement in the efficiency of these proof systems translates directly into showing larger factors within which these optimization problems are hard to approximate. In 1994--1995 two exciting workshops were held at the Weizmann Institute in Israel on the new developments in probabilistically verifiable proofs and their applications to approximation problems, cryptography, program checking, and complexity theory at large. Over 60 papers were presented in the workshop series, and we are proud to include three of them in this special section. ""On the Power of Finite Automata with Both Nondeterministic and Probabilistic States"" by Anne Condon, Lisa Hellerstein, Samuel Pottle, and Avi Wigderson, considers constant round interactive proof systems where the verifier is restricted to use constant space and public coins. An equivalent characterization is finite automata with both nondeterministic and random states (npfa's), which accept their languages with a small probability of error. The paper shows that npfa's restricted to run in polynomial expected time accept only the regular languages in the case of npfa with 1-way input head, and that if L is a nonregular language, then either L or its complement is not accepted by any npfa with a 2-way input head. ""A Parallel Repetition Theorem"" by Ran Raz, addresses and resolves the Parallel Repetition Conjecture which has eluded researchers for some time. The broader topic is what happens to the error probability of proof systems when they are composed. It has been known for awhile that sequential composition of proof systems (both single and multiprover interactive proofs) reduces the error exponentially, but this increases the number of rounds. For interactive proof systems, parallel repetition is known to reduce the error exponentially, and the Parallel Repetition Conjecture asserts that the same holds in a one-round two-prover proof system. Raz proves a constructive bound on the probability of error which indeed reduces at an exponential rate. The constant in the exponent is logarithmic in the total number of possible answers of the two provers, which means one can achieve two-prover one-round MIPs for NP statements with arbitrarily small constant error probability. This, in turn, has played a crucial role in further developments in the area and in particular in those reported in the next paper. ""Free Bits, PCPs, and Nonapproximability---Towards Tight Results"" by Mihir Bellare, Oded Goldreich, and Madhu Sudan, continues the investigation of PCPs and nonapproximability with emphasis on trying to get closer to tight results. The work consists of three parts. The first part presents several PCP proof systems for NP, based on a new error-correcting code called the Long Code. The second part shows that the connection between PCPs and hardness of approximation is not accidental. In particular, it shows that the transformation of a PCP for NP into hardness results for MaxClique can be reversed. Finally, the third part initiates a systematic investigation of the properties of PCPs as a function of the various parameters: randomness, query complexity, free-bit complexity, amortized free-bit complexity, proof size, etc. Two more papers submitted for this special section were not ready at this time for publication. They will appear in future issues of the SIAM Journal on Computing.","","Goldwasser S","","1998","737–738","10.1137/SMJCAT000027000003000737000001","https://doi-org.proxy.bnl.lu/10.1137/SMJCAT000027000003000737000001;http://dx.doi.org/10.1137/SMJCAT000027000003000737000001","Journal Article"
"Intrusion Detection Based on Data Mining","In this article we discuss our research in developing general and systematic methods for intrusion detection. The key ideas are to use data mining techniques to discover consistent and useful patterns of system features that describe program and user behavior, and use the set of relevant system features to compute (inductively learned) classifiers that can recognize anomalies and known intrusions. The paper also discusses the current level of computer security development in Tanzania with particular interest in IDS application with the fact that approach is easy to implement with less complexity to computer systems architecture, less dependence on operating environment (as compared with other security-based systems) and ability to detect abuse of user privileges easily. The findings are geared towards developing security infrastructure and providing ICT services.","","Oreku GS,Mtenzi FJ","","2009","696–701","10.1109/DASC.2009.56","https://doi-org.proxy.bnl.lu/10.1109/DASC.2009.56;http://dx.doi.org/10.1109/DASC.2009.56","Conference Paper"
"Investigating Current-Based And Gating Approaches For Accurate And Energy-Efficient Spiking Recurrent Neural Networks","Spiking Neural Networks (SNNs) with spike-based computations and communications may be more energy-efficient than Artificial Neural Networks (ANNs) for embedded applications. However, SNNs have mostly been applied to image processing, although audio applications may better fit their temporal dynamics. We evaluate the accuracy and energy-efficiency of Leaky Integrate-and-Fire (LIF) models on spiking audio datasets compared to ANNs. We demonstrate that, for processing temporal sequences, the Current-based LIF (Cuba-LIF) outperforms the LIF. Moreover, gated recurrent networks have demonstrated superior accuracy than simple recurrent networks for such tasks. Therefore, we introduce SpikGRU, a gated version of the Cuba-LIF. SpikGRU achieves higher accuracy than other recurrent SNNs on the most difficult task studied in this work. The Cuba-LIF and SpikGRU reach state-of-the-art accuracy, only <1.1% below the accuracy of the best ANNs, while showing up to a 49x reduction in the number of operations compared to ANNs, due to the high spike sparsity.","","Dampfhoffer M,Mesquida T,Valentian A,Anghel L","","2022","359–370","10.1007/978-3-031-15934-3_30","https://doi-org.proxy.bnl.lu/10.1007/978-3-031-15934-3_30;http://dx.doi.org/10.1007/978-3-031-15934-3_30","Conference Paper"
"IoT for Agricultural Information Generation and Recommendation: A Deep Learning-Based Approach","Agriculture is the foundation of national economy. Therefore, countries all over the world—developed and developing countries—attach great importance to the sustainable development of agriculture. With the rapid development of Internet of Things (IoT) technology, advance applications are being designed to enhance agricultural economy. With the application of IoT, the production mode of traditional agriculture has been restructured and rationalized. Based on the applications of IoT in agriculture, this paper presents a method to automatically classify and recommend agricultural information. The standard domain-related theories and information service system are exploited to promote IoT technology in the construction of agricultural informatization. A convolutional neural network (CNN) model is used to classify agricultural information based on the vector file generated after preprocessing textual agricultural data. With the clustering method, the influence of unbalanced number of documents in the dataset is minimized. Finally, an information recommendation method based on multimodal interaction behavior is proposed for agricultural information recommendation. Potential features from textual information are extracted which are then fed to long short-term memory (LSTM) in connection with the interaction behavior. LSTM is used for the prediction of the possibility of interaction with respect to the information recommendations system. The experimental results show the feasibility of CNN in agricultural information classification problem. A commendable clustering accuracy is obtained for the agriculture category containing a large number of documents. However, the category with fewer documents is less clustered. The model may be used to effectively extract and classify agricultural information and has great significance in structuring and shaping agricultural information for convenient use in agricultural decision-making.","","Wang H,Zhao Y,Shao C,Tirunagari S","","2022","","10.1155/2022/7378755","https://doi-org.proxy.bnl.lu/10.1155/2022/7378755;http://dx.doi.org/10.1155/2022/7378755","Journal Article"
"Key Issues of Information Systems Management in Botswana","Studies on key issues in information systems IS management aim at finding out critical IS issues that are of concern to IS executives and business leaders. The purpose of this paper was to investigate the key IS management issues in Botswana. A questionnaire was administered to collect data from information systems professionals working from the level of a programmer and above. A simple average was used to rank the key factors while factor analysis was carried out to determine the major groups of key issues in IS management. The results of simple average calculation showed that an information system security is the key management issue in Botswana. The results of factor analysis showed that the classification of key issues of IS management put forward by Niederman et al. 1991 has continued to change with new issues such as mobile applications and ecommerce showing up strongly and information systems security becoming a group in its own right. The findings continue to show that the key issues of IS management tend to differ across space and time. Culture and level of economic development are some of the factors which can make key issues differ from one country to another.","","","","2017","70–84","10.1504/IJISCM.2017.086237","https://doi-org.proxy.bnl.lu/10.1504/IJISCM.2017.086237;http://dx.doi.org/10.1504/IJISCM.2017.086237","Journal Article"
"Knowledge-Based Information Extraction: A Case Study of Recognizing Emails of Nigerian Frauds","This paper describes the methodology, process and results of developing an application ontology as software specification of the semantics of forensics in the email suspicious of Nigerian frauds. Real life examples of fraud emails are analyzed for evidence and red flags to capture the underlying domain semantics with an application ontology of frauds. A model of the natural language structure in regular expressions is developed in the light of the ontology and applied to emails to extract linguistic evidences of frauds. The evaluation of the initial results shows a satisfactory recognition as an automatic fraud alert system. It also demonstrates a methodological significance: the methodical conceptual modeling and specific purpose-driven linguistic modeling are effective in encapsulating and managing their respective needs, perspectives and variability in real life linguistic processing applications.","","Gao Y,Zhao G","","2005","161–172","10.1007/11428817_15","https://doi-org.proxy.bnl.lu/10.1007/11428817_15;http://dx.doi.org/10.1007/11428817_15","Conference Paper"
"Land Use Analysis Using GIS, Radar and Thematic Mapper in Ethiopia: PhD Showcase","Land degradation, and poverty issues are very common in our world, especially in developing countries in Africa. There are fewer adaptation strategies for climate change in these countries. Ethiopia is a tropical country found in the horn of Africa. The majority of the population live in rural areas and agriculture is the main economic sector. Extensive agriculture has resulted in an unexpected over-exploitation and land degradation. The project locations are Southwestern and Northwestern Ethiopia. The main objectives are to analize the accuracy of land use classification of each sensors, classification algorithms and analyze land use change. Thematic Mapper (TM) and Radar data will be used to classify and monitor land use change. Two consecutive satellite images will be used to see the land use change in the study area (1998, 2008). ERDAS Imagine will be used to resample and spatially register the Radar and TM data. The image classification for this research study is supervised signature extraction. The Maximum likelihood decision rule and C4.5 algorithm will be applied to classify the images. TM and Radar data will be fused by layer staking. The accuracy of the digital classification will be calculated using error matrix. Land change modeler will be used for analyzing and predicting land cover change. The impact of roads, urban and population density on land use change will be analayzed using GIS.","","Tadesse HK","","2010","53–58","10.1145/1869890.1869897","https://doi-org.proxy.bnl.lu/10.1145/1869890.1869897;http://dx.doi.org/10.1145/1869890.1869897","Conference Paper"
"Learned Features Are Better for Ethnicity Classification","Ethnicity is a key demographic attribute of human beings and it plays a vital role in automatic facial recognition and have extensive real world applications such as Human Computer Interaction (HCI); demographic based classification; biometric based recognition; security and defense to name a few. In this paper, we present a novel approach for extracting ethnicity from the facial images. The proposed method makes use of a pre trained Convolutional Neural Network (CNN) to extract the features, then Support Vector Machine (SVM) with linear kernel is used as a classifier. This technique uses translational invariant hierarchical features learned by the network, in contrast to previous works, which use hand crafted features such as Local Binary Pattern (LBP); Gabor, etc. Thorough experiments are presented on ten different facial databases, which strongly suggest that our approach is robust to different expressions and illuminations conditions. Here we consider ethnicity classification as a three class problem including Asian, African-American and Caucasian. Average classification accuracy over all databases is 98.28%, 99.66% and 99.05% for Asian, African-American and Caucasian respectively. All the codes are available for reproducing the results on request.","","Anwar I,Ul Islam N","","2017","152–164","10.1515/cait-2017-0036","https://doi-org.proxy.bnl.lu/10.1515/cait-2017-0036;http://dx.doi.org/10.1515/cait-2017-0036","Journal Article"
"Learning Sustainable Locust Control Methods in Virtual Reality","Invasion of locust swarms has affected the crops in many countries in Africa and Asia, which is a significant threat to food security. Therefore, different approaches are adopted to monitor and control the locust swarms to save the crops. Furthermore, it has been proved in various studies that technology can help in agriculture through drones, real-time data monitoring, or teaching the farmers with the latest tools. Following the UN sustainability goals for food security, this research has presented a Virtual Reality(VR) based educational application to teach sustainable locust management strategies. Using hand tracking technology in the Oculus Quest lets users learn how farmers can deal with locusts without pesticides. Based on a storytelling approach, the methods presented are profitable for the farmers and free of any harm to crops regarding food security. This application can help motivate the adoption of these sustainable locust control strategies in broader interventions for environmental recovery.","","Hahn N,Fuchs B,Fortna M,Cobb E,Iqbal MZ","","2022","271–274","10.1145/3505284.3532973","https://doi-org.proxy.bnl.lu/10.1145/3505284.3532973;http://dx.doi.org/10.1145/3505284.3532973","Conference Paper"
"Lessons Learned Building Low-Cost DIY Tactile Graphics and Conducting a Tactile Drawing Club in Colombia During COVID-19","Perceiving images and drawing are fundamental parts of human life, and thus access to them should be a universal right. However, there is a large breach for people with visual impairments to access diverse graphics, let alone drawing. There are several techniques of tactile graphics, such as swell paper, Braille embossing, and thermoform that help to alleviate this gap. However, in developing countries, the high cost and lack of access make them impractical. In this work, we describe our experience improving access to tactile graphics and drawing in Colombia. We created low-cost, effective and efficient, tactile graphics and drawing techniques that improve on current solutions. These techniques were created from the best practices of two projects adapting pieces from the Colombian art heritage [52, 53] for blind and visually impaired people. They were then applied to a third project: running a virtual tactile drawing club with blind and visually impaired participants in the middle of the COVID-19 pandemic. The lessons learned from these experiences are presented in this paper with the hope they can help the community democratize access to tactile graphics.","","Zuniga-Zabala MF,Guerra-Gomez JA","","2022","","10.1145/3491101.3503559","https://doi-org.proxy.bnl.lu/10.1145/3491101.3503559;http://dx.doi.org/10.1145/3491101.3503559","Conference Paper"
"Limits on the Rate of Locally Testable Affine-Invariant Codes","Despite its many applications, to program checking, probabilistically checkable proofs, locally testable and locally decodable codes, and cryptography, ""algebraic property testing"" is not well-understood. A significant obstacle to a better understanding, was a lack of a concrete definition that abstracted known testable algebraic properties and reflected their testability. This obstacle was removed by [Kaufman and Sudan, STOC 2008] who considered (linear) ""affine-invariant properties"", i.e., properties that are closed under summation, and under affine transformations of the domain. Kaufman and Sudan showed that these two features (linearity of the property and its affine-invariance) play a central role in the testability of many known algebraic properties. However their work does not give a complete characterization of the testability of affine-invariant properties, and several technical obstacles need to be overcome to obtain such a characterization. Indeed, their work left open the tantalizing possibility that locally testable codes of rate dramatically better than that of the family of Reed-Muller codes (the most popular form of locally testable codes, which also happen to be affine-invariant) could be found by systematically exploring the space of affine-invariant properties.In this work we rule out this possibility and show that general (linear) affine-invariant properties are contained in Reed-Muller codes that are testable with a slightly larger query complexity. A central impediment to proving such results was the limited understanding of the structural restrictions on affine-invariant properties imposed by the existence of local tests. We manage to overcome this limitation and present a clean restriction satisfied by affine-invariant properties that exhibit local tests. We do so by relating the problem to that of studying the set of solutions of a certain nice class of (uniform, homogenous, diagonal) systems of multivariate polynomial equations. Our main technical result completely characterizes (combinatorially) the set of zeroes, or algebraic set, of such systems.","","Ben-Sasson E,Sudan M","","2011","412–423","","","Conference Paper"
"Live Enrolment for Identity Documents in Europe","Digital image alterations (morphing) of identity document photos is a major concern and may potentially allow citizens with malicious intent to enrol for identity document(s) later to be used also by another individual. Taking the photo in the application office – live enrolment – can address this issue. However, this is a break with tradition and entails a sizeable overhaul in the public sector, which can be reluctant to change and often lacks the necessary formal methods that ensure a smooth transition. The objective of this paper is to map the main barriers and drivers related to live enrolment based on theoretical research and interviews conducted with high-ranking officers at passport authorities in Estonia, Kosovo, Norway and Sweden. These countries have successfully switched to live enrolment. The main driver for live enrolment has been increased security; for Estonia, user convenience was important and was behind the decision of keeping alternative application processes for the citizens around. The absence of legacy systems makes it easier to implement public sector innovations, such as live enrolment. Behind the successful implementation is proper risk management, covering technological, political and organisational risks. Finally, the research results indicate varying experiences, obstacles, cultural differences and trade-offs, emphasizing the need to understand barriers and drivers in a contextualised way.","","Kalvet T,Karlzén H,Hunstad A,Tiits M","","2018","29–39","10.1007/978-3-319-98690-6_3","https://doi-org.proxy.bnl.lu/10.1007/978-3-319-98690-6_3;http://dx.doi.org/10.1007/978-3-319-98690-6_3","Conference Paper"
"Long-View Player Detection Framework Algorithm in Broadcast Soccer Videos","In this paper, we propose an efficient video analysis framework to assign broadcast soccer video shots into their respective view classes, and then detect players in long view shots. Our technique is built on dominant color region based segmentation for soccer playfield extraction. A long-view shot classifier uses a combination of ""grass-area"" ratio and ""top-grass"" analysis. A player detector applies the distinctive uniform knowledge of interesting objects based on colors referring from the result of playfield. In order to verify the player region segmented using colour, we introduce the four-seed edge features which prune the redundant edges denoting the noise of court lines or audiences. The player detection performance is suitable to employ tracking methods in order to exploit higher semantic information from the games. Experimental evaluation of the framework is extensively demonstrated in numerous challenging test sequences of the 2010 FiFa World Cup South Africa. The results show the robustness of our framework, and the potential future-work.","","Tran Q,Tran A,Dinh TB,Duong D","","2011","557–564","10.1007/978-3-642-25944-9_72","https://doi-org.proxy.bnl.lu/10.1007/978-3-642-25944-9_72;http://dx.doi.org/10.1007/978-3-642-25944-9_72","Conference Paper"
"Low Latency and Division Free GaussJordan Solver in Floating Point Arithmetic","In many applications, the solution of a linear system is computed with Gaussian elimination followed by back-substitution, or GaussJordan elimination. The latter is intrinsically more parallel, enabling smaller computing latencies at the price of more complex hardware. However both methods require the division operator, which leads to a time-consuming resource in the critical path of the algorithms and impacts the global processings latency. Jordan was already aware of a division free algorithm. However, its implementation involves multiplications at each step and the size of the numbers rapidly becomes too big for an efficient implementation of large systems. In this work, we present a small modification to the division free algorithm in order to keep the size of the numbers in a reasonable range for standard floating point numbers. This is possible thanks to the special format of floating point numbers, which enables error free and hardware efficient divisions by powers of two. We also propose a parallel and pipelined architecture that best exploits the proposed algorithm, including partial pivoting. We specially focus on the global latency of the system as a function of its size, the latency of the floating point operators, and the number of operators that are available. Results demonstrate that current FPGAs can solve linear systems larger than hundred equations within ten microseconds. This represents a two order of magnitude improvement over previous implementations for relatively small systems. Low latency solvers are necessary for real time applications (simulation/control).The divider circuits used in most previous works induce long latencies.We propose a division free parallel architecture adapted to floating point arithmetic.We obtain two orders of magnitude gains compared to previous works.100-equation systems can be solved under 10 microseconds.","","David JP","","2017","185–193","10.1016/j.jpdc.2016.12.013","https://doi-org.proxy.bnl.lu/10.1016/j.jpdc.2016.12.013;http://dx.doi.org/10.1016/j.jpdc.2016.12.013","Journal Article"
"Low Voltage Digitally Controlled Impedance Based Energy Efficient Vedic Multiplier Design on 28nm FPGA","Low Voltage Digitally Controlled Impedance (LVDCI) is an I/O standard available on FPGA. This design is LVDCI IO standard based Energy Efficient Vedic Multiplier Design on FPGA. Selection of IO standard play an important role in power dissipation of design. Therefore, we are going to select the most energy efficient IO standards in LVDCI family for Vedic Multiplier. This Vedic multiplier design is a part of project of Vedic arithmetic circuits. The final deliverable of this project is Vedic Processor by merging both concepts of Veda, first book of this world, and the latest technology of this world. In order to test thermal aware design, we want to see that how does an electronic device behave if we change the temperature of surrounding in which it is working. For that purpose we have taken temperatures of four different regions. Furnace Creek Ranch is area of North America recorded the highest temperature of the world that is 56.7°C [1]. Approximately, 53.5°C is the maximum temperature recorded in Mohenjo-Daro situated in Sindh Pakistan [1]. We have also taken median temperature of Delhi i.e. 40°C and standard normal temperature i.e. 21°C. We are operating Vedic Multiplier with the four different temperature and different LVDCI IO standard and observe device performance, and power dissipation. When we use 28nm FPGA under room temperature of 40°C, there are 93.42%, 92.6%, 93.99%, 93.59% and 89.79% reduction in total power dissipation of Vedic multiplier using LVDCI 15, LVDCI 18, LVDCI DV2 15, LVDCI DV2 18 and HSLVDCI 15 respectively. Similarly, when we use 28nm FPGA, there is approximately 90-96% reduction in leakage power dissipation of Vedic multiplier using different LVDCI and different temperature. There is no change in I/O power with change in temperature for uniform IO standard. When we use different IO standard of LVDCI family, there is significant reduction in leakage power. FPGA based on 28 nm technology is more energy efficient than 40 nm technology based FPGA.","","Goswami K,Pandey B,Jain A,Singh D","","2014","951–955","10.1109/CICN.2014.201","https://doi-org.proxy.bnl.lu/10.1109/CICN.2014.201;http://dx.doi.org/10.1109/CICN.2014.201","Conference Paper"
"Low-Cost Communication for Rural Internet Kiosks Using Mechanical Backhaul","Rural kiosks in developing countries provide a variety of services such as birth, marriage, and death certificates, electricity bill collection, land records, email services, and consulting on medical and agricultural problems. Fundamental to a kiosk's operation is its connection to the Internet. Network connectivity today is primarily provided by dialup telephone, although Very Small Aperture Terminals (VSAT) or long-distance wireless links are also being deployed. These solutions tend to be both expensive and failure prone. Instead, we propose the use of buses and cars as ""mechanical backhaul"" devices to carry data to and from a village and an internet gateway. Building on the pioneering lead of Daknet [15], and extending the Delay Tolerant Networking Research Group architecture [24], we describe a comprehensive solution, encompassing naming, addressing, forwarding, routing, identity management, application support, and security. We believe that this architecture not only meets the top-level goals of low cost and robustness, but also exposes fundamental architectural principles necessary for any such design. We also describe our experiences in implementing a prototype of this architecture.","","Seth A,Kroeker D,Zaharia M,Guo S,Keshav S","","2006","334–345","10.1145/1161089.1161127","https://doi-org.proxy.bnl.lu/10.1145/1161089.1161127;http://dx.doi.org/10.1145/1161089.1161127","Conference Paper"
"Low-Infrastructure Methods to Improve Internet Access for Mobile Users in Emerging Regions","As information technology supports more aspects of modern life, digital access has become an important tool for developing regions to lift themselves from poverty. Though broadband internet connectivity will not be universally available in the short-term, widely-employed mobile devices coupled with novel delay-tolerant networking do allow limited forms of connectivity. This paper explores the design space for internet access systems operating with constrained connectivity. Our starting point is C-LINK, a collaborative caching system that enhances the performance of interactive web access over DTN and cellular connectivity. We discuss our experiences and results from deploying C-LINK in Nicaragua, before moving on to a broader design study of other issues that further influence operation. We consider the impact of (i) storing web content collaboratively cached across all user nodes, (ii) hybrid transport layers exploiting the best attributes of limited cellular and DTN-style connectivity. We also explore the behavior of future systems under a range of usage and mobility scenarios. Even under adverse conditions, our techniques can improve average service latency for page requests by a factor of 2X. Our results point to the considerable power of leveraging user mobility and collaboration in providing very-low-infrastructure internet access to developing regions.","","Isaacman S,Martonosi M","","2011","473–482","10.1145/1963192.1963361","https://doi-org.proxy.bnl.lu/10.1145/1963192.1963361;http://dx.doi.org/10.1145/1963192.1963361","Conference Paper"
"MODIS-Based Remote-Sensing Monitoring of the Spatiotemporal Patterns of China's Grassland Vegetation Growth","China has abundant grassland resources approximately 400 million ha of natural grasslands, which account for 41.7% of China's total area. Grasslands are an important base for boosting the development of China's livestock husbandry economy and maintaining China's ecological security. Using Moderate Resolution Imaging Spectroradiometer MODIS remotely sensed data, this study developed a grassland vegetation growth index that ranked the magnitude of grassland vegetation growth indices across a wide variety of field experiments. This study applied the grassland vegetation growth index to conduct remote-sensing monitoring of the spatiotemporal status of China's grassland vegetation growth in 2008. We found that the vegetation growth of China's grassland was classified as ‘good’ in 2008. The areas of grassland with desirable vegetation growth accounted for 38.47% of China's monitored grassland areas, and the areas with less desirable vegetation growth accounted for 22.85%. Additionally, the good vegetation growth was stable within each 10 day study period in 2008. The vegetation growth reached a balance in early June. After early September, the proportion of grasslands with desirable vegetation growth declined, and the proportion of grasslands with balanced and less desirable growth increased. The regions with less desirable vegetation growth mainly included the middle and eastern regions of Inner Mongolia, the northern region of Xinjiang, and most parts of Heilongjiang. The regions with desirable vegetation growth were mainly distributed in the north of Tibet, the southwest of Qinghai, the west of Inner Mongolia, Gansu, Ningxia, Shanxi, and the northwest of Liaoning. The remote-sensing monitoring of the spatiotemporal patterns of China's grassland vegetation growth in the present study revealed the overall vegetation growth status of China's grassland on a broad scale. These findings could provide a helpful scientific basis for understanding China's grassland vegetation conditions and the management and regulation of grassland livestock husbandry.","","Xu B,Yang XC,Tao WG,Miao JM,Yang Z,Liu HQ,Jin YX,Zhu XH,Qin ZH,Lv HY,Li JY","","2013","3867–3878","10.1080/01431161.2012.762696","https://doi-org.proxy.bnl.lu/10.1080/01431161.2012.762696;http://dx.doi.org/10.1080/01431161.2012.762696","Journal Article"
"Making Encryption Work in the Cloud","Many enterprises are choosing to leverage cloud services because of their simplicity and cost effectiveness. However, concerns over government inspection of data, service provider breaches, and insufficient access controls are driving conversations about information security controls in the cloud. Specifically, enterprise and Software as a Service (SaaS) providers have a particularly high interest in using cryptographic techniques for protecting data.Concerns over government inspection of data, service provider breaches, and insufficient access controls are driving conversations about information security controls in the cloud.Security practitioners are seeking clarity on the relative strengths and weaknesses of various encryption schemes, the trade-offs between security and application functionality, and the adverse impact that selecting the wrong encryption scheme may have on business operations. Alexandra Boldyreva at Georgia Tech and Paul Grubbs of Skyhigh Networks examine the options.","","Boldyreva A,Grubbs P","","2014","8–10","10.1016/S1353-4858(14)70101-1","https://doi-org.proxy.bnl.lu/10.1016/S1353-4858(14)70101-1;http://dx.doi.org/10.1016/S1353-4858(14)70101-1","Journal Article"
"Managing Customary Land Conflicts and Demarcations Using Mobile Applications Tools: A Case Study of Zambia","Zambia has witnessed domestic and international customary land boundary conflicts due to improper land demarcation mechanism and partial documentation of customary land parcels. In this study we recommend utilisation and integration of Information Communication Technology ICT tools such as the Participatory Geographical Information System PGIS and the mobile application to be used in the implementation of the customary land management system. This will enable families and community groups to properly demarcate customary land boundaries thereby reducing land conflicts and providing security of tenure for customary land.","","","","2018","323–334","","","Journal Article"
"Manifold Learning for Multi-Classifier Systems via Ensembles","Statistical classification of hyperspectral data is challenging because the inputs are high in dimension, while the quantity of labeled data is typically limited. The resulting classifiers are often unstable and have poor generalization. Nonlinear manifold learning algorithms assume that the original high dimensional data actually lie on a low dimensional manifold defined by local geometric differences between samples. Recent research has demonstrated the potential of these approaches for nonlinear dimension reduction and representation of high dimensional observations. Nonlinear scattering phenomena associated with processes observed in remote sensing data suggest that these may be useful for analysis of hyperspectral data. However, computational requirements limit their applicability for classification of remotely sensed data. Multi-classifier systems potentially provide a means to exploit the advantages of manifold learning through decomposition frameworks, while providing improved generalization. This paper reports preliminary results obtained from an ensemble implementation of Landmark Isomap in conjunction with a kNN classifier. The goal is to achieve improved generalization of the classifier in analysis of hyperspectral data in a dynamic environment with limited training data. The new method is implemented and applied to Hyperion hyperspectral data collected over the Okavango Delta of Botswana.","","Crawford M,Kim W","","2009","519–528","10.1007/978-3-642-02326-2_52","https://doi-org.proxy.bnl.lu/10.1007/978-3-642-02326-2_52;http://dx.doi.org/10.1007/978-3-642-02326-2_52","Conference Paper"
"Mapping the Diversity of Agricultural Systems in the Cuellaje Sector, Cotacachi, Ecuador Using ATL08 for the ICESat-2 Mission and Machine Learning Techniques","The mapping of cropland helps to make decisions due to the intensification of its use, where the conditions of the crops change due to climatic variability and other socio-economic factors. In this way, the implementation of modern sustainable agriculture is essential to prevent soil degradation as measures to guarantee food security, propose sustainable rural development and protect the provision of different ecosystem services associated with the soil. NASA’s Ice, Cloud, and Land Elevation Satellite-2 (ICESat-2) launched September 15, 2018, offers new possibilities for the mapping of global terrain and vegetation. An additional science objective is to measure vegetation canopy height as a basis for estimating large-scale biomass and biomass change. The Advanced Topographic Laser Altimeter System (ATLAS) instrument on-board ICESat-2 utilizes a photon-counting LIDAR and ancillary systems (GPS and star cameras) to measure the time a photon takes to travel from ATLAS to Earth and back again and to determine the photon’s geodetic latitude and longitude. ICESat-2 ATL08 (Along-Track-Level) data product is developed for vegetation mapping with algorithms for along-track elevation profile of terrain and canopy heights retrieval of the from ATLAS point clouds. Thus, this study presents a brief look at the ATL08 product highlight the broad capability of the satellite for vegetation applications working with data of study area Seis de Julio de Cuellaje (SDJC), province of Imbabura, Ecuador. The study used Normalized Difference Vegetation Index (NDVI) by the year 2020 time-series at 30 m resolution by employing a Machine Learning (ML) approach. The results of this research indicate that the ATL08 data from the ICESat-2 product provide estimates of canopy height, show the potential for crop biomass estimation, and a machine learning land cover classification approach with a precision of 95.57% with Digital Elevation Model (DEM) data.","","Fernando G","","2021","170–181","10.1007/978-3-030-87013-3_13","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-87013-3_13;http://dx.doi.org/10.1007/978-3-030-87013-3_13","Conference Paper"
"Market Information Needs Risk Assessment toward ICT Usage for Green Bean Producers in Dakar Region of Senegal","In Senegal, information and communication technologies (ICTs) have been applied to accelerate the development of horticulture. Farmers can access information about weather, market price, and production volume through the ICT-based information systems. However, little is known about the nature and limitations of actual ICT usage among farmers in rural areas. Green bean is one of the dominant garden crops in Senegal, and market information is crucial to its farm management. Therefore, this study aims to assess the marketing risks, ICT usage, and information needs of green bean producers to further promote the use of ICT-based information systems. A survey was conducted in Dakar Region, the chief production area of green bean in Senegal. From the results of this study, it is found that perishability and competition were the main marketing risks of green bean producers. Mobile phone and telecentre were the most commonly adopted ICT in their daily life. Their key information needs included wholesale, retail, and input prices. Language and cost were the major limiting factors in further usage of ICT. Furthermore, female producers showed vulnerability in price risk. Younger producers appeared to have relatively higher usage of TV and household telephone while older producers had higher usage of radio usage. Similarly, higher education was positively correlated to higher information needs on weather and agricultural policy. Among ethnic groups, Serer and other ethnic minority groups appeared to be more vulnerable to marketing risks. Members of producers' associations seemed to have less concern about marketing risks and higher radio usage. Meanwhile, telecentre users showed higher marketing risks and greater information needs, indicating the telecentre as one of the key media to assist the vast uses. In sum, the findings of this study suggested tailored information requires handy media and proper format to reach rural producers. Based on the results, there is a necessity to develop an information system supported by voice service in local dialects as well as reliable and cost effective power sources. Finally, a research model for horticultural market information systems is also proposed to meet users' needs and enhance growth opportunities for horticulture industry in Senegal.","","Chang WI,Tuan CL","","2011","235–246","","","Journal Article"
"Measuring the Big Data Readiness of Developing Countries – Index Development and Its Application to Africa","The use of big data promises to drive economic growth and development and can therefore be a value-adding factor, but compared to private or public organisations, the country level is rarely investigated, and that is even more evident for developing countries. Another topic hardly ever considered in the big data research field is ‘big data readiness’, which means the level of preparation and willingness to exploit big data. We address these shortcomings in the literature and focus on the big data readiness of developing countries. Thus, the first research question is: what components are required for an index measuring big data readiness, and how can such an index be designed? We use a design science approach to develop the “Big Data Readiness Index” (BDRI), which is then applied to all African countries to answer our second research question: how do African countries perform in terms of the BDRI? Our analysis yields country rankings that show relatively high BDRI scores for coastal countries, such as South Africa, Kenya and Namibia, and for islands, such as Mauritius. Related implications for both research and policy are discussed.","","Joubert A,Murawski M,Bick M","","2021","327–350","10.1007/s10796-021-10109-9","https://doi-org.proxy.bnl.lu/10.1007/s10796-021-10109-9;http://dx.doi.org/10.1007/s10796-021-10109-9","Journal Article"
"Medical Scientific Output and Specialization in Latin American Countries","“Smart specialization” allows one to identify national strengths and weaknesses within research fields and establish priorities accordingly. It may be a useful strategy for building scientific capacity in developing and peripheral countries. The objective of this paper is to characterize the scientific output and specialization of the most productive Latin American countries with focus on international collaboration and impact. We conducted a descriptive study based on the SCImago Institutions Ranking (SIR) portal, in the field of Medicine, for the period 2003–2013. The set of indicators applied was based on documents, citation, and collaboration. The results show that at the global level, Surgery, Cardiology, Oncology, Neurology, and Public Health are the most productive subjects in Medicine; in Latin America the most productive topics are Public Health, Infectious Diseases, Surgery, Neurology, and Cardiology and Cardiovascular Medicine. The most prolific countries are Brazil, Mexico and Argentina, though the ones having greater impact and more collaboration are Peru, Puerto Rico, and Argentina. The most productive and visible fields, such as Oncology, Cardiology, and Infectious Diseases, are related to major global health problems involving chronic and emerging diseases. This information could be useful to design pragmatic policies, to encourage research in key fields in order to respond better to the health needs of a given population.","","Zacca-González G,Chinchilla-Rodríguez Z,Vargas-Quesada B","","2018","1635–1650","10.1007/s11192-018-2717-7","https://doi-org.proxy.bnl.lu/10.1007/s11192-018-2717-7;http://dx.doi.org/10.1007/s11192-018-2717-7","Journal Article"
"MeghaOS: A Framework for Scalable, Interoperable Cloud Based Operating System","Cloud computing is becoming relevant due to increase in speed of Internet and reduction in its access cost. Desktop computing demands expensive hardware and software suits which become obsolete too often. Ownership of Personal Computers has always remained low in developing countries mainly due to its prohibitive cost. Alternate models of Computer usage like Public-Access Kiosks and low cost Laptops have been tried with limited success. Issues like security and privacy are major concerns in pubic computing. Laptops and other mobile devices lack required hardware support to run computing intensive applications. Increased penetration of Internet and mobile phones are providing new opportunities to bring computing closer to people. Cloud based Operating Systems are an effort in this direction. The present system, named MeghaOS, provides a framework for Desktop-like Operating System OS on a Web Browser. The Cloud becomes a metaphor for Operating System services accessed though Internet. Unlike traditional Operating System, MeghaOS can be accessed on any device having just a Web Browser. Since applications developed using this framework will be cached in Client's machine, network utility will be low. Since data and applications are hosted remotely users can use them without transferring data into local device. MeghaOS provides scalable, multi-device compatible, browser accessible framework for Cloud based Operating System demonstrating next generation computing paradigm.","","Srinivasa KG,S. HR,H. MK,Venkatesh N","","2012","53–70","10.4018/ijcac.2012010104","https://doi-org.proxy.bnl.lu/10.4018/ijcac.2012010104;http://dx.doi.org/10.4018/ijcac.2012010104","Journal Article"
"MehfoozAurat: Transforming Smart Phones into Women Safety Devices Against Harassment","In Pakistan, workingwomen often become victims of harassment during traveling which exacerbates uncertainty and hesitance among other workingwomen regarding their security. This paper discusses the android application, MehfoozAurat (safe woman), which we developed to support the lower socio-economic income bracket of working women who use public transport. The key features include safe routes, emergency alerts and audio recording with a unique self-defense section. The app has text based output in the national language, Urdu, which makes it accessible to the majority who are unfamiliar with the English language. Our usability tests reveal that the system is perceived to be useful and easy to learn; with brief learning, even the uneducated workingwomen were able to benefit from the application.","","Sarosh MY,Yousaf MA,Javed MM,Shahid S","","2016","","10.1145/2909609.2909645","https://doi-org.proxy.bnl.lu/10.1145/2909609.2909645;http://dx.doi.org/10.1145/2909609.2909645","Conference Paper"
"Mesh Messaging in Large-Scale Protests: Breaking Bridgefy","Mesh messaging applications allow users in relative proximity to communicate without the Internet. The most viable offering in this space, Bridgefy, has recently seen increased uptake in areas experiencing large-scale protests (Hong Kong, India, Iran, US, Zimbabwe, Belarus), suggesting its use in these protests. It is also being promoted as a communication tool for use in such situations by its developers and others. In this work, we report on a security analysis of Bridgefy. Our results show that Bridgefy, as analysed, permitted its users to be tracked, offered no authenticity, no effective confidentiality protections and lacked resilience against adversarially crafted messages. We verified these vulnerabilities by demonstrating a series of practical attacks on Bridgefy. Thus, if protesters relied on Bridgefy, an adversary could produce social graphs about them, read their messages, impersonate anyone to anyone and shut down the entire network with a single maliciously crafted message.","","Albrecht MR,Blasco J,Jensen RB,Mareková L","","2021","375–398","10.1007/978-3-030-75539-3_16","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-75539-3_16;http://dx.doi.org/10.1007/978-3-030-75539-3_16","Conference Paper"
"Milking the Quality Test: Improving the Milk Supply Chain Under Competing Collection Intermediaries","We examine operational and incentive issues that conspire to reduce the quality of milk—via deliberate adulteration by milk farmers—acquired by competing collection intermediaries in developing countries. Broadly speaking, three main forces in the milk supply chain lead to the low quality of milk: high testing costs, harmful competition among stations, and free-riding among farmers. The goal of this study is to provide recommendations that address the quality problem with minimal testing. Interestingly, some intuitive interventions—such as providing stations with better infrastructure (e.g., storage and refrigeration facilities) or subsidizing testing costs—could hurt the quality of milk in the presence of competition. To save testing costs we utilize mixed testing, where the milk combined from multiple farmers is tested once. However, mixed testing makes the system vulnerable to free-riding among farmers. We counter free-riding by applying a credible threat of individual testing (although not its actual use in equilibrium). We then propose two interventions to combat the harmful competition among stations. The novelty of our proposals lies in utilizing the force of competition to solve a problem created by competition. The incentives in our proposals provide a new tool for the stations to compete and convert the harmful effect of competition (quality reduction) into a beneficial one (quality improvement), resulting in a socially desirable equilibrium outcome: all the farmers provide high-quality milk and each competing station conducts only one mixed test and no further testing.This paper was accepted by Serguei Netessine, operations management.","","Mu L,Dawande M,Geng X,Mookerjee V","","2016","1259–1277","10.1287/mnsc.2015.2171","https://doi-org.proxy.bnl.lu/10.1287/mnsc.2015.2171;http://dx.doi.org/10.1287/mnsc.2015.2171","Journal Article"
"Mobile Agent-Based Approach for Modeling the Epidemics of Communicable Diseases","The increase in the use of mobile phones generates the formation of mobile social networks which can make use of various purposes including education, public health and controlling epidemics. Social networks consist of the basic building blocks called as the communities within which the social interactions are intensive, but between which they are very weak. Everyone could observe that the spread of infectious disease inside communities often has the ability to cross countries borders and spread rapidly. With the widespread of diseases causing major public health problem, we argue that human mobility patterns not only influence the spreading, but are also useful for preventing and creating awareness of the diseases. In this paper, we present new opportunities offered by the field of mobile social networks for understanding the spread of infectious diseases. For this purpose we propose two models namely MABM (Mobile Agent Based Model) and SDC (Spread Discovery Control) model to understand the spread of communicable diseases between different regions. The proposed SDC model is used to comprehend the spread of diseases by extracting the community structures and the analysis of mobility pattern of each agent (user) within the mobile network. Moreover, the understanding of spread details helps us to propose the control strategy to avoid the spread of the epidemic disease on the specific region. To realize our proposed models in a better way, we have modeled one such communicable disease usually spreading every year in West African region.","","Saravanan M,Karthikeyan P,Arathi A,Kiruthika M,Suganya S","","2013","16–20","10.1145/2492517.2492612","https://doi-org.proxy.bnl.lu/10.1145/2492517.2492612;http://dx.doi.org/10.1145/2492517.2492612","Conference Paper"
"Mobile Game-Based Learning System for a Local Language","The problem of language endangerment as a result of deficiency among the Bassa natives of Liberia and the prevention of the extinction threat posed on the language motivates the need to explore the use of game-based learning system for its resolution. A bilingual Electronic Dictionary (ED) for automatic translation of English text to equivalent Bassa language text alongside its corresponding audio pronunciation on an Android-based mobile device was developed. The system was designed using the Unified Modelling Language (UML) tools and implemented using the Java programming language in Android studio environment. The system was evaluated using Mean Opinion Score (MOS). Result of evaluation shows that age is directly proportional to the knowledge of Bassa language in Liberia. It was evident that the elderly Bassa natives have better knowledge of the language while the younger ones have less or do not understand at all. The mobile application software developed in this work will aid youth learner of the Bassa language.","","Soclo MI,Ninan OD,Olufokunbi KC","","2022","52–73","10.1504/ijmlo.2022.119954","https://doi-org.proxy.bnl.lu/10.1504/ijmlo.2022.119954;http://dx.doi.org/10.1504/ijmlo.2022.119954","Journal Article"
"Mobile Personal Health Records: Research Agenda for Applications in Global Health","Health threats, such as HIV/AIDS, maternal health and SARS, are global in nature, as their impact goes beyond the borders of any one nation. This has compelled a global approach to combating these threats, commonly by multinational partnerships among many different types of institutions. Although diffusion of mobile technology in the developing world has been successful, and personal health records on mobile devices (mPHRs) have shown effectiveness in certain health-related contexts, they have not been widely used to address health threats globally. The purpose of this article is to discuss six areas in which research on mPHRs can be used to address global health issues.","","Dohan MS,Abouzahra M,Tan J","","2014","2576–2585","10.1109/HICSS.2014.325","https://doi-org.proxy.bnl.lu/10.1109/HICSS.2014.325;http://dx.doi.org/10.1109/HICSS.2014.325","Conference Paper"
"Modelling of Ultra High Frequency Television Band Radio Signal Propagation in Underground Mine Environment","Solutions operating at ultra high frequency television band (UHF TV) have been deployed in above ground networks and communication systems providing data connectivity for different applications, but its' deployment for underground communications haven't been tested to date. Signal level and throughput measurements have been organised inside a mine environment that exploits platinum ore in the Republic of South Africa. Signal propagation has been modelled using scatter and direct signal component for which losses follow 15th and 6th power of the distance on the crossing and in the tunnel respectively. Measurements taken in the mine showed a connectivity with UDP level throughputs in the order of 1 Mb/s for distances of 350 m. It was demonstrated that the proposed deployment could be combined with Wi-Fi networks in 2.4 and 5 GHz for connecting standard smart devices from underground to above ground communication systems including the provision of internet services. It is expected that communication systems based on UHF TV band could supplement or even replace existing communications that are usually based on leaky feeders since they can provide wireless broadband data connectivity in a mining environment.","","Vujić DS,ă?Ertić JD","","2019","2117–2128","10.1007/s11276-018-1801-5","https://doi-org.proxy.bnl.lu/10.1007/s11276-018-1801-5;http://dx.doi.org/10.1007/s11276-018-1801-5","Journal Article"
"Multi-Factor, Multi-State, Multi-Model Scenarios","Decision-makers aiming to improve food security, livelihoods and resilience are faced with an uncertain future. To develop robust policies they need tools to explore the potential effects of uncertain climatic, socioeconomic, and environmental changes. Methods have been developed to use scenarios to present alternative futures to inform policy. Nevertheless, many of these can limit the possibility space with which decision-makers engage. This paper will present a participatory scenario process that maintains a large possibility space through the use of multiple factors and factor-states and a multi-model ensemble to create and quantify four regional scenarios for Southeast Asia. To do this we will explain 1) the process of multi-factor, multi-state building was done in a stakeholder workshop in Vietnam, 2) the scenario quantification and model results from GLOBIOM and IMPACT, two economic models, and 3) how the scenarios have already been applied to diverse policy processes in Cambodia, Laos, and Vietnam. We developed 4 multi-factor, multi-state socio-economic scenarios for Southeast Asia.Diverse scenarios provide wide possibility space for testing of robust policies.Quantifying scenarios in multiple models is challenging but increases scenario robustness.Using multiple model increases the scenario possibility space.","","Mason-D'Croz D,Vervoort J,Palazzo A,Islam S,Lord S,Helfgott A,Havlík P,Peou R,Sassen M,Veeger M,van Soesbergen A,Arnell AP,Stuch B,Arslan A,Lipper L","","2016","255–270","10.1016/j.envsoft.2016.05.008","https://doi-org.proxy.bnl.lu/10.1016/j.envsoft.2016.05.008;http://dx.doi.org/10.1016/j.envsoft.2016.05.008","Journal Article"
"Multi-Objective Optimisation of Robotic Active Particle Swarms for Continuous Repair of Large Scale High Value Structures","The manufacture and creation of large scale high value structures has been done by humans for centuries. Examples include the Egyptian pyramids, Bridges, Modern Skyscrapers to mention a few. These structures are large but also provide a high value in terms of economy, culture, display of prestige to mention a few. With advances in space technology, we are bound to see these large scale high value structures constructed in space. The vacuum of space present us with the challenges of repairing these structures. This is due to the inhospitable and dangerous environment of space. With increasing number of structures in space, there is bound to be more debris created resulting in high impact damages to these high value structures. Inspired by the biological blood clotting process and biological active particles, in this work, we propose the use of a swarm of live on artificial active particles for the purposes of continuous and timely repair of these structures. We tackle one of the challenges of artificial active particles research; the ability to navigate in crowded and obstacle filled environments. This challenge can be viewed from the perspective of a constrained multi-objective optimisation problem in which a balance between exploration of an environment and its exploitation needs to be achieved while taking into consideration the various other constraints that apply to an active particle. In this work, we show how artificial active particles could avoid obstacles in their environment through the use of an exploration mechanism and find damaged sites. Our results show that as the ability to explore increases, the active particles are able to navigate around obstacles and find a damaged site. However, there is a limit to this.","","Oyekan J","","2021","1312–1318","10.1109/CEC45853.2021.9504749","https://doi-org.proxy.bnl.lu/10.1109/CEC45853.2021.9504749;http://dx.doi.org/10.1109/CEC45853.2021.9504749","Conference Paper"
"My Morning Routine: An Interactive UDL Compliant E-Book on Health and Hygiene for Learners with Visual Difficulties","Health instruction assembles students’ information, abilities, and positive perspectives about wellbeing. However, 40% of the children in Pakistan are visually impaired and 38% have some cognitive disability due to malnutrition and poor hygiene practices. Despite COVID-19 putting the focus on the significance of hand cleanliness to forestall the spread of illness, reports from different countries have shown that the hand hygiene compliance rate has been estimated at only 40%. Using a Universal Design of Learning (UDL) approach, this research developed and produced a UDL compliant interactive android e-book that teaches young minds about the importance of staying clean and sanitization, especially to those learners who respond better when materials are paired with lights, sounds and/or movement. The scripting, story layout, design, and development were implemented using the seven stages of action and Nielson’s design heuristics. Drawing upon the cyclic process of developing prototypes and then learners providing feedback upon each version, this e-book was designed to optimize learning by minimizing the cognitive load on the learners, providing ease for learners with visual or cognitive learning disabilities. Results showed that the visually challenged learners responded well to the minimal design interface and graphics. Major impact of the research was students developing the habits of handwashing and following healthy morning routines, as indicated in the interviews and surveys conducted from the learners.","","Rizwan A,Abid M,Quidwai NU,Kiyani MN","","2021","470–482","10.1007/978-3-030-91540-7_48","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-91540-7_48;http://dx.doi.org/10.1007/978-3-030-91540-7_48","Conference Paper"
"Named Entity Recognition in a South African Context","The feasibility of a probabilistic Named Entity Recognition system in a South African context was tested. The intended use of the system is in a cyber forensic domain. At the core of the system is a dynamic Bayesian Network, which takes into account the probabilistic relationship between variables as well as contextual information. We illustrate the performance of such a system using different probability thresholds for classification purposes and compare the performance with and without a name gazetteer. Our system compares competently with similar existing systems in the information extraction domain. Future work will involve the application of the system in the cyber forensic environment, which poses new challenges such as diverse text types.","","Louis A,De Waal A,Venter C","","2006","170–179","10.1145/1216262.1216281","https://doi-org.proxy.bnl.lu/10.1145/1216262.1216281;http://dx.doi.org/10.1145/1216262.1216281","Conference Paper"
"Near Real-Time Detection of Poachers from Drones in AirSim","The unrelenting threat of poaching has led to increased development of new technologies to combat it. One such example is the use of thermal infrared cameras mounted on unmanned aerial vehicles (UAVs or drones) to spot poachers at night and report them to park rangers before they are able to harm any animals. However, monitoring the live video stream from these conservation UAVs all night is an arduous task. Therefore, we discuss SPOT (Systematic POacher deTector), a novel application that augments conservation drones with the ability to automatically detect poachers and animals in near real time [Bondi et al., 2018b]. SPOT illustrates the feasibility of building upon state-of-the-art AI techniques, such as Faster RCNN, to address the challenges of automatically detecting animals and poachers in infrared images. This paper reports (i) the design of SPOT, (ii) efficient processing techniques to ensure usability in the field, (iii) evaluation of SPOT based on historical videos and a real-world test run by the end-users, Air Shepherd, in the field, and (iv) the use of AirSim for live demonstration of SPOT. The promising results from a field test have led to a plan for larger-scale deployment in a national park in southern Africa. While SPOT is developed for conservation drones, its design and novel techniques have wider application for automated detection from UAV videos.","","Bondi E,Kapoor A,Dey D,Piavis J,Shah S,Hannaford R,Iyer A,Joppa L,Tambe M","","2018","5814–5816","","","Conference Paper"
"Never Retreat, Never Retract: Argumentation Analysis for Political Speeches","In this work, we apply argumentation mining techniques, in particular relation prediction, to study political speeches in monological form, where there is no direct interaction between opponents. We argue that this kind of technique can effectively support researchers in history, social and political sciences, which must deal with an increasing amount of data in digital form and need ways to automatically extract and analyse argumentation patterns. We test and discuss our approach based on the analysis of documents issued by R. Nixon and J. F. Kennedy during 1960 presidential campaign. We rely on a supervised classifier to predict argument relations (i.e., support and attack), obtaining an accuracy of 0.72 on a dataset of 1,462 argument pairs. The application of argument mining to such data allows not only to highlight the main points of agreement and disagreement between the candidates' arguments over the campaign issues such as Cuba, disarmament and health-care, but also an in-depth argumentative analysis of the respective viewpoints on these topics.","","Menini S,Cabrio E,Tonelli S,Villata S","","2018","","","","Conference Paper"
"New Adaptation Linkages: Perception, Preferences and Obstruction to Banking Technology in Kenya","Web technology is transforming all businesses into information-based activities and the rate of technological change is so high that emerging electronic commerce is already making fundamental changes in the economic landscape, affecting every aspect of how business is and will be conducted. There is substantial evidence to suggest that e-banking is being embraced by financial institutions in developed and emerging markets to the extent that explosive growth is almost at hand. This paper explores the adoption linkages in customer perceptions, preferences, and barriers to the adoption of banking technology in Kenya. The data for this study has been collected from bank customers in using well structured and pre-tested questionnaires. The result indicated that necessity perception is positive and ATM, Mobile and Internet banking were mostly preferred compared to others whilst negative linkage was observed between barriers and adoption as Security, bank lag in adoption and unawareness were identified as the most reported barriers to adoption. It means that positive link enable adoption while negative link distract adoption. The findings implicate banks and other financial institutions to increase the campaigns which may develop positive customer perceptions and preferences at the same time look for alternatives of reducing the possible barriers posing the banking technology.","","Nyangosi R,Nyariki KO,Nyang'au SN","","2012","62–77","10.4018/jitpm.2012040104","https://doi-org.proxy.bnl.lu/10.4018/jitpm.2012040104;http://dx.doi.org/10.4018/jitpm.2012040104","Journal Article"
"New Audio Encryption Package for TV Cloud Computing","For any cloud computing (ClComp), encryption of multimedia is one of the main applications as cloud tries to maintain it in a good situation and protect from any tampering. This work provides a new technique for audio for TV cloud computing. Encrypting the audio signals is addressed based on chaotic map and the algorithm was tested using an audio tone (AT) to evaluate the performance. The software of encrypt audio using AT based on chaotic map is specially designed to meet the needs of ClComp of Egyptian Radio and Television Union (ERTU). The proposed software of ClComp of ERTU is practical in nature and aims to provide individuals with an understanding of how to create cutting-edge web applications to be deployed distributive across the latest hosting platforms of ClComp of ERTU, including public/hybrid ClComp of ERTU, peer-to-peer networks, clusters, and multi-servers.","","Eldin SM,Khamis SA,Hassanin AA,Alsharqawy MA","","2015","131–142","10.1007/s10772-014-9253-5","https://doi-org.proxy.bnl.lu/10.1007/s10772-014-9253-5;http://dx.doi.org/10.1007/s10772-014-9253-5","Journal Article"
"Noisy SMS Machine Translation in Low-Density Languages","This paper presents the system we developed for the 2011 WMT Haitian Creole--English SMS featured translation task. Applying standard statistical machine translation methods to noisy real-world SMS data in a low-density language setting such as Haitian Creole poses a unique set of challenges, which we attempt to address in this work. Along with techniques to better exploit the limited available training data, we explore the benefits of several methods for alleviating the additional noise inherent in the SMS and transforming it to better suite the assumptions of our hierarchical phrase-based model system. We show that these methods lead to significant improvements in BLEU score over the baseline.","","Eidelman V,Hollingshead K,Resnik P","","2011","344–350","","","Conference Paper"
"Nonparametric Procedures in ICTs-Based Agricultural Market Information Network Pattern Analysis in Western African Regions","Information and communication technology (ICT) has become an important and essential decision support tool in agricultural products marketability. The high production cost of farms and the increasing demand for food have pushed ICT to the forefront of the food supply chain. In developing world such as Sub-Saharan African (SSA) regions where the farm profitability is generally low, efforts have been focused on agronomy and production technologies for enhancing farm productivity. In today's competitive global and regional marketplaces, however, producing a sound product is not enough to ensure agricultural farm viability. Market information is considered as a prerequisite of farm business to enable the management of the products flow and substantially increase the benefit. Furthermore, ICT can reduce poverty by improving poor people's access to the market information to have better managerial decisions for maximizing their farms profits. Nevertheless, the realistic availability and effectiveness of ICT in current market information network to farm management in Africa have not yet been much explored. Therefore, this study aims to (i) analyse the ICT contribution in agricultural products market information system (MIS) through nonparametric procedures and (ii) identify the main problems for seeking an effective market-oriented information network pattern. For this study, important data for horticultural marketing have been collected in Saint-Louis and Dakar regions located in Senegal, Western Africa. From the results of this study, it is mainly found that there are different market information network patterns in the survey areas. These market information network patterns mostly rely on weak personal social contacts of producers and one-way media. Statistically, it is observed that some widely available ICTs have not been used effectively for market information dissemination in the survey areas. Basically, the major constraints of ICTs application for MIS in Senegal are the poverty of information contents, disadvantages of the remote communities, language incapability and out-of-date information. Therefore, this study proposes an information network scheme as an effective strategy to enhance the existing market information system in Senegal.","","Chang WI,Tuan CL,Traore S","","2010","81–91","","","Journal Article"
"Observing Gender Dynamics and Disparities with Mobile Phone Metadata","We explore the extent to which gender disparities in Pakistan are reflected in the anonymized mobile phone logs of millions of Pakistani residents. Our analysis uses data capturing the communications behavior of several million individuals, for whom we observe the gender, but no additional demographic or personally identifying information. Here, we focus on validating aggregate regional patterns, correlating metrics derived from the mobile phone logs with socioeconomic statistics collected from more traditional sources. In these preliminary results, we observe a statistically significant relationship between districts with relatively high rates of female mobile phone penetration and districts that report high levels of gender parity in traditional surveys. However, this relationship is not uniform, and less developed regions exhibit a weaker correlation. We interpret these findings as suggestive evidence that such data can provide a novel perspective on gender dynamics in developing countries.","","Reed PJ,Khan MR,Blumenstock J","","2016","","10.1145/2909609.2909632","https://doi-org.proxy.bnl.lu/10.1145/2909609.2909632;http://dx.doi.org/10.1145/2909609.2909632","Conference Paper"
"On Demand Radio Frequency Identification Based Vehicle Tracking System","Over the years, many systems have addressed the problem of location sensing. In the past, geographic positioning systems (GPS) have been widely used to track moving objects located outside environments. These systems have several problems such as operational, environmental and high cost. The fixed GPS infrastructure causes several problems in wireless systems. Thus, GPS is considered not a suitable solution for the fixed environment. Due to this, there is a need for the system that can be replaced with less effort to meet future needs. Thus, the purpose of this paper is to discuss the available wireless technologies like radio frequency identification (RFID) techniques and mobile ad hoc sensor network. In doing so, the application of these technologies for remote objects information acquisition and tracking of moving objects is discussed. Further, the authors attempt to develop a communications setup for highways of Pakistan by using RFID and wireless sensor networks techniques to build a network that can be used for object tracking and information acquisition of moving vehicles on highways. This system may be used for variety of purposes especially for security enhancements at highways.","","Memon S,Khoumbati K,Shaikh A","","2010","34–43","10.1504/IJBIS.2010.034003","https://doi-org.proxy.bnl.lu/10.1504/IJBIS.2010.034003;http://dx.doi.org/10.1504/IJBIS.2010.034003","Journal Article"
"On the Concrete Efficiency of Probabilistically-Checkable Proofs","Probabilistically-Checkable Proofs (PCPs) form the algorithmic core that enables fast verification of long computations in many cryptographic constructions. Yet, despite the wonderful asymptotic savings they bring, PCPs are also the infamous computational bottleneck preventing these powerful cryptographic constructions from being used in practice. To address this problem, we present several results about the computational efficiency of PCPs. We construct the first PCP where the prover and verifier time complexities are quasi-optimal (i.e., optimal up to poly-logarithmic factors). The prover and verifier are also higly-parallelizable, and these computational guarantees hold even when proving and verifying the correctness of random-access machine computations. Our construction is explicit and has the requisite properties for being used in the cryptographic applications mentioned above.Next, to better understand the efficiency of our PCP, we propose a new efficiency measure for PCPs (and their major components, locally-testable codes and PCPs of proximity). We define a concrete-efficiency threshold that indicates the smallest problem size beyond which the PCP becomes ""useful"", in the sense that using it is cheaper than performing naive verification (i.e., rerunning the computation); our definition accounts for both the prover and verifier complexity.We then show that our PCP has a finite concrete-efficiency threshold. That such a PCP exists does not follow from existing works on PCPs with polylogarithmic-time verifiers.As in [Ben-Sasson and Sudan, STOC '05], PCPs of proximity for Reed-Solomon (RS) codes are the main component of our PCP. We construct a PCP of proximity that reduces the concrete-efficiency threshold for testing proximity to RS codes from 2683 in their work to 243, which is tantalizingly close to practicality.","","Ben-Sasson E,Chiesa A,Genkin D,Tromer E","","2013","585–594","10.1145/2488608.2488681","https://doi-org.proxy.bnl.lu/10.1145/2488608.2488681;http://dx.doi.org/10.1145/2488608.2488681","Conference Paper"
"Optimal Design-Space Exploration of Streaming Applications","Many embedded and scientific applications are pipelined (i.e., streaming) and deployed on application-specific systems. Typically, there are several design parameters in the algorithms and architectures used that impact the tradeoff between different metrics of application performance as well as resource utilization. Efficient automatic exploration of this design space is the goal of our research. We present a global optimization framework comprising a domain-specific variation of branch-and-bound that reduces search complexity by exploiting the topology of the application's pipelining. We exploit the topological information to discover decomposability through the canonical Jordan block form. The reduction in search complexity for four real-world streaming applications (drawn from the literature) is significant, ranging from a million-fold reduction in search space size to a reduction factor of 10 billion. All four optimization problems are thereby solvable in reasonable time.","","Padmanabhan S,Chen Y,Chamberlain RD","","2011","227–230","10.1109/ASAP.2011.6043274","https://doi-org.proxy.bnl.lu/10.1109/ASAP.2011.6043274;http://dx.doi.org/10.1109/ASAP.2011.6043274","Conference Paper"
"PENCIL: A Platform-Neutral Compute Intermediate Language for Accelerator Programming","Programming accelerators such as GPUs withlow-level APIs and languages such as OpenCL and CUDAis difficult, error-prone, and not performance-portable. Au-tomatic parallelization and domain specific languages (DSLs)have been proposed to hide complexity and regain performanceportability. We present P ENCIL, a rigorously-defined subset ofGNU C99 -- enriched with additional language constructs -- that enables compilers to exploit parallelism and produce highlyoptimized code when targeting accelerators. P ENCIL aims toserve both as a portable implementation language for libraries, and as a target language for DSL compilers. We implemented a P ENCIL-to-OpenCL backend using astate-of-the-art polyhedral compiler. The polyhedral compiler, extended to handle data-dependent control flow and non-affinearray accesses, generates optimized OpenCL code. To demon-strate the potential and performance portability of P ENCILand the P ENCIL-to-OpenCL compiler, we consider a numberof image processing kernels, a set of benchmarks from theRodinia and SHOC suites, and DSL embedding scenarios forlinear algebra (BLAS) and signal processing radar applications(SpearDE), and present experimental results for four GPUplatforms: AMD Radeon HD 5670 and R9 285, NVIDIAGTX 470, and ARM Mali-T604.","","Baghdadi R,Beaugnon U,Cohen A,Grosser T,Kruse M,Reddy C,Verdoolaege S,Betts A,Donaldson AF,Ketema J,Absar J,van Haastregt S,Kravets A,Lokhmotov A,David R,Hajiyev E","","2015","138–149","10.1109/PACT.2015.17","https://doi-org.proxy.bnl.lu/10.1109/PACT.2015.17;http://dx.doi.org/10.1109/PACT.2015.17","Conference Paper"
"Participatory Sensing Platform Concept For Wildlife Animals In The Himalaya Region, Nepal","Human Computer Biosphere Interaction (HCBI) is a relatively new academic discipline that acts as a critical juncture between the conservation biology and the Information, Communication and Technology (ICT). HCBI domain exploits the capabilities of the repertoire of available technological tools to remotely sense data from difficult geographical terrains in a secure and cost-effective manner. In this perspective paper, we highlight some of the bio-acoustic technologies that we have been using for our research in Fukushima prefecture, Japan. Learning from our experience in Fukushima, we provide our preliminary viewpoint on the possibility of incorporating HCBI research in Manang, Nepal. Our impressions are largely based on the site visit to Manang and informal interaction with locals and conservation specialists. The preliminary feasibility study will prove useful in future as we plan a full-fledged ICT based animal conservation study to assess how the application of ICT tools for wildlife monitoring can contribute to the economic empowerment of locals in Manang who depend on subsistence farming. In summary, this paper provides a preliminary overview of the potentiality of technology transfer from Japan to the remote hilly areas in Nepal for wildlife conservation by employing ICT tools and participatory sensing approach.","","Shimotoku D,Yuan T,Parajuli LK,Kobayashi HH","","2022","87–98","10.1007/978-3-031-05431-0_6","https://doi-org.proxy.bnl.lu/10.1007/978-3-031-05431-0_6;http://dx.doi.org/10.1007/978-3-031-05431-0_6","Conference Paper"
"Perceptions and Expectations of IT Service Delivery Post Migration to a Microsoft Platform at a University of Technology in South Africa","The implementation of Microsoft (MS) technologies/solutions as organisational infrastructure has become popular in the South African and international higher education (HE) arena. With benefits such as reduced costs, improved productivity and improved service delivery, MS technologies/solutions seem to be the preferred choice for many institutions worldwide. This study presents work in progress on identifying the quality of service using this new organisational infrastructure within the Durban University of Technology (DUT). DUT is the first University of Technology (UoT) in South Africa to implement nine MS technologies simultaneously. Through this implementation, the DUT has attempted to greatly simplify the collaboration and communication of its employees and ensure the security and protection of the organization's information and assets. Since migration to the MS platform, staff have raised concerns regarding the new solutions, pertaining to aspects such as security (with specific reference to login credentials and data), accessibility (with specific reference to mobile devices and wireless connectivity) and reluctance to use self- help tools to improve their IT experience. Migrating from a non-integrated system to an integrated one has also resulted in IT service delivery becoming a contentious issue regarding the support received from the UoT's IT staff. This paper discusses the types of MS technologies implemented at the university and the impact that these solutions have had on the full time administrative and academic staff at the university regarding their perceptions and expectations of current IT service delivery. The quality of this service was measured using the SERVQUAL instrument. As a result of the research, a service management framework appropriate for the predominantly MS (Microsoft) environment will be proposed to the DUT's Information Technology Support Services (ITSS) management.","","Reddy N,Singh P,Petkov D","","2013","85–89","10.1145/2513456.2513457","https://doi-org.proxy.bnl.lu/10.1145/2513456.2513457;http://dx.doi.org/10.1145/2513456.2513457","Conference Paper"
"Personalized Persuasion to Promote Positive Work Attitudes in Public Workplaces","This paper investigates how mobile persuasive system targeting African audience could be designed and tailored to promote employee's commitment to the ideals, visions, and mission of an organization. We conduct a qualitative study with two categories of workers to uncover core factors that influence employee's attitudes to their jobs and map our findings to their matching social influence persuasive techniques. We propose that a persuasive system (PS) employing the social influence strategies could motivate workers towards acceptable positive pro-workplace behaviors and etiquette. The PS allows workers too compare their behaviors against set goals and acceptable standards, compete and compare performances with peers, view and respond to peers' activities, and receive recognition for accomplishing a target task. The system ensures the security of worker's data via the authentication of login credentials while showing them a personalized persuasive display of essential workplace information. We present a prototype persuasive system called ""PAULApp"" for motivating pro-workplace behaviors and plans for evaluation. PAULApp was designed using the iterative design process and was informed by the findings from the user studies.","","Nkwo M,Orji R","","2019","185–190","10.1145/3314183.3323858","https://doi-org.proxy.bnl.lu/10.1145/3314183.3323858;http://dx.doi.org/10.1145/3314183.3323858","Conference Paper"
"Perspectives on Teaching Computer Architecture in Developing Countries","Different areas of computer science have different challenges with respect to curriculum development, textbook writing, and teaching. Computer architecture represents one extrema in this hyper-dimensional space: it is an applied discipline, the theory for many sub-areas is still in development, and unlike traditional theoretical areas, problem-solving and tutorial based teaching is still uncommon. Students typically appreciate the rigor of traditional algorithm courses because they are similar to the courses they have seen in high school, however computer architecture is an engineering discipline: it is a science, an art, and sometimes a combination of both. As the name suggests, it is quite like traditional ""architecture"" (designing beautiful buildings...). To further complicate matters, most textbooks in this subject have originally been written in the late nineties and fail to capture most of the developments that have happened over the last two decades, which are fundamental and revolutionary at the same time. In the late nineties the field was an applied discipline where the design of systems, the specific design choices made by engineers, and a description of important architectures was considered proper pedagogical practice. This was probably acceptable in developed countries where students had an adequate exposure to computers since their teenage years. However, this approach did not work in India and a few other developing countries where I taught. Hence, there was a need to grow the field and instead focus on providing timeless insights that are not dependent on specific architectures or specific technologies. There was a need to bring the field in line with other fields such as chemistry, physics, biology, and of course traditional CS (data structures, algorithms, discrete math, etc.). This was the nature of the challenge that I faced when I started writing my two books on computer architecture (www.basiccomparch.com and www.advcomparch.com). There was a need to formalize basic notions, provide a theoretical framework, and create a discipline that is more in line with traditional theoretical subjects, which the students (at least in developing countries) are more used to. Hence, a novel pedagogical approach was developed where the connect between Turing machines and basic architectures was shown. The same approach was followed to explain all the major concepts by relating them to other concepts in traditional math or CS: caches were connected with hashtables, virtual memory was connected with indexing, I/O was connected with networking, OOO processing was connected with graph algorithms, and memory models were re-explained with novel concepts developed by the verification community. The end result of doing so was 1500 pages of computer architecture (captured in my two books). Many concepts appear to be intuitive such as memory consistency and routing algorithms in on-chip networks. However, this never leads to a deeper understanding and cannot lead to practical designs because there is not enough knowledge to write real code and capture corner cases. This is where formal training and a connect with well-established CS concepts is required. In my second book on Advanced Computer Architecture, especially in the later half, I focused on power management, security, reliability, and architectures for AI/ML. Here again, the theory was not well developed and thus there were no popular mathematical formalisms. New notations and new theoretical tools were introduced to put these areas on a sound footing. This is by far the most important contribution of my two books, which is to formalize and ""mathematize"" concepts in computer architecture that hitherto had very applied definitions, which were often prone to misinterpretations. Towards the end of the talk, we will also digress into some of my other academic adventures such as co-chairing a committee to create the CBSE CS curriculum for schools, a lab course on processor design and kernel hacking (future of OS teaching), and my take on the future of teaching and learning (in general).","","Sarangi SR","","2022","7","10.1145/3561833.3568498","https://doi-org.proxy.bnl.lu/10.1145/3561833.3568498;http://dx.doi.org/10.1145/3561833.3568498","Conference Paper"
"Pest Management In Cotton Farms: An AI-System Case Study from the Global South","Nearly 100 million families across the world rely on cotton farming for their livelihood. Cotton is particularly vulnerable to pest attacks, leading to overuse of pesticides, lost income for farmers, and in some cases farmer suicides. We address this problem by presenting a new solution for pesticide management that uses deep learning, smartphone cameras, inexpensive pest traps, existing digital pipelines, and agricultural extension-worker programs. Although generic, the platform is specifically designed to assist smallholder farmers in the developing world. In addition to outlining the solution, we consider the set of unique constraints this context places on it: data diversity, annotation challenges, shortcomings with traditional evaluation metrics, computing on low-resource devices, and deployment through intermediaries. This paper summarizes key lessons learned while developing and deploying the proposed solution. Such lessons may be applicable to other teams interested in building AI solutions for global development.","","Dalmia A,White J,Chaurasia A,Agarwal V,Jain R,Vora D,Dhame B,Dharmaraju R,Panicker R","","2020","3119–3127","10.1145/3394486.3403363","https://doi-org.proxy.bnl.lu/10.1145/3394486.3403363;http://dx.doi.org/10.1145/3394486.3403363","Conference Paper"
"Place-Based Assessment of Intersection of Biophysical and Social Vulnerability to Flooding in Accra, Ghana","The relationship between flood hazards and social vulnerability is firmly on the intellectual agenda of geographers in Ghana. In an attempt to theorize and empirically examine this relationship, scholars have commonly followed a one-sided methodological strand. In this article, a triple-helix approach that relies on the application of social vulnerability index; mapping potential flood hazard zones; and examining degree of coincidence between flood hazards and social vulnerability, is used. Situating the analysis within Hazards-of-Place Model of Vulnerability, the study identifies spatial disparities in biophysical and social vulnerability within the City. It emerged that communities in the Ashiedu Keteke sub-metro were the most vulnerable based on the hazards-of-place model. Significantly, while flood risk awareness was very high among community members, the perception of flood risk management was poor. The study argues that understanding place-based vulnerability is crucial in mitigating the effect of hazards and building resilient communities.","","Aboagye D,Attakora-Amaniampong E,Owusu-Sekyere E","","2020","55–68","10.4018/IJAGR.2020010104","https://doi-org.proxy.bnl.lu/10.4018/IJAGR.2020010104;http://dx.doi.org/10.4018/IJAGR.2020010104","Journal Article"
"Plenary Lecture 3: A Fuzzy Technologies of Weakly Structurable Systems' Modeling and Simulation","The Plenary Speech will present the new approach to the study of optimization of weakly structurable fuzzy dynamic systems (Extremal Fuzzy Dynamic System (EFDS)). This approach is based on the six papers published in the Int. Journal of General Systems (by G. Sirbiladze, ""Modeling of Extremal Fuzzy Dynamic Systems"". Parts I-VI: 34,2, 2005, 107-138; 139-167; 169-198; 35, 4, 2006, 435-459; 35, 5, 2006, 529-554; 36,1 2007, 19-58). Different from other approaches where the source of fuzzy uncertainty in dynamic systems is expert, this approach considers time as long as an expert to be the source of fuzzy uncertainty. This notably widens the area of studied problems. All these is connected to the incomplete, imprecise, anomal and extremal processes in nature and society, where connections between the system's objects are of subjective (expert) nature, which is caused by lack of objective information about the evolution of studied system, for example in 1) engineering problems, 2) economics and business of developing countries, 3) management of evacuation processes in catastrophe areas, estimation of disease spreading in epidemical regions; 4) research of complex systems of applied physics, 5) conflictology, sociology, medical diagnosis, etc; One of our purposes is to create scenarios describing possible evolution of EFDS using methods of optimization developed by the framework of expert-possibilistic theory. This includes construction of algorithms of logical-possibilistic simulations of anomal and extremal process analysis.The plenary speech will cover the following topics: introduce the notions of extremal fuzzy time moments and intervals; construction of fuzzy processes with possibilistic uncertainty, the source of which is extremal fuzzy time intervals; the dynamics of EFDS's; questions of the ergodicity of EFDS's; Fuzzy-integral representations of controllable extremal fuzzy processes; Sufficient and necessary conditions for the existence of an extremal fuzzy optimal control processes.A separate consideration will be given to the case where an extremal fuzzy control process acting on the EFDS does not depend on an EFDS state. Applying Bellman's optimality principle and assuming that the gain-loss process exists for the EFDS, a variant of the fuzzy integral representation of an optimal control is given for the EFDS. This variant employs the instrument of extended extremal fuzzy composition measures. An example of constructing of the EFDS optimal control will be presented.","","Sirbiladze G","","2009","18","","","Conference Paper"
"Plenary Talk","Michael Merritt is Executive Director of the Cross-Layer Analytics and Design Research Department, responsible for applied research directed at application, network, and infrastructure design and performance with particular emphasis on interactions that cross layers of abstraction and technology. Michael has published over thirty-five research articles, co-authored a book on database concurrency control, holds five patents, and served for many years as an area editor of Distributed Computing and the Journal of the ACM. He is a recognized expert in distributed computing, computer security, and network traffic analysis. He has taught at Georgia Tech, MIT, Stevens Institute of Technology, and Columbia University.","","Merritt M","","2013","1","10.1145/2484239.2493965","https://doi-org.proxy.bnl.lu/10.1145/2484239.2493965;http://dx.doi.org/10.1145/2484239.2493965","Conference Paper"
"Poster - Mapping Opium Poppy Cultivation in Afghanistan Using Satellite Imagery","Afghanistan is the world’s largest supplier of illicit opium, accounting for an estimated 70-80% of supply. In 2019, this generated an estimated income of $1.2-$2.1 billion domestically, or around 10% of Afghanistan’s gross domestic product. The illicit drug economy has provided livelihoods to millions of Afghans, but has also had numerous negative effects, including funding insurgent groups, exacerbating corruption and insecurity, and contributing to high domestic levels of drug addiction. From 2002 to 2017, the U.S. government spent over $8 billion on counter-narcotics efforts in Afghanistan, achieving little long-term success. The lack of reliable data has contributed to this failure; the robustness and interpretation of top-line estimates of area under cultivation have been questioned and criticized. Counter-narcotics efforts have focused on reducing total cultivation area, rather than trying to understand local socioeconomic or political conditions. The lack of granularity in official cultivation statistics has also impeded efforts by aid agencies to evaluate the impact of various interventions aimed at transitioning farmers away from poppy. Currently, official statistics on poppy cultivation are released annually by the United Nations Office on Drugs and Crime (UNODC) at a district level.1 These are produced using commercial high-resolution (0.5m × 0.5m) imagery, manually annotated by analysts and verified with ground imagery. In districts with substantial cultivation, a limited number of sites are sampled for labeling, while in other districts, all known cultivation areas are annotated. Only aggregate district-level cultivation figures are published and no detailed maps are available. The UNODC also conducts in-person surveys to characterize socioeconomic conditions. These methods, while undoubtedly valuable, are costly and difficult to undertake under poor security conditions. Furthermore, reports are released after long delays, with the government being suspected of blocking publication in some years. This paper investigates the possibility of using publicly available satellite imagery to generate poppy cultivation maps at high resolution. Some advantages of this source of data include its timeliness and cost-effectiveness, easy availability of data, and high level of granularity. These maps can then be combined with other data sources, such as grid-level data on climate, population, and healthcare, to further our quantitative understanding of the socioeconomic circumstances associated with poppy cultivation, a complex and persistent development challenge. This work complements official estimates, as well as related work that relies on commercial high-resolution satellite imagery, manual labelers, expert knowledge or qualitative methods. In developing these methods, we build on work using automated methods and spectral imagery to classify opium poppy, wheat, as well as other agricultural crops. In initial work, we limit our analysis to Helmand, a province accounting for more than half of all cultivation, where crop cycles are well-known and there are few major alternative crops. We carefully choose image acquisition dates based on crop cycles, and measure levels of vegetation growth in the pre- and post-harvest stages. We then apply a rule-based classification approach to infer areas under poppy cultivation, finding that our aggregate area estimates track official statistics closely at a district level (Pearson’s correlation ρ ≥ .8). Future work will involve refining the methodology and extending it to the rest of Afghanistan over multiple years. Early analysis suggests that this approach could generalize to other provinces in Southern and Western Afghanistan, but we expect to face more difficulty especially in the Northern parts of Afghanistan, due to smaller plot sizes, mixed cultivation patterns, complex terrain and the close proximity of agriculture to natural vegetation. Some potential solutions include automated strategies to infer best acquisition windows, and classifying agricultural land and opium poppy using more flexible approaches, such as unsupervised clustering methods. We hope that an extension of our current approach can provide additional quantitative insight to the local circumstances surrounding poppy cultivation, and ultimately contribute to the design of effective policies to protect the welfare of farmers while governments work towards their counter-narcotics goals.","","Tai XH,Nair SR,Mehra S","","2021","416","10.1145/3460112.3472308","https://doi-org.proxy.bnl.lu/10.1145/3460112.3472308;http://dx.doi.org/10.1145/3460112.3472308","Conference Paper"
"Poster: Optimal Path Finding for Emergency Cases on Android","This paper intends to develop the optimal path finding for emergency cases on mobile devices. According to the weak road network infrastructure of Myanmar, there are some difficulties for Emergency Vehicles. In some townships, there are narrowed roads which are not wide enough to enter the vehicles and closed roads which are not passed through the other streets. In the emergency cases (e.g. Accident or Fire), the drivers mistakenly choose these roads, it can cause problems and delays. The main objective of this system is to find the optimal routes between incident site and emergency services without delay caused by closed and narrowed roads. The system uses Multiple Sources Single-Destination (MSSD) Algorithm using node exclusion to calculate optimal route. Our proposed system significantly solves to find the accident location and locate the closest emergency services by using the real-time technology (GPS/GSM).","","Phyo KZ,Sein MM","","2016","71","10.1145/2938559.2948851","https://doi-org.proxy.bnl.lu/10.1145/2938559.2948851;http://dx.doi.org/10.1145/2938559.2948851","Conference Paper"
"Pre-Entry Experience, Postentry Adaptations, and Internationalization in the African Mobile Telecommunications Industry","We study the evolution of the African mobile telecommunications industry from its effective beginning and explore the sources of ownership advantages among indigenous firms, by assembling historical qualitative and quantitative firm-level data. Our historical qualitative findings suggest that a few start-ups gained industry-specific knowledge through their pre-entry experience, directed their postentry development of capabilities toward adaptations to challenging market and operational conditions, and leveraged their adaptive capabilities to enter and compete in other African countries. Using our quantitative panel data, we show that these firms successfully internationalized across the continent. In particular, compared with other start-ups, they had higher rates of foreign entry in African countries that had relatively weaker rule of law, and greater market reach in African countries that had relatively larger low-income consumer segments. These patterns corroborate that their capabilities for overcoming the industry’s challenging market and operational conditions were their key ownership advantages. Through our triangulated analysis, we show that inherited industry knowledge provides a foundation for postentry capability development, and entrepreneurial leadership guides this process to create ownership advantages for regional internationalization.","","Jahanbakht M,Mostafa R,Veloso F","","2022","969–990","10.1287/orsc.2021.1470","https://doi-org.proxy.bnl.lu/10.1287/orsc.2021.1470;http://dx.doi.org/10.1287/orsc.2021.1470","Journal Article"
"Predicting Student Performance Using Advanced Learning Analytics","Educational Data Mining (EDM) and Learning Analytics (LA) research have emerged as interesting areas of research, which are unfolding useful knowledge from educational databases for many purposes such as predicting students' success. The ability to predict a student's performance can be beneficial for actions in modern educational systems. Existing methods have used features which are mostly related to academic performance, family income and family assets; while features belonging to family expenditures and students' personal information are usually ignored. In this paper, an effort is made to investigate aforementioned feature sets by collecting the scholarship holding students' data from different universities of Pakistan. Learning analytics, discriminative and generative classification models are applied to predict whether a student will be able to complete his degree or not. Experimental results show that proposed method significantly outperforms existing methods due to exploitation of family expenditures and students' personal information feature sets. Outcomes of this EDM/LA research can serve as policy improvement method in higher education.","","Daud A,Aljohani NR,Abbasi RA,Lytras MD,Abbas F,Alowibdi JS","","2017","415–421","10.1145/3041021.3054164","https://doi-org.proxy.bnl.lu/10.1145/3041021.3054164;http://dx.doi.org/10.1145/3041021.3054164","Conference Paper"
"Prediction for Various Drought Classes Using Spatiotemporal Categorical Sequences","Drought frequently spreads across large spatial and time scales and is more complicated than other natural disasters that can damage economic and other natural resources worldwide. However, improved drought monitoring and forecasting techniques can help to minimize the vulnerability of society to drought and its consequent influences. This emphasizes the need for improved drought monitoring tools and assessment techniques that provide information more precisely about drought occurrences. Therefore, this study developed a new method, Model-Based Clustering for Spatio-Temporal Categorical Sequences (MBCSTCS), that uses state selection procedures through finite mixture modeling and model-based clustering. The MBCSTCS uses the functional structure of first-order Markov model components for modeling each data group. In MBCSTCS, the suitable order K of the components is selected by Bayesian information criterion (BIC). In MBCSTCS, the estimated mixing proportions and the posterior probabilities are used to compute probability distribution associated with the future steps of transitions. Furthermore, MBCSTCS predicts drought occurrences in future time using spatiotemporal categorical sequences of various drought classes. The MBCSTCS is applied to the six meteorological stations in the northern area of Pakistan. Moreover, it is found that MBCSTCS provides expeditious information for the long-term spatiotemporal categorical sequences. These findings may be helpful to make plans for early warning systems, water resource management, and drought mitigation policies to decrease the severe effects of drought.","","Niaz R,Almazah MM,Zhang X,Hussain I,Faisal M,Amirteimoori A","","2021","","10.1155/2021/7145168","https://doi-org.proxy.bnl.lu/10.1155/2021/7145168;http://dx.doi.org/10.1155/2021/7145168","Journal Article"
"Preventing Illegal Logging: Simultaneous Optimization of Resource Teams and Tactics for Security","Green security – protection of forests, fish and wildlife – is a critical problem in environmental sustainability. We focus on the problem of optimizing the defense of forests against illegal logging, where often we are faced with the challenge of teaming up many different groups, from national police to forest guards to NGOs, each with differing capabilities and costs. This paper introduces a new, yet fundamental problem: Simultaneous Optimization of Resource Teams and Tactics (SORT). SORT contrasts with most previous game-theoretic research for green security – in particular based on security games – that has solely focused on optimizing patrolling tactics, without consideration of team formation or coordination. We develop new models and scalable algorithms to apply SORT towards illegal logging in large forest areas. We evaluate our methods on a variety of synthetic examples, as well as a real-world case study using data from our on-going collaboration in Madagascar.","","Carthy SM,Tambe M,Kiekintveld C,Gore ML,Killion A","","2016","3880–3886","","","Conference Paper"
"Proposal for a Platform for the Continuity of Distance Learning in African Schools and Universities at the End of the Politico-Military Crisis in the Face of Covid-19: Case of the Central African Republic","Following the perpetual political-military crises, most of the rural areas of the Central African Republic (CAR) are occupied by armed groups. This leads to human insecurity in these areas. Children, adolescents, and youth are out of school. Primary and secondary school teachers are unable to travel to unsafe areas. Due to the problem of human insecurity in rural areas and especially poverty in several rural areas of CAR, parents are unable to finance the education of their children who have taken the baccalaureate exams to travel to the capital Bangui to study at Bangui University alone. In this article, we propose a platform for the continuity of educational activities in the Central African Republic. Our initially proposed platform solution allows the creation of a distance primary and secondary school in bimodal mode in the rural areas of the CAR. In a second step, it allows the creation of a complete distance university training coupled with traditional education for young people from all rural areas of the Central African Republic. This platform has been tested at the Higher Institute of Technology (Department of Computer Science and Telecommunications) and the Faculty of Science of the University of Bangui and has enabled the partial resumption of pedagogical activities in these institutions. It has been applied in the field of STEM (science, technology, engineering and mathematics) and can be extended to other disciplines. Access to resources is efficient thanks to the coupling of the WireGuard VPN server and the Apache Guacamole server which is a gateway using standard protocols via a browser. It also uses VXLAN technology which moves the WireGuard VPN server subnet from OSI Layer 3 to Layer 2 and allows the organization of practical work that requires being in the same local subnet. Access to this platform provides learners in the Central African Republic with a complete and secure distance learning environment for courses, assignments and tutorials.","","Mervyl Saint-Juste Kossingou G,Dégboé B,Gladys Gladys Ndassimba N,Ouya S,Mendy G","","2021","","10.1145/3454127.3456603","https://doi-org.proxy.bnl.lu/10.1145/3454127.3456603;http://dx.doi.org/10.1145/3454127.3456603","Conference Paper"
"Proposed Framework of Smart Transportation in Pakistan: Issues, Challenges, Vulnerabilities,and Solutions","This paper proposes a framework for a smart transportation system of Pakistan and discusses modern approaches as solutions to emerging threats and vulnerabilities of STS. In addition, STS changes the life of people and decreases the number of accidents, deaths, and traffic incidents. STS is saving the time of users and makes the urban city even smarter. The aim of STS is to accomplish more efficiency of traffic by decreasing traffic issues. It also provides the information about route traffic toward destination, local expediency, passing, vehicle dynamic or requested information, availability of seats to users, which decreases journey time of commuters and improves their security and ease. This paper discusses STS, its application and working mechanism, and the main parameters of the proposed framework of STS of Pakistan such as road condition monitoring, traffic management, municipal involvement, link data for society, accidental measures, and security, which are necessary while designing or implementing such systems.","","Awan JH,Memon S,Shah AA,Pathan KT","","2020","48–63","10.4018/IJCWT.2020100104","https://doi-org.proxy.bnl.lu/10.4018/IJCWT.2020100104;http://dx.doi.org/10.4018/IJCWT.2020100104","Journal Article"
"Protocols That Hide User's Preferences in Electronic Transactions","The Internet creates many new threats to personal privacy and raises some unique privacy concerns. In this paper we study the problem of how to protect users' privacy in web transactions of digital products. In particular, we introduce a system which (1) allows a user to disclose his/her identity information (such as user account or credit card number) to a web site in exchange for a digital product, but (2) prevents the web site from learning which specific product the user intends to obtain. The problem concerned here is orthogonal to the problem of anonymous transactions [M. Reed, P. Syverson, D. Goldschag, Anonymous connections and Onion Routing, IEEE Journal of Selected Areas in Communication 16 (4) (1998) 482-494; M. Reiter, A. Rubin, Crowds: anonymity for web transactions, ACM Transactions on Information System Security, 1 (1) (1998) 66-92] but commensurate with the general problem of PIR (private information retrieval) [B. Chor, O. Goldreich, E. Kushilevita, M. Sudan, Private information retrieval, in: Proceedings of 36th FOCS, 1995, pp. 41-50; B. Chor, N. Gilboa, Computational private information retrieval, in: Proceedings of 29th STOC, 1997, pp. 304-313]. Most of the existing results in PIR, however, are theoretical in nature and can not be applied in practice due to their huge communication and computational overheads. In the present paper, we introduce two practical solutions that satisfy the above two requirements and analyze their security and performance. Another issue we study in this paper is how to recover sales statistics data in our user privacy-protected system. We present a novel solution to the problem along with its security analysis.","","Bao F,Deng RH","","2005","503–515","","","Journal Article"
"Provable Security for the Fuzzy Fingerprint Vault","We investigate the security of privacy enhancing techniques for biometric applications.The fuzzy vault of Jules and Sudan is a technique that allows error tolerant authentication, while preserving the privacy of the reference data. Several publications have proposed its application to fingerprints in order to implement privacy-enhanced biometric authentication. While the heuristic security estimates given are promising, no rigid security analysis has been presented so far. We explore if and under what circumstances a provably secure fuzzy fingerprint vault can be implemented. Based on bounds on the loss of entropy for the general fuzzy vault and realistic models for minutiae distributions, we deduce lower bounds for attacks that attempt to recover the template. Furthermore, we show how to select optimal parameters and evaluate both, minimum minutiae match rates and minimum number of minutiae needed to obtain an appropriate security level. Our results indicate that a provable secure scheme is hard to achieve with current fingerprint technology.","","Merkle J,Niesing M,Schwaiger M,Ihmor H,Korte U","","2010","65–73","10.1109/ICIMP.2010.17","https://doi-org.proxy.bnl.lu/10.1109/ICIMP.2010.17;http://dx.doi.org/10.1109/ICIMP.2010.17","Conference Paper"
"Proving Sustainability: The International Development Monitoring Initative","Nearly a billion people in the world lack access to safe drinking water, two billion have inadequate sanitation facilities, three billion use biomass for their daily energy needs and nearly half the world's population live in rural isolation, lacking access to the most basic human services. Combined, these limitations are a leading cause of the perpetuating cycle of poverty and political insecurity. Meanwhile, the majority of international development agencies are responsible for self-reporting project outcomes. At best, expert spot-checks are conducted in the field occasionally. These results tend to show individual project success, while meta-surveys indicate on-going challenges in the sector. This disconnect may be addressed through independent data monitoring technologies that provide objective data on system performance and use and can be used to demonstrate success and identify project weaknesses. By demonstrating which technologies and programs are truly successful, these successes can be targeted for scaling, through savings realized by eliminating unsuccessful approaches. This will benefit developing communities by providing proven and accountable programs. The Sustainable Water, Energy and Environmental Technologies Laboratory, the SWEETLab , at Portland State University is working with partners to demonstrate this concept across several applications and countries. The SWEETSense technology can provide objective, qualitative and continuous operational data on the usage and performance of programs across a range of sectors and communities. The data is then directly integrated into SWEETData , an internet database presenting summary statistics on performance and usage of the monitored technologies to front-end users. The SWEETLab is currently demonstrating this concept in water, sanitation, household energy and rural infrastructure programs with diverse partners including Mercy Corps, the Lemelson Foundation, Bridges to Prosperity, Manna Energy Limited and Vestergaard Frandsen, in several countries including Indonesia, Haiti, Guatemala and Rwanda. Remote monitoring systems are an innovative method to ensure the success of appropriate technology projects. Rather than infrequent engagement, remote monitoring systems ensure that community partnerships are maintained through continuous monitoring. This approach seeks to raise the quality and accountability of these projects internationally.","","Thomas E,Zumr Z,Barstow C,Linden K","","2011","164–170","10.1109/GHTC.2011.74","https://doi-org.proxy.bnl.lu/10.1109/GHTC.2011.74;http://dx.doi.org/10.1109/GHTC.2011.74","Conference Paper"
"Quantifying the Strength and Durability of Induced Immunity to HIV Infection in Women Engaging in Unprotected Sexual Contacts with Infected Men","Evidence is accumulating that exposure to human immunodeficiency virus (HIV) can lead to an increased resistance or immunity to subsequent infection. A multirisk model that permits either induced immunity or infection to develop after heterosexual inoculation with HIV is shown to be compatible with a wide spectrum of disparate male-to-female transmission data. When the model is applied to time-dependent, HIV-seroprevalence data, the probability that an unexposed woman would remain unexposed after an unprotected contact with an infected man was estimated to be greater than 0.95 on the average. Thus, it would require at least 14 unprotected sexual contacts with HIV-infected men for 50% of an unexposed cohort of women to become exposed to the virus. This suggests that there is a low probability that HIV virions will be found to have penetrated the mucosal barriers of the reproductive tract after a contact. The model also predicts, that the average woman whose mucosal barriers have been breached by HIV has a significant probability of developing immunity to the virus rather than infection. Modelling data for a cohort of unexposed Nairobi women leads to the prediction that the probability of acquiring induced immunity per contact is about 60% of the probability of acquiring the disease per contact. The modelling results also predict that those who had developed resistance to HIV run the small, but significant risk of becoming infected nonetheless by continuing high-risk behavior. For the common contact rate of ten per month, the modelling predicts that the HIV-transmission risk per contact for unexposed women in the Nairobi cohort is 1178 while the transmission risk for the cohort's immunized women is 11548. These numbers suggest that HIV infection is difficult to transmit through heterosexual intercourse on the average and that male-to-female HIV-transmission risk per contact for African women lies between 1178 and 11548. Direct confirmation of the predictions in the last paragraph has been subsequently observed in two completely independent studies. The Nairobi research team recently reported that a notable number of Nairobi prostitutes previously identified to be members of the HIV-resistant group became infected nonetheless. Second, in a study of 174 sexually monogamous, discordant couples in Rakai, Uganda reporting contacts rates of nine to ten per month, the male-to-female HIV-transmission risk per contact was found to be 1769 by direct measurement, a value that falls between the above limits of 1178 and 11548 predicted by the modelling. Thus, a second major prediction of this paper has been directly confirmed, and induced immunity to HIV is limited and not absolutely protective. Circumstantial evidence suggests that the induced immunity to HIV predicted by the model could be generated and/or initiated by nonspecific innate immune responses, specific immunological responses, including IgA-mediated mucosal immunity and cytotoxic T lymphocytes (CTL) immunity, or some combination of the above. It is suggested here, that a decrease in the ability of HIV virions to penetrate the protective mucus layer of the reproductive tract may be a prerequisite, cofactor, or the principle cause of the induced immunity or resistance demonstrated to exist in this paper. The value of the probability that induced immunity to HIV will develop after a contact is shown to be a sensitive function of the woman's human leucocyte antigen (HLA) supertype profile.","","Kramer I,Shearer GM","","2002","1435–1458","10.1016/S0895-7177(02)00299-6","https://doi-org.proxy.bnl.lu/10.1016/S0895-7177(02)00299-6;http://dx.doi.org/10.1016/S0895-7177(02)00299-6","Journal Article"
"Quest for Fire, Water, Earth and Air: An Interaction Design Bus and Art Installation Reflecting Climate Change Concerns through Human and Elemental Connectedness","The notion of travelling to open doors onto different perspectives is an antidote to living, working and socializing in spaces mediated by technologically designed artifacts. Interfaces have become ubiquitous and relationships and styles of communication have changed in keeping with this ever-present trend. The Bachelors in Technology design students, from the Cape Peninsula University of Technology, have shared their concerns through their design research problems in exactly these areas. Questions regarding water safety, food security, air quality, sewerage management, marginalisation of people with disability, cultural specificity being erased by generic digital content arose; it became clear that the fragile threads connecting the ecosystem to the human system need nurturing. From an internal landscape to an external one, these students apply themselves creatively and intellectually in order to tackle real problems pro-actively; to talk less and do more. To this end, a sizable art installation piece has been conceptualized and constructed which will be unveiled with an accompanying performance piece at the 13th Participatory Design Conference (PDC) in Namibia, in October 2014.","","Chisin AV,van Niekerk J,M'Rithaa MK","","2014","183–185","10.1145/2662155.2662229","https://doi-org.proxy.bnl.lu/10.1145/2662155.2662229;http://dx.doi.org/10.1145/2662155.2662229","Conference Paper"
"RETRACTED ARTICLE: Acceptance and Usage of a Mobile Information System Services in University of Jordan","Along with the significant development of information and communication technologies (ICTSs), an incredible number of mobile applications have become available. Hence, the main purpose of the current study is to investigate the use and acceptance of the ‘Mobile Information System’ developed and implemented by University of Jordan, which Known as (Mobile Student Information System). Data were obtained from 275 undergraduate students of University of Jordan via questionnaire to test the ‘Mobile Services Acceptance Model’ using Structural Equation Model. The results reveal that user acceptance of mobile information system services is largely affected by trust, perceived security, perceived ease of use and perceived usefulness. Findings also show that context of applications is a strong motivational factor of perceived ease of use and perceived usefulness, which then significantly affects user intention to use mobile information system. While, the personal characteristics and features do not have effect on user intentions. Both theoretical and practical implications of the study’s findings are discussed.","","Almaiah MA","","2018","1873–1895","10.1007/s10639-018-9694-6","https://doi-org.proxy.bnl.lu/10.1007/s10639-018-9694-6;http://dx.doi.org/10.1007/s10639-018-9694-6","Journal Article"
"ROBOTMAN: Security Robot for Human-Robot Interaction Inside Malls","The market for service robot is rapidly growing nowadays to interact in a direct manner with humans. In the future we expect that robots will be able to provide a variety of services for humans. The concept of humanoid robot working as security guards for public places has grown in recent years. The security job is presented as a difficult activity that requires a significant physical wear on the average individual. Additionally, the demand of security services are growing around the world but companies that provide the services do not have enough trained personal to satisfy this opportunity.Thus, a security robot was developed in order to perform patrols during the night, while functioning as a platform for human-robot interaction during the day in indoors. One of the goals is to improve the welcoming of visitors to the mall using a robot that can also provide security and give information about the mall to the customers. A security company provided the key information, knowledge and guidance regarding the activities that a security guard is required to perform when working inside a mall. This work was developed with government funding and the collaboration between industry and university.We designed a stable and aesthetically pleasing security humanoid robot that is able to not only monitor a specific area, but to welcome visitors, provide information, help people, and improve their visit to a mall located in Peru. The design process is presented in Fig. 1a and preliminary tests were performed inside a mall Fig. 1.b. The robot has several sensors such as security cameras, depth camera, proximity sensors and a LIDAR to avoid obstacles, also actuators to move the arms and head to show expressions, LED eyes to represent emotional states, microphones and a pleasant voice to improve interaction with the public.The results reveal that the robot is a helpful tool for the security guards to improve their work and also satisfy at some level the expectations of the customers. The robot's appearance fulfills its objective of inviting people to interact with it, in this way the robot achieves its role of informative agent. The customers were able to interact through its interactive screen and the remote application for telecommunication with an external human agent that work for the mall and answer all their questions projecting his voice through the robot.We conclude that social robots could improve the life of the people not only in their homes, but also in open spaces where security and attention to costumers is needed. It's still a long way to the robot to perform as a human security guard but in the moment we present a helpful tool that can support their activities remotely. This technology is not aiming to replace humans, but to improve his performance in their job allowing them to cover large and remote areas.","","López JA,Cuéllar F","","2017","410","10.1145/3029798.3036653","https://doi-org.proxy.bnl.lu/10.1145/3029798.3036653;http://dx.doi.org/10.1145/3029798.3036653","Conference Paper"
"Real-Time Large-Scale Map Matching Using Mobile Phone Data","With the wide spread use of mobile phones, cellular mobile big data is becoming an important resource that provides a wealth of information with almost no cost. However, the data generally suffers from relatively high spatial granularity, limiting the scope of its application. In this article, we consider, for the first time, the utility of actual mobile big data for map matching allowing for “microscopic” level traffic analysis. The state-of-the-art in map matching generally targets GPS data, which provides far denser sampling and higher location resolution than the mobile data. Our approach extends the typical Hidden-Markov model used in map matching to accommodate for highly sparse location trajectories, exploit the large mobile data volume to learn the model parameters, and exploit the sparsity of the data to provide for real-time Viterbi processing. We study an actual, anonymised mobile trajectories data set of the city of Dakar, Senegal, spanning a year, and generate a corresponding road-level traffic density, at an hourly granularity, for each mobile trajectory. We observed a relatively high correlation between the generated traffic intensities and corresponding values obtained by the gravity and equilibrium models typically used in mobility analysis, indicating the utility of the approach as an alternative means for traffic analysis.","","Algizawy E,Ogawa T,El-Mahdy A","","2017","","10.1145/3046945","https://doi-org.proxy.bnl.lu/10.1145/3046945;http://dx.doi.org/10.1145/3046945","Journal Article"
"Recognition System for Libyan Vehicle License Plate","Automatic license plate recognition system plays an essential role in real life applications, especially those related to security and traffic managements. It essentially extracts and recognizes number plate information from videos or captured images of the targeted vehicle. Vehicle license plates differ from one country to another and because of this the effectiveness of implementing any particular method or system varies based on the plate type. In this study, we present an automatic detection, segmentation and recognition system for Libyan vehicle license plates. The main challenge in this work is our determination to use images of real vehicle plates in Libya, and the majority of these plates are not in a good condition because of poor vehicle maintenance. Three different approaches were used in the proposed system as follows: (1) Projection histogram based approach is used to locate the authorized plate license; (2) Connected component analysis based approach is used to segment the plate characters; (3) The template matching based approach is used to recognise the extracted characters. The proposed system was tested on 200 vehicle images varying in illumination conditions and backgrounds. The detection accuracy of the implemented system was 87%, the segmentation accuracy was 90% and the recognition accuracy was 86%.","","Almabruk TA,Almaghairbe R,Bukewitin T,Roper M","","2021","","10.1145/3492547.3492595","https://doi-org.proxy.bnl.lu/10.1145/3492547.3492595;http://dx.doi.org/10.1145/3492547.3492595","Conference Paper"
"Recognizing Weak Embeddings of Graphs","We present an efficient algorithm for a problem in the interface between clustering and graph embeddings. An embedding φ : G → M of a graph G into a 2-manifold M maps the vertices in V(G) to distinct points and the edges in E(G) to interior-disjoint Jordan arcs between the corresponding vertices. In applications in clustering, cartography, and visualization, nearby vertices and edges are often bundled to the same point or overlapping arcs due to data compression or low resolution. This raises the computational problem of deciding whether a given map φ : G → M comes from an embedding. A map φ : G → M is a weak embedding if it can be perturbed into an embedding ψ ε : G → M with ‖ φ − ψ ε ‖ 0, where ‖.‖ is the unform norm.A polynomial-time algorithm for recognizing weak embeddings has recently been found by Fulek and Kynčl. It reduces the problem to solving a system of linear equations over Z2. It runs in O(n2ω)≤ O(n4.75) time, where ω ∈ [2,2.373) is the matrix multiplication exponent and n is the number of vertices and edges of G. We improve the running time to O(n log n). Our algorithm is also conceptually simpler: We perform a sequence of local operations that gradually “untangles” the image φ(G) into an embedding ψ(G) or reports that φ is not a weak embedding. It combines local constraints on the orientation of subgraphs directly, thereby eliminating the need for solving large systems of linear equations.","","Akitaya HA,Fulek R,Tóth CD","","2019","","10.1145/3344549","https://doi-org.proxy.bnl.lu/10.1145/3344549;http://dx.doi.org/10.1145/3344549","Journal Article"
"Recognizing Weak Embeddings of Graphs","We present an efficient algorithm for a problem in the interface between clustering and graph embeddings. An embedding ϕ : G → M of a graph G into a 2-manifold M maps the vertices in V(G) to distinct points and the edges in E(G) to interior-disjoint Jordan arcs between the corresponding vertices. In applications in clustering, cartography, and visualization, nearby vertices and edges are often bundled to a common node or arc, due to data compression or low resolution. This raises the computational problem of deciding whether a given map ϕ : G → M comes from an embedding. A map ϕ : G → M is a weak embedding if it can be perturbed into an embedding φε : G → M with [Equation] for every ε > 0.A polynomial-time algorithm for recognizing weak embeddings was recently found by Fulek and Kynčl [14], which reduces to solving a system of linear equations over Z2. It runs in O(n2ω) ≤ O(n4.75) time, where ω ≈ 2.373 is the matrix multiplication exponent and n is the number of vertices and edges of G. We improve the running time to O(n log n). Our algorithm is also conceptually simpler than [14]: We perform a sequence of local operations that gradually ""untangles"" the image ψ(G) into an embedding φ(G), or reports that φ is not a weak embedding. It generalizes a recent technique developed for the case that G is a cycle and the embedding is a simple polygon [1], and combines local constraints on the orientation of subgraphs directly, thereby eliminating the need for solving large systems of linear equations.","","Akitaya HA,Fulek R,Tóth CD","","2018","274–292","","","Conference Paper"
"Recurrent Neural Networks on Duty of Anomaly Detection in Databases","In the paper we present a new approach based on application of neural networks to detect SQL attacks. SQL attacks are those attacks that take advantage of using SQL statements to be performed. The problem of detection of this class of attacks is transformed to time series prediction problem. SQL queries are used as a source of events in a protected environment. To differentiate between normal SQL queries and those sent by an attacker, we divide SQL statements into tokens and pass them to our detection system, which predicts the next token, taking into account previously seen tokens. In the learning phase tokens are passed to recurrent neural network (RNN) trained by backpropagation through time (BPTT) algorithm. Teaching data are shifted by one token forward in time with relation to input. The purpose of the testing phase is to predict the next token in the sequence. All experiments were conducted on Jordan and Elman networks using data gathered from PHP Nuke portal. Experimental results show that the Jordan network outperforms the Elman network predicting correctly queries of the length up to ten.","","Skaruz J,Seredynski F","","2007","85–94","10.1007/978-3-540-72395-0_12","https://doi-org.proxy.bnl.lu/10.1007/978-3-540-72395-0_12;http://dx.doi.org/10.1007/978-3-540-72395-0_12","Conference Paper"
"Relating Violence to MODIS Fire Detections in Darfur, Sudan","The Moderate Resolution Imaging Spectroradiometer MODIS Thermal Anomalies and Fire Detection data product can provide an input into early warning and rapid response efforts of interest to human rights, humanitarian and security communities. A review of fire detection data during a period of intense violence in Darfur, Sudan, marked by burning campaigns targeted at many settlements in the region, was conducted to test which, if any, of these fires were detected by MODIS. The results indicate that a significant portion of the fires related to violence were detected, and a relationship was found between increased fire detections and reported violence. However, underlying difficulties in the anecdotal reporting introduce uncertainties into the results. While not universally applicable, calculating increases in fire detections on a daily, global basis can possibly provide objective, satellite-based information on certain violent conflicts impacting civilian populations.","","Bromley L","","2010","2277–2292","","","Journal Article"
"Relating Violence to MODIS Fire Detections in Darfur, Sudan","The Moderate Resolution Imaging Spectroradiometer (MODIS) Thermal Anomalies and Fire Detection data product can provide an input into early warning and rapid response efforts of interest to human rights, humanitarian and security communities. A review of fire detection data during a period of intense violence in Darfur, Sudan, marked by burning campaigns targeted at many settlements in the region, was conducted to test which, if any, of these fires were detected by MODIS. The results indicate that a significant portion of the fires related to violence were detected, and a relationship was found between increased fire detections and reported violence. However, underlying difficulties in the anecdotal reporting introduce uncertainties into the results. While not universally applicable, calculating increases in fire detections on a daily, global basis can possibly provide objective, satellite-based information on certain violent conflicts impacting civilian populations.","","Bromley L","","2010","2277–2292","","","Journal Article"
"Removing Background of Raman Spectrum Based on Wavelet Transform","Raman spectrum is usually so weak that the noise usually distorts the interesting Raman bands. Especially, when the sample is fuscous, the strong fluorescence background often completely dominates Raman peaks. In this case, it is vital to remove fluorescence background for analyzing of Raman spectrum. Wavelet transform (WT) has proved to be a high-performance signal processing tool, and very efficient in removing low frequency noise. In this paper, WT was used to remove fluorescent background of Raman spectrum of Sudan I. Both the global thresholding method and the interval thresholding method were applied, and their de-noising performances were compared. The results indicated that the interval thresholding method is more efficient than the global thresholding method in removing fluorescence background of Raman spectrum.","","Li G","","2009","198–200","10.1109/FCC.2009.69","https://doi-org.proxy.bnl.lu/10.1109/FCC.2009.69;http://dx.doi.org/10.1109/FCC.2009.69","Conference Paper"
"Requirements Engineering in an Emerging Market","The growing importance of requirements engineering RE in software development cannot be overemphasized. A faulty requirements gathering exercise and the emergent requirements document could mislead the entire software development drive, resulting in a software product that falls short of user expectation in terms of meeting needs and delivering within budget, time and scope. Achieving the objective of a well articulated and coordinated requirements document in an ideal economic environment is tasking let alone in an emerging market characterized by macro-economic variables such as high cost of doing business, weak institutions, poor infrastructure, lack of skilled and competitive workforce, among others coupled with micro-economic personal tendencies like resistance to change, vested interest, technophobia and insider abuse. This paper reports on industrial experience of designing and implementing an n-tier enterprise application in an African university using service oriented software engineering SOSE approach. The application is meant to facilitate the actualization of the 25-year strategic plan of the institution. We applied design and software engineering skills: Literature were examined, requirements gathered, the n-tier enterprise solution modeled using unified modeling language UML, implementation achieved using Microsoft SharePoint and the results evaluated. Though success was recorded, the challenges encountered during the requirements engineering stage were quiet reflective of the challenges of software project management in a typical relatively unstable macroeconomic environment. The outcome of this study is a compendium of lessons learnt and recommendation for successful RE in the context of an emerging economy like Africa in the hope that this will guide would-be software stakeholders in such a business landscape.","","Okewu E","","2015","476–491","10.1007/978-3-319-21410-8_37","https://doi-org.proxy.bnl.lu/10.1007/978-3-319-21410-8_37;http://dx.doi.org/10.1007/978-3-319-21410-8_37","Conference Paper"
"Rescue Command Communication Systems and Emergency Management Platform in Mine Based on Internet of Things","In view of several problems existing among current rescue command communication and emergency management systems in mine, such as these systems have fewer supporting technologies and functions, has lower level of informatization and networking, has weaker technology extensibility due to the C/S software architecture, has more difficulty in remote online maintenance and upgrade in the future etc. a rescue command communication system and emergency management platform in mine based on Internet of Things are put forward. This system integrate the Internet of Things, wireless Mesh network, optical fiber and satellite communications platform comprehensively, as well as adopts B/S architecture, data mining database and remote database shared access modern information and other key technologies in order to realize the functions including disaster incident management, rescue command, visual management of disaster sites, rescue team and equipments management and emergency rescue plan management, etc. Strong extensibility and practicability were proved through the practical applications in a coal mine in Inner Mongolia and also proved by some training tests in a national rescue team in Heilongjiang province. These features of this system not only contribute to the informatization and networking of emergency command and rescue team management in the coal mine and rescue team, but also offer important reference value for other mine rescue teams at home or abroad to improve their ability on emergency command and management.","","Liu C,Song W,Guo D,Wang L","","2013","17–22","10.1109/ITA.2013.10","https://doi-org.proxy.bnl.lu/10.1109/ITA.2013.10;http://dx.doi.org/10.1109/ITA.2013.10","Conference Paper"
"Resonance: Dynamic Access Control for Enterprise Networks","Enterprise network security is typically reactive, and it relies heavily on host security and middleboxes. This approach creates complicated interactions between protocols and systems that can cause incorrect behavior and slow response to attacks. We argue that imbuing the network layer with mechanisms for dynamic access control can remedy these ills. We propose Resonance, a system for securing enterprise networks, where the network elements themselves enforce dynamic access control policies based on both flow-level information and real-time alerts. Resonance uses programmable switches to manipulate traffic at lower layers; these switches take actions (e.g., dropping or redirecting traffic) to enforce high-level security policies based on input from both higherlevel security policies and distributed monitoring and inference systems. We describe the design of Resonance, apply it to Georgia Tech's network access control system, show how it can both overcome the current shortcomings and provide new security functions, describe our proposed deployment, and discuss open research questions.","","Nayak AK,Reimers A,Feamster N,Clark R","","2009","11–18","10.1145/1592681.1592684","https://doi-org.proxy.bnl.lu/10.1145/1592681.1592684;http://dx.doi.org/10.1145/1592681.1592684","Conference Paper"
"Respeak: A Voice-Based, Crowd-Powered Speech Transcription System","Speech transcription is an expensive service with high turnaround time for audio files containing languages spoken in developing countries and regional accents of well-represented languages. We present Respeak - a voice-based, crowd-powered system that capitalizes on the strengths of crowdsourcing and automatic speech recognition (instead of typing) to transcribe such audio files. We created Respeak and optimized its design through a series of cognitive experiments. We deployed it with 25 university students in India who completed 5464 micro-transcription tasks, transcribing 55 minutes of widely-varied audio content, and collectively earning USD 46 as mobile airtime. The Respeak engine aligned the transcript generated by five randomly selected users to transcribe Hindi and Indian English audio files with a word error rate (WER) of 8.6% and 15.2%, respectively. The cost of speech transcription was USD 0.83 per minute with a turnaround time of 39.8 hours, substantially less than industry standards. Using a mixed-methods analysis of cognitive experiments, system performance and qualitative interviews, we evaluate Respeak's design, user experience, strengths, and weaknesses. Our findings suggest that Respeak improves the quality of speech transcription while enhancing the earning potential of low-income populations in resource-constrained settings.","","Vashistha A,Sethi P,Anderson R","","2017","1855–1866","10.1145/3025453.3025640","https://doi-org.proxy.bnl.lu/10.1145/3025453.3025640;http://dx.doi.org/10.1145/3025453.3025640","Conference Paper"
"Reverse Engineering Human Mobility in Large-Scale Natural Disasters","Delay/Disruption-Tolerant Networks (DTNs) have been around for more than a decade and have especially been proposed to be used in scenarios where communication infrastructure is unavailable. In such scenarios, DTNs can offer a best-effort communication service by exploiting user mobility. Natural disasters are an important application scenario for DTNs when the cellular network is destroyed by natural forces. To assess the performance of such networks before deployment, we require appropriate knowledge of human mobility. In this paper, we address this problem by designing, implementing, and evaluating a novel mobility model for large-scale natural disasters. Due to the lack of GPS traces, we reverse-engineer human mobility of past natural disasters (focusing on 2010 Haiti earthquake and 2013 Typhoon Haiyan) by leveraging knowledge of 126 experts from 71 Disaster Response Organizations (DROs). By means of simulation-based experiments, we compare and contrast our mobility model to other well-known models, and evaluate their impact on DTN performance. Finally, we make our source code available to the public.","","Stute M,Maass M,Schons T,Hollick M","","2017","219–226","10.1145/3127540.3127542","https://doi-org.proxy.bnl.lu/10.1145/3127540.3127542;http://dx.doi.org/10.1145/3127540.3127542","Conference Paper"
"Review Article: RePIDS: A Multi Tier Real-Time Payload-Based Intrusion Detection System","Intrusion Detection System (IDS) deals with huge amount of network traffic and uses large feature set to discriminate normal pattern and intrusive pattern. However, most of existing systems lack the ability to process data for real-time anomaly detection. In this paper, we propose a 3-Tier Iterative Feature Selection Engine (IFSEng) for feature subspace selection. Principal Component Analysis (PCA) technique is used for the pre-processing of data. Mahalanobis Distance Map (MDM) is used to discover hidden correlations between the features and between the packets. We also propose a novel Real-time Payload-based Intrusion Detection System (RePIDS) that integrates a 3-Tier IFSEng and the MDM approach. Mahalanobis Distance (MD) dissimilarity criterion is used to classify each packet as either a normal or an attack packet. The effectiveness of the proposed RePIDS is evaluated using DARPA 99 dataset and Georgia Institute of Technology attack dataset. The traffic for Web-based application is considered for validating our model. F-value, a criterion, is used to evaluate the detection performance of RePIDS. Experimental results show that RePIDS achieves better performance (high F-values, 0.9958 for DARPA 99 dataset and 0.976 for Georgia Institute of Technology attack dataset respectively, with only 0.85% false alarm rate) and lower computational complexity when compared against two state-of-the-art payload-based intrusion detection systems. Additionally, it has 1.3 time higher throughput in comparison with real scenario of medium sized enterprise network.","","Jamdagni A,Tan Z,He X,Nanda P,Liu RP","","2013","811–824","10.1016/j.comnet.2012.10.002","https://doi-org.proxy.bnl.lu/10.1016/j.comnet.2012.10.002;http://dx.doi.org/10.1016/j.comnet.2012.10.002","Journal Article"
"Risk Analysis of Enterprises’ Investment in Infrastructure in Developing Countries Based on Structural Equation Model","In order to control the risks of Chinese enterprises in infrastructure investment in developing countries, the corresponding evaluation system is constructed through a structural equation model algorithm to analyze these risks, so as to achieve risk prediction and risk controllability. Structural equation modeling is a method to establish, estimate, and test causality. It can replace multiple regression, path analysis, factor analysis, covariance analysis, and other methods and clearly analyze the effect of individual indicators on the population and the interrelationship between individual indicators. It is a multivariate statistical modeling technology mainly applied to confirmatory model analysis. Due to the guidance of national policies, there are more and more opportunities for Chinese enterprises to invest abroad. However, due to the influence of political, economic, and environmental factors, overseas investment is facing many difficulties. This paper analyzes the risks from four aspects: bilateral policy risk, legal difference and litigation risk, international economic risk, and technical risk through structural equation model algorithm. Aiming at these risks, the simulation software of the algorithm is constructed in MATLAB big data analysis software, and the risk control measures are put forward. Finally, with the support of China’s policies, in order to ensure the investment income, we should carry out risk intervention for the foreseeable risk and reduce the impact of risk on the investment income as much as possible, so as to improve the risk prevention and management awareness of overseas investment business. By analyzing the characteristics of venture capital and the various kinds of risks affecting venture capital, the risk structure model estimation of risk sneak attack is established by using the principle of structural equation model, and the impact of various risks on investment risks can be analyzed, so that the risk measurement and control of venture capital provides the basis of theoretical knowledge.","","Lu H,Wang L,Khattak HA","","2022","","10.1155/2022/4790726","https://doi-org.proxy.bnl.lu/10.1155/2022/4790726;http://dx.doi.org/10.1155/2022/4790726","Journal Article"
"Rubric-Based Formative Assessment to Support Students’ Learning of Organic Chemistry in the Selected Secondary Schools in Rwanda: A Technology-Based Learning","A significant number of instructors, researchers and students have claimed that chemistry is a challenging subject to teach and learn at all education levels. Its main learning difficulties are in line with certain sights of its phenomena that are abstract, and some chemistry teachers do not specify what to be learned and assessed in chemistry lesson. The current work investigates the use of formative assessment rubrics for supporting secondary school students’ progressive learning in organic chemistry through a technology-based learning project approach in Rwanda. The investigators used a convergent parallel research design, and quantitative data were gathered by distributing questionnaires to the students, and the answers were statistically analyzed. Qualitative data were obtained through observation and interview and were narratively analyzed. The results from this study showed that rubric-based formative assessment supported students’ learning of organic chemistry via technology-based learning approach. This is accredited to the fact that students were motivated while doing their assessment and they were able to do self-assessment by applying the provided rubrics via technology. The students understood instructors’ expectations, encouraged their learning, sharpened their technology skills, and their knowledge retention was also increased. The instructors were able to grade the students’ tasks fast with the help of an analytic rubric and good formative feedback was availed to students on time. The instructors were also able to diagnose the strengths and weaknesses of the learners and give them quick formative feedback.","","Nsabayezu E,Mukiza J,Iyamuremye A,Mukamanzi OU,Mbonyiryivuze A","","2022","12251–12271","10.1007/s10639-022-11113-5","https://doi-org.proxy.bnl.lu/10.1007/s10639-022-11113-5;http://dx.doi.org/10.1007/s10639-022-11113-5","Journal Article"
"SOSerbia: Android-Based Software Platform for Sending Emergency Messages","This paper presents Android-based SOS platform named SOSerbia for sending emergency messages by citizens in Serbia. The heart of the platform is SOS client Android application which is an easy and simple solution for sending SOS messages with unique combination of volume buttons. The proposed platform solves a lot of safety, security, and emergency problems for people who can be in dangerous situations. After a person presses a correct combination of buttons, a message with his or her location is sent to the operating center of the Serbian Police. The platform merges several appropriately combined advanced Android technologies into one complete solution. The proposed solution also uses the Google location API for getting user’s location and Media Player broadcast receiver for reading pressed buttons for volume. This logic can be also customized for any other mobile operating system. In other words, the proposed architecture can be also implemented in iOS or Windows OS. It should be noted that the proposed architecture is optimized for different mobile devices. It is also implemented with simple widget and background process based on location. The proposed platform is experimentally demonstrated as a part of emergency response center at the Ministry of Interior of the Republic of Serbia. This platform overcomes real-life problems that other state-of-the-art solutions introduce and can be applied and integrated easily in any national police and e-government systems.","","Jovanovic M,Babic I,Cabarkapa M,Misic J,Mijalkovic S,Nikolic V,Randjelovic D,Fuentes M","","2018","","10.1155/2018/8283919","https://doi-org.proxy.bnl.lu/10.1155/2018/8283919;http://dx.doi.org/10.1155/2018/8283919","Journal Article"
"SPOT Poachers in Action: Augmenting Conservation Drones with Automatic Detection in near Real Time","The unrelenting threat of poaching has led to increased development of new technologies to combat it. One such example is the use of long wave thermal infrared cameras mounted on unmanned aerial vehicles (UAVs or drones) to spot poachers at night and report them to park rangers before they are able to harm animals. However, monitoring the live video stream from these conservation UAVs all night is an arduous task. Therefore, we build SPOT (Systematic POacher deTector), a novel application that augments conservation drones with the ability to automatically detect poachers and animals in near real time. SPOT illustrates the feasibility of building upon state-of-the-art AI techniques, such as Faster RCNN, to address the challenges of automatically detecting animals and poachers in infrared images. This paper reports (i) the design and architecture of SPOT, (ii) a series of efforts towards more robust and faster processing to make SPOT usable in the field and provide detections in near real time, and (iii) evaluation of SPOT based on both historical videos and a real-world test run by the end users in the field. The promising results from the test in the field have led to a plan for larger-scale deployment in a national park in Botswana. While SPOT is developed for conservation drones, its design and novel techniques have wider application for automated detection from UAV videos.","","Bondi E,Fang F,Hamilton M,Kar D,Dmello D,Choi J,Hannaford R,Iyer A,Joppa L,Tambe M,Nevatia R","","2018","","","","Conference Paper"
"Safe Farming as a Service of Blockchain-Based Supply Chain Management for Improved Transparency","Precision agriculture is based on the idea of utilizing technology to improve the efficiency of agriculture industry. Blockchain technology has great potential to revolutionize the agricultural industry. Furthermore, various Internet of Things (IoT) based solutions are proposed to enhance production such as crops condition monitoring system. These technologies aim to address various stages of the agricultural supply chain by improving the processes. The key issue faced by farmers is to ensure the protection of their crops from animals during all stages of a harvest. This paper proposes a IoT-based prevention system to tackle this issue for safe farming. The solution is based on the input of the sensor nodes deployed in the field to detect animal attacks. These sensors report a hazard to a Repelling and Notifying System (RNS) in the field. The RNS produces human-safe ultrasonic sound waves that are unbearable for animals, thus they leave the field. The proposed RNS system also reports all hazard incidents to a centralized Farm Management System (FMS) maintained by the farmer. The paper also proposes a way the FMS can add value to a broader arena by becoming a service to an Agricultural Blockchain system. As a blockchain node, the FMS maintains a shared ledger as part of blockchain to share the details of incidents with meta information with other nodes in the blockchain. This information is vital for other blockchain nodes of the agricultural blockchain such as other FMS, companies, authorities and standard bodies. The low-cost RNS performance evaluation concludes that it is power efficient that makes it even affordable for developing countries, and as a Blockchain service it enables novel applications for the agriculture industry.","","Iqbal R,Butt TA","","2020","2139–2150","10.1007/s10586-020-03092-4","https://doi-org.proxy.bnl.lu/10.1007/s10586-020-03092-4;http://dx.doi.org/10.1007/s10586-020-03092-4","Journal Article"
"Safe Mathare: A Mobile System for Women's Safe Commutes in the Slums","The spread of mobile phone usage to slum areas raises the possibility of using mobile technology to address problems facing the poorest of the world's poor. We present a case study of Safe Mathare, a design project aimed at improving women's safety in Nairobi, Kenya. Safe Mathare provides community patrols with basic smartphone technology to help women commute safely through a slum neighborhood during dusk and dawn hours. The project started as a prototype developed in a university course and has found willing partners with local NGOs and government. During its pilot phase, it has run into many challenges in particular around the issue of vigilantism. This paper explores the development and implementation of Safe Mathare, raising the questions of whether and how design can leverage technology to build a social network for security.","","Hagan M,Zhang N,Kaye Jjofish","","2012","47–52","10.1145/2371664.2371675","https://doi-org.proxy.bnl.lu/10.1145/2371664.2371675;http://dx.doi.org/10.1145/2371664.2371675","Conference Paper"
"SafeStreet: Empowering Women against Street Harassment Using a Privacy-Aware Location Based Application","Sexual harassment of women in public places (e.g., foot-paths, buses, and shopping malls) of major cities in developing countries is a growing concern. These harassments can happen in various forms ranging from commenting, catcalling, and staring to touching and groping, to attacking and raping. Though, the most severe form of harassments such as attacking and raping get some attention from the society, NGOs and law-enforcement agencies, unfortunately, other forms of harassments that are more widespread in public places remain largely un-attended or ignored in our conservative society. However, these harassments are more common and can have various negative psychological impacts on women that include a persistent feeling of insecurity, loss of self-esteem, restricted participation in daily life activities in public places. In this paper, we propose a crowd-powered privacy-aware location based mobile application, SafeStreet, that empowers women in public places against sexual harassments. SafeStreet allows a women to privately capture and share her own experiences in the street. SafeStreet enables a women to find a safe path, i.e., the path to a destination that has less harassment hazard, at any point of time.","","Ali ME,Rishta SB,Ansari L,Hashem T,Khan AI","","2015","","10.1145/2737856.2737870","https://doi-org.proxy.bnl.lu/10.1145/2737856.2737870;http://dx.doi.org/10.1145/2737856.2737870","Conference Paper"
"Sampling Strategies for Mining in Data-Scarce Domains","Data mining has traditionally focused on the task of drawing inferences from large data sets. However, many scientific and engineering domains, such as fluid dynamics and aircraft design, are characterized by scarce data, due to the expense and complexity of associated experiments and simulations. In such data-scarce domains, it is advantageous to focus the data collection effort on only those regions deemed most important to support a particular data mining objective. This article describes a mechanism that interleaves bottom-up data mining, to uncover multilevel structures in spatial data, with top-down sampling, to clarify difficult decisions in the mining process. The mechanism exploits relevant physical properties, such as continuity, correspondence, and locality, in a unified framework. This leads to effective mining and sampling decisions that are explainable in terms of domain knowledge and data characteristics. This approach is demonstrated in two diverse applications-mining pockets in spatial data, and qualitative determination of Jordan forms of matrices.","","Ramakrishnan N,Bailey-Kellogg C","","2002","31–43","10.1109/MCISE.2002.1014978","https://doi-org.proxy.bnl.lu/10.1109/MCISE.2002.1014978;http://dx.doi.org/10.1109/MCISE.2002.1014978","Journal Article"
"Saving the Planet, One Handset at a Time: Designing Low-Power, Low-Bandwidth GPUs","GPUs for mobile devices have to deliver ever-increasing performance and capability while living within strict power and memory bandwidth limits. In this talk we'll explore how these limits influence the design of mobile GPUs, and how applications can exploit GPU features to achieve the best power efficiency and performance, using ARM's Mali™ GPU family as a case study.","","Olson TJ","","2012","","10.1145/2341910.2341912","https://doi-org.proxy.bnl.lu/10.1145/2341910.2341912;http://dx.doi.org/10.1145/2341910.2341912","Conference Paper"
"Secure Smartcardbased Fingerprint Authentication","In this paper, the fundamental insecurities hampering a scalable, wide-spread deployment of biometric authentication are examined, and a cryptosystem capable of using fingerprint data as its key is presented. For our application, we focus on situations where a private key stored on a smartcard is used for authentication in a networked environment, and we assume an attacker can launch o -line attacks against a stolen card.Juels and Sudan's fuzzy vault is used as a starting point for building and analyzing a secure authentication scheme using fingerprints and smartcards called a figerprint vault. Fingerprint minutiae coordinates mi are encoded as elements in a nite eld F and the secret key is encoded in a polynomial f(x) over F[x]. The polynomial is evaluated at the minutiae locations, and the pairs (mi, f(mi)) are stored along with random (ci, di) cha points such that di ≠ f(ci). Given a matching fingerprint, a valid user can seperate out enough true points from the cha points to reconstruct f(x), and hence the original secret key.The parameters of the vault are selected such that the attacker's vault unlocking complexity is maximized, subject to zero unlocking complexity with a matching fingerprint and a reasonable amount of error. For a feature location measurement variance of 9 pixels, the optimal vault is 269 times more difficult to unlock for an attacker compared to a user posessing a matching fingerprint, along with approximately a 30% chance of unlocking failure.","","Clancy TC,Kiyavash N,Lin DJ","","2003","45–52","10.1145/982507.982516","https://doi-org.proxy.bnl.lu/10.1145/982507.982516;http://dx.doi.org/10.1145/982507.982516","Conference Paper"
"Securing the Human: Broadening Diversity in Cybersecurity","Recent global demand for cybersecurity professionals is promising, with the U.S. job growth rate at 28%, three times the national average. Lacking qualified applicants, many organizations struggle to fill open positions. In a global survey, 2,300 security managers reported that 59% of their security positions were unfilled, although 82% anticipated cyberattacks to their systems. At the same time, the cybersecurity field is broadening, not only in technical concepts but also in human factors, business processes, and international law. The field has not become culturally diversified, however. Professionals hired in 2018 included only 24.9% women, 12.3% African Americans, and 6.8% Latinos. These facts create an opportunity for higher education: diversify the profession while increasing the numbers of skilled computer scientists. New and integrated methods of attracting student populations in the field of cybersecurity are needed. The working group goal is to evaluate the effectiveness of approaches used in higher education to diversify the cybersecurity field through literature review, analysis of the findings, and a survey on techniques used for diversification of the cybersecurity field.","","Azhar M,Bhatia S,Gagne G,Kari C,Maguire J,Mountrouidou X,Tudor L,Vosen D,Yuen TT","","2019","251–252","10.1145/3304221.3325537","https://doi-org.proxy.bnl.lu/10.1145/3304221.3325537;http://dx.doi.org/10.1145/3304221.3325537","Conference Paper"
"Security Protection Technology in Multi-Attribute Data Transmission Based on Fuzzy Genetic Algorithm","Because the traditional data transmission security protection methods ignore the process of multi-attribute data detection, resulting in the abnormal data false alarm rate, high missing alarm rate, eliminating accuracy and other problems, a multi-attribute data transmission security protection method based on fuzzy genetic algorithm is proposed. The anomaly detection method based on fuzzy data mining and genetic algorithm is adopted to detect and obtain the abnormal data in the multi-attribute data transmission, and the abnormal data in the multi-attribute data transmission is eliminated through the abnormal data elimination method based on PSO and SVM, so as to realize the security protection of multi-attribute data transmission. It is verified that the recall rate and accuracy rate of abnormal data of the proposed method are higher than 95%, and the removal accuracy of abnormal data is higher. Moreover, this method is far better than the comparison method in positive likelihood ratio and Jordan index, and has higher application value.","","Lv S,Chen H","","2022","897–917","10.1007/s11277-021-08447-7","https://doi-org.proxy.bnl.lu/10.1007/s11277-021-08447-7;http://dx.doi.org/10.1007/s11277-021-08447-7","Journal Article"
"Semimodularity and the Jordan–HöLder Theorem in Posets, with Applications to Partial Partitions","Lattice-theoretical generalizations of the Jordan–Hölder theorem of group theory give isomorphisms between finite maximal chains with same endpoints. The best one has been given by Czédli and Schmidt (after Grätzer and Nation), and it applies to semimodular lattices and gives a chain isomorphism by iterating up and down the perspectivity relation between intervals [x∧y,x] and [y,x∨y] where x covers x∧y and x∨y covers y. In this paper, we extend to arbitrary (and possibly infinite) posets the definitions of standard semimodularity and of the slightly weaker “Birkhoff condition”, following the approach of Ore (Bull Amer Math Soc 49(8):567–568, 1943). Instead of perspectivity, we associate tags to the covering relation, a more flexible approach. We study the finiteness and length constancy of maximal chains under both conditions and obtain Jordan–Hölder theorems. Our theory is easily applied to groups, to closure ranges of an arbitrary poset, and also to five new order relations on the set of partial partitions of a set (i.e. partitions of its subsets), which do not constitute lattices.","","Ronse C","","2019","255–280","10.1007/s10801-018-0852-0","https://doi-org.proxy.bnl.lu/10.1007/s10801-018-0852-0;http://dx.doi.org/10.1007/s10801-018-0852-0","Journal Article"
"Serverless Science Gateway Development for Ca2+ Binding Site Prediction on Amazon Web Services: Case Study","In this paper we discuss the development of a science gateway; identifying Ca2+ binding sites in proteins using a java application developed by Dr. Jenny Yang at the Chemistry department, Georgia State University. Starting with a Protein Data Bank (PDB) X-ray or NMR structure file, MUGC application predicts calcium binding sites using a graph theory-based algorithm [1]. The project creates a science gateway to provide access to the MUGC algorithm using tools provided by Amazon Web Services. The full-stack solution uses S3 storage, AWS Lambda functions, and API gateway to relay the PDB files to the back-end computing in EC2. Architecture for a full stack serverless processing pipeline is implemented which allows users to access the application. The design is optimized for scalability, reliability, security, performance, and cost.","","Mashiku M,Edirisinghe N","","2019","","10.1145/3332186.3333050","https://doi-org.proxy.bnl.lu/10.1145/3332186.3333050;http://dx.doi.org/10.1145/3332186.3333050","Conference Paper"
"Session Details: Demonstrations","It is our great pleasure to welcome you to the Demo Track of WWW 2016, The 25th International World Wide Web Conference, held in Montreal, Canada, during April 11-15, 2016.The WWW 2016 Demo Track, like in the tradition of WWW Demo conference series, allows researchers and practitioners to demonstrate new systems in a dedicated session. Demo contributions are based on an implemented and tested system that pursues one or more innovative ideas in the interest areas of Web data and information management, Web search, Web intelligence tools, Web mining, social network applications and so forth. Topics of interest for the 2016 edition's conference include (but are not limited to) the following ones: Behavioral Analysis and PersonalizationBig Data on the WebCrowdsourcing Systems and Social MediaContent AnalysisGraph Data Management and MiningHigh-Performance Infrastructures for Data- Intensive Web TasksInternet Economics and MonetizationPervasive Web and MobilitySecurity and PrivacySemantic WebSocial Networks and Graph AnalysisWeb Information RetrievalWeb Infrastructure: Datacenters, Content Delivery Networks, and Cloud ComputingWeb MiningWeb ScienceWeb Search Systems and ApplicationsDemo contributions come from academic researchers, industrial practitioners with prototypes or inproduction deployments, as well as from any W3C-related activities. All have in common to show innovative use of Web-based techniques.The WWW 2016 Demo Track call for papers attracted 65 submissions from all over the world (USA, North America, South America, Europe, Australia, Asia, Africa). The program committee reviewed and accepted a very selected collection of 29 papers, and the final statistics is the following: WWW 2016 Demo Track Statistics Number of Submitted Papers 65 Number of Accepted Papers 29.","","Cuzzocrea A,El Saddik A","","2016","","","","Conference Paper"
"Session Details: Tutorials","It is our great pleasure to welcome you to the WWW 2016 Tutorials. We received 21 proposals from all around the world covering a broad range of topics. We evaluated them regarding relevance, quality, and novelty, selecting 5 half-day tutorials and 2 full-day tutorials. We also took in account the coverage of the different areas related to WWW as well as the potential audience, to schedule them in two consecutive days with the minimal audience interest overlap.The morning of the first day includes the following four tutorials: Computational Social Science for the World Wide WebCentrality Measures on Big GraphsThe afternoon of the first day includes the following four tutorials: Computational Social Science for the World Wide Web (continued)Cryptographic Currencies Crash CourseThe second day starts with three tutorials: Building Decentralized Applications for the Social WebAutomatic Entity Recognition and Typing in Massive Text CorporaMining Big Time-series Data on the WebThe final afternoon includes the last three tutorials: Building Decentralized Applications for the Social Web (continued)Analyzing sequential User Behavior on the WebThe call for tutorials attracted submissions from United States, Europe, Asia, Africa and South America. Review and acceptance statistics are as follows: WWW 2016 Tutorials Reviewed -21 Accepted - 7.We believe that the program provides a good balance between several trending topics such as deep learning, social media analysis, graph mining, crowdsourcing, knowledge databases, mobile data, etc. Hence we hope that you will find the tutorial program interesting, providing you with a valuable opportunity to learn and share ideas with other researchers and practitioners from institutions around the world.","","Tiropanis T,Weber M","","2016","","","","Conference Paper"
"Shadow Aware License Plate Recognition System","During recent years, license plate recognition have been widely used as a core technology for security or traffic applications such as in traffic surveillance, parking lot access control, and information management. In this paper, Shadow Aware License Plate Recognition (SALPR) system is proposed to recognize Egyptian LP. This system achieves high recognition rate through applying shadow detection and removal, rotation adjustment and using Multilayer perceptron as a powerful tool to perform the recognition process. To show the efficiency of the proposed system, experiments have been done on numerous captured images including various types of vehicles with different lighting and noise effects. The experimental results yield 95.5 % recognition accuracy, the recognition process takes 1.6 s to recognize plate information. Most of the elapsed time used is for the license plate extraction and rotation adjustment. The results show the feasibility of the methodology followed in this paper. Performance comparison between SALPR and other LP recognition techniques shows that for most of the cases, SALPR performs better than other techniques under different lighting conditions and it shows the high robustness of the proposed algorithm.","","El-Said SA","","2015","225–235","10.1007/s00500-014-1245-5","https://doi-org.proxy.bnl.lu/10.1007/s00500-014-1245-5;http://dx.doi.org/10.1007/s00500-014-1245-5","Journal Article"
"Shim Shimmeny: Evaluating the Security and Privacy Contributions of Link Shimming in the Modern Web","Link shimming (also known as URL wrapping) is a technique widely used by websites, where URLs on a site are rewritten to direct link navigations to an intermediary endpoint before redirecting to the original destination. This ""shimming"" of URL clicks can serve navigation security, privacy, and analytics purposes, and has been deployed by prominent websites (e.g., Facebook, Twitter, Microsoft, Google) for over a decade. Yet, we lack a deep understanding of its purported security and privacy contributions, particularly in today's web ecosystem, where modern browsers provide potential alternative mechanisms for protecting link navigations without link shimming's costs.In this paper, we provide a large-scale empirical evaluation of link shimming's security and privacy contributions, using Facebook's real-world deployment as a case study. Our results indicate that even in the modern web, link shimming can provide meaningful security and privacy benefits to users broadly. These benefits are most notable for the sizable populations that we observed with a high prevalence of legacy browser clients, such as in mobile-centric developing countries. We discuss the tradeoff of these gains against potential costs. Beyond link shimming, our findings also provide insights for advancing user online protection, such as on the web ecosystem's distribution of responsibility, legacy software scenarios, and user responses to website security warnings.","","Li F","","2020","","","","Conference Paper"
"SignSupport: A Mobile Aid for Deaf People Learning Computer Literacy Skills","This paper discusses a prototype of a learning aid on a mobile phone to support Deaf people learning computerliteracy skills. The aim is to allow Deaf people to learn at their own pace which in turn reduces the dependenceon a teacher to allow weaker learners be assisted. We studied the classroom dynamics and teaching methods toextract how lesson content is delivered. This helped us develop an authoring tool to structure lesson content forthe prototype. A prototype has been developed using South African Sign Language videos arranged accordingto the structure of pre-existing lessons. The technical goal was to implement the prototype on a mobile deviceand tie the resulting exported lesson content from the authoring tool to a series of signed language videos andimages so that a Deaf person can teach him/herself computer literacy skills. Results from the user testing foundthe prototype successful in allowing Deaf users to learn at their own pace thereby reducing the dependence onthe teacher.","","G. Ng'ethe G,H. Blake E,Glaser M","","2015","501–511","10.5220/0005442305010511","https://doi-org.proxy.bnl.lu/10.5220/0005442305010511;http://dx.doi.org/10.5220/0005442305010511","Conference Paper"
"Simulating Corn Supply, Demand and Consumption in Egypt: A System Dynamics Approach","Modeling the corn supply chain to satisfy population needs is a challenge, since corn is considered an essential food crop for achieving food security in many countries. Egypt is one of the biggest importers of corn in the world, since its domestic production is not sufficient to satisfy its population needs. A simulation model is built to represent the problem of local corn supply in Egypt, through studying the population demand, the capability of purchase from the markets, the production and import of corn. The proposed model provides good basis for showing the real life cycle of corn during the period (1990-2010) and projects the future until year 2030. It indicates gradual increase in population number so as the demand and imports. Finally, set of policies are applied to manage and improve production and import processes.","","Khodeir MH,Abdelsalam HM","","2016","14–20","10.1145/2908446.2908484","https://doi-org.proxy.bnl.lu/10.1145/2908446.2908484;http://dx.doi.org/10.1145/2908446.2908484","Conference Paper"
"Simulating DDoS Attacks on the US Fiber-Optics Internet Infrastructure","Network-based attacks like the distributed denial-of-service (DDoS) attacks are not new, but we are beginning to see attacks of unprecedented scale. Examples of such attacks include the 2016 attack on DYN INC that crippled a part of the Internet for hours, and the attack on Liberia, which partially brought down the African nation. Limitations in identifying vulnerable Internet infrastructure and testing possible defense strategies are a part of the problem. We need a simulation testbed that can reflect the complexity of the Internet, yet allows to swiftly test attacks, providing insights that can apply to real-world attack scenarios. In this research, we have designed a test-bed that mirrors the Internet infrastructure of the US and can simulate the Internet traffic flow patterns for different attack targets. We also estimate the degradation in the quality-of-service and the number of users impacted in two attack scenarios.","","Kumar S,Carley KM","","2017","","","","Conference Paper"
"Simulation of Vehicular Network Use in Emergency Situations and Security Applications on a Pakistan Highway","VANETs (vehicular ad hoc networks), which are revolutionary techniques to enhance road safety, can be used to broadcast information about dangerous traffic conditions or accidents. However, distributing important information for driver safety and well-being has strict time and reliability requirements. This is because messages must be received by all cars involved in a potentially dangerous scenario for proper precautions to be taken to avoid the problem from materializing or intensifying. Because of the deterioration in conventional wireless communication system performance, ensuring that such requirements are met is a serious concern. To validate the concept before the actual installation of such systems and their absorption into the vehicle sector, it is therefore critical to employ simulation methodologies that are both reliable and thorough. This piece consists of large-scale, realistic security simulation research of an emergency situation based on actual road traffic data acquired on a Pakistan route. The study’s findings are detailed in the following paragraphs. Aspects such as the incorporation of fixed communication units along a stretch of roadway and the performance of the vehicular network notifying all vehicles engaged in the various accident scenarios modeled on the same stretch of highway were evaluated. Both of these characteristics were designed to increase safety and security applications. After doing the investigation, it was observed that when fixed communication units are incorporated into the network infrastructure, there is a shorter delay in receiving the accident notification. This was the conclusion made after reviewing the findings. Drivers of vehicles located closer to the accident site will be able to respond in a timely and safe manner as a result of this improvement in network performance, and drivers security of vehicles located further away will have the option of exiting the highway to avoid potential congestion caused by increased road traffic.","","Al-Douri AT,Mohammed Kadhim N,Mohamad AA,Abeyie M,Azeem I","","2022","","10.1155/2022/2902263","https://doi-org.proxy.bnl.lu/10.1155/2022/2902263;http://dx.doi.org/10.1155/2022/2902263","Journal Article"
"Smart Agriculture for Sustainable Food Security Using Internet of Things (IoT)","Internet of Things (IoT) is being used in various parts of human life (domestic and commercial) to provide ease in living, safety, increase productivity, monitoring, and resource optimization in various industries. Agriculture is one of them, where IoT and robots are being used before and after the cultivation process, from preparing land for cultivation to supplying them to the consumer market. These domains include crop monitoring, smart irrigation, pest monitoring, and smart pest control, harvesting, and safely supplying them in the consumer market by maintaining the quality and integrity of the final product. Pakistan is an agricultural country, where it stands in terms of advanced agriculture technology. In this review, we discussed the major IoT ecosystem components. What are the most practiced smart agriculture techniques and their benefits and some widely used applications of IoT in agriculture? Through this overview, we are trying to highlight the potential of IoT in agriculture for sustainable food security for Pakistan.","","Qureshi T,Saeed M,Ahsan K,Malik AA,Muhammad ES,Touheed N,Islam SK","","2022","","10.1155/2022/9608394","https://doi-org.proxy.bnl.lu/10.1155/2022/9608394;http://dx.doi.org/10.1155/2022/9608394","Journal Article"
"Smart4Gap: Factors That Influence Smartphone Security Decisions in Developing and Developed Countries","Despite the importance of an up-to-date Operating System (OS) for smartphone security, few users update it whenever it becomes obsolete. We believe intellectual, financial, sociocultural and other factors may highly affect users' behaviour in updating their OS, and these factors might significantly vary among users of different demographics and users in different geographic locations. In this paper, we conducted a survey of 206 participants from different demographics in Japan and Tanzania (two countries with different socio-cultures, per-capita incomes, security and privacy perceptions). We study and analyze in-depth users' privacy and security attitudes to examine our claims. Our results show that in both countries, the majority of users, even those with higher education levels, do not either set their devices into auto-update mode or instantly update their smartphone OS despite the awareness of security issues. Moreover, users in Tanzania are mostly cost-conscious (mobile data is highly-priced), while those in Japan are mostly concerned with preserving phone battery. Furthermore, the majority of users who update their OS in Tanzania are motivated by improved User Interfaces (UI) and better device performance while in Japan, users are more motivated by security features, and they consider OS updates as generally important. Overall, in both countries, income and motivators are the major determinant for auto- and instant- update behavior for smartphone OS.","","Ndibwile JD,Luhanga ET,Fall D,Miyamoto D,Kadobayashi Y","","2018","5–15","10.1145/3285957.3285980","https://doi-org.proxy.bnl.lu/10.1145/3285957.3285980;http://dx.doi.org/10.1145/3285957.3285980","Conference Paper"
"Social Network Theory: A Comparative Analysis of the Jewish Revolt in Antiquity and the Cyber Terrorism Incident over Kosovo","This paper uses social network theory to compare the social network of the Jewish Revolt in 66-73 AD and the cyber terrorist attacks during the Kosovo war in 1999. The goal is to demonstrate that terrorist networks in Antiquity and cyber terrorist networks today not only mirror each other in their patterns of “terror” stratagems but also differ in key ways. The use of social network theory is appropriate because the theory embodies a particular theoretical orientation towards the structure of terrorist networks. This is why social network theory applies well to the Jewish Revolt and the Kosovo war. The ultimate goal of this analysis is to bridge the gap between theory and practice.","","Matusitz J","","2011","34–44","10.1080/19393555.2010.544702","https://doi-org.proxy.bnl.lu/10.1080/19393555.2010.544702;http://dx.doi.org/10.1080/19393555.2010.544702","Journal Article"
"Socio-Economic Factors in the Application of Information and Communication Technologies in Nigerian Print Media","Information and communication technologies (ICTs) have opened up new opportunities for the Nigerian print media to improve on their products and services. This study explores the socio-economic factors associated with the adoption and use of ICTs by the media. Of a total of 54 socio-economic factors considered, exactly 50% were found to have significant influence on the adoption and success of ICT applications. The factors that have the greatest positive influence on adoption of ICTs include organizational goal, profitability, organizational image, communication in the organization, productivity, and openness of workers to change. They also constitute success factors in the use of these technologies. The factors that constrained adoption and also successful application include high rate of inflation, unfavourable exchange rate of the naira to the dollar, low wage level, huge costs, low gross national product, inadequate funding, and unstable political situation. These constraining factors are indicators of economic weakness and political uncertainty. It seems that the significance of such factors, which are completely external to a business organization, was often underestimated in studies of organizational performance in developing countries.","","Ehikhamenor FA","","2002","602–611","10.1002/asi.10044","https://doi-org.proxy.bnl.lu/10.1002/asi.10044;http://dx.doi.org/10.1002/asi.10044","Journal Article"
"Some Geometric Measures of Spheres in Banach Spaces","In this paper, we first give relations between Pythagorean parameters and other well-known parameters: the coefficient of weak orthogonality, James and von Neumann-Jordan constants. Consequently, some known results in [J. Gao, On the generalized Pythagorean parameters and the applications in Banach spaces, Discrete Contin. Dyn. Syst. Ser. B, 8 (3) (2007) 557-567; J. Gao, On some geometric parameters in Banach spaces, J. Math. Anal. Appl. 344 (2007) 114-122; A. Jimenez-Melado, E. Llorens-Fuster, S. Saejung, The von Neumann-Jordan constant, weak orthogonality and normal structure in Banach spaces, Proc. Am. Math. Soc. 134 (2006) 355-364] are deduced and strengthened. Secondly we present several sufficient conditions for a Banach space and its dual to have normal structure. Finally, some open questions posed at the end of Gao (2007) are answered in the negative.","","Gao J,Saejung S","","2009","102–107","10.1016/j.amc.2009.03.060","https://doi-org.proxy.bnl.lu/10.1016/j.amc.2009.03.060;http://dx.doi.org/10.1016/j.amc.2009.03.060","Journal Article"
"Some Issues on Intrusion Detection in Web Applications","In the paper we present a new approach based on application of neural networks to detect SQL attacks. SQL attacks are those attacks that take the advantage of using SQL statements to be performed. The problem of detection of this class of attacks is transformed to time series prediction problem. SQL queries are used as a source of events in a protected environment. To differentiate between normal SQL queries and those sent by an attacker, we divide SQL statements into tokens and pass them to our detection system, which predicts the next token, taking into account previously seen tokens. In the learning phase tokens are passed to a recurrent neural network (RNN) trained by backpropagation through time (BPTT) algorithm. Then, two coefficients of the rule are evaluated. The rule is used to interpret RNN output. In the testing phase RNN with the rule is examined against attacks and legal data to find out how evaluated rule affects efficiency of detecting attacks. All experiments were conducted on Jordan network. Experimental results show the relationship between the rule and a length of SQL queries.","","Skaruz J,Seredynski F","","2006","164–174","10.1007/978-3-540-69731-2_17","https://doi-org.proxy.bnl.lu/10.1007/978-3-540-69731-2_17;http://dx.doi.org/10.1007/978-3-540-69731-2_17","Conference Paper"
"South Africa Crime Visualization, Trends Analysis, and Prediction Using Machine Learning Linear Regression Technique","South Africa has been classified as one of the most homicidal, violent, and dangerous places across the globe. However, the two elements that pushed South Africa high in the crime rank are the rates of social violence and homicide. It was reported by Business Insider that South Africa is among the most top 15 ferocious nations on earth. By 1995, South Africa was rated the second highest in terms of murder. However, the crime rate has reduced for some years and suddenly rose again in recent years. Due to social violence and crime rates in South Africa, foreign investors are no longer interested in continuing or starting a business with the nation, and hence, its economy is declining. South Africa’s government is looking for solutions to the crime issue and to redeem the image of the country in terms of high crime ranking and boost the confidence of the investors. Many traditional approaches to data analysis in crime-related studies have been done in South Africa, but the machine learning approach has not been adequately considered. The police station and many other agencies that deal with crime hold a lot of databases that can be used to predict or analyze criminal happenings across the provinces of South Africa. This research work aimed at offering a solution to the problem by building a model that can predict crime. The machine learning approach shall be used to extract useful information from South Africa's nine provinces' crime data. A crime prediction system that can analyze and predict crime is proposed. To accomplish this, South Africa crime data on 27 crime categories were obtained from the popular data repository “Kaggle.” Diverse data analytics steps were applied to preprocess the datasets, and a machine learning algorithm (linear regression) was used to build a predictive model to analyze data and predict future crime. The appropriate authorities and security agencies in South Africa can have insight into the crime trends and alleviate them to encourage the foreign stakeholders to continue their businesses.","","Obagbuwa IC,Abidoye AP,Daneshvar Rouyendegh (B. Erdebilli) B","","2021","","10.1155/2021/5537902","https://doi-org.proxy.bnl.lu/10.1155/2021/5537902;http://dx.doi.org/10.1155/2021/5537902","Journal Article"
"Speculative Vulnerability: Uncovering the Temporalities of Vulnerability in People's Experiences of the Pandemic","Pandemic-tracking apps may form a future infrastructure for public health surveillance. Yet, there has been relatively little exploration of the potential societal implications of such an infrastructure. In semi-structured interviews with 23 participants from India, the Middle East and North Africa (MENA), and the United States, we discussed attitudes and preferences regarding the deployment of apps that support contact tracing to contain the spread of COVID-19. Through interpretive analysis, we examined the relationship between persistent discomfort and vulnerability when using such apps. Such an examination yielded three temporal forms of vulnerability: real, anticipatory, and speculative. By identifying and defining the temporalities of vulnerability through an analysis of people's pandemic-related thoughts and experiences, we develop the overlapping discourses of humanistic infrastructure studies and infrastructural speculation. In doing so, we explore the concept of vulnerability itself and present implications for the study of vulnerability in Human-Computer Interaction (HCI) and for the oversight of app-based public health surveillance.","","Seberger JS,Obi I,Loukil M,Liao W,Wild DJ,Patil S","","2022","","10.1145/3555586","https://doi-org.proxy.bnl.lu/10.1145/3555586;http://dx.doi.org/10.1145/3555586","Journal Article"
"Square-Free Decomposition in Finite Characteristic: An Application to Jordon Form Computation","In ([GT]) has been addressed the problem of the computation of the square-free decomposition for univariate polynomials with coefficients in arbitrary fields. The complete square-free decomposition can be computed over arbitrary fields of finite characteristic solely assuming that the field satisfies the Condition P of Seidenberg ([Se]), which has been proven equivalent to the ability computing such decompositions (see also [MRR]). If we assume that the field is only an effective field (i.e. of a field K where there are constructive procedures for performing rational operations in K and for deciding whether or not two elements in K are equal), it is possible to obtain a weaker decomposition into powers of relatively prime factors, not necessarily square-free, but such that within each factor the roots have constant multiplicity. Although this is a partial decomposition, much useful information can be gathered from this result. As an application we present an algorithm to compute the Jordan form of a matrix over an arbitrary effective field. In particular we show how to handle problems of inseparability while splitting invariant factors and constructing symbolic Jordan form.The computation of normal forms of a matrix, in particular of the Jordan form, is a very important task and has many useful applications, so it has been widely studied for many years and many efficient algorithms, sequential and parallel ([O], [L], [Gi1], [Gi2], [Ol], [KKS], [RV]), are already available for its computation. There are already algorithms which compute the Jordan form of a matrix over general fields ([GD], [RV]), but they are based on dynamic evaluation ([D5]) and we want to avoid the use of such a scheme, that requires a special computational environment. Storjohann ([St]) has given a new algorithm for computing the rational canonical form which has a deterministic complexity of O(n3) but he does not compute the transition matrix with the same complexity. Steel's ([S]) algorithm for computing generalized Jordan form has a complexity O(n4) but requires factoring polynomials into irreducibles. Kaltofen et. al. ([KKS]) give fast parallel algorithms for canonical forms and make the observation that one could compute a symbolic Jordan form from a rational canonical form by splitting the invariant factors using gcd's and square-free decompositions. They require the computation of complete square-free decompositions and thus also require that K be a perfect field with the ability to compute pth roots. They also don't compute the transition matrix. Ozello ([O]) presents an algorithm for computing the rational canonical form which is deterministic with complexity O(n4), and leaves the question of faster probabilitic approaches for future work. Giesbrecht ([Gi2]) gives a probabilistic algorithm whose complexity is essentially the same as matrix multiplication but requires choosing n ""good"" random vectors simultaneously thus giving only a probability of 1/4 of making a successful choice.Our aim is to obtain a general sequential algorithm, of a complexity comparable with most of the existing algorithms, that works in the widest possible setting, without requiring particular computing resources and hence of easy and straightforward implementation. Because of our hypothesis, in general, our algorithm will produce a symbolic Jordan form ([K], [RV]), but the main difference with the other available algorithms based on dynamic evaluation is that our algorithm is a rational algorithm, since all the computations take place in the given field, except for the output and eventually the computation of the inverse of the transition matrix. To obtain all the information on the symbolic roots of the characteristic polynomial (multiplicities and recognition) we, at first, transform the given matrix A into a pseudo-rational form, i.e. a block diagonal matrix, similar to A, with companion matrices on the diagonal without requiring any kind of divisibility of the associated polynomials. Then we refine the factorization of the characteristic polynomial, given by the polynomials whose companion matrices are on the diagonal of the pseudo-rational form, using partial square-free decomposition and gcd computations, so that we can identify the same roots in different blocks and also we reduce, as much as possible without factorization, the degree of the defining polynomials for the eigenvalues.The pseudo-rational form is computed with a probabilistic algorithm of complexity O(n3) such that each independent random choice is verifiable with probability better than 1 - 1/n of success. We derive this probabilistic algorithm from one for the computation of the rational form, which has a complexity of O(n4), and is obtained via a straightforward analysis of the properties of the minimal polynomial that leads to a natural way to construct invariant subspaces.","","Fortuna E,Gianni P","","1999","14–32","10.1145/500457.500460","https://doi-org.proxy.bnl.lu/10.1145/500457.500460;http://dx.doi.org/10.1145/500457.500460","Journal Article"
"StrongBox: A GPU TEE on Arm Endpoints","A wide range of Arm endpoints leverage integrated and discrete GPUs to accelerate computation such as image processing and numerical processing applications. However, in spite of these important use cases, Arm GPU security has yet to be scrutinized by the community. By exploiting vulnerabilities in the kernel, attackers can directly access sensitive data used during GPU computing, such as personally-identifiable image data in computer vision tasks. Existing work has used Trusted Execution Environments (TEEs) to address GPU security concerns on Intel-based platforms, while there are numerous architectural differences that lead to novel technical challenges in deploying TEEs for Arm GPUs. In addition, extant Arm-based GPU defenses are intended for secure machine learning, and lack generality. There is a need for generalizable and efficient Arm-based GPU security mechanisms.To address these problems, we present StrongBox, the first GPU TEE for secured general computation on Arm endpoints. During confidential computation on Arm GPUs, StrongBox provides an isolated execution environment by ensuring exclusive access to the GPU. Our approach is based in part on a dynamic, fine-grained memory protection policy as Arm-based GPUs typically share a unified memory with the CPU, a stark contrast with Intel-based platforms. Furthermore, by characterizing GPU buffers as secure and non-secure, StrongBox reduces redundant security introspection operations to control access to sensitive data used by the GPU, ultimately reducing runtime overhead. Our design leverages the widely-deployed Arm TrustZone and generic Arm features, without hardware modification or architectural changes. We prototype StrongBox using an off-the-shelf Arm Mali GPU and perform an extensive evaluation. Our results show that StrongBox successfully ensures the GPU computing security with a low (4.70% - 15.26%) overhead across several indicative benchmarks.","","Deng Y,Wang C,Yu S,Liu S,Ning Z,Leach K,Li J,Yan S,He Z,Cao J,Zhang F","","2022","769–783","10.1145/3548606.3560627","https://doi-org.proxy.bnl.lu/10.1145/3548606.3560627;http://dx.doi.org/10.1145/3548606.3560627","Conference Paper"
"Survey on DNS Configurations, Interdependencies, Resilience and Security for *.Ke Domains","Statistics and research work show that the Legacy DNS as used today is slow, vulnerable to denial of service attacks, and does not support fast updates. To further compound this problem, configuring the DNS is complex and most of its implementations in use on many web servers are insecure. Consequently, Internet resources hosted on such servers have been subject to attacks of every kind. The *.ke domains have had a good share of such attacks, for example, 103 Government of Kenya's websites (.go.ke) were recently (January 2012) hacked in one night. In this paper, we present results of a survey for the *.ke domains whose main objective was to establish whether the DNS configurations for the *.ke domains met minimum setup configurations for security, resilience and interdependencies. Our focus on the three aspects was informed by the fact that these aspects are responsible for most DNS implementation shortcomings and by extension, responsible for most of the vulnerabilities and consequent attacks. To achieve this objective, 2,000 *.ke domains were collected through newspapers and magazines, posters and billboards, Internet, email directories and the main *.ke domain registrant KENIC. Dig and NSLOOKUP utilities were then used to drill down their configuration aspects such as primary and DNS servers, DNS application running on them, the dependencies among the DNS server, geographical location, MX records and web servers.The results indicated a very low compliance to the standard DNS configuration requirements making *.ke domains non-resilient to failure, vulnerable (over 60%) and overly insecure. Other findings were that 40% of the domains were hosted by 2 name servers and a further 46% of the domains interrogated were hosted a paltry 8 name servers. Of the 768 servers queried for their DNS applications 574 responded with the DNS application type and version; displaying such private information predisposes the server to attacks. it was also found out that on average, a *.ke domain DNS server depends on an average of 234 DNS servers and that some domains had only one DNS server.The study revealed major gaps in the way the DNS servers for *.ke domains are configured and questioned the capacity of those tasked with configuring these servers. Crypto graphical solutions like IPSEC and NSIG were recommended to secure the DNS servers. Awareness campaigns and capacity building on importance of DNS and security issues surrounding it on the technicians tasked with configuring the servers was also recommended. These findings were then used to inform the development of a web-based step-by-step DNS Configuration Tool. The latter is an online highly technical guide that the administrators can use to check if their DNS server(s) are properly set up to take care of configurations, resilience and interdependencies issues that may render the domain insecure and unavailable.","","Kagwe JG,Masinde M","","2012","","10.1145/2160601.2160632","https://doi-org.proxy.bnl.lu/10.1145/2160601.2160632;http://dx.doi.org/10.1145/2160601.2160632","Conference Paper"
"System Architecture for Delay Tolerant Media Distribution for Rural South Africa","Wireless communication offers access to information even to users living in areas where little to no access to affordable communication channels is available. Delay Tolerant Networks (DTNs) enable content distribution in such areas, using mobility of devices and avoiding the need for traditional network infrastructure. In DTNs, data is passed from mobile device to mobile device, whenever possible, in an intelligent way. DTNs have the potential to reach out to under-served regions where cellular Internet access (3G, LTE, and beyond) might be expensive or unavailable. We are interested in DTNs for distributing media from cities to under-served rural areas. The content is distributed to the target destinations, using either public transportation or commuting vehicles such as taxis, equipped with wireless DTN-enabled devices. At each target destination, a micro-entrepreneur business is established with the help of our network: Micro-entrepreneurs use DTN-enabled projectors (also referred to as cinemas-in-a-backpack) to deliver entertainment content at low cost, and exploit the opportunity to create a micro-business around the show events. In this paper, we introduce the DTN system setup, present performance results of laboratory tests and test with a local commuter train of periodic and predictable mobility. Further, we present the target scenario and specific technical challenges. We aim to explore opportunities for a rural, under-served region in the north of Pretoria, South Africa.","","Galati A,Bourchas T,Siby S,Mangold S","","2014","65–72","10.1145/2643230.2643239","https://doi-org.proxy.bnl.lu/10.1145/2643230.2643239;http://dx.doi.org/10.1145/2643230.2643239","Conference Paper"
"System Performance and Layered Analysis Tool","Naval Surface Warfare Center Panama City Division (NSWC-PCD) has developed a System Performance and Layered Analysis Tool (SPLAT) using MATLAB. The overall goal is to detect terrorist threats, particularly in an open crowded area, in a timely manner. Given a sensor configuration and a scenario specification, it combines a layered set of threat detection sensors to determine overall system performance in terms of probability of detection, probability of false alarm, and cost. SPLAT avoids overly optimistic performance estimates inherent when a series of closely spaced detection events are modeled as discrete, independent Bernoulli trials. SPLAT describes all sensors using multi-dimensional lookup tables, thereby circumventing the need to mathematically model complex sensor performance functions. This methodology is sufficiently general that it can be applied to a broad class of problems where multiple stationary sensors attempt to detect a moving target.","","Hyland JC,Smith CM","","2011","2600–2611","","","Conference Paper"
"Technical Aspects of the Online E-Management Control and Evaluation System for Universities","This paper briefly describes several technical aspects and general structure of the e-Management Control and Evaluation System (e-MCES) at the University of Technology (UTech), Jamaica. Some our original technical and security solutions we have implemented in it. We consider this web application as a base for a full management system for educational institutions that includes strategic, academic, and financial planning and management components. This approach will allow the institution to respond promptly to real-world challenges and opportunities that might affect its short- and long-term strategies.","","Kulkarni AB,Pougatchev V","","2011","20–25","","","Conference Paper"
"Technical and Economic Feasibility for Passive Housing in the Social Sector of Honduras","In this research, the authors designed an energy efficiency system applied for social housing in Honduras. The design consists of constructing a standardized passive house in areas where communities do not have access to electricity and gas. The social-economic situation in Honduras is very delicate, with almost 1.5 million people homeless. 8% of the population don't have access to electricity. For rural areas, people only rely on a wood fire to cock, which has accelerated deforestation all long the country. In the region, other countries are adopting more energy efficiency politics to counter-attack social-economic difficulties and climate change. Honduras has not yet recovered from the bankrupt of the governmental bureau in charge of the productive chain of electricity. It is urgent to apply relief measures, and passive houses sure are one that can make Honduras take one step toward development. The social housing will need an OFFGRID photovoltaic (PV) system to supply their electrical energy and a pre-fabricated biodigester to produce biogas with biomass found in the community. The authors replaced the conventional concrete block used in Honduras with an ICF block to improve thermic conditions inside the house. Building a house with an ICF block is even cheaper than one of concrete block, and there is a difference in temperature inside the house of 6 degrees Celsius between the ICF and concrete one. The project will have a return on investment period of no more than six years. The inversion for each house is $ 10,836.71. The authors consider the design suggested in this investigation can benefit the social-economic situation in Honduras as energy efficiency and social politic. However, there is still more to be done to perceive mayor results in the Honduran energy efficiency culture.","","Luis Ordoez-Avila J,Hermida E","","2022","178–183","10.1145/3497701.3497735","https://doi-org.proxy.bnl.lu/10.1145/3497701.3497735;http://dx.doi.org/10.1145/3497701.3497735","Conference Paper"
"Technology, Governance, and the Escalation of Ebola: Wicked Problems in Real Time","Digital technologies have been perceived as a means of facilitating governance in addressing complex, dynamic policy problems. Yet, technology alone cannot resolve interdependencies among divergent organizations operating at different levels of authority, access to resources, and experience in heterogeneous contexts. We report preliminary findings from an ongoing study of the recent Ebola outbreak in West Africa that revealed breakdowns in governance due in part to limited use of digital technologies to support systematic monitoring of the spread of the disease, search for, and exchange of, valid information and knowledge essential to manage a rapidly evolving, complex threat. We apply a systems theory approach to this wicked problem as a framework for examining the interactions between key actors involved in the response to this epidemic. Preliminary findings are drawn from a content analysis of news articles posted on the United Nations Relief Web and include a chronological record of the Ebola outbreak in West Africa from March through December 2014. A planned network analysis will measure the centrality of actors, as well as the strength and direction of ties among the participating actors: local, provincial, national, regional, and international. We anticipate developing a model of sociotechnical design for addressing complex policy problems","","Bert J,Shin YA,Chalfont B","","2015","71–78","10.1145/2757401.2757434","https://doi-org.proxy.bnl.lu/10.1145/2757401.2757434;http://dx.doi.org/10.1145/2757401.2757434","Conference Paper"
"Terminal Ballistics of Intercept Ammunition against Mortar Targets","The threat imposed by rockets, artillery projectiles, and mortar grenades (RAM) is of major concern for military installations and objects, e.g., in Iraq or Afghanistan. A good portion of these attacks are undertaken with unguided rockets and mortar projectiles with calibers up to 120 mm. This paper concentrates on mortars. A counter RAM system based on 155 mm HE projectiles is applied to intercept and destroy incoming targets at a safe distance of the installation. Therefore, the impact of fragments and a blast wave as warhead mechanisms against a typical Russian mortar projectile with a caliber of 82 mm is investigated by adopting different empirical equations. A response plot overlayed on the fragment map is derived from the detonation and penetration threshold. These results are input parameters for a statistical approach of estimating the ammunition consumption as a function of the multi-shot kill probability.","","Graswald M,Rothe H","","2008","720–728","","","Conference Paper"
"Testing of Network Security Systems through DoS, SQL Injection, Reverse TCP and Social Engineering Attacks","Cyber-attacks are happening with an ever-increasing frequency with the goal of gaining access to sensitive information. These attacks can cause huge damage to all kinds of organisations. With web applications becoming a preferred target for attackers through which to try and access sensitive data, it has become of a paramount importance for organisations to implement robust security policies. Measures should be taken to prevent these attacks by testing security systems before attacks happen. The most frequent types of attacks are: SQL injection, DoS, reverse TCP and social engineering. In this paper, we use penetration testing techniques on computer systems and networks. We analyse firewalls and other protective systems and their role through different scenarios. Using penetration testing techniques, we try to find the best solution for protecting sensitive data within the governmental network of Kosovo. We also tackle the issue of social engineering attacks on networks.","","Maraj A,Rogova E,Jakupi G","","2020","115–133","10.1504/ijguc.2020.103976","https://doi-org.proxy.bnl.lu/10.1504/ijguc.2020.103976;http://dx.doi.org/10.1504/ijguc.2020.103976","Journal Article"
"The Blend of Credit Scoring Model for Individual in the Dmaic Process for Reducing Non-Performing Loan Risk","Non-performing loan (NPL) is the main threat for all financial institutions. In order to improve loan approval process and reduce the risk of NPL, this research proposes an application of six sigma and credit scoring model. Six Sigma is an outstanding tool for process improvement by reducing defects in the process in manufacturing and service industries. Credit scoring model is a statistical model that aid in the decision making for the bank and other financial institution whether they should approve or reject the loan application. Six Sigma offers value by reducing defects and Credit scoring model can enhance credit lending policy. The implementation of Six sigma and Credit scoring model in bank loan approval process is a new topic and few literatures have studied in this area. The objectives of this research are to identify factors causing NPL and propose framework using Six Sigma and Credit scoring model to improve bank loan process and enhance the credit lending policy to reduce the risk of NPL. Case study of a bank in Cambodia is illustrated.","","Thavarith V,Liangrokapart J","","2019","195–202","10.1145/3335550.3335583","https://doi-org.proxy.bnl.lu/10.1145/3335550.3335583;http://dx.doi.org/10.1145/3335550.3335583","Conference Paper"
"The CAS-PEAL Large-Scale Chinese Face Database and Baseline Evaluations","In this paper, we describe the acquisition and contents of a large-scale Chinese face database: the CAS-PEAL face database. The goals of creating the CAS-PEAL face database include the following: 1) providing the worldwide researchers of face recognition with different sources of variations, particularly pose, expression, accessories, and lighting (PEAL), and exhaustive ground-truth information in one uniform database; 2) advancing the state-of-the-art face recognition technologies aiming at practical applications by using off-the-shelf imaging equipment and by designing normal face variations in the database; and 3) providing a large-scale face database of Mongolian. Currently, the CAS-PEAL face database contains 99 594 images of 1040 individuals (595 males and 445 females). A total of nine cameras are mounted horizontally on an arc arm to simultaneously capture images across different poses. Each subject is asked to look straight ahead, up, and down to obtain 27 images in three shots. Five facial expressions, six accessories, and 15 lighting changes are also included in the database. A selected subset of the database (CAS-PEAL-R1, containing 30 863 images of the 1040 subjects) is available to other researchers now. We discuss the evaluation protocol based on the CAS-PEAL-R1 database and present the performance of four algorithms as a baseline to do the following: 1) elementarily assess the difficulty of the database for face recognition algorithms; 2) preference evaluation results for researchers using the database; and 3) identify the strengths and weaknesses of the commonly used algorithms.","","Gao W,Cao B,Shan S,Chen X,Zhou D,Zhang X,Zhao D","","2008","149–161","10.1109/TSMCA.2007.909557","https://doi-org.proxy.bnl.lu/10.1109/TSMCA.2007.909557;http://dx.doi.org/10.1109/TSMCA.2007.909557","Journal Article"
"The Coming African Tsunami of Information Insecurity","As the affordability and use of mobile phones in Africa increase, so too will security vulnerabilities.","","Goodman S,Harris A","","2010","24–27","10.1145/1859204.1859215","https://doi-org.proxy.bnl.lu/10.1145/1859204.1859215;http://dx.doi.org/10.1145/1859204.1859215","Journal Article"
"The Cyber Espionage Crimes in the Jordanian Law","The current article aims to show the position of the Arab laws in general and the Jordanian legislator in particular against cyber spying. First, the article pointed out the concept and classification of state secrets. Then, it approached the extent of applicability of the traditional provisions on the espionage committed via electronic means. Furthermore, an analysis was done on Article 12 of the Jordanian Electronic Crimes Law by going deep into stating the elements of the crime set therein and arriving at the penalties that resulted from breaching it. Finally, the article concluded the possibility of applying Articles 15 and 16 of the Jordanian Law on the Protection of State Secrets and Documents (1970) criminalising obtaining state secrets and disclosing secrets obtained by the office without legal justification.","","Issa HA,Alkhseilat A","","2022","111–123","10.1504/ijesdf.2022.121203","https://doi-org.proxy.bnl.lu/10.1504/ijesdf.2022.121203;http://dx.doi.org/10.1504/ijesdf.2022.121203","Journal Article"
"The Digital Turn in Radio: A Critique of Institutional and Organizational Modeling of New Radio Practices and Cultures","This article conducts a critical analysis of the use of Internet and mobile phone technologies by Capital radio in Malawi. It examines the uses of the Internet, social networking sites and mobile text-messaging by the radio station. Three central questions constitute the major concerns of the article: (a) To what extent do institutional and organizational contexts shape the uptake and uses of the Internet and mobile phones by radio journalists? (b) How do the uses of the Internet and mobile phones in turn influence the institutional cultures and organizational practices? (c) To what extent, if at all, does radio convergence reconfigure traditional radio to create new spaces that augment audience participation? The article argues that any meaningful critique of the technological affordances to the radio institution must critically engage with the complex questions of the dialectical relationship between technology, structure, and agency especially given the seductive myth of the so- called new media. It concludes that digital media technologies on radio are subject to organisational, institutional, and social shaping, and that questions about the emancipatory power of these technologies especially to audiences and citizens are often exaggerated because the question of power relations between actors or interests is often overlooked. The digital turn and the demotic turn on radio therefore must not be seen as synonymous with the participatory turn, especially in African countries where the regulation of corporate power in mass media is weak and where multiple forms of the digital divide that impede on consistent and meaningful use of digital media still persist.","","Moyo L","","2013","214–222","10.1016/j.tele.2012.10.003","https://doi-org.proxy.bnl.lu/10.1016/j.tele.2012.10.003;http://dx.doi.org/10.1016/j.tele.2012.10.003","Journal Article"
"The Georgia Tech Aware Home","The Aware Home Research Initiative (AHRI) at Georgia Tech is devoted to the multidisciplinary exploration of emerging technologies and services based in the home. Starting in 1998, our collection of faculty and students has created a unique research facility that allows us to simulate and evaluate user experiences with off-the-shelf and state-of-the-art technologies. With specific expertise in health, education, entertainment and usable security, we are able to apply our research to problems of significant social and economic impact.","","Kientz JA,Patel SN,Jones B,Price E,Mynatt ED,Abowd GD","","2008","3675–3680","10.1145/1358628.1358911","https://doi-org.proxy.bnl.lu/10.1145/1358628.1358911;http://dx.doi.org/10.1145/1358628.1358911","Conference Paper"
"The Global Agricultural Concept Scheme and Agrisemantics","Key concepts from three thesauri about agriculture and nutrition--AGROVOC, CAB Thesaurus, and NAL Thesaurus--have been merged into a Global Agricultural Concept Scheme (GACS). The respective partner organizations--Food and Agriculture Organization of the UN (FAO), CAB International (CABI), and the USDA National Agricultural Library (NAL)-- undertook this initiative in 2013 with the goal of facilitating search across databases, improving the semantic reach of their databases by supporting queries that freely draw on terms from any mapped thesaurus, and achieving economies of scale from joint maintenance. The GACS beta release of May 2016 has 15,000 concepts and over 350,000 terms in 28 languages.The creation of GACS began by mapping three sets of 10,000 frequently used concepts from the three thesauri to each other, pairwise. Mappings were vetted by experts; vetted mappings were algorithmically checked for awkward clusters, or ""lumps""; and lumps were resolved through discussion on teleconferences and in meetings--for example, by drawing a line between ""energy intake"" (related to organisms) and ""energy consumption"" with the narrower ""fuel consumption"" (related to natural resources). Mappings were manually corrected, and GACS was iteratively regenerated, until the set of concepts was considered stable enough for publication as GACS Beta.Some inevitable results of this process of aggregation, such as overlapping labels, have already been fixed. Other issues, such as concepts with multiple hierarchical relations (""polyhierarchy""), have yet to be tackled. The working group has revived a classification scheme, developed jointly in the 1990s, to tag concepts by thematic group. Concepts are being typed as chemical, geographical, organisms, products, or topics. Alongside generic thesaurus relations to broader, narrower, and related concepts, organisms will be related to relevant products.GACS is seen as a first step for Agrisemantics, an emerging community network of semantic assets relevant to agriculture and food security. Within Agrisemantics, the general-purpose, search-oriented concepts of GACS are intended to serve as a hub for concepts defined, with more precision, in a multitude of ontologies modeled for specific domains. Ontologies, in turn, are intended to provide global identity to concepts used in a vast diversity of quantitative datasets, such as sensor readings and crop yields, defined for a multitude of software applications and serialization formats.Such semantic authority control of data elements could support, for example, an analysis of the yield gap in sub-Saharan Africa. A wheat data element, labeled 'GW' in a phenotype dataset, could be mapped to the concept 'grain weight' as defined and globally identified in the CGIAR Crop Ontology. In turn, the Crop Ontology concept could be mapped to the broader concept 'Grain' in GACS. Searches could return not only datasets about grain weight, but references to published papers where the weight of the grain was studied.Agrisemantics aims at improving the discoverability and semantic interoperability of agricultural information and data for the benefit of researchers, policy-makers, and farmers with the ultimate goal of enabling innovative responses to the challenges of food security under conditions of climate change. Achieving these goals will require innovation in processes for the cooperative maintenance of linked semantic assets in the modern Web environment.","","Baker T,Caracciolo C,Doroszenko A,Finch L,Suominen O,Suri S","","2016","14–15","","","Conference Paper"
"The Identification of Mammalian Species through the Classification of Hair Patterns Using Image Pattern Recognition","The identification of mammals through the use of their hair is important in the fields of forensics and ecology. The application of computer pattern recognition techniques to this process provides a means of reducing the subjectivity found in the process, as manual techniques rely on the interpretation of a human expert rather than quantitative measures. The first application of image pattern recognition techniques to the classification of African mammalian species using hair patterns is presented. This application uses a 2D Gabor filter-bank and motivates the use of moments to classify hair scale patterns. Application of a 2D Gabor filter-bank to hair scale processing provides results of 52% accuracy when using a filter-bank of size four and 72% accuracy when using a filter-bank of size eight. These initial results indicate that 2D Gabor filters produce information that may be successfully used to classify hair according to images of its patterns.","","Moyo T,Bangay S,Foster G","","2006","177–181","10.1145/1108590.1108619","https://doi-org.proxy.bnl.lu/10.1145/1108590.1108619;http://dx.doi.org/10.1145/1108590.1108619","Conference Paper"
"The Impact of Facebook and Smart Phone Usage on the Leisure Activities and College Adjustment of Students in Serbia","This study examined the simultaneous impact of Facebook (FB) and smart phone usage (SP) on the leisure activities (LA) and college adjustment (SACQ) of students in Serbia. The moderating effects of gender on the observed relationships were also examined. An exploratory study of students in Serbia (N = 485) revealed that: 1. Students in Serbia spend a daily average of 2.76 h on Facebook, while the average total daily smart phone use is 8:34 h 2. Facebook and smart phone use has no decisive influence on the allocation of time for leisure activities and college adjustment. 3. Facebook and smart phone use still has a certain positive effect on leisure activities, but this influence can become slightly negative if Facebook and smart phones are used too much. 4. In cases of a lack of time, students are more likely to sacrifice academic work, rather than time for Facebook, smart phones, or leisure activities. 5. The moderating effects of students' gender on the observed relationships are weakly expressed. Finally, Facebook and smart phone use has become a common and integral part of life for the majority of Serbian students, and the time for these activities is integrated into their overall time. Presented are the results of the influence of Facebook and smart phone usage.The questionnaires were completed by 485 students.Facebook and smart phone use has no decisive influence o leisure activities.Slightly negative influence if Facebook and smart phones are used too much.Sacrificing academic work, rather than time for Facebook.","","Janković B,Nikolić M,Vukonjanski J,Terek E","","2016","354–363","10.1016/j.chb.2015.09.022","https://doi-org.proxy.bnl.lu/10.1016/j.chb.2015.09.022;http://dx.doi.org/10.1016/j.chb.2015.09.022","Journal Article"
"The Junior High Years: A Time for Beginning Engineering Orientation","The thesis of this paper is that the junior high school years are a key time in the development of orientation towards careers. It is suggested that since women are so grossly underrepresented in the engineering profession, efforts to attack the problem should include work with students at this period in their lives. A team-taught discussion of engineering as an interesting and vital career for women and men, accompanied by a dynamic demonstration of applied scientific principles, has been offered by Georgia Institute of Technology to two school systems in the Metropolitan Atlanta area. Three programs-Lasers and Holograms (Electrical Engineering), Polymer Chemistry (Textile Engineering), and High Temperature and High Temperature Materials (Ceramic Engineering) have been developed by faculty in the respective schools and are described in this paper. Reception has been enthusiastic and the suggestion is made that such programs can act as catalysts to produce longer range programs which can help move us toward parity for women in the engineering profession.","","Burks EL","","1975","15–20","10.1109/TE.1975.4320938","https://doi-org.proxy.bnl.lu/10.1109/TE.1975.4320938;http://dx.doi.org/10.1109/TE.1975.4320938","Journal Article"
"The Narrative and Media Literacy as Influential Factors in the Efficacy of Programs for the Prevention of Teenage Pregnancy","Unwanted pregnancy in Ecuador is a public health problem. Studies have shown that various psychosocial factors affect risky sexual behavior. Lack of information and poor access to sexual and reproductive healthcare service, an early start to sexual activity, impulsivity, and perceived invulnerability, among others. Interesting results have also been found on the effects that persuasive narrative produce through educational and entertainment videos for changes in attitudes and intention of risky behavior in the area of health. And separately media literacy has been studied as a factor in the level of critical skills used by teens, which makes them more critical in the face of media products that try and convince them of something, but what has not been studied is how being media competent affects their mediation of persuasive arguments in the field of communication on healthcare. The objective of this study is to determine if the level of media literacy mitigates the impact of two videos, narrative and non-narrative, how that impacts their attitude, knowledge, and intentional behavior to prevent unwanted pregnancy, and the perceived vulnerability, counter-argumentation will also be considered, transport and identification with characters as variable mitigating factors. Experimental research will be applied to adolescent women. The results are intended to be used to show the efficacy of the messages in pregnancy prevention videos are key to be considered in healthcare campaigns for sexual and reproductive health in adolescents.","","Cabrera CG,Igartua JJ","","2016","1189–1196","10.1145/3012430.3012668","https://doi-org.proxy.bnl.lu/10.1145/3012430.3012668;http://dx.doi.org/10.1145/3012430.3012668","Conference Paper"
"The Network Analysis for AgriTech and FoodTech Start-up and Support Organisations: Twitter Analytic Perspective in Thailand","Over the last decade, entrepreneurial ecosystem research has grown popular among researchers, policymakers, and practitioners. There have been many research attempts to investigate the gap in the entrepreneurial ecosystem between academics and practice. However, there still a lacks of research that provides an understanding of the interconnectedness and networking among entrepreneurial actors or supporting organisations, particularly in developing countries, for example, Thailand. In order to provide valuable opportunities to enhance and understand start-ups and support organisations networking in the entrepreneurial ecosystem, this paper applied social media analysis to demonstrate how social media data can be used to evaluate networks and explore interconnectedness. The research also helps to understand the relationship between AgriTech, FoodTech start-ups and support organisations in the entrepreneurial ecosystem.Using Twints and the Twitter API, data were retrieved from Twitter's databases for start-ups, incubators or accelerators, and other support organisation information within the entrepreneurial ecosystem. The results indicate a lack of interconnections among AgriTech and FoodTech startups and support organisations in Thailand's ecosystem, such as incubators and accelerators. According to an analysis of social media, most start-up aid organisations in Thailand originated from local or national organisations, not global ones. These represent the fragility of Thai start-ups’ support organisations which lack a connection with international opportunities.This research utilised social media analysis as an alternate evaluation approach for assessing the connection or network activity among local entrepreneurial actors. Furthermore, the evaluation findings can be used to identify the weak points in an ecosystem and suggest policies for growing and enhancing a start-up entrepreneurial ecosystem in developing nations such as Thailand.","","Pintoo E,Guo Y,Bal J","","2022","547–555","10.1145/3556089.3556145","https://doi-org.proxy.bnl.lu/10.1145/3556089.3556145;http://dx.doi.org/10.1145/3556089.3556145","Conference Paper"
"The Paper Slip Should Be There! Perceptions of Transaction Receipts in Branchless Banking","Mobile-based branchless banking has become a key mechanism for enabling financial inclusion in the developing world. A key component of all branchless banking systems is a mechanism to provide receipts to users after each transaction as evidence for successful transaction completion. In this paper, we present results from a field study that explores user perceptions of different receipt delivery mechanisms in the context of a branchless banking system in India. Our study shows that users have an affinity for paper receipts: despite the provision of an SMS receipt functionality by the system developers and their discouragement of the use of paper, users have pro-actively initiated a practice of issuing and accepting paper receipts. Several users are aware of the security limitations of paper receipts but continue to use them because of their usability benefits. We conclude with design recommendations for receipt delivery systems in branchless banking.","","Panjwani S,Ghosh M,Kumaraguru P,Singh SV","","2013","328–331","10.1145/2493190.2493236","https://doi-org.proxy.bnl.lu/10.1145/2493190.2493236;http://dx.doi.org/10.1145/2493190.2493236","Conference Paper"
"The Relationship between KM Strategies and IT Applications in SMEs","Little is known about how small and medium sized enterprises (SMEs) utilize their information technology (IT) to support their Knowledge Management (KM) strategy. Some research has been conducted in this field but from a western cultural perspective, and mainly in the large organizations context. Research on the relationships between KM strategy and IT in SMEs in developing countries, such as Saudi Arabia, is limited. The research reported in this paper addressed this relationship. KM strategy, in this research has been classified into two main strategies: aggressive KM strategy and conservative KM strategy, based on the organizations' orientation towards eight dimensions: external knowledge, internal knowledge, tacit knowledge, explicit knowledge, exploration, exploitation, broad knowledge-base and narrow knowledge-base. A total of 143 SMEs, participated in the survey. The results indicate that the proposed classifications of KM strategies were valid, the IT applications can be classified into: Internet-based IT, IT for codification and IT for collaboration, and the association between KM strategy and IT was confirmed.","","Azyabi N,Fisher J,Tanner K,Gao S","","2014","3645–3654","10.1109/HICSS.2014.453","https://doi-org.proxy.bnl.lu/10.1109/HICSS.2014.453;http://dx.doi.org/10.1109/HICSS.2014.453","Conference Paper"
"The Status of Information Security Systems in Banking Sector from Social Engineering Perspective","Social Engineering Attack has recently become a real threat affecting organizations, and 53.9% of such attacks target the banking sector. Successful attacks violate privacy by breaching sensitive data, and can cause huge financial loss for organizations and individuals, alongside reputational damage for firms. Although banks invest extensive resources in cyber security, with large budgets spent on securing their hardware and software, the human factor offers numerous weaknesses that can be easily exploited, and real and pertinent security challenges remain serious threats. This paper presents an information technology governance framework applied on a Jordanian bank to protect the system from social engineering attack. We worked on a case study that mainly focuses on phishing attack, which is considered one of the most common threats in banks, and the way staff will deal with it. The results show positive improvements in staff awareness and in avoiding such types of attacks, as well as a marked increase in reporting any suspicious activity noticed by employees.","","Hammour RA,Gharaibeh YA,Qasaimeh M,Al-Qassas RS","","2019","","10.1145/3368691.3368705","https://doi-org.proxy.bnl.lu/10.1145/3368691.3368705;http://dx.doi.org/10.1145/3368691.3368705","Conference Paper"
"Timely Detection and Mitigation of Stealthy DDoS Attacks Via IoT Networks","Internet of Things (IoT) networks consist of sensors, actuators, mobile and wearable devices that can connect to the Internet. With billions of such devices already in the market which have significant vulnerabilities, there is a dangerous threat to the Internet services and also some cyber-physical systems that are also connected to the Internet. Specifically, due to their existing vulnerabilities IoT devices are susceptible to being compromised and being part of a new type of stealthy Distributed Denial of Service (DDoS) attack, called Mongolian DDoS, which is characterized by its widely distributed nature and small attack size from each source. This article proposes a novel anomaly-based Intrusion Detection System (IDS) that is capable of timely detecting and mitigating this emerging type of DDoS attacks. The proposed IDS’s capability of detecting and mitigating stealthy DDoS attacks with even very low attack size per source is demonstrated through numerical and testbed experiments.","","Doshi K,Yilmaz Y,Uludag S","","2021","2164–2176","10.1109/TDSC.2021.3049942","https://doi-org.proxy.bnl.lu/10.1109/TDSC.2021.3049942;http://dx.doi.org/10.1109/TDSC.2021.3049942","Journal Article"
"Towards Improving Data Validity of Cyber-Physical Systems through Path Redundancy","Cyber-physical systems have shown to be susceptible to cyber-attacks. Incidents such as Stuxnet Attack and Ukraine power outage have shown that attackers are capable of penetrating into industrial control systems, compromising PLCs, and sending false commands to physical devices while reporting normal sensing values. Therefore, one of the critical needs of CPS is to ensure the validity of the sensor values. In this paper, we explore path diversity in SCADA networks and develop Path Redundancy to improve data validity. The proposed solution is shown to be able to effectively prevent data integrity attacks and detect false command attacks from a single compromised path or PLC. We provide detailed analysis on solution design and implement an application of the technique in building automation networks. Our cost-efficient and easy-to-deploy solution improves the resilience of SCADA networks.","","Zheng Z,Reddy AL","","2017","91–102","10.1145/3055186.3055189","https://doi-org.proxy.bnl.lu/10.1145/3055186.3055189;http://dx.doi.org/10.1145/3055186.3055189","Conference Paper"
"Towards a Photogrammetry and Virtual Reality Based Heritage Information System: A Case Study of Shawbak Castle in Jordan","The paper presents an interdisciplinary project which is the first step towards a 3D Geographical Information System (GIS) dedicated to Cultural Heritage with a specific focus application on the Castle of Shawbak, also known as the ""Crac de Montréal"" in Jordan.Current 3D GIS already provide support for urban models on a city scale. Our project however focuses on a building scale encompassing its atomic elements such as ashlars blocks, cement, stratigraphic unit and architectonic elements. At this scale we need a full 3D interface in order to manage accurate measurements and a mainly heterogeneous archaeological documentation.The project is conducted by four laboratories: the MAP-GAMSAU located in the school of Architecture of Marseilles, France in charge of the photogrammetric survey phase; The LSIS laboratory, France, will be in charge of the knowledge based approach; SimVis from The Department of Computer Science, University of Hull, UK, for the virtual reality aspect and of course the ""Dipartimento di Studi storici e Geografici"" from the University of Florence, Italy, in charge of the archaeological part.To manage these archaeological data the project is divided into three phases: The survey phase: using a knowledge based photogrammetric tool, Arpenteur (http://www.arpenteur.net), the photogrammetric campaign ensures a survey founded on archaeological knowledge and directly linked with a database built by archaeologists. The objective here is to link an already existing archaeological database with a photogrammetric tool in order to simplify the photogrammetric process. Our goal here is to offer to the archaeology community a new tool for surveying where technical photogrammetric aspects are more or less hidden from the surveyor. The second phase is the use of the knowledge base to ensure data consistency through a complex and multi-user survey phase. Based on data fusion coming from different sources, this phase will ensure a reversible way to merge several partial surveys exploiting the complementarities between sources, solving different existing conflicts and reducing the possible redundancies. This fusion process deals with archaeological information as well as spatial information. Finally we need a high resolution interface between the final geometry and the archaeological database. Virtual reality using interactive immersive devices and specially designed software tools is an efficient method for revisiting the site and for analysing, updating and revising knowledge.This project described in this paper is work in progress. After three photogrammetric campaigns in Jordan the first results are available on the project web site: http://www.shawbak.net","","Drap P,Durand A,Nedir M,Seinturier J,Papini O,Boucault F,Chapman P,Viant W,Vannini G,Nuccioti M","","2006","67–74","","","Conference Paper"
"Tracing SQL Attacks via Neural Networks","In the paper we present a new approach based on application of neural networks to detect SQL attacks. SQL attacks are those attacks that take the advantage of using SQL statements to be executed. The problem of detection of this class of attacks is transformed into time series prediction problem. SQL queries are used as a source of events in a protected environment. To differentiate between normal SQL queries and those sent by an attacker, we divide SQL statements into tokens and pass them to our detection system, which predicts the next token, taking into account previously seen tokens. In the learning phase tokens are passed to recurrent neural network (RNN) trained by backpropagation through time (BPTT) algorithm. Training data in the output of RNN are shifted by one token forward in time with relation to input. An additional rule is defined to interpret RNNs output. Experiments were conducted on Jordan and Elman networks and the results show that the Jordan network outperforms the Elman network predicting correctly queries with higher efficiency. Moreover, our results lead to the form of the rule, which can be successfuly applied to the subset of SQL statements taken into consideration in this study.","","Skaruz J,Seredynski F,Bouvry P","","2007","549–558","","","Conference Paper"
"Tracking and Disrupting Dark Networks: Challenges of Data Collection and Analysis","The attack on September 11, 2001 set off numerous efforts to counter terrorism and insurgencies. Central to these efforts has been the drive to improve data collection and analysis. Section 1 summarizes some of the more notable improvements among U.S. government agencies as they strive to develop their capabilities. Although progress has been made, daunting challenges remain. Section 2 reviews the basic challenges to data collection and analysis focusing in some depth on the difficulties of data integration. Three general approaches to data integration are identified--discipline-centric, placed-centric and virtual. A summary of the major challenges in data integration confronting field operators in Iraq and Afghanistan illustrates the work that lies ahead. Section 3 shifts gears to focus on the future and introduces the discipline of Visual Analytics--an emerging field dedicated to improving data collection and analysis through the use of computer-mediated visualization techniques and tools. The purpose of Visual Analytics is to maximize human capability to perceive, understand, reason, make judgments and work collaboratively with multidimensional, conflicting, and dynamic data. The paper concludes with two excellent examples of analytic software platforms that have been developed for the intelligence community--Palantir and ORA. They signal the progress made in the field of Visual Analytics to date and illustrate the opportunities that await other IS researchers interested in applying their knowledge and skills to the tracking and disrupting of dark networks.","","Roberts NC","","2011","5–19","10.1007/s10796-010-9271-z","https://doi-org.proxy.bnl.lu/10.1007/s10796-010-9271-z;http://dx.doi.org/10.1007/s10796-010-9271-z","Journal Article"
"Traffic Characterization and Internet Usage in Rural Africa","While Internet connectivity has reached a significant part of the world's population, those living in rural areas of the developing world are still largely disconnected. Recent efforts have provided Internet connectivity to a growing number of remote locations, yet Internet traffic demands cause many of these networks to fail to deliver basic quality of service needed for simple applications. For an in-depth investigation of the problem, we gather and analyze network traces from a rural wireless network in Macha, Zambia. We supplement our analysis with on-site interviews from Macha, Zambia and Dwesa, South Africa, another rural community that hosts a local wireless network. The results reveal that Internet traffic in rural Africa differs significantly from the developed world. We observe dominance of web-based traffic, as opposed to peer-to-peer traffic common in urban areas. Application-wise, online social networks are the most popular, while the majority of bandwidth is consumed by large operating system updates. Our analysis also uncovers numerous network anomalies, such as significant malware traffic. Finally, we find a strong feedback loop between network performance and user behavior. Based on our findings, we conclude with a discussion of new directions in network design that take into account both technical and social factors.","","Johnson DL,Pejovic V,Belding EM,van Stam G","","2011","493–502","10.1145/1963192.1963363","https://doi-org.proxy.bnl.lu/10.1145/1963192.1963363;http://dx.doi.org/10.1145/1963192.1963363","Conference Paper"
"Training with Additional Semantic Constraints for Enhancing Neural Machine Translation","Replacing the traditional cross-entropy loss with BLEU as the optimization objective is a successful application of reinforcement learning (RL) in neural machine translation (NMT). However, a considerable weakness of the approach is that the monotonic optimization of BLEU’s training algorithm ignores the semantic fluency of the translation. One phenomenon is an incomprehensible translation accompanied by an ideal BLEU. In addition, sampling inefficiency as a common shortcoming of RL is more prominent in NMT. In this study, we address these issues in two ways. (1) We use the annealing schedule algorithm to add semantic evaluation for reinforcement training as part of the training objective. (2) We further attach a value iteration network to RL to transform the reward into a decision value, thereby making model training highly targeted and efficient. We use our approach on three representative language machine translation tasks, including low resource Mongolian-Chinese, agglutinative Japanese-English, and common task English-Chinese. Experiments show that our approach achieves significant improvements over the strong baselines, besides, it also saves nearly one-third of training time on different tasks.","","Ji Y,Hou H,Chen J,Wu N","","2019","300–313","10.1007/978-3-030-29908-8_24","https://doi-org.proxy.bnl.lu/10.1007/978-3-030-29908-8_24;http://dx.doi.org/10.1007/978-3-030-29908-8_24","Conference Paper"
"Transfer Learning from Deep Features for Remote Sensing and Poverty Mapping","The lack of reliable data in developing countries is a major obstacle to sustainable development, food security, and disaster relief. Poverty data, for example, is typically scarce, sparse in coverage, and labor-intensive to obtain. Remote sensing data such as high-resolution satellite imagery, on the other hand, is becoming increasingly available and inexpensive. Unfortunately, such data is highly unstructured and currently no techniques exist to automatically extract useful insights to inform policy decisions and help direct humanitarian efforts. We propose a novel machine learning approach to extract large-scale socioeconomic indicators from high-resolution satellite imagery. The main challenge is that training data is very scarce, making it difficult to apply modern techniques such as Convolutional Neural Networks (CNN). We therefore propose a transfer learning approach where nighttime light intensities are used as a data-rich proxy. We train a fully convolutional CNN model to predict nighttime lights from daytime imagery, simultaneously learning features that are useful for poverty prediction. The model learns filters identifying different terrains and man-made structures, including roads, buildings, and farmlands, without any supervision beyond nighttime lights. We demonstrate that these learned features are highly informative for poverty mapping, even approaching the predictive performance of survey data collected in the field.","","Xie M,Jean N,Burke M,Lobell D,Ermon S","","2016","3929–3935","","","Conference Paper"
"Turning the Postal System into a Generic Digital Communication Mechanism","The phenomenon that rural residents and people with low incomes lag behind in Internet access is known as the ""digital divide."" This problem is particularly acute in developing countries, where most of the world's population lives. Bridging this digital divide, especially by attempting to increase the accessibility of broadband connectivity, can be challenging. The improvement of wide-area connectivity is constrained by factors such as how quickly we can dig ditches to bury fibers in the ground; and the cost of furnishing ""last-mile"" wiring can be prohibitively high.In this paper, we explore the use of digital storage media transported by the postal system as a general digital communication mechanism. While some companies have used the postal system to deliver software and movies, none of them has turned the postal system into a truly generic digital communication medium supporting a wide variety of applications. We call such a generic system a Postmanet. Compared to traditional wide-area connectivity options, the Postmanet has several important advantages, including wide global reach, great bandwidth potential and low cost.Manually preparing mobile storage devices for shipment may appear deceptively simple, but with many applications, communicating parties and messages, manual management becomes infeasible, and systems support at several levels becomes necessary. We explore the simultaneous exploitation of the Internet and the Postmanet, so we can combine their latency and bandwidth advantages to enable sophisticated bandwidth-intensive applications.","","Wang RY,Sobti S,Garg N,Ziskind E,Lai J,Krishnamurthy A","","2004","159–166","10.1145/1015467.1015485","https://doi-org.proxy.bnl.lu/10.1145/1015467.1015485;http://dx.doi.org/10.1145/1015467.1015485","Conference Paper"
"Tutorial: Private Information Retrieval","Private information retrieval (PIR) is a cryptographic primitive that facilitates the seemingly impossible task of letting users fetch records from untrusted and remote database servers without revealing to those servers which records are being fetched. The research literature on PIR is vast; in the over two decades since its 1995 introduction by Chor, Goldreich, Kushilevitz, and Sudan, the cryptography, privacy, and theoretical computer science research communities have studied PIR intensively and from a variety of perspectives. Alas, despite a series of significant advances, most privacy practitioners and theoreticians alike fall into one of two camps: (i) those who believe that PIR is so inefficient and abstruse as to make it all-but-useless in practice, and (ii) those who remain blissfully unaware that PIR even exists. Indeed, to date not even one of the numerous PIR-based applications proposed in the research literature has been deployed at scale to protect the privacy of users ""in the wild"". This tutorial targets both of the above camps, presenting a bird's-eye overview of the current state of PIR research. Topics covered will span the spectrum from purely theoretical through imminently applicable and all the high points in between, thereby providing participants with an awareness of what modern PIR techniques have (and do not have) to offer, dispelling the myth of PIR's inherent impracticality, and hopefully inspiring participants to identify practical use cases for PIR within their own niche areas of expertise. This introductory tutorial will be accessible to anyone comfortable with college-level mathematics (basic linear algebra and some elementary probability and number theory).","","Henry R","","2017","2611–2612","10.1145/3133956.3136069","https://doi-org.proxy.bnl.lu/10.1145/3133956.3136069;http://dx.doi.org/10.1145/3133956.3136069","Conference Paper"
"Two Methods for Large-Scale Nonlinear Optimization and Their Comparison on a Case Study of Hydropower Optimization","This paper presents two methods for the optimization of structured large-scale problems: a decomposition method of dual type for nonlinear problems and a sequential quadratic programming based method. Practical details of application of the methods to the case study problem of the hydropower system of an African river are then given. Comparison of results is presented, indicating that both methods are useful and efficient, having however different features from a practical point of view. General remarks concerning the practical differences between a decomposition-based method and a method exploiting the problem structure within the framework of general purpose optimization routines are finally presented.","","Arnold E,Tatjewski P,Wołochowicz P","","1994","221–248","","","Journal Article"
"Txteagle: Mobile Crowdsourcing","We present txteagle, a system that enables people to earn small amounts of money by completing simple tasks on their mobile phone for corporations who pay them in either airtime or MPESA (mobile money). The system is currently being launched in Kenya and Rwanda in collaboration with the mobile phone service providers Safaricom and MTN Rwanda. Tasks include translation, transcription, and surveys. User studies in Nairobi involving high school students, taxi drivers, and local security guards have been completed and the service has recently launched in Kenya nationwide.","","Eagle N","","2009","447–456","10.1007/978-3-642-02767-3_50","https://doi-org.proxy.bnl.lu/10.1007/978-3-642-02767-3_50;http://dx.doi.org/10.1007/978-3-642-02767-3_50","Conference Paper"
"UMS-Dev-Sec: A Proposed Framework to Address Security Concerns of UMS Devices","USB Mass Storage (UMS) devices are affordable, convenient, practical, and have the ability to interface easily with a number of operating systems, and various hardware systems. UMS devices are found among virtually any person in the workplace today. However, UMS devices hold significant security risks, often overlooked. These risks arise mainly due to their compact size, storage capacity or the fact that UMS technology is integrated into Smartphones, cameras, music players, to name most significant. Considering that UMS technology is incorporated into devices that employees need daily to perform their work, such as Smartphones, it is not a feasible option to ban UMS technology from the workplace. However, without a guiding framework, UMS devices pose security risks to both organization and individual users.This paper reports on research conducted at the research institution in South Africa to evaluate the employee's understanding of the security risks to the organization and to them in person. From the results derived from the research conducted, a framework was developed to address the security concerns associated with UMS devices.","","Molotsi K,Tait BL","","2013","72–76","10.1145/2513456.2513487","https://doi-org.proxy.bnl.lu/10.1145/2513456.2513487;http://dx.doi.org/10.1145/2513456.2513487","Conference Paper"
"Under Quantum Computer Attack: Is Rainbow a Replacement of RSA and Elliptic Curves on Hardware?","Among cryptographic systems, multivariate signature is one of the most popular candidates since it has the potential to resist quantum computer attacks. Rainbow belongs to the multivariate signature, which can be viewed as a multilayer unbalanced Oil-Vinegar system. In this paper, we present techniques to exploit Rainbow signature on hardware meeting the requirements of efficient high-performance applications. We propose a general architecture for efficient hardware implementations of Rainbow and enhance our design in three directions. First, we present a fast inversion based on binary trees. Second, we present an efficient multiplication based on compact construction in composite fields. Third, we present a parallel solving system of linear equations based on Gauss-Jordan elimination. Via further other minor optimizations and by integrating the major improvement above, we implement our design in composite fields on standard cell CMOS Application Specific Integrated Circuits (ASICs). The experimental results show that our implementation takes 4.9 us and 242 clock cycles to generate a Rainbow signature with the frequency of 50 MHz. Comparison results show that our design is more efficient than the RSA and ECC implementations.","","Yi H,Khokhar UM","","2018","","10.1155/2018/2369507","https://doi-org.proxy.bnl.lu/10.1155/2018/2369507;http://dx.doi.org/10.1155/2018/2369507","Journal Article"
"Understanding Actors in Complex Security Problems","This article arose while working on the rhino poaching problem in South Africa and having to deal with the large number of stakeholders and complexity. The purpose of actor modelling is to develop a deeper understanding of how stakeholders and threats contribute to the complex security problems. This article is the author's reflection on two different attempts at modelling actors in the rhino problem. A framework is developed and a number of issues are raised with respect to actor modelling: First, values and perspectives are driven by actor needs. The knowledge acquired by actors is determined by perspectives. With a diversity of actors, there is a ""fragmentation of perspective"" that hampers addressing the problem. Thus, dealing with fragmentation of perspective, requires an approach that is inclusive of actors and different ways of knowing. The validity of actor modelling is limited by what can be determined about the values and interests of actors and this varies across actors. Second, actors have multiple identifications with multiple levels of relationality. For high levels of identification combined with low levels of relationality, there is a challenge for a researcher to understand actor behaviour. Third, actors operate in an autonomy-heteronomy space. This is not a continuum, but both autonomy and heteronomy experienced at the same time. When actors are autonomous they live out their values and interests and are most creative. When creativity is applied, there are many ways what of satisfying interests and living out values why, but actors do not behave randomly. Under autonomy, understanding motivation why is more important than what because why is more stable and what cannot be predicted. Actors are dynamic, non-deterministic and non-linear. Fourth, the model represents not only structure but also motivation or purpose and resources; thus, addressing certain aspects of subjective and objective fragmentation. Based on the argument advanced in the paper, the sources of actor complexity leading to novel emerging behaviour in social systems are actor needs and the corresponding values and perspectives, high levels of identification with low levels of relationality and autonomy.","","Gonçalves D","","2018","1–18","10.4018/IJSDS.2018040101","https://doi-org.proxy.bnl.lu/10.4018/IJSDS.2018040101;http://dx.doi.org/10.4018/IJSDS.2018040101","Journal Article"
"Understanding Consumer Intention Towards Blockchain-Based Mobile Payment Adoption Services in Pakistan","The paper reflects the application of a positivist study and quantitative methods for evaluation of variable relationships. The researcher developed a survey-based methodology and disseminated the questionnaire to consumers of Pakistan through online. Structural equation modeling, confirmatory factor analysis and all supporting statistical tests have been applied on the data in order to evaluate the accuracy;the findings suggest that the usability and factors like the security of online services influence the consumers. Moreover, the performance and effectiveness of these measures influence the decision to use and recommend the services to others as well. The study contributed to the literature by validating and supporting the applicability, usage and development of mobile payment services and produces important implications for the managerial and policymakers of these industries.","","Ali Z,Bano H","","2022","1–21","10.4018/IJeC.307136","https://doi-org.proxy.bnl.lu/10.4018/IJeC.307136;http://dx.doi.org/10.4018/IJeC.307136","Journal Article"
"Understanding Gender Bias: Differences in Tech Stereotypes According to the Socio-Economic Background of Girls","Of all the countries that belong to OCDE, the Latin American countries have the highest levels of inequality. Chile is among them, with scores similar to Bolivia and Guatemala [10]. Also, the number of women living in poverty is higher than that of men [4]. Women’s economic context is essential for their families, as 90% of single-parent families are supported by women [12]. One way of achieving economic development may be choosing a career in technology, as tech jobs are among the highest-paid in the country [9]. Also, they are flexible, allowing women to balance work and family, and have been proven to promote social mobility and country economic growth [2, 7]. However, there is a well-known gender gap in technology; for example, only 24% of computer science students are women in Chile [9]. To inspire women to have a computer science career, interventions should be undertaken while they are girls, by addressing stereotypes that influence their attitude towards technology [6]. These stereotypes are influenced by the context in which girls grow [5]; in particular their socio-economic context [3]. Therefore, it may be essential to understand the context of girls, and their thoughts towards tech stereotypes, to create better computer science education interventions. We conducted a preliminary interview study with sixth grade girls, since at this age, stereotypes can still be challenged [1, 11], while the opportunities to challenge stereotypes decrease from the eighth grade on [8]. The research question of this study is whether there are different stereotypes regarding technology among girls with different socio-economical levels. It has been hypothesized that there will be different stereotypes among these girls. Twelve interviews were done: 6 with girls from low vulnerability contexts, and 6 with girls from high vulnerability contexts. The interview data were transcribed and analyzed using grounded theory under Charmaz’s perspective. The results from this preliminary study were that girls from a high vulnerability context have a negative attitude towards technology mainly because of misconceptions regarding technology, e.g. what it does and how to work with it. On the other hand, girls from low vulnerability contexts have stereotypes in which tech careers were considered to be manly, and they also had concerns about family-work balance. With this information, a semi-structured interview has been developed to apply to girls from low and high vulnerability contexts and analyzed with ground theory. Further, with this qualitative information, a quantitative tool will be developed. A national survey will be created to determine if these different stereotypes are also present in the larger population of girls. With this information, better computer science education interventions may be created, especially focused on high vulnerability contexts, considering the particular stereotypes that these girls have regarding tech stereotypes, that keep them away from computer science careers.","","Vergara K,Herskovic V,Guerrero P","","2022","55–56","10.1145/3501709.3544289","https://doi-org.proxy.bnl.lu/10.1145/3501709.3544289;http://dx.doi.org/10.1145/3501709.3544289","Conference Paper"
"Understanding Individuals' Perceptions, Determinants and the Moderating Effects of Age and Gender on the Adoption of Mobile Learning: Developing Country Perspective","In recent years, mobile devices, applications and services have largely spread over the globe and have become a popular commodity. This study is launched to investigate the factors that influence individuals' intention to adopt and use of mobile learning (m-learning) in Jordan. Besides, it provides quantified indicators, designs principles, opportunities, limitations and a conceptual model that might help in understanding m-learning phenomenon in the Jordanian educational environment. The current study is based on a modified Technology Acceptance Model (TAM) by incorporating social influence, security and privacy, price value and service quality factors as external variables. This study examines also the moderating effects of age and gender differences among the study variables. The suggested model was tested with data collected by means of a paper-based questionnaire by using WarpPLS 4.0 software. The results reveal that individuals' adoption and the use of m-learning can be anticipated from individuals' behavioural intention with 39% in variance.","","Jaradat MI","","2014","253–275","10.1504/IJMLO.2014.067028","https://doi-org.proxy.bnl.lu/10.1504/IJMLO.2014.067028;http://dx.doi.org/10.1504/IJMLO.2014.067028","Journal Article"
"Understanding Online Shopping Adoption in India: Unified Theory of Acceptance and Use of Technology 2 UTAUT2 With Perceived Risk Application","The purpose of this research is to analyze perceived risk and drivers of online shopping influencing behavioral intention in India. The study empirically validates website design, cash-on-delivery COD mode of payment, and different facets of perceived risk with the unified theory of acceptance and use of technology2 UTAUT2 of Venkatesh et al. [Venkatesh V, Thong JYL, Xu X 2012 Consumer acceptance and use of information technology: Extending the unified theory of acceptance and use of technology. MIS Quart. 361:157-178]. Findings of the study revealed that perceived risk had a negative relation with behavioral intention, whereas the drivers were positively associated with behavioral intention. Besides analyzing cash-on-delivery mode of payment as a construct, it also includes website design to enhance application of UTUAT2 in Indian and other similar developing countries' context. The study will help online retailers to focus in the right direction by eliminating threats and convert nonshoppers to online shoppers.","","Tandon U,Kiran R,Sah AN","","2016","420–437","10.1287/serv.2016.0154","https://doi-org.proxy.bnl.lu/10.1287/serv.2016.0154;http://dx.doi.org/10.1287/serv.2016.0154","Journal Article"
"Understanding Strategies for Implementing Integrated Information Systems for Rabies Surveillance","Rabies continues to be one of the most perilous viral diseases that affect the nervous system and remains a significant threat to public health across the globe. Available data that show that rabies claims about 59,000 human lives annually. Most industrialized countries have eliminated rabies from domestic dog populations. Conversely, in most of the developing countries, rabies remains endemic in domestic dog populations and poorly controlled. One of the challenges in eradicating rabies in developing countries is attributed to ineffective surveillance systems. Different stakeholders have developed solutions to address this problem without tangible outcomes. Estimation of the economic burden particularly in developing countries is difficult because of the inadequacy of update and reliable surveillance data. Certainly, it is very challenging even to obtain basic information on how many human lives are lost due to rabies and the economics behind preventing the disease amongst those exposed. Up-to-date, official reporting of incidence data on rabies and rabies exposures status remains desperately poor in most canine rabies-endemic countries. Consequently, there is increasingly underestimation of the true burden of the diseases. Worse still data from active surveillance studies highlight the disparities between officially reported and recorded and likely occurring rabies deaths. In some cases, it has been shown that there are higher mortality rates than officially reported data, especially in resource deprived areas. This calls for a need to establish an integrated surveillance system, which allows data to be shared openly among different stakeholders dealing with rabies. The paper presents the state of art of rabies in Tanzania and evaluates the application of ICT in surveillance. It also advocates for a need of a comprehensive approach to addressing the problem. Development and adoption of integrated surveillance systems for rabies and other zoonotic diseases remain a nightmare in many developing countries including Tanzania. This paper calls for the development of an integrated standard mechanism for countries to assess their rabies status and measure progress in eliminating the disease. Such a system will fill the missing link between surveillance and control measures.","","Geofrey A,Kipanyula MJ,Fue K,Sanga C","","2017","13–26","10.4018/IJUDH.2017010102","https://doi-org.proxy.bnl.lu/10.4018/IJUDH.2017010102;http://dx.doi.org/10.4018/IJUDH.2017010102","Journal Article"
"Understanding the Acceptance of Mobile University Services: An Empirical Analysis","The use of mobile technologies is increasingly widespread because of the need of mobility. This study aims to explore the utilisation of mobile phone services in the educational environment and investigate students' expectations and attitudes towards mobile university services in Jordan. Data for this study have been collected using a questionnaire containing 34 questions. Out of the 400 questionnaires that were distributed randomly to students at Al-Hussein Bin Talal University in Jordan, 370 were returned (92.5%). As a result of this study it appears that if students have positive attitude towards mobile university, they will use it. This study found that a large majority of the students indicated their willingness to become users of such services if offered; taking into consideration security and privacy, and social influences as factors that could affect the success of using mobile university in Jordan. This study gives quantified indicators about mobile university and a model that might help in understanding the mobile university environment in Jordan.","","Jaradat MI","","2010","407–427","10.1504/IJMLO.2010.037537","https://doi-org.proxy.bnl.lu/10.1504/IJMLO.2010.037537;http://dx.doi.org/10.1504/IJMLO.2010.037537","Journal Article"
"Unsecured Economies Panel: Symposium Summary","A panel summary by Kripa Shankar.Panel Members:•Karthik Kannan, Krannert School of Management, Purdue University•Jackie Rees, Krannert School of Management, Purdue University•Dmitri Alperovitch, McAfee•Paul Doyle, ProofSpace•Kevin Morgan, Arxan TechnologiesAdding a new dimension to the CERIAS 10th Annual Security Symposium, five of the panelists with varied background came together on the final day to share their work and experiences on ""Unsecured Economies: Protecting Vital IP"".Setting the platform for this discussion was this report (http://resources.mcafee.com/content/NAUnsecuredEconomiesReport). ""Together with McAfee, an international team of data protection and intellectual property experts undertook extensive research and surveyed more than 1,000 senior IT decision makers in the US, UK, Japan, China, India, Brazil and the Middle East regarding how they currently protect their companies digital data assets and intellectual property. A distributed network of unsecured economies has emerged with the globalization of many organizations, leaving informational assets even more at risk to theft and misuse. This report investigates the cybercrime risks in various global economies, and the need for organizations to take a more holistic approach to vulnerability management and risk mitigation in this ever-evolving global business climate.""Karthik Kannan, Assistant Professor of Management Information Systems, CERIAS, Krannert School of Management, Purdue University was the first to start the proceedings. He gave a brief overview of the above report, which was the product of the collaborative research done by him, Dr. Jackie Rees and Prof. Eugene Spafford as well. The motivation behind this work, was that more and more information was becoming digital and traditional geographic boundaries were blurring. Information was being outsourced to faraway lands and as a result protecting leaks was becoming harder and harder. Kannan, put forth questions like: ""How do perceptions and practices vary across economies and cultures?"", and sighted an example from India where salary was not personal information, and was shared and discussed informally. To get answers for more such questions, a survey was devised. This survey was targeted at senior IT decision makers, Chief Information Officers and directors of various firms across the globe. US, UK, Germany, Brazil, China and India were among the countries chosen, giving the survey the cultural diversity element that it needed. Adding more value to the survey was the variety of sectors: Defense, Retail, Product Development, Manufacturing and Financial Services. According to results of the survey, a majority of the intellectual property (47%) originates from North America and Western Europe, and on an average firms lost $4.6 million worth of IP last year. Kannan went on to explain how security was being perceived in developing countries, and also discussed how respondents reacted to security investment during the downturn. Statistics like: 42% of the respondents saying laid-off employees are the biggest threat caused by the economic downturn, showed that insider threats were on the rise. The study put forth many case studies to show that data thefts from insiders tend to have greater financial impact given the high level of data access, and an even greater financial risk to corporations.Jackie Rees, also an Assistant Professor of Management Information Systems, CERIAS, Krannert School of Management, Purdue University took it up from where Kannan had left and brought to light some of the stories that did not go into the report. Rees explained the reasons behind the various sectors storing information outside the home country. While Finance sector viewed it as being safer to store data elsewhere; the IT , Product Development and Manufacturing sectors found it to be more efficient for the supply chain; and the Retail and Defense sector felt better expertise was available elsewhere. Looking at the perspective on the amount that these sectors were spending on security, 67% of the Finance industry said it was ""just right"", while ""30%"" of Retail felt it was ""too little"". The other results seemed varied but consistent with our intuitions, however all sectors seemed to agree that the major threat to deal with was ""its own employees"". The worst impact of a breach was on the reputation of the organization. Moving on to the global scene where geopolitical perceptions have become a reality in information security policies, Rees shared that certain countries are emerging as clear sources of threats to sensitive data. She added that Pakistan is seen as big threat by most industries according to respondents while China and Russia are in the mix. Poor law enforcement, corruption and lack of cooperation in these economies were sighted as a few reasons for them to emerge as threats.Dmitri Alperovitch, Vice President of Threat Research, McAfee Corporation began by expressing his concern over the fact that Cybercrime is one of the headwinds hitting our economy. He pointed out that the economic downturn has resulted in less spending on security, and as a result increased vulnerabilities and laid of employees were now the serious threats. Elucidating, he added that most of the vulnerabilities are used by insiders who not only know what is valuable, but also know how to get it. Looking back at the days when a worm such as Melissa that was named after the attacker's favorite stripper seems to be having a much lesser malicious intent that those of today, where virtually all threats now are financially motivated and more to do with money laundering. Sighting examples, Alperovitch told us stories of an organization in Turkey that was recently caught for credit and identity theft, of members of law enforcement being kidnapped, and of how Al-Qaeda and other terrorist groups were using such tools to finance terrorist groups and activities. Alperovitch vehemently stressed on the problem that this threat model was not understood by the industry and hence the industry is not well protected.Paul Doyle, Founder Chairman & CEO, Proofspace began by thanking CERIAS and congratulating the researchers at McAfee for their contributions. Adding a new perspective of thinking to the discussion, Doyle proposed that there has not been enough control over the data. Data moves over supply chain, but ""Control"" does not move. Referring to yesterday's discussion on cloud computing, where it was pointed out that availability is a freebie, Doyle said the big challenge here was that of handling integrity of data. Stressing on the point he added that integrity of data is the least common divisor, and that it was the least understood area in security as well. How do we understand when a change has occurred? In the legal industry, we have a threat factor in the form of a cross-examining attorney. What gives us certainty in other industries? We have not architected our systems to handle the legal threat vector. Systems lack the controls and audit ability needed for provenance and ensured integrity. Trust Anchor of Time has to be explored. ""How do we establish the trust anchor of time and how confidentiality tools can help in increasing reliabilities?"" are important areas to work on.Kevin Morgan, Vice President of Engineering, Arxan Technologies began with an insight on how crime evolves in perfect synchrony with the socio-economic system. Every single business record is accessible in the world of global networking, and access enables crime. Sealing enterprise perimeters has failed, as there is no perimeter any more. Thousands and thousands of nodes execute business activity, and most of the nodes (like laptops and smart phones) are mobile, which in turn means that data is mobile and perimeter-less. Boundary protection is not the answer. We have to assume that criminals have access to enterprise data and applications. Assets, data and applications must be intrinsically secure and the keys protecting them must be secure too. Technology can help a great deal in increasing the bar for criminals and the recent trends are really encouraging.After the highly informative presentations, the panel opened up for questions for the next hour. A glimpse of the session can be found in the transcript of the Q&A session below.Q&A Session: A transcript snapshotQ: We are in the Mid-West, no one is going to come after us. What should I as a security manager consider doing? How do you change the perception that organizations in ""remote"" locations are also subject to attack?•Alperovitch: You are cyber and if you have valuable information you will be targeted. Data manipulation is what one has to worry about the most.•Morgan: Form Red teams, perform penetration tests and share the results with the company.•Doyle: Employ allies and make sure you are litigation ready. Build a ROI model and lower total cost of litigation.Q: CEOs consider cutting costs. They cut bodies. One of the biggest threats to security is letting the people go. It's a paradox. How do we handle this?•Kannan: We have not been able to put a dollar value to loss of information. Lawrence Livermore National Lab has a paper on this issue which might be of interest to you.•Rees: Try to turn it into a way where you can manage information better by adding more controls.Q: How do we stress our stand on why compliance is important?•Doyle: One of our flaws as a professional committee is that we are bad in formulating business cases. We have to take a leaf out of Kevin's (of Cisco) books who formulates security challenges into business proposals. Quoting an analogy, at the end of the day it is the brakes and suspensions are the ones that decide the maximum speed of the automobile, not the engine or the aerodynamics. The question is: How fast we can go safely? Hence compliance becomes important.Q: Where do we go from here to find out how data is actually being protected?•Kannan: Economics and behavioral issues are more important for information security. We need to define these into information security models.•Rees: Governance structure of information must also be studied.•Alperovitch: The study has put forth those who may be impacted by the economy. We need to expose them to the problem. Besides we also need to help law enforcement get information from the private sector as the laws are not in place. We also need to figure out a way to motivate companies to share security information and threats with the community.•Doyle: Stop thinking about security and start thinking about risk and risk management. Model return-reward proposition in terms of risk.•Morgan: We need to step up as both developers and consumers.Q: The $4.6 million estimate. How was it estimated?•Rees: We did a rolling average across the respondents, keeping in mind the assumption that people underestimate problems.Q: Was IP integral to the business model of a company that there was a total loss causing the company to go bust?•Rees: We did not come across any direct examples of firms that tanked and fell because of IP loss.Q: Could you suggest new processes to enforce security of data?•Doyle: We need to find ways from the other side. If we cannot stop them, how do we restrict and penalize them using the law?Q: Infrastructure in Purdue and US has been there for long and we have adapted and evolved to newer technologies. However other old organization and developing countries are still backward, and it actually seems to be helping them, as they need to be less bothered with the new-age threats. What's your take on that?•Kannan: True. We spoke to the CISO of a company in India. His issues were much less as it was a company with legacy systems.•Alperovitch: There is a paradigm shift in the industry. Security is now becoming a business enabler.","","Shankar K","","2009","","","","Conference Paper"
"Urben Research in Ethnic, Demographic and Household-Economic Structures with Small Area, Micro-Databases (Abstract Only)","Computerized U.S. Census data has been most widely used for (1) employment, fertility, demographic and stratification research involving Public Use Sample (PUS) microdata on the national level, and (2) applied research (for planning, administration, marketing, and other applications) with summary (aggregated) data for localized (i.e., block, tract, community, etc.) geographic units. A third, highly productive avenue of research, involving Census PUS micro-data for localized urban units (i.e., SMSAs, counties and especially selected large-city neighborhoods), has not received the attention it merits, either among sophisticated public data users or among novice users.Three forms of current or future small area, Census microdata constitute resources for urban research. First, conventional 1970 Census PUS data sets are available for counties and/or SMSAs (with minimum populations of 250,000). Second, special tabulations for the two largest U.S. cities permit analysis of 1970 household and person records group by (sub-county) urban neighborhoods (27 in New York City; 12 in Chicago). Third, 1980 Census microdata, by allowing identification of geographic areas of smaller population size (100,000 population), will vastly expand the applications of localized research with the conventional PUS or special tabulations. In addition, the 1980 PUS microdata will, for the first time, allow comparative time-series analyses of county (or SMSA) area populations, over the 1970-1980 decade.In contrast to national PUS microdata research, local level analyses have the advantages of (1) smaller data set size and processing costs, (2) more immediate integration of computerized research hypotheses with additional sources of (qualitative) information and questions (stemming from direct knowledge of the communities studied), and (3) increased ability to zero in on specialized ethnic, occupational-industrial, migrant, age, etc. urban population groups which are disproportionately represented in particular local environments. Our own research projects (at various stages of development) which attempt to exploit these advantages include computerized analysis of:1. Patterns of household composition, and source and structure of family income, among Upper East Side and Upper West Side Manhattan residents with family incomes of $ 50,000. or more (as reported in the 1970 Census)2. Employment patterns of married women of Cuban immigrant background, in relation to family class position and period of immigration, for Hudson County, New Jersey3. Contrasts in the occupational positions and household patterns of first-generation and second-generation husbands and wives of Italian background in a New York City working class community (Astoria-Long Island City, Queens)4. Wives' employment patterns in relation to ethnic background and husbands' occupations and income levels in a working class community located in a manufacturing center (South Side, Chicago)5. Change in the social and demographic characteristics of succeeding groups of migrants to an expanding ""sunbelt"" metropolitan area (Albuquerque, New Mexico)6. Contrasts in local housing markets and housing availability, involving analysis of the number and characteristics of vacant housing units for New Jersey counties.These, as well as other projects we have assisted, have been undertaken with varied software resources, including packages (such as CENTS-AID) with unique hierarchical file processing capabilities, as well as more versatile (non-hierarchical), general purpose packages (such as SPSS). The advantages and research applications of small area, micro-databases can be realized with a range of software techniques and user-formulated research strategies.","","Benenson H,Just S","","1981","62","10.1145/800275.810943","https://doi-org.proxy.bnl.lu/10.1145/800275.810943;http://dx.doi.org/10.1145/800275.810943","Conference Paper"
"User Awareness and Tolerance of Privacy Abuse on Mobile Internet","User awareness regarding privacy abuse.Mobile market development.Influential factors on user awareness regarding internet content blocking.Relationship between country level development and the user tolerance regarding privacy abuse. The paper presents the results of an exploratory study about the level of privacy abuse and the awareness level of users when communicating and using mobile Internet. The study looks into the relationships and associations between the telecommunications market developmental level, the wealth of a country, users' skills, the affordability of mobile technologies, the level of user tolerance of state-mandated content censorship, and related privacy threats. The results and findings are drawn from a collection of data gathered from ten countries which have a low reputation for respecting human rights. These countries are primarily Asian or African states. Differences within the user community tolerance levels are discussed from the perspective of the key parameters which define the level of development of the information society and also the user skill levels. For a better understanding of the issue, a brief introduction explains the capacity of smartphones to ensure user privacy, and availability of the circumvention tools for smartphones.","","Callanan C,Jerman-Blažič B,Blažič AJ","","2016","109–128","10.1016/j.tele.2015.04.009","https://doi-org.proxy.bnl.lu/10.1016/j.tele.2015.04.009;http://dx.doi.org/10.1016/j.tele.2015.04.009","Journal Article"
"Uses of Mobile Phones in Post-Conflict Liberia","Liberia is a country emerging from years of protracted and devastating civil conflict. Left without any fixed line telephone infrastructure, it relies solely on the mobile phone for telephony. This study investigates the usage of mobile phones in this immediate post-conflict setting. In particular, we adopt the uses and gratifications approach to media research, giving focus to both instrumental and intrinsic motivations for use. Mobile phone users in both the capital city of Monrovia and in various rural areas were surveyed using the Q methodology, which identified distinct perspectives within these urban and rural groups. Participants were then sorted into groups where each group contained users with similar perspectives on their mobile phones. These identified groups included sets of users who saw their phones as productivity enhancers, means of connectivity to family and friends, essential business tools, technological curiosities, and sources of personal security. The idea of a phone as a stylish object was markedly rejected, especially in rural areas. We contrast these Q-sort results from Liberia with previous work from Kigali, Rwanda, finding differences especially as related to security.","","Best ML,Wornyo E,Smyth TN,Etherton J","","2009","468–477","","","Conference Paper"
"Using Information Technology for an Improved Pharmaceutical Care Delivery in Developing Countries. Study Case: Benin","One of the problems in health care in developing countries is the bad accessibility of medicine in pharmacies for patients. Since this is mainly due to a lack of organization and information, it should be possible to improve the situation by introducing information and communication technology. However, for several reasons, standard solutions are not applicable here. In this paper, we describe a case study in Benin, a West African developing country. We identify the problem and the existing obstacles for applying standard ECommerce solutions. We develop an adapted system approach and describe a practical test which has shown that the approach has the potential of actually improving the pharmaceutical care delivery. Finally, we consider the security aspects of the system and propose an organizational solution for some specific security problems.","","Edoh TO,Teege G","","2011","1123–1134","10.1007/s10916-011-9717-y","https://doi-org.proxy.bnl.lu/10.1007/s10916-011-9717-y;http://dx.doi.org/10.1007/s10916-011-9717-y","Journal Article"
"Using Mobile Phones for Secure, Distributed Document Processing in the Developing World","Although paper plays an essential role in many information ecologies in the developing world, paper-based record keeping can be inefficient and inflexible. The CAM document-processing framework, so called because the phoneýs built-in digital camera plays a key role in the user interface, exploits smart mobile phonesý utility, usability, and growing ubiquity to link paper with modern information tools. The CAM interface consists of CamForm augmented documents, which users interact with; the CamBrowser mobile phone application, which interprets these documents; and the CamShell scripting language, which ties the two together. CAM is a cost effective and accessible way of providing information services to remote rural areas.","","Parikh TS","","2005","74–81","10.1109/MPRV.2005.43","https://doi-org.proxy.bnl.lu/10.1109/MPRV.2005.43;http://dx.doi.org/10.1109/MPRV.2005.43","Journal Article"
"Using Smart Cards and X.509 Digital Certificates for a Student Management Information System at the University of Prishtina","In this paper is presented a novel software solution for the implemention of a Student Management Information System at the University of Prishtina. The novelty of implemented solution is based on extending the subject name in X.509 digital certificates and using this certificate for securing student grades. The issued X.509 digital certificate is used to digitally sign the student grades, which is in full compliance with the Kosovo Law on Information Society. For security reasons, the certificate and its associated private are stored in a smart card. The access to private key is protected by a personal identification number. The protection of the student grades against misuse was a ""must have"" feature of the software solution for the management of the university. This implementation was installed at the Faculty of Electrical and Computer Engineering and has successfully passed a six semester testing period. Beyond increasing the security of the systems, students were, for the first time in the history of the University of Prishtina, able to apply online to take an exam.","","Rexha B,Lajqi H,Limani M","","2010","29–33","","","Conference Paper"
"Validation of Land Surface Temperature Derived from MSG/SEVIRI with in Situ Measurements at Gobabeb, Namibia","Land surface temperature LST derived from Meteosat Second Generation/ Spinning-Enhanced Visible and Infrared Imager MSG/SEVIRI data is an operational product of the Land Surface Analysis Satellite Applications Facility LSA SAF. The LST has a temporal resolution of 15 minutes, a sampling distance of 3 km at nadir, and a targeted accuracy of better than 2 K. Gobabeb Namibia is one of Karlsruhe Institute of Technology's KIT's four dedicated stations for LST validation. In March 2010, a field survey was performed to characterize the Gobabeb site more closely. SAF LST and in situ LST obtained over a period of 3 days from additional measurements with a telescopic mast on the Namib gravel plains were in good agreement with each other bias 1.0 K. For the same period, the bias between SAF LST and Gobabeb main station LST was even smaller 0.4 K. A mobile measurement system was set up by fixing the telescopic mast to a four-wheel drive. Around solar noon, LST from in situ measurements along a 40 km track and LST from Gobabeb main station had a bias of 0.4 K and a standard deviation of 1.2 K, which means that in situ LSTs at Gobabeb main station are representative for large parts of the gravel plains. Exploiting this relationship, 2 years of LST from MSG/SEVIRI were compared with in situ LST from Gobabeb main station. The magnitude of the monthly biases between the two data sets was generally less than 1.0 K and root mean square errors were below 1.5 K. Furthermore, the bias appears to exhibit a seasonality, which could be accounted for in future validation work.","","Göttsche FM,Olesen FS,Bork-Unkelbach A","","2013","3069–3083","10.1080/01431161.2012.716539","https://doi-org.proxy.bnl.lu/10.1080/01431161.2012.716539;http://dx.doi.org/10.1080/01431161.2012.716539","Journal Article"
"Voice Recognition Package for ERTU's Cloud","This paper discusses the application of voice recognition for Egyptian Radio and Television Union's cloud. It is used as secure access to the cloud by authorized group (AuthGs). The voice of each member from AuthGs is watermarked using singular value decomposition and then encrypted by Chaotic map. The results are transmitted through channel under several conditions and received at the receiver side, and then the recognition rate is calculated for various extraction of watermarking after decryption method. It is done to find out the suitable technique for AuthGs to access the cloud and insure the security and privacy of the cloud. Many tests are performed to compare between the voice before and after process to grantee the high robustness of the signal from illegal eavesdrops or any abuse behaviour. The feature extraction is performed using artificial neural network to store it in a database to compare with.","","Serag Eldin SM","","2017","51–67","10.1007/s10772-016-9387-8","https://doi-org.proxy.bnl.lu/10.1007/s10772-016-9387-8;http://dx.doi.org/10.1007/s10772-016-9387-8","Journal Article"
"Website Usability Analysis of Non Profit Organizations: A Case Study of Pakistan","Nonprofit organizations are an important pillar of any society, which specifically serve under privileged sections of society. Modern Information and communication technologies have huge potential to benefit the working processes of such organizations but deploying software application in such settings is quite challenging. These challenges emerge due to shortage of skilled employees, limited funds and weak organizational structures. In order to further understand the technological implications in such settings this paper explores the websites of different nonprofit organizations of Pakistan to understand usability problems. In order to gather empirical data, it prepared questionnaire mainly focusing on Jakob Nielson's heuristics. These questionnaires were distributed to final year undergraduate students taking a Human Computer Interaction module. The findings highlight serious usability issues in these websites. These findings are helpful for the nonprofit organizations to improve these websites for better information access.","","Saeed S,Shabbir S","","2014","70–83","10.4018/ijpada.2014100105","https://doi-org.proxy.bnl.lu/10.4018/ijpada.2014100105;http://dx.doi.org/10.4018/ijpada.2014100105","Journal Article"
"What Improves Citizens' Privacy Perceptions toward RFID Technology? A Cross-Country Investigation Using Mixed Method Approach","Empirically, we compared RFID-related privacy measures in Australia and Bangladesh.We explore the privacy concerns and solutions from citizens' perspective.Basic privacy-perceptions among users from different cultures are not contradictory.We developed six contributing factors that may enhance citizens' privacy in RFID-use. Privacy is a serious concern to radio frequency identification (RFID) technology. Worldwide, several companies scrapped RFID projects because of high resistance from consumers and their advocacy groups - which actually demand RFID-specific privacy policies. This concern is even more acute when RFID is used in public applications; because, in general case, citizens cannot refuse to provide data, and the data collected by a government agency would offer serious threats if are shared among third parties. Limited research has been performed in this specific issue; they all agree that perceived privacy increased RFID acceptance. But, what drives privacy perceptions are yet to be researched - this study closes this research gap. In order to conduct the current research, mixed method of research approach has been adopted. In the qualitative research stage, the authors conducted two focused-group discussion sessions and eight in-depth interviews in two different countries: Australia and Bangladesh; arguing that the status, and the perceptions and tolerance of the citizens on privacy are different in these two regions. The explored factors have been examined with empirical data obtained from these two countries. It is found that, there are distinct differences in perceptions in developed and developing countries. The detail findings offer practical suggestions to the agency managers so that they can ensure better privacy of the citizens. As a significant theoretical contribution, this study enhances existing literature identifying the antecedents of privacy, which play even different roles in different cultural backgrounds.","","","","2014","711–719","10.1016/j.ijinfomgt.2014.07.002","https://doi-org.proxy.bnl.lu/10.1016/j.ijinfomgt.2014.07.002;http://dx.doi.org/10.1016/j.ijinfomgt.2014.07.002","Journal Article"
"When the Playing Fields Aren't Even: Personalised Attention in the Multilingual, Varied-Ability Classroom","This paper describes an English-language application developed within an educational system undergoing radical change. Since the mid-1990s, South African education has moved from a dual system favouring one privileged class, to one that embraces integration and equality. This move has been complex and fraught with the difficulties inherent in incorporating disadvantaged pupils from multilingual backgrounds into previously-advantaged' classrooms with English as principle medium of tuition. In order to cope with widely-varying student needs, an interactive computer-based application has been created to enable students to diagnose their own specific weaknesses and to provide personalised assistance in overcoming them. Results demonstrate that the system is highly effective in improving students' performance, establishing a closer sense of personal attention, and in alleviating the pedagogical stressesexperienced by instructors in an extremely demanding educational environment.","","Jacobs G,Meyer D","","2002","1346","","","Conference Paper"
"Why Do People Seek Anonymity on the Internet? Informing Policy and Design","In this research we set out to discover why and how people seek anonymity in their online interactions. Our goal is to inform policy and the design of future Internet architecture and applications. We interviewed 44 people from America, Asia, Europe, and Africa who had sought anonymity and asked them about their experiences. A key finding of our research is the very large variation in interviewees' past experiences and life situations leading them to seek anonymity, and how they tried to achieve it. Our results suggest implications for the design of online communities, challenges for policy, and ways to improve anonymity tools and educate users about the different routes and threats to anonymity on the Internet.","","Kang R,Brown S,Kiesler S","","2013","2657–2666","10.1145/2470654.2481368","https://doi-org.proxy.bnl.lu/10.1145/2470654.2481368;http://dx.doi.org/10.1145/2470654.2481368","Conference Paper"
"Wireless Communication as a Reshaping Tool for Internet of Things (IoT) and Internet of Underwater Things (IoUT) Business in Pakistan: A Technical and Financial Review","Pakistan is one of the growing nations, specifically in the field of Information and Communication Technology (ICT). During the last decade, an intense rise in the adaptation of ICT has been observed in all the major cities of Pakistan. This includes, but not limited to, e-commerce, mobile technology, computer communication networks, embedded systems, software engineering, etc. Due to the resource constraints, Pakistan is not the producer of any technology; however, it is a potential consumer of numerous technologies and their products. It therefore, attracts most of the producers around the globe to invest in the technology business in Pakistan. According to the Board of Investment (BOI) Pakistan, the country has received more than US$5.7 billion during the last decade as the foreign investment in IT and Telecommunication sectors only. Moreover, it has more than 140 million cellular subscribers, around 45 million 3G/4G subscribers, more than 3 million fixed local line subscribers and approximately 48 million broadband subscribers [1]. Likewise, Pakistan is also one of the biggest buyers of Consumer Electronics (CE). Very few of the local companies are producing CE products, however, a major share of the CE market has been captured by the international brands of China, Japan, Korea, USA, Germany, etc. In the light of the facts, it can be inferred that the application of ICT such as the Internet of Things (IoT) and Internet of Underwater Things (IoUT) in consumer electronics has the strong potential in shaping a new dimension of CE business in Pakistan. Moreover, the recent literature has strongly advocated for the scope of 5G IoT/IoUT. This is due to the fact that existing communication infrastructure will not be sufficient to handle modern day IoT/IoUT need. In this article, a comprehensive study on the scope of IoT/IoUT enabled consumer electronics business is presented. In addition, the rationale of 5G IoT/IoUT integration in the developing countries like Pakistan is discussed. Moreover, the threats and opportunities in the business of IoT/IoUT enabled CE devices are also been presented. Finally, this study submits the recommendations to establish IoT/IoUT enabled CE business in Pakistan.","","Rizvi SS,Zubair M,Ahmad J,Hashmani M,Khan MW","","2021","1087–1105","10.1007/s11277-019-06937-3","https://doi-org.proxy.bnl.lu/10.1007/s11277-019-06937-3;http://dx.doi.org/10.1007/s11277-019-06937-3","Journal Article"
"Women in Rural Bangladesh: Empowered by Access to Mobile Phones","Mobile phones are seen as a means for social and economic progress in rural and remote areas of developing countries. In Bangladesh the availability and use of information and communication technology (ICT), particularly mobile phones, is thought to have accelerated the development of women in the rural population by creating the possibility of a wider connection. Using qualitative and quantitative methods for data collection, this research has investigated the impact of mobile phone use by women with particular emphasis on opportunities in health, education and livelihood. A sample of 99 women from three rural villages in Bangladesh showed that mobile phones provide easy access to health related services. Although impact on facilitating girls' education appears to be limited, mobile phones have an indirect effect in ensuring security for girls. Respondents confirmed that their overall living standards have improved due to access to information on economic and income earning opportunities. These rural women also feel independent and empowered by access to a mobile phone. It can be argued that mobile phone technology can facilitate improvements in the living standards of rural women, which contribute to their personal development. Finally, the paper suggests that wide and innovative utilization of ICT is needed to accelerate development of women in the rural population with the help of low-cost mobile phone technology.","","Islam MK,Slack F","","2016","75–84","10.1145/2910019.2910074","https://doi-org.proxy.bnl.lu/10.1145/2910019.2910074;http://dx.doi.org/10.1145/2910019.2910074","Conference Paper"
"Workshop Report: Reducing Internet Latency, 2013","This paper reports on a workshop convened to develop an action plan to reduce Internet latency.Internet latency has become a focus of attention at the leading edge of the industry as the desire to make Internet applications more responsive outgrows the ability of increased bandwidth to address this problem. There are fundamental limits to the extent to which latency can be reduced, but there is considerable capacity for improvement throughout the system, making Internet latency a multifaceted challenge. Perhaps the greatest challenge of all is to re-educate the mainstream of the industry to understand that bandwidth is not the panacea, and other optimizations, such as reducing packet loss, are at odds with latency reduction.For Internet applications, reducing the latency impact of sharing the communications medium with other users and applications is key. Current Internet network devices were often designed with a belief that additional buffering would reduce packet loss. In practice, this additional buffering leads to intermittently excessive latency and even greater packet loss under saturating load. For this reason, getting smarter queue management techniques more widely deployed is a high priority. We can reduce these intermittent increases in delay, sometimes by up to two orders of magnitude, by shifting the focus from packet loss avoidance to delay avoidance using technology that we already have developed, tested, implemented and deployed today.There is also plenty of scope for removing other major sources of delay. For instance, connecting to a website could be completed in one roundtrip (the time it takes for packets to travel from source to destination and back again) rather than three or four, by folding two or three rounds of flow and security set-up into the first data exchange, without compromising security or efficiency.Motivating the industry to deploy these advances needs to be aided by the availability of mass-market latency testing tools that could give consumers the information they need to gravitate towards low latency services, providers and products. There is no single network latency metric but several alternatives have been identified that compactly express aggregate delay (e.g. as relationships or a constellation), and tools that make use of these will give greater insight into the impact of changes and the diversity of Internet connections around the world.In many developing countries (and in rural regions of developed countries), aside from Internet access itself, there are significant structural issues, such as trombone routes through the developed world and a lack of content distribution networks (CDNs), that need to be addressed with more urgency than Active Queue Management (AQM) deployment, but the `blank slate' of new deployments provides an opportunity to consider latency now. More widespread use of Internet exchange points for hosting local content and fostering local interconnections is key to addressing some of these structural challenges.","","Ford M","","2014","80–86","10.1145/2602204.2602218","https://doi-org.proxy.bnl.lu/10.1145/2602204.2602218;http://dx.doi.org/10.1145/2602204.2602218","Journal Article"
"Usability Evaluation of the ETax Portal for Uganda","The eTax portal/system is a web-based tax filling and payment system designed to reduce cumbersome manual processes, cut evasion and help boost domestic revenue collection. With the electronic system, tax paying individuals and businesses can apply for driving permit renewals, road licences, passport fees and motor vehicle registration online. The system is also used for payment of public services and other remittances such as the payment of traffic fines, court bails and other licenses. Given the public facing nature of eTax portals, their usability is key for members especially the tax paying public to find them easy to use, effective, efficient as well as satisfying to use. This paper presents results of an evaluation of an eTax portal for Uganda using the popularly used Jakob Nielsen's 10 Usability Heuristics for User Interface Design. Based on the results, the paper further presents recommendations on how URA can fix current usability gaps to make the portal more effective, efficient and satisfying to use. This is hoped to attract and retain more tax payers in the country to use it as opposed to continuing to use the traditional manual system which is not only costly, but also reduces the level of compliance. Furthermore, a usable eTax portal will decrease training, support and maintenance costs. The paper also provides general recommendations on how to develop and manage more usable websites.","","Baguma R","","2018","449–458","10.1145/3209415.3209470","https://doi-org.proxy.bnl.lu/10.1145/3209415.3209470;http://dx.doi.org/10.1145/3209415.3209470","Conference Paper"
"Monitoring Short Term Changes of Malaria Incidence in Uganda with Gaussian Processes","A method to monitor communicable diseases based on health records is proposed. The method is applied to health facility records of malaria incidence in Uganda. This disease represents a threat for approximately 3.3 billion people around the globe. We use Gaussian processes with vector-valued kernels to analyze time series components individually. This method allows not only removing the effect of specific components, but studying the components of interest with more detail. The short term variations of an infection are divided into four cyclical phases. Under this novel approach, the evolution of a disease incidence can be easily analyzed and compared between different districts. The graphical tool provided can help quick response planning and resources allocation.","","Andrade-Pacheco R,Mubangizi M,Quinn J,Lawrence N","","2015","2–8","","","Conference Paper"
"Learning Adversary Behavior in Security Games: A PAC Model Perspective","Recent applications of Stackelberg Security Games (SSG), from wildlife crime to urban crime, have employed machine learning tools to learn and predict adversary behavior using available data about defender-adversary interactions. Given these recent developments, this paper commits to an approach of directly learning the response function of the adversary. Using the PAC model, this paper lays a firm theoretical foundation for learning in SSGs and provides utility guarantees when the learned adversary model is used to plan the defender's strategy. The paper also aims to answer practical questions such as how much more data is needed to improve an adversary model's accuracy. Additionally, we explain a recently observed phenomenon that prediction accuracy of learned adversary behavior is not enough to discover the utility maximizing defender strategy. We provide four main contributions: (1) a PAC model of learning adversary response functions in SSGs; (2) PAC-model analysis of the learning of key, existing bounded rationality models in SSGs; (3) an entirely new approach to adversary modeling based on a non-parametric class of response functions with PAC-model analysis and (4) identification of conditions under which computing the best defender strategy against the learned adversary behavior is indeed the optimal strategy. Finally, we conduct experiments with real-world data from a national park in Uganda, showing the benefit of our new adversary modeling approach and verification of our PAC model predictions.","","Sinha A,Kar D,Tambe M","","2016","214–222","","","Conference Paper"
"User Behavior and Change: File-Sharers and Copyright Laws","Though the impact of file-sharing of copyrighted content has been discussed for over a decade, only in the past few years have countries begun to adopt legislation to criminalize this behavior. These laws impose penalties ranging from warnings and monetary fines to disconnecting Internet service. While their supporters are quick to point out trends showing the efficacy of these laws at reducing use of file-sharing sites, their analyses rely on brief snapshots of activity that cannot reveal long- and short-term trends.In this paper, we introduce an approach to model user behavior based on a hidden Markov model and apply it to analyze a two-year-long user-level trace of download activity of over 38k users from around the world. This approach allows us to quantify the true impact of file-sharing laws on user behavior, identifying behavioral trends otherwise difficult to identify. For instance, despite an initial reduction in activity in New Zealand when a three-strikes law took effect, after two months activity had returned to the level observed prior to the law being enacted. Given that punishment seems to, at best, result in short-term compliance, we suggest that incentives-based approaches may be more effective at changing user behavior.","","Gavaldà-Miralles A,Otto JS,Bustamante FE,Amaral LA,Duch J,Guimerà R","","2014","319–324","10.1145/2674005.2675009","https://doi-org.proxy.bnl.lu/10.1145/2674005.2675009;http://dx.doi.org/10.1145/2674005.2675009","Conference Paper"
"Adversary Models Account for Imperfect Crime Data: Forecasting and Planning against Real-World Poachers","Poachers are engaged in extinction level wholesale slaughter, so it is critical to harness historical data for predicting poachers' behavior. However, in these domains, data collected about adversarial actions are remarkably imperfect, where reported negative instances of crime may be mislabeled or uncertain. Unfortunately, past attempts to develop predictive and prescriptive models to address this problem suffer from shortcomings from a modeling perspective as well as in the implementability of their techniques. Most notably these models i) neglect the uncertainty in crime data, leading to inaccurate and biased predictions of adversary behavior, ii) use coarse-grained crime analysis and iii) do not provide a convincing evaluation as they only look at a single protected area. Additionally, they iv) proposed time-consuming techniques which cannot be directly integrated into low resource outposts. In this innovative application paper, we (I) introduce iWare-E a novel imperfect-observation aWare Ensemble (iWare-E) techniquefootnoteiWare-E is a predictive model integrated into Protection Assistant for Wildlife Security system (PAWS) developed at the University of Southern California, which is designed to handle the uncertainty in crime information efficiently. This approach leads to superior accuracy for adversary behavior prediction (up to 34% increase in AUC) compared to the previous state-of-the-art. We also demonstrate the country-wide efficiency of the models and are the first to (II) evaluate our adversary behavioral model across different protected areas in Uganda, i.e., Murchison Fall and Queen Elizabeth National Park, (totaling about 7500 square km) as well as (III) on fine-grained temporal resolutions. Lastly, (IV) we provide a scalable planning algorithm to design fine-grained patrol routes for the rangers, which achieves up to 150% improvement in number of predicted attacks detected.","","Gholami S,Mc Carthy S,Dilkina B,Plumptre A,Tambe M,Driciru M,Wanyama F,Rwetsiba A,Nsubaga M,Mabonga J,Okello T,Enyel E","","2018","823–831","","","Conference Paper"
"Evaluation of Spectrum Occupancy: A Case for Cognitive Radio in Uganda","In recent years, proliferation of wireless devices has increased wireless access to nearly all of the world's population and use of services like mobile systems, GPS and Wi-Fi. Users are mobile, dynamic and majority prefer the 30MHz - 3000MHz band of the 300GHz spectrum due to propagation and equipment feasibility, rendering spectrum finite and constrained since virtually all radio-frequency (RF) spectrum is licensed. Cognitive radio (CR), a novel approach, sharing unoccupied spectrum by secondary users (SUs) while minimising interference to satisfy service (QoS) of PUs. The paper provides basis for exploiting the Uganda's spectrum sharing guideline and generally CR in Uganda. Maker ere University in Kampala, the capital, is chosen as a representative busy environment. The spectrum usage in shows relatively high utilisation in the FM, TV and mobile bands with high underutilisation of RF spectrum, for the Ugandan indoor and outdoor radio environment over a week. Further measures and statistics including channel occupancy/vacancy statistics, channel utilization from spectrum detected above the power threshold per band, are compared to other cities. Analysis of temporally freed TV bands is also presented.","","Kagarura GM,Okello DK,Akol RN","","2013","167–174","10.1109/MSN.2013.66","https://doi-org.proxy.bnl.lu/10.1109/MSN.2013.66;http://dx.doi.org/10.1109/MSN.2013.66","Conference Paper"
"The Evolving Braid: How an Organization in Uganda Achieved Reliable Communications","When engaged in ICTD research, it is often simpler to focus efforts on a single specific technology, whether that entails computers for telecenters, mobile phones for data collection, or text messages for public health education. In practice, however, people and organizations use a variety of technologies together, smoothly interweaving them as they navigate their lives. In this paper we analyze the ways in which a health financing organization in Uganda integrates a variety of communications technologies together to achieve reliable communications with their partnering health facilities distributed throughout Southwest Uganda. Based on four years of participant observation, we describe two communication scenarios in this organization to illustrate braided communications at work. We find that stakeholders work together to develop and maintain effective relationships using many different communications channels together in parallel, a combined channel we describe as braided communications. Braided communications have three primary characteristics. Firstly, they use co-existing channels, employing each as best suits a given set of goals. Secondly, they are co-dependent, or co-reinforcing, with strengths of individual channels reinforcing weaknesses of other channels. Finally, they are co-evolving; as available technologies and the ways in which they are used change, the nature of the braided use changes as well.","","Densmore M,Bellows B,Chuang J,Brewer E","","2013","257–266","10.1145/2516604.2516620","https://doi-org.proxy.bnl.lu/10.1145/2516604.2516620;http://dx.doi.org/10.1145/2516604.2516620","Conference Paper"
"Adaptive Resource Allocation for Wildlife Protection against Illegal Poachers","Illegal poaching is an international problem that leads to the extinction of species and the destruction of ecosystems. As evidenced by dangerously dwindling populations of endangered species, existing anti-poaching mechanisms are insufficient. This paper introduces the Protection Assistant for Wildlife Security (PAWS) application - a joint deployment effort done with researchers at Uganda's Queen Elizabeth National Park (QENP) with the goal of improving wildlife ranger patrols. While previous works have deployed applications with a game-theoretic approach (specifically Stackelberg Games) for counter-terrorism, wildlife crime is an important domain that promotes a wide range of new deployments. Additionally, this domain presents new research challenges and opportunities related to learning behavioral models from collected poaching data. In addressing these challenges, our first contribution is a behavioral model extension that captures the heterogeneity of poachers' decision making processes. Second, we provide a novel framework, PAWS-Learn, that incrementally improves the behavioral model of the poacher population with more data. Third, we develop a new algorithm, PAWS-Adapt, that adaptively improves the resource allocation strategy against the learned model of poachers. Fourth, we demonstrate PAWS's potential effectiveness when applied to patrols in QENP, where PAWS will be deployed.","","Yang R,Ford B,Tambe M,Lemieux A","","2014","453–460","","","Conference Paper"
"Patient Management Systems: The Early Years","As I scanned through old papers and reports in preparation for these remarks, I became depressed in the “sameness” of those proposals and descriptions with what is happening today. Then I realized there are major differences - today's systems work and are affordable.The health care delivery system is an industry whose magnitude, complexity and pervasiveness are rarely acknowledged. In a few decades, the industry has literally changed from a cottage industry to a multi-billion dollar giant with whom every individual in our society has come into contact. It is a personal industry, yet at the same time, one of our most technically sophisticated industries. It is not surprising that computers are becoming an integral part of that system. This paper discusses some of the experiences in reaching that goal.As a beginning engineer back in the 1960s, I, with many others, felt that the development of computerized patient management systems was not only natural but mandatory. One merely needs to observe the process to realize that keeping track of what was done and charging appropriately, of sending information from one place to another, of storing data and printing it on demand, and of controlling process and flow are tasks which computers perform well. Many medical specialties already used forms for the collection of data. Most medical knowledge was already clearly identified in textbooks, including what questions to ask, what parameters to measure, what tests to order, how to diagnose, and how to treat. “A simple matter of programming” was a phrase often used and believed. It later became a standing joke. Many predicted that the use of computers for medical applications would develop into a multi-million dollar market whose potential would be quickly realized. The actual events proved to be quite different.The development of patient management systems has been influenced by several factors. The first, and perhaps one of the most significant factors, is that of technology - hardware and software. During this development period, computers evolved from single tasking, “untouchable” and “unfriendly” mainframes to highly interactive, multiuser minicomputers.A second factor is that of the people involved - both the developers and the users. The developers had to learn first what to do and how to do it and then learn how to package and sell it to the ultimate user.Economic factors also influenced progress. As computer costs decreased, the cost of delivering patient care increased. Computers seem to be offer one way to reduce and control these costs.Another factor was the tremendous increase in the amount of data generated and the demand for that data by a variety of individuals. For example, both the number of laboratory tests available and the number of tests actually ordered increased exponentially during this period. Estimates on the costs of information handling vary between 25 and 39% of the total cost of health care [1]. With the influx of many research dollars from NIH, actual medical knowledge increased.Finally, the influence of external factors such as the government and third party payers contributed significantly to the development of patient management systems. As one observer commented [2], “I think that just as the Medicare legislation forced hospitals, almost without exception, to use the computer for financial processing, patient accounting, and patient billing, the PSRO type of thing - which will get built on more and more, particularly with national health insurance likely to go in within the next year - will force computerization of the clinical side of the hospital.”The digital computer became available for general use in the late 1950s. These first systems provided few user-oriented features and required considerable knowledge and skill to use. Early systems were batch oriented and supported single tasking only. These computers were large, required specially prepared spaces, and were quite expensive. In addition to machine language, followed by assembly language, only Fortran and Cobol were available as higher level languages. Most programs were written by computer specialists who had only limited interaction with those who would ultimately use the systems. The reliability of early systems left much to be desired. Hardware failures were the norm rather than the exception. Software crashes were commonplace. Perhaps life with these early systems was best described as “working with a machine you couldn't touch; working with a machine that didn't work; working with a machine that you couldn't afford; and working with systems that were not useful.”I shared office space with two cardiology fellows who seemed to spend most of their day making meticulous measurements of amplitudes and time durations of the various waveforms of the ECG. After recording these carefully on paper, they applied a set of rules to interpret the ECG readings. This task seemed to me to be a simple engineering problem which could be solved almost trivially by a computer. Unfortunately there were the problems of noise, wandering baselines, arrhythmias and PVC's, variations in patterns and other factors to solve to produce the same result as the human. Researchers quickly learned that it was difficult to teach the computer to recognize patterns which were easily identified by humans [3, 4, 5].Gordon [6] points out difficulties of attempting to overlay the computer's orderly, pedantic and, indeed, binary world with the softness, variability and “between the lines implications” of medical data under human direction - a point that is still valid. He notes that the adoption of computer technology in practice must be concerned with the customs of 200,000 physicians serving independently or in 7,000 hospitals and clinics. Changes from manual documentation to automated procedures are often bewildering and ineffective.The early development of patient management systems was supported primarily by NIH grants. Since 1968, the National Center for Health Services Research has played a major role in supporting the development, application and evaluation of patient management systems [7]. No hospital could afford a computer. Since the funding came from external sources, developers often did what they wanted to do and how they wanted to do it, rather than interfacing with users who wanted to have nothing to do with the system in the first place.Developers were consistent in their reasons for developing patient care systems. Almost all papers or proposals started with a line, “We are currently in the midst of a health-care crisis. The average cost of a hospital bed has tripled since 1957.” Systems were proposed to reduce the costs of patient care, to reduce length of stay, to improve patient care, to improve nursing care, to improve communication, and to improve decision making. Little evaluation was done. For the most part, we did what we knew how to do and wrote research papers to justify it.Melville H. Hodge sets the stage for this period in the Preface of his book Medical Information Systems [8]. He states that, in the early 1960s, a small group of hospitals became identified with one common goal, that of a commitment to serve as a site for the development of computerized handling of patient information. Some of these early hospitals include Akron Childrens' Hospital in Ohio; El Camino in Mountain View, California; Baptist in Beaumont, Texas; St. Francis in Peoria, Illinois; Charlotte Memorial in North Carolina; Washington Veteran's Administration Hospital; Henry Ford Hospital, Detroit, Michigan; Monmouth Medical Center, Long Branch, N.J.; Mary's Help Hospital, Daly City, California; Deaconess Hospital, Livingston, Indiana; Latter Day Saints Hospital, Salt Lake City, Utah; and Downstate Medical Center, New York City, New York. We owe a debt of gratitude to these early pioneers, and I might say suffering sites.Most major computer companies, such as IBM, Burroughs, Control Data, Honeywell and NCR, seeing the potential of significant sales, were active in their support. Industries experienced in using computers to manage complex systems joined in. Some of these companies include Lockheed, who supported the early development of the Technicon Hospital Information System; McDonnell-Douglas, who is still active in the field; and other companies, such as GE, who later abandoned these efforts. Most of these systems were well reported in the literature (See, for example (9,10]).Many groups in Europe were developing systems at the same time: the Danderyd Hospital [11] and Karolinska Hospital [12] in Sweden; London Hospital [13] and Kings Hospital [14] in England; and the Hanover Hospital [15] in Germany to mention a few.Unfortunately, most of these early systems resulted in resounding failures. The reason primarily for these failures and for the slow progress into the 1970s was largely due to underestimating the complexity of the information requirements of patient management systems. Furthermore, users, as contrasted to developers, were not involved at an adequate level and, in fact, were not ready for computers. Hardware and software tools were inadequate. Hospitals felt that they had been oversold an unattainable product, and, at the loss of millions of dollars, abandoned their efforts in computerization. As Hodge notes, optimism and enthusiasm was replaced by skepticism and then cynicism.Fortunately others persisted. As technology advanced, driven by the space efforts of the '60s, developers learned to appreciate the complexity of the problem and began to address smaller, more easily defined components of the overall system. A few successes appeared, although some projects failed in the transition from carefully nurtured demonstration projects into systems which interfaced with, usually, the least paid, least motivated, and least educated employees of the medical support staff.By the early 1970s, however, some of these early systems, after years of development and many more development dollars than anyone anticipated, became commercially available [16,17]. After a period of overpromise and underachievement, some progress could be noted [18].The Technicon system, begun by Lockheed in the 1960s, was installed at the El Camino Hospital in Mountain View, California and became, perhaps, the best known “successful” application. The “success” of this system in its early years at El Camino can perhaps be measured by an article in the October 1973 issue of DATAMATION [19]. El Camino was truly a guinea pig in the development of the hospital information system and suffered through the many bugs. During the first year of installation, more than 2000 changes were made to the system, many of these major changes which affected the appearance of things such as reports. Each passing day saw improvement in the attitude of doctors and nurses. In mid-1972, 66% of the doctors opposed the system. By the beginning of 1973, the majority of doctors, except for internists, favored the system. The El Camino system is perhaps one of the most thoroughly evaluated systems of any of the early development systems [20, 21]. The results of this evaluation did encourage further development in patient management systems.The ultimate success of the system at El Camino led to the spread of this and other systems into other hospitals.New crises were encountered as reduced funding from the federal government forced hospitals to decide if computerization was worth the cost and then to find the money to do it. Some hospitals were forced to abandon systems even though the systems finally looked promising.Patient management systems tend to be primarily an automation of manual processes. In 1969, Feinstein [22] noted that while computers had been applied effectively in situations where a standard mechanism already exists for dealing with the data, computers had not yet had an important impact on the more inherently clinical features of medical strategy and tactics. Many of the points made in this article are still valid criticisms of patient management systems. Schwartz [23] makes a similar point. He states that “few systems have fully explored the possibility that the computer as an intellectual tool can reshape the present system of health care, fundamentally alter the role of the physician, and profoundly change the nature of medical manpower recruitment and medical education - in short, the possibility that the health-care system by the year 2000 will be basically different from what it is today.” We clearly have some distance to go.The development of many of the components of a patient management system was driven in the late 1960s and early 1970s by interest in automated multiphasic health testing. The work of Dr. Morris Collen and his colleagues at the Kaiser-Permanente Medical Group in California [24,25] contributed to both a high level of interest in this field and in the progress of automation of tests, data collection and analysis. Dr. Collen stressed the need for AMHT systems to provide high quality testing, to provide good service to doctors and patients, and to be economical. In the early 1970s, only the first of these conditions had been met. The same could be said about other components of patient management systems.Barnett, in an article [26] in The New England Journal of Medicine, again argued the cause for computer applications in areas of medical care. He identified seven major areas in patient management systems which had made progress in development. Caceres [27] similarly reviewed the state of the art and stressed that the physician and patient care data must interact via the computer to realize automated patient management system goals.Patient management systems, to be effective, do need to become a part of the physician/patient interface. Early systems were designed partly by the scientist, partly from the business world, and very little by the practicing physician. Systems designed in our computer laboratories often had major flaws which were obvious when we introduced them into the real world. Intelligent use of computers requires an understanding of the things computers do well: quantified information, well-defined vocabulary, great speed, repetition, accuracy, and versatile control. Humans, on the other hand, communicate by speech, vision, and touch, and have an unlimited vocabulary and great adaptability. It is when the computer is applied in areas of human incompetence, that previously impossible results can be achieved [28]. Too few systems take advantage of this fact. Often we fail to realize that the computer is no substitute for intelligence. It is not a magic box which can make gold from straw.One early experience at Duke is typical of the early days. For over two years, Duke had been involved with IBM in the development of a system called Clinical Decision Support Systems (CDSS). Duke had sent several MDs to work with IBM to develop a system in which the doctor would sit down with a computer terminal, describe the patient's history, physical findings, and laboratory data, and the computer would return the diagnosis and recommend a treatment. A remote system was set up at Duke, and the system was to be demonstrated to the faculty and house staff. Before the grand opening, a few doctors sat down and entered data on patient with some “easy” problems, such as influenza or pneumonia. After an hour of conversation with the computer, the computer was no closer to a conclusion than it was at the beginning. It seems that the computer did not know of the more common diseases since they were not well defined in the literature. The decision was made not to demonstrate or implement the system.Instead, Duke then decided to develop a smaller subset of the system - the automation of the initial or screening medical history. A 19-page mark sense form was designed to be completed by the patient, processed by the computer, and be presented to the doctor in narrative form. After three iterations, the form was complete, and actually did an effective job of collecting the initial medical history. Unfortunately, the logistics of processing this form on a large, remotely located main frame computer led to itsfailure. The 19-page history was scanned by a mark sense reader and the results written on a 9-track magnetic tape. The patient's name, address, and free text data was keypunched onto cards, and the tape, cards, and program were submitted for delivery to the Triangle Universities Computation Center (TUCC), located some 12 miles away, for processing. Rarely did the tape, data, and program arrive at TUCC at the same time, and we spent most of our time trying to track down the components and get them together for processing. And when we managed that, the tape, created on one vendor's machine, could not be read on the other vendor's tape unit. The result was the history usually arrived in the doctor's hands a week after the patient had been seen. This problem was ultimately solved with a minicomputer directly interfaced to the scanner which produced the histories immediately.We tried to use what we had learned with the automated histories to develop a computerized medical record for the Division of Obstetrics at Duke. We metwith a group of physicians, argued over what parameters constituted an appropriate data base, and finally compromised by including any parameter any person felt they might use. The result was a 23 page, narrative printout for a new OB workup. Obviously, this computer program was not reducing the paper work nor helping the doctor. A quick redesign with the assistance of only one physician reduced the output to an acceptable amount; in fact, the essence of the output was reduced to approximately ten lines on the first page in a starred box. We learned an important lesson - the difference between “what I might want and what I need”.Technology produced the minicomputer in the mid-60s and removed some of the problems associated with the mainframes. The cost of these computers was around $30,000. The first of these was the LINC or Laboratory Instrumentation Computer developed at MIT and distributed to a number of system developers by NIH. This move by NIH was, in my opinion, one of the most significant events in the field of medical informatics, and really led to the development of the minicomputer industry. The LINC permitted an affordable, hands-on, real-time interaction with a computer. The minicomputer moved into the locations in which the projects were developed. The first minis were single user and had to be programmed in assembly language. The University of Washington in St. Louis developed a popular operating system which solved many of the system problems.The minicomputer opened the door for many new development in patient management including clinical laboratory systems, automated ECG systems, and ambulatory care patient record systems. Octo Barnett, at Mass General, led the way with the development of COSTAR and the programming language MUMPS [29].At Duke, we learned of the power of the minicomputer on a borrowed LINC-8 and designed a system in 1967 to createon-line surface maps of cardiac body potentials - a process which had previously been performed on a mainframe at a much greater expense of time and money. A group of us then became interested in developing a computerized medical record. Our newly-acquired Digital Equipment Corporation PDP-12 was a dream. It had a 4K memory of 12-bit words, a CRT screen which had to be refreshed under program control, two 135 kbyte DEC minitapes, 12 binary control switches, 6 A-to-D channels, and 6 potentiometers A-to-D inputs. Our first system was the Obstetrical Medical Record in which detailed data was retained during the pregnancy of some 1500 women who subsequently delivered at the Duke Medical Center. One tape would contain the records of approximately one month's pregnancies. Near the end of each month, someone was on call to change the tapes as the women came to Duke for delivery. The output was in upper case only on a teletype located just outside the delivery suite. One lesson we learned was that MDs did place value on the ability of a system to deliver information reliably as it was needed.The programs were written originally in assembly language and used the LAP-6 operating system. These assembly language programs were later converted into a programming language called GEMISCH which we use today.The PDP 12 gave way to a PDP 11/20 in the early '70s. The addition of a movable head, 1.2 Mbyte hard disk seemed to offer more storage than we could ever need. This minicomputer had 28 Kwords of 16-bit memory. We wrote a multiuser operating system which supported 7 simultaneous users using a round-robin swapping algorithm.User acceptance of computers played a major role in the development of patient management systems. The success of any innovation in a medical setting depends upon the attitude of the physicians involved. Surveys [30] indicated that physicians were reluctant to touch the keyboard of a CRT. They were doctors and “not typists”. Systems designed and introduced by physicians were more apt to be accepted than one designed by a non-MD.At Duke, we conducted one experiment which demonstrates this attitude. We asked a number of primary care physicians to look at a computer-generated medical history and a hand-written, human-generated history. The physicians overwhelmingly selected the hand-written form. We then reversed the process, taking the computer-generated medical history and coping it by hand, reformatting it slightly. We then took a human-generated history, typed it into the computer, and printed it on a drum printer so that it was obviously computer-generated. We showed these two histories to a number of physicians and again they overwhelmingly selected the hand-written form.Many worried, and perhaps justly, that computers would be over-accepted, andthe computer's “word” would become truth. In an editorial in JAMA [31], M. Southgate compares today's physician with the medicine man of a primitive tribe who consults his spirits for knowledge. To the modern physician, the computer becomes the powerful and all knowing spirit.Patients had little problem in accepting the computer as part of their health care delivery team [32]. Our own experience with using the PDP-12, certainly a rather imposing creature to a unenlightened patient, for collecting headache histories suggested that patients were less intimidated by the computer than the doctor. The adventuresome spirit of our patients was best illustrated by one incident involving a 67 year old lady. While answering questions about her headache, she would occasionally laugh. Not thinking our displays were humorous, we finally asked her what was funny. She replied that she was just waiting until the man hidden in the “computer box” would step out and greet her.The developers of patient management systems were committed to the task. Typical of that attitude is Mel Hodge: “I am a believer. I happen to believe that the problems of health care delivery are susceptible to well-considered, well-executed approaches and that the introduction of information systems technology is among the more powerful approaches available. I have invested more than a decade to my life in this belief [8].” Many of us can now say we have invested a career to this belief.Both of our speakers in this patient management systems section have contributed significantly to the development of this field. Both have been involved from the early years. Melville Hodge headed the development team which was responsible for the Technicon Medical Information System. This system was the first successful HIS which was subsequently implemented in a number of institutions and is today still a leader in the field of patient management systems.Homer Warner, with his colleagues at the Latter Day Saints (LDS) Hospital in Salt Lake City, Utah, developed a number of subsystems over this period which constitute a patient management system called HELP.The HELP system had its beginning in the late 1950s when Dr. Warner and colleagues began exploring the use of computers in the diagnosis of congenital heart disease [33]. The HELP system grew out of a group of subsystems which were designed to directly help the doctor or the nurse with specific data as relates to recognizing and dealing with specific events in a patient's illness [34]. These efforts included the goal of using the computer to enhance the decision making process [35] in the medical arena. Dr. Warner and colleagues dealt early with specific data collection, management [36], and analysis in such areas as the clinical laboratory, patient monitoring [37], and electrocardiographic interpretation by computer [38]. In the early 1970s, theseareas were integrated to use a common database. Warner describes the HELP system in a recent book [39].The Technicon system, and the contributions of Hodge, is important because it was one on the first systems which worked and was accepted. This system primarily dealt with the service-related components of a patient management system - order entry and result reporting. Contributions were made in what was done and how it was done, even though other systems did not necessarily follow exactly the same patterns. The Technicon system represents one milestone in the development of patient management systems.Warner and his group, through years of development, have added and important and necessary component of clinical involvement. By early-on collecting data, Warner and his group were able to develop their own probabilities for diseases and their relationship to signs, symptoms, and findings. Most impressive is that the HELP system is still evolving at even now represents a state of the art approach to automated patient management.These early years of development had to occur. I am always impressed that, as we became smart enough to recognize what we should do next, technology was always just available to enable us to do it. We are now entering a stage in which the tools seem to be adequate, the users seem to be receptive, the results justify the costs, and the applications seem to be useful. Perhaps we have now arrived at the point in which computerized patient management systems can change the way we teach physicians, the way we practice medicine, and the way we do medical research.","","Hammond WE","","1987","153–164","10.1145/41526.41541","https://doi-org.proxy.bnl.lu/10.1145/41526.41541;http://dx.doi.org/10.1145/41526.41541","Conference Paper"
"Measuring the Impact of the Copyright Amendment Act on New Zealand Residential DSL Users","The Copyright (Infringing File Sharing) Amendment Act 2011 (CAA) is a New Zealand law that aims to provide copyright holders with legal recourse when content is illegally shared over the Internet. This paper presents a study of residential DSL user behaviour using packet traces captured at a New Zealand ISP before, shortly after and several months after the CAA coming into effect. We use libprotoident to classify the observed traffic based on the application protocol being used to identify and examine any changes in traffic patterns that may be a result of the new law. We find that the use of peer-to-peer applications declined significantly once the CAA was in effect, suggesting a strong correlation. We also found that there were increases in tunneling, secure file transfer and remote access traffic amongst a small segment of the user population, which may indicate an increased uptake in the use of foreign seedboxes to bypass the jurisdiction of the CAA.","","Alcock S,Nelson R","","2012","551–558","10.1145/2398776.2398833","https://doi-org.proxy.bnl.lu/10.1145/2398776.2398833;http://dx.doi.org/10.1145/2398776.2398833","Conference Paper"
"A Game to Teach Network Communication Reliability Problems and Solutions","After the recent introduction of Computer Science into New Zealand High Schools, a lack of coherent resources for the new topics has created challenges for teachers and students working with the new qualifications. In response to this, a ""Computer Science Field Guide"" has been developed, which provides an on-line open-source ""text book"" that contains chapters with rich content that covers each topic required, each including videos, games and interactive applications. The Network Communication Protocols topic has been particularly difficult to cover because it is focuses on the key concepts in protocols, whereas most teaching material available is about using protocols rather than creating them. Also, the field guide takes a constructivist approach, and there is little material available that approaches the topic this way. This paper presents the research and development of a new interactive game for teaching Network Communication Protocols. Packet Attack is designed to teach key concepts around communication reliability problems and their solutions with respect to the transmission control protocol. The game has a novel approach of letting the user become the problem (unreliability of transmission) to try to prevent messages getting through, rather than them trying to solve the issues.","","Jarman S,Bell T","","2014","43–49","10.1145/2670757.2670773","https://doi-org.proxy.bnl.lu/10.1145/2670757.2670773;http://dx.doi.org/10.1145/2670757.2670773","Conference Paper"
"Scene Collaging: Analysis and Synthesis of Natural Images with Semantic Layers","To quickly synthesize complex scenes, digital artists often collage together visual elements from multiple sources: for example, mountains from New Zealand behind a Scottish castle with wisps of Saharan sand in front. In this paper, we propose to use a similar process in order to parse a scene. We model a scene as a collage of warped, layered objects sampled from labeled, reference images. Each object is related to the rest by a set of support constraints. Scene parsing is achieved through analysis-by-synthesis. Starting with a dataset of labeled exemplar scenes, we retrieve a dictionary of candidate object segments that match a query image. We then combine elements of this set into a ""scene collage"" that explains the query image. Beyond just assigning object labels to pixels, scene collaging produces a lot more information such as the number of each type of object in the scene, how they support one another, the ordinal depth of each object, and, to some degree, occluded content. We exploit this representation for several applications: image editing, random scene synthesis, and image-to-anaglyph.","","Isola P,Liu C","","2013","3048–3055","10.1109/ICCV.2013.457","https://doi-org.proxy.bnl.lu/10.1109/ICCV.2013.457;http://dx.doi.org/10.1109/ICCV.2013.457","Conference Paper"
"Continuous Transition in Outsourcing: A Case Study","Outsourcing is typically considered to occur in three phases: decision, transition and operation. As outsourcing is now well established the switching of vendors and transitioning from one system to another is common. However, most of the research to date on outsourcing has focused on the decision and operation phases, leaving a gap between theory and practice concerning the transition phase. Transition in outsourcing entails the changing of systems, business processes and/or vendors. If a suitable transition approach is not applied pressures for another transition can immediately build. This paper presents results from a case study carried out on the 'Novopay Project' in which the Ministry of Education in New Zealand changed their vendor from an onshore to a near-shore provider. This project resulted in a sequence of three transitions, with each following a different approach as a direct result of the experiences encountered in the previous transition. In this research we made use of the rich 'data dump' of evidence provided by the Ministry of Education (MoE). Our analysis describes how a client organization can become trapped in a continuous transition cycle if a suitable approach is not applied. Transition1 involved the client - MoE - moving from complete outsourcing to selective insourcing. After realizing that they did not have the capabilities to manage insourcing, Transition2 was initiated. In Transition2 the sourcing approach reverted back to complete outsourcing. When it was realized that the new vendor in Transition2 could not in fact deliver a new service model or support end-users in following new business processes, Transition3 was initiated. In Transition3, the client established an internal company to insource service operations to support end-users. Transition can be a sound business strategy initiated for a range of reasons. However, if a flawed sourcing approach is chosen it can result in 'continuous transition'.","","Raza B,Clear T,MacDonell SG","","2017","41–50","10.1109/ICGSE.2017.6","https://doi-org.proxy.bnl.lu/10.1109/ICGSE.2017.6;http://dx.doi.org/10.1109/ICGSE.2017.6","Conference Paper"
"Multivariate Sequential Analytics for Treatment Trajectory Forecasting","Chronic conditions, especially cardiovascular disease account for a large burden on modern healthcare systems. These conditions are by their nature ones that unfold over a long period of time, typically involving many healthcare events, treatments and changes of patient status. The gold standard in public health informatics for risk assessment is regression-based. While these techniques are effective in identifying factors contributing to risk, they produce reductive scores (e.g. probability of a specific class of event, like a heart attack) or binary prediction results, and moreover, they are sequence agnostic. In the area of long-term chronic disease management, multivariate sequential modeling offers an opportunity to forecast disease progression and treatment trajectory in a fine-grained manner in order to aid clinical decision making. This paper investigates the suitability of Long short-term memory, a type of recurrent neural network, in conducting multivariate sequential modeling in the healthcare domain, specifically in the task of forecasting. The eventual goal is to apply this technique to linked New Zealand health data through the Vascular Informatics using Epidemiology and the Web (VIEW) research project. This paper presents initial experiments and results for modeling patients' treatment trajectories during hospitalization using the Medical Information Mart for Intensive Care (MIMIC-III) data set.","","Hsu W,Warren J,Riddle P","","2019","","10.1145/3290688.3290724","https://doi-org.proxy.bnl.lu/10.1145/3290688.3290724;http://dx.doi.org/10.1145/3290688.3290724","Conference Paper"
"A LFM-Based Adaptive Wake-up Signal Detection Approach for Underwater Acoustic Communication System","The paper focuses on wake-up mechanism for underwater acoustic communication (UAC) system. Wake-up mechanisms for UAC terminals play an important role in reducing the power consumption and extending the battery life. Compared with terrestrial wireless counterparts, the wake-up receivers for UAC terminals are challenged by the severe underwater acoustic channels, which are characterized by doubly-selective fading and low signal-to-noise ratio (SNR). Furthermore, the wake-up receiver is with weak processing ability. The paper proposes a wake-up mechanism named as channel-adaptive detection and joint decision (ChAD-JD). ChAD-JD uses linear frequency modulation (LFM) as wake-up signals. In order to increase the detection probability and reduce the probability of false alarm, the novel approach applies channel-adaptive detection and joint decision methods, respectively. Simulation and experimental results show that ChAD-JD is more reliable and effective compared with traditional LFM-based detection methods with a fixed threshold.","","Li H,Wang D,Xie Y,Hu X","","2018","","10.1145/3291940.3291962","https://doi-org.proxy.bnl.lu/10.1145/3291940.3291962;http://dx.doi.org/10.1145/3291940.3291962","Conference Paper"
"How Methods Make Designers","Through their combination of lifestyle and method, Silicon Valley models for tech production such as design thinking, startup incubators, lean management, etc. are spreading across the globe. These paradigms are positioned by product designers, politicians, investors and corporations alike as replicable routes to individual and national empowerment. They are portrayed as universal templates, portable across national borders and applicable to local needs. We draw from our ethnographic engagements with tech entrepreneurial efforts in Ghana, China, and Jamaica to unpack the stakes involved in their uptake, showing that while local actors produce situated alternatives, their work nevertheless often results in a continued valorization of these seemingly universal methods. We argue that design methods shape not only use practices, but have consequences for the life worlds of professional designers. This includes how they impact personal and national identities, confer legitimacy in transnational innovation circles, and secure access to social and economic resources. Ultimately, we call for an inclusion of these factors in ongoing conversations about design and design methods.","","Avle S,Lindtner S,Williams K","","2017","472–483","10.1145/3025453.3025864","https://doi-org.proxy.bnl.lu/10.1145/3025453.3025864;http://dx.doi.org/10.1145/3025453.3025864","Conference Paper"
"Wave Information Studies (WIS) Pacific Regional Hindcast","Coastal wave information is invaluable to coastal engineering projects, designs, maintenance of structures, erosion studies and storm climatology analyses. The mission of the Wave Information Studies (WIS) program in the Coastal and Hydraulics Laboratory (CHL), Engineer Research and Development Center (ERDC) in Vicksburg, MS, is to provide a database of wave information for all the United States coastlines. This information is useful in both civil and military applications. WIS populates this wave information database with wave parameter results from a wave hindcast, a process that uses input wind fields over a gridded area (grid points are identified as water with a specific depth or land) as input to a numerical wave hindcast computer code that models all the physical processes produced from ocean wind wave generation for past events. These wave hindcasts produce wave spectral energy information for every grid point and provide a continuous record of wave information. WIS hindcast results are compared with measurements from in-situ buoys for quality control. The WIS website currently contains at least 20 years of recent wave information for stations near the Atlantic, Gulf of Mexico, Pacific Basin, and Great Lakes coastlines. The Pacific Basin hindcast presented special challenges because of the vast area of the basin, the scarcity of measured information, the necessity for accurate propagation of swell energy from North Pacific and southern hemisphere storms over the Pacific basin, and accurate obstruction definition of small islands in the grid. Research and testing of several wave hindcast models resulted in the choice of the WAVEWATCH III (version 2.22 developed at NOAA/NCEP) numerical wave hindcast model for the Pacific Basin hindcast. This numerical hindcast model using state-of-the-art input wind fields from Oceanweather, Inc., produced 23 years (1981–2004) of wave hindcast information for the Pacific Basin. This information has proved to be invaluable for projects in the Hawaiian Islands and American Samoa. The next frontier for WIS is to produce wave information close to the Pacific mainland coastline. Regional Pacific wind fields for five years at a spacing of 0.25 degrees were secured from Oceanweather, Inc., to use with existing basin wind fields for the same time period at 0.5 degree spacing. The WIS CHL staff has collaborated with NOAA/NCEP to use the new multi-grid WAVEWATCH III numerical wave hindcast model to produce a wave hindcast that computes results from three nested grids in one run. This new technology developed and released by NOAA/NCEP late in 2007 allows WIS to run the basin 0.5 degree grid along with two regional grids (0.25 deg and 1/12 deg) covering the Pacific mainland west coast. Energy can move freely in and out of the boundaries of the three nested grids. This complex multi-grid WAVEWATCH III MPI parallel application would not be possible without the parallel computing resources available at the ERDC MSRC. This paper will show the initial results of the hindcast, comparisons of results with measured information, and will give an overview of the computing process for the Pacific Regional hindcasts.","","Tracy B,Spindler D","","2008","299–304","10.1109/DoD.HPCMP.UGC.2008.84","https://doi-org.proxy.bnl.lu/10.1109/DoD.HPCMP.UGC.2008.84;http://dx.doi.org/10.1109/DoD.HPCMP.UGC.2008.84","Conference Paper"
"CrowdEstimator: Approximating Crowd Sizes with Multi-Modal Data for Internet-of-Things Services","Crowd mobility has been paid attention for the Internet-of-things (IoT) applications. This paper addresses the crowd estimation problem and builds an IoT service to share the crowd estimation results across different systems. The crowd estimation problem is to approximate the crowd size in a targeted area using the observed information (e.g., Wi-Fi data). This paper exploits Wi-Fi probe request packets (""Wi-Fi probes"" for short) broadcasted by mobile devices to solve this problem. However, using only Wi-Fi probes to estimate the crowd size may result in inaccurate results due to various environmental uncertainties which may lead to crowd overestimation or underestimation. Moreover, the ground-truth is unavailable because the coverage of Wi-Fi signals is time-varying and invisible. This paper introduces auxiliary sensors, stereoscopic cameras, to collect the near ground-truth at a specified calibration choke point. Two calibration algorithms are proposed to solve the crowd estimation problem. The key idea is to calibrate the Wi-Fi-only crowd estimation based on the correlations between the two types of data modalities. Then, to share the calibrated results across systems required by different stakeholders, our system is integrated with the FIWARE-based IoT platform. To verify the proposed system, we have launched an indoor pilot study in the Wellington Railway Station and an outdoor pilot study in the Christchurch Re:START Mall in New Zealand. The large-scale pilot studies show that stereoscopic cameras can reach minimum accuracy of 85% and high precision detection for providing the near ground-truth. The proposed calibration algorithms reduce estimation errors by 43.68% on average compared to the Wi-Fi-only approach.","","Wu FJ,Solmaz G","","2018","337–349","10.1145/3210240.3210320","https://doi-org.proxy.bnl.lu/10.1145/3210240.3210320;http://dx.doi.org/10.1145/3210240.3210320","Conference Paper"
"Integrating Cognitive Support with CASE-Tools for Design Recovery","Reverse engineering (RE) activities account for the largest part of current expenses in software maintenance. The RE support provided by existing design tools is limited to simple mappings of idioms in the source code to diagrammatic primitives. Human analysts still have togo through the laborious task of manually detecting patterns and creating higher abstractions. Perhaps the most important challenge in automating RE is to deal with the imperfect knowledge inherently involved in the detection process. Recently, a number of researchershave developed prototypes of design tools with knowledge-based RE capabilities. For several reasons these research prototypes are rarely acceptable for industrial-strength applications. Consequently, innovative technologies often have difficulties reaching their target audience. We try to address this issue by adopting established design tools and extending them with knowledge-based RE functionality. This paper reports on the development of such an extension component and contains a case study that shows the feasibility of this approach.","","Jahnke JH","","2002","145–154","","","Conference Paper"
"Understanding Sustainable Mobility: The Potential of Electric Vehicles","Rising awareness of the environmental impacts of dominant mobility practices lead to the development of the sustainable mobility paradigm. This paradigm advocates three features of a mobility system: 1. A reduced need to travel, 2. Modal shift towards more sustainable options, and 3. Reduced vehicle kilometres travelled. In this paper, two sets of data are presented to explore the potential of electric vehicles to contribute to a more sustainable mobility system. First, data from an international Delphi of transport experts shows how a sustainable future can be characterised by different features: efficient internal combustion engine vehicles, electric vehicles, and reduced personal car ownership. Thus electric vehicles are presented as both an opportunity and a threat in relation to sustainable mobility. A second body of empirical material is drawn from interviews with electric vehicle owners, and discusses the drivers and barriers to ownership. Interestingly, participants suggest changing mobility practices associated with electric vehicle ownership, evidenced by decreasing kilometres travelled. The paper concludes by suggesting that there may be potential for electric vehicles to contribute to a sustainable mobility future through modified mobility practices and renewable energy sources in New Zealand.","","Scott M,Hopkins D,Stephenson J","","2014","27–30","10.1109/MDM.2014.63","https://doi-org.proxy.bnl.lu/10.1109/MDM.2014.63;http://dx.doi.org/10.1109/MDM.2014.63","Conference Paper"
"Effectiveness of Mobile Electrocardiogram in Healthcare: From Mobile Application and Development to Community Reaction","Chronic diseases such as heart and blood vessels are considered among the most common and serious reasons of mortality in the world. In Europe alone, over four million deaths a year (45% of all deaths) are caused by heart diseases [1]. In addition, chronic diseases are responsible for 70 % of United States deaths, and account for more than 75% of annual United States medical care cost [2]. For instance, Cardio Vascular Diseases (CVD) are considered the main cause for around 14.3% of total deaths in Denmark5, and it is the main cause for over 45% of the total death in Lebanon6. It is too costly to keep CVD patients under control locally within the vicinity of a healthcare unit. Thus, researchers recently started to realize the need for automated monitoring in health systems that are expected to reduce the overall death rate and cost associated with monitoring of patients. However, a general monitoring health system will not cover all diseases at once. Therefore, there is a pushing necessity for monitoring health systems which are dedicated to specific health cases. To contribute to the ongoing efforts, this work develops an automated system which could be customized for various chronic diseases. A mobile application based solution is proposed. Further, the work concentrates on CVD by conducting a survey in Lebanon to investigate the acceptance and awareness of ECG for remote monitoring of patients. The results are promising and reflect how specialists are aware of the need to utilize the rapid development in technology combined with the widespread usage of mobile phone which may be used as the main device to guarantee 24/7 communication link for ECG. Adopting ECG in the healthcare system will allow for capturing some valuable data which could guide the development of a recommendation system. This will issue necessary alerts to specialists and guidance to patients and their careers so that specialists could attend to the case on timely basis and patients with their careers could follow the recommendations to keep the case under control until the specialist becomes available. Finally, a secure forum based communication system will be developed to allow patients to share their experience and specialists to provide consultancy and guidance on demand.","","Kassem A,Yildirim UO,Turğut KA,Wiil UK,Özyer T,Alhajj R","","2017","896–903","10.1145/3110025.3120985","https://doi-org.proxy.bnl.lu/10.1145/3110025.3120985;http://dx.doi.org/10.1145/3110025.3120985","Conference Paper"
"Experiences in MHealth for Chronic Disease Management in 4 Countries","This paper describes mHealth applications to deal with Non Communicable Diseases in North and Latin America: In Chile, a project focused on Diabetes Mellitus type 2; In the United States, Honduras, and Mexico, projects focused in diabetes, heart failure, depression, hypertension, and cancer. Information Technologies used include voice and sms on cell phones and electronic health records systems.","","Piette JD,Blaya JA,Lange I,Sanchis JB","","2011","","10.1145/2093698.2093868","https://doi-org.proxy.bnl.lu/10.1145/2093698.2093868;http://dx.doi.org/10.1145/2093698.2093868","Conference Paper"
"Prototype of an Alignment Model of the Ministry of Telecommunications and the Information Society to a Public Organization in Ecuador","This work contains information on technological advances in various public institutions in Ecuador, to improve the quality of services to users from government management. The objective was to design a prototype that is an alignment model for the Ministry of Telecommunications and the information society to a public organization in Ecuador; for this reason, it was important to work with a quantitative methodology that allowed to objectively know the management and applicable strategies and clarified its usefulness in the Ecuadorian context. In order for this alignment to be possible, it was proposed to comply with the decrees and laws, which allow the ease of communication between public and private companies, as well as strengthen citizen participation, support communication activity through access to public data, which values and respects diversity. It turned out that the ITIL model together with linear programming are the most suitable options to allow technology to be managed with good practices in public institutions. In this way, it was possible to conclude that state companies must align themselves, making good use of the information society, respecting the theory of public service, community communication, cybernetic theory, universal and affordable universal access to ICT, to all citizens, in order to provide care to users with quality and warmth based on the country's public policies.","","Toapanta SM,Canales MJ,Rojas JG,Gallegos LE","","2020","58–64","10.1145/3404663.3404676","https://doi-org.proxy.bnl.lu/10.1145/3404663.3404676;http://dx.doi.org/10.1145/3404663.3404676","Conference Paper"
"Flexible Robotic Teleoperation Architecture Under IEC 61499 Standard for Oil & Gas Process","One of the main characteristics of oil extraction stations is the latent danger present in the installations due to the nature of the procedures done and the type of raw material used. In Ecuador, another specific complication is presented in this type of stations due to their geographical locations. Teleoperation allows a human operator to transmit his abilities and capabilities into specialized robotic elements capable of replicating them. This allows a person to successfully execute manipulation and transporting tasks in dangerous environments with limited access, from a secure place located in a far distance. However, for the implementation of teleoperated systems, it is necessary to ensure the execution of operative and communication tasks in real time. This can be obtained with the use of advanced and high performance devices and improved communication protocols. The aim of this paper is to propose the Robotic Technology Transfer (RTT) of a teleoperation system developed in academic research laboratories to the industrial oil extraction field. It allows an operator to control a mobile manipulator to perform inspection and maintenance tasks in a Drilling Rig from an oil extraction station, basing its work on the use of the industrial automation standard IEC-61499 and the MQTT protocol for communications.","","Garcia CA,Naranjo JE,Campana LA,Castro M,Beltran C,Garcia MV","","2018","1269–1272","10.1109/ETFA.2018.8502520","https://doi-org.proxy.bnl.lu/10.1109/ETFA.2018.8502520;http://dx.doi.org/10.1109/ETFA.2018.8502520","Conference Paper"
"Design and Implementation of a Non-Ionizing Radiation Measuring System Evaluated with an Unmanned Aerial Vehicle","Nowadays the growing number of mobile phones has increased the number of stations needed in order to improve the quality of service for users. This growth of cellular antennas has caused a degree of worry and fear among citizens due to locations where they are installed, ever closer to our homes. The International Commission on Non-Ionizing Radiation Protection (ICNIRP) has established maximum limits that must be met to ensure that no negative effects on health will be generated to people. In Perú, informality regarding delivery of authorizations, control and monitoring of cellular antennas, is one of the causes of insecurity. The uncertainty about the harmful effects that might result in a society surrounded by stations grows. This paper focuses on the design and implementation of a system for measuring non-ionizing radiation of cell phone antennas in order to verify compliance with the maximum permissible limits. The design is made in the downlink ranges bands of 850 MHz and 1900 MHz, and measurement tests were conducted in two stages: at ground level and mounted on an UAV flying around a cell phone antenna.","","Prado GV,Medina MA","","2015","52–57","10.1109/APCASE.2015.17","https://doi-org.proxy.bnl.lu/10.1109/APCASE.2015.17;http://dx.doi.org/10.1109/APCASE.2015.17","Conference Paper"
"Risk Quantification of Metabolic Syndrome with Quantum Particle Swarm Optimisation","Metabolic syndrome (MetS) is a combination of interrelated risk factors associated with an increased risk of developing type II diabetes Mellitus (T2DM), stroke and cardiovascular diseases (CVD). The economic, social and medical burden coupled with increased morbidity of the aforementioned diseases makes their prevention an active research area. Currently, the traditional method of MetS diagnosis is based on dichotomised definitions provided by various expert health organisations. However, this method is laced with the indetermination of MetS in individuals with borderline risk factor values due to a binary diagnosis and the assumption of equal weighting for all risk factors during diagnosis. The purpose of this paper is to examine the use of the MetS areal similarity degree risk analysis based on weighted radar charts comprising of diagnostic thresholds and risk factor results of an individual. We further enhance this risk quantification method by applying quantum particle swarm optimization to derive the weights. The proposed risk quantification was carried out using a sample of 528 individuals from an examination survey conducted between 2007 and 2014 in Serbia. The results are evaluated with the traditional dichotomised method of MetS diagnosis, in this case the joint interim statement (JIS). The results obtained showed that the proposed risk quantification method outperformed the dichotomised method at diagnosing MetS even in individuals who present risk factor examination values at the threshold borderlines.","","Kakudi HA,Loo CK,Pasupa K","","2017","1141–1147","10.1145/3041021.3054935","https://doi-org.proxy.bnl.lu/10.1145/3041021.3054935;http://dx.doi.org/10.1145/3041021.3054935","Conference Paper"
"Weather Forecast Information Dissemination Design For Low-Literate Farmers: An Exploratory Study","Pakistan's agricultural sector has been making gigantic contributions towards the nation's economy, with agriculture accounting for 22% of the gross domestic product (GDP) while engaging approximately half of the country's labor force. A significant developmental challenge in this sector is inadequacy and inaccessibility of information regarding weather forecast. In this paper, we propose an Android-based solution for farmers that can facilitate the timely, localized, and customized dissemination of granular weather forecast that shields the whole agricultural ecosystem and supply chain from weather variability by appropriate decision-making. We describe our Android mobile application that sends a customized weather forecast that is configured according to the user preferences. Information is disseminated by the cloud server through encrypted SMS to the subscribing farmers containing weather information. This information is encoded through visuals and icons in a simple to understand user-interface that is accompanied by Urdu language text in a design tailored for low-literate farmers of Pakistan. The testing, feedback, and evaluation include design understanding, the effectiveness of icons and images, usability, adaptation to touch screen is in progress which will help us to reiterate the mobile app user interface (UI) to improve the preliminary design.","","Idrees F,Batool A,Qadir J","","2017","","10.1145/3136560.3136596","https://doi-org.proxy.bnl.lu/10.1145/3136560.3136596;http://dx.doi.org/10.1145/3136560.3136596","Conference Paper"
"Matching Ukrainian Wikipedia Red Links with English Wikipedia’s Articles","This work tackles the problem of matching Wikipedia red links with existing articles. Links in Wikipedia pages are considered red when lead to nonexistent articles. In other Wikipedia editions could exist articles that correspond to such red links. In our work, we propose a way to match red links in one Wikipedia edition to existent pages in another edition. We define the task as a Named Entity Linking problem because red link titles are mostly named entities. We solve it in a context of Ukrainian red links and English existing pages. We created a dataset of 3171 most frequent Ukrainian red links and a dataset of almost 3 million pairs of red links and the most probable candidates for the correspondent pages in English Wikipedia. This dataset is publicly released1. In this work we define conceptual characteristics of the data — word and graph properties — based on its analysis and exploit these properties in entity resolution. BabelNet knowledge base was applied to this task and was regarded as a baseline for our approach (F1 score = 32 %). To improve the result we introduced several similarity metrics based on mentioned red links characteristics. Combined in a linear model they resulted in F1 score = 85 %. To the best of our knowledge, we are the first to state the problem and propose a solution for red links in Ukrainian Wikipedia edition.","","Liubonko K,Sáez-Trumper D","","2020","819–826","10.1145/3366424.3383571","https://doi-org.proxy.bnl.lu/10.1145/3366424.3383571;http://dx.doi.org/10.1145/3366424.3383571","Conference Paper"
"Analysis of the Kupyna-256 Hash Function","The hash function Kupyna was recently published as the Ukrainian standard DSTU 7564:2014. It is structurally very similar to the SHA-3 finalist GrØstl, but differs in details of the round transformations. Most notably, some of the round constants are added with a modular addition, rather than bitwise xor. This change prevents a straightforward application of some recent attacks, in particular of the rebound attacks on the compression function of similar AES-like hash constructions. However, we show that it is actually possible to mount rebound attacks, despite the presence of modular constant additions. More specifically, we describe collision attacks on the compression function for 6 out of 10 rounds of Kupyna-256 with an attack complexity of $$2^70$$, and for 7 rounds with complexity $$2^125.8$$. In addition, we can use the rebound attack for creating collisions for the round-reduced hash function itself. This is possible for 4 rounds of Kupyna-256 with complexity $$2^67$$ and for 5 rounds with complexity $$2^120$$.","","Dobraunig C,Eichlseder M,Mendel F","","2016","575–590","10.1007/978-3-662-52993-5_29","https://doi-org.proxy.bnl.lu/10.1007/978-3-662-52993-5_29;http://dx.doi.org/10.1007/978-3-662-52993-5_29","Conference Paper"
"Comparative Risk Analysis of Development of the Lignite Basins in Serbian Part of the Danube Region","The paper gives an overview of the global business risks and risks in the mining development in the Kolubara and Kostolac lignite basins in the area of the Danube river in Serbia. An identification of main risks is undertaken by application of a comprehensive development framework approach, comparative analysis and Spider method. Risks in the development of mining are emphasized by global economic and financial crisis, as well as by the adoption of Kyoto Protocol regulations and mechanisms. The paper shows that the consideration and elimination of risk factors is important for the increase of competitiveness and energy efficiency in the lignite basins as an integral part of the efforts for achieving the sustainable development in the Serbian part of the Danube region.","","Zeković S,Maričić T","","2011","171–176","","","Conference Paper"
"Digital Educational Environment of a Modern University: Theory, Practice and Administration","The article reveals theoretical and practical aspects of the digital educational environment of a university. The main normative and legal documents of Ukraine regulating the informatization of the sphere of national education are determined. The experience of introduction of the system of electronic educational courses by the leading institutions of higher education of Ukraine is analysed; the concepts of “distance education”, “digital educational environment”, “educational management” are specified. It has been found that education is a social institution with its own laws, principles and regulations, so the ability to manage education is as important and difficult as finding the right vector for development of all mankind. The benefits of education transformation are listed: development of students’ self-determination, ability to concentrate on the most valuable teaching material; increase of mobility of personality, ability to adapt to the dynamic environment; ensuring cooperation with diverse audiences; creating an individualized educational trajectory of the student; comfortable learning environment. An attempt is made to identify the definition of “digital educational environment” as a set of relevant resources that is able to ensure the implementation of educational, scientific, international and managerial activities of higher educational institutions. It was established that higher educational institutions of Ukraine in the conditions of distance learning increase the capacity of the digital educational environment. The conditions and modern vectors of information educational development are considered, and the basic problems, needed to be resolved at the state level, are defined. Strengths (flexible schedule of educational tasks, provision of inclusiveness, control and evaluation of the results of educational activities, individual consultations in remote mode, etc.) and weaknesses revealed of the development of the digital educational environment (the delay in the creation of digital training courses, lack of information literacy of teachers, low level of integration of digital learning environment and teaching disciplines, etc.). Presented the model of digital education environment of the university from the position of organizational and administrative activity. Described four operational modules of the specified model: scientific and technical module (repository, open publication system, digitalization of the library fund); educational module (electronic management system of educational courses, online learning, control of students’ knowledge quality); administrative module (electronic document management, education environment management, digital archive, online questionnaires, operational process management, digital security systems, innovative activities in the education and information environment); informational module (official website of the institution of higher education, personal pages of teachers, 3D-courses, pages of the university in social networks). It is established that the level of compliance of all activities of the designated operational areas is an indicator of the successful functioning of the university under the conditions of digitalization of the educational environment.","","Vasyliuk TG,Lysokon IO,Shimko IM","","2022","161–168","10.1145/3526242.3526260","https://doi-org.proxy.bnl.lu/10.1145/3526242.3526260;http://dx.doi.org/10.1145/3526242.3526260","Conference Paper"
"CyberActivist: Tool for Raising Awareness on Privacy and Security of Social Media Use for Activists","Bosnia-Herzegovina (BH) and its entity Republika Srpska (RS) are among the most fragile democratic environments in Europe. In the first phase of our long-term participatory design case study, we engaged the some of the main activists in BH/RS, providing a structured picture of their practices in recent years, concrete needs and the various constraints under which they act. Our research highlighted importance and utilization of the social media for the activism in the region, but also problems such as limited budgets and know-how of the activists, intensive outsourcing practices, and a lack of awareness regarding data privacy and cyber security. Due to the perspective of BH/RS, the rising number of threats and impact incidents, and activist experiences from other unstable regions, we propose a more structured approach to privacy and security within activist circles and non-profit organizations. As the initial step in the second phase of our study, we offered a prototype of the free web application “CyberActivist” to BH/RS activists for user tests. Based on their qualitative feedback we defined the functional and non-functional requirements on further improvement of this privacy and security awareness tool. In the next phase, we will technically address their direct feedback, as well as design recommendations from relevant research and user experience literature. We also plan to propose design method improvements, design corresponding privacy and security trainings and to further internationalize the tool.","","Tadic B,Rohde M,Wulf V","","2018","498–510","10.1007/978-3-319-91521-0_36","https://doi-org.proxy.bnl.lu/10.1007/978-3-319-91521-0_36;http://dx.doi.org/10.1007/978-3-319-91521-0_36","Conference Paper"
"Home Area Network: A Security Perspective","This paper relates to establishing and analysing the need for home area network (HAN) security. There always exists the need to balance the security set up against the risk being mitigated. Many of the noncomputing savvy households pay very little attention to home network security. Previously, viruses and other malicious programs were the only threats envisaged. With the advent of broadband, wireless networking, and convergence of different communication technologies being adopted by HANs, these vulnerabilities have further increased. People like to think that private personal information theft, identity theft and credit card frauds will not affect them. This paper begins with a brief background to home area network security, discusses the current and future technology trends likely to impact HAN security. The authors cover why HAN security is crucial and go on to suggest application of security solutions in few of the typical home area network scenarios in New Zealand.","","Sathu H,Shukla R","","2007","85–90","","","Conference Paper"
"Cloudy with a Chance of Poaching: Adversary Behavior Modeling and Forecasting with Real-World Poaching Data","Wildlife conservation organizations task rangers to deter and capture wildlife poachers. Since rangers are responsible for patrolling vast areas, adversary behavior modeling can help more effectively direct future patrols. In this innovative application track paper, we present an adversary behavior modeling system, INTERCEPT (INTERpretable Classification Ensemble to Protect Threatened species), and provide the most extensive evaluation in the AI literature of one of the largest poaching datasets from Queen Elizabeth National Park (QENP) in Uganda, comparing INTERCEPT with its competitors; we also present results from a month-long test of INTERCEPT in the field. We present three major contributions. First, we present a paradigm shift in modeling and forecasting wildlife poacher behavior. Some of the latest work in the AI literature (and in Conservation) has relied on models similar to the Quantal Response model from Behavioral Game Theory for poacher behavior prediction. In contrast, INTERCEPT presents a behavior model based on an ensemble of decision trees (i) that more effectively predicts poacher attacks and (ii) that is more effectively interpretable and verifiable. We augment this model to account for spatial correlations and construct an ensemble of the best models, significantly improving performance. Second, we conduct an extensive evaluation on the QENP dataset, comparing 41 models in prediction performance over two years. Third, we present the results of deploying INTERCEPT for a one-month field test in QENP - a first for adversary behavior modeling applications in this domain. This field test has led to finding a poached elephant and more than a dozen snares (including a roll of elephant snares) before they were deployed, potentially saving the lives of multiple animals - including elephants.","","Kar D,Ford B,Gholami S,Fang F,Plumptre A,Tambe M,Driciru M,Wanyama F,Rwetsiba A,Nsubaga M,Mabonga J","","2017","159–167","","","Conference Paper"
"BCEAP - A Blockchain Embedded Academic Paradigm to Augment Legacy Education through Application","Education plays an important role in the economic and social progress of any community. Currently, the higher education system needs immense of enhancements for fulfilling essential needs of the productive and beneficial educational environment. The major challenges faced by the higher education system is the verification of student's data at the time of admission in the university. Current admission system requires a lot of time along with an excess of human resources. there is no mechanism for the authentication of degrees and educational certificates in Pakistan. In this paper, the proposed system based on blockchain technology. This system can validate and verify degree/certificates. The proposed system can verify and validate the student's educational record from respective educational stakeholders like HEC, PEC, IBCC. It allows students to apply for admission using the single platform at a few clicks. Using blockchain, this system is secure, tamper-resistant, time saving, efficient and reliable.","","Ghaffar A,Hussain M","","2019","","10.1145/3341325.3342036","https://doi-org.proxy.bnl.lu/10.1145/3341325.3342036;http://dx.doi.org/10.1145/3341325.3342036","Conference Paper"
"Quality Model for the Selection of Floss-Based Issue Tracking System","The complexity of the issue tracking systems (ITS) which meet the requirements of the Infrastructure Technology Information Library (ITIL) encumbers their selection. In addition, we have to consider some other variables, such as the wide range of tools, their functionality level and their costs. Regarding the cost of the ITS, nowadays the use of ITS based on Free/Libre Open Source Software (FLOSS) is an increasing trend. Therefore, the purpose of this article is to present a model to evaluate the quality characteristics of the FLOSS-ITS according to ITIL recommendations. This quality model is aimed at selecting the best of the available tools. The set of characteristics evaluated is presented based on the product perspective of the Software Quality Systemic Model (MOSCA). This perspective is inspired on the ISO/IEC 9126 standard and Dromey's quality model. Also it was applied to a case study -a venezuelan company-, which is willing to exploit and extend the capabilities of this type of tools to its customers. The case study allowed us to establish the FLOSS-ITS's quality requirements: functionality, reliability and usability. Lastly, validation of the model through its application to three FLOSS-ITS tools is presented.","","Raffoul E,Domínguez K,Pérez M,Mendoza LE,Grimán AC","","2008","43–49","","","Conference Paper"
"A Dynamic Graph-Based Cluster Ensemble Approach to Detect Security Attacks in Surveillance Network","Wireless sensor networks (WSNs) are underlying network infrastructure for a variety of mission-critical surveillance applications. The network should be tolerant of unexpected failures of sensor nodes to meet the Quality of Service (QoS) requirements of these applications. One major cause of failure is active security attacks such as Denial of Service (DoS) attacks. This paper models the problem of detecting such attacks as an anomaly detection problem in a dynamic graph. The problem is addressed by employing a voting based cluster ensemble approach called the K-Means Spectral and Hierarchical ensemble (KSH) approach. The experimental result shows that KSH detected DoS attacks with better accuracy when compared to baseline approaches. sectionIntroduction and Motivation WSNs play a vital role in a variety of mission-critical surveillance applications, such as military surveillance. These applications demand different QoS, such as energy efficiency, coverage, and connectivity from the underlying network. To meet these QoS requirements, WSNs should be tolerant of sensor node failures. Active security attacks such as DoS attacks are one major cause of such failures. The famous Maroochy water treatment and Ukrainian power grid attacks are good instances of active security attacks over wireless sensor networks. Active security attacks are more dangerous in terms of severity it creates in the network. For instance, such an attack on WSNs deployed for military surveillance applications can lead to physical intrusions to happen without being undetected.","","Thomas D","","2021","194–195","","","Conference Paper"
"Dengue Spread Information System (DSIS)","Mosquitoes are responsible for transfer of many vector-borne diseases including Malaria, Zika and Dengue. These amount to 17% of the total infectious diseases across the globe, leading to a death toll approximately 700,000 annually.Dengue is a preventable viral infection transmitted by Aedes mosquitoes. However, over the past 50 years, the number of dengue cases has increased by a whopping 30-fold. Every year an approximately 500,000 people are admitted with severe dengue, with an estimated 40,000 deaths. In several countries in south American continent and Asia, dengue is one of the leading causes of death. It is mainly found in tropical and sub-tropical regions, particularly surrounding urban and semi-urban areas. Historically, there has been an intensive increase in the number of dengue cases from 2000-2010 and, if adequately explored, essential information can be retrieved.Our work involves the development of the Dengue Spread Information System (DSIS), a geographic-health information system designed to highlight the spread of dengue cases in Iquitos, Peru, and San Juan, Puerto Rico from 1990 to 2013. The application is aimed at citizens, travelers, policymakers and researchers to analyze and interpret the change in risk factors leading to dengue outbreaks and develop essential early warning applications and policies to counter future dengue outbreaks.","","Bhanot K,Schroeder D,Llewellyn I,Luczak N,Munasinghe T","","2020","150–159","10.1145/3418094.3418133","https://doi-org.proxy.bnl.lu/10.1145/3418094.3418133;http://dx.doi.org/10.1145/3418094.3418133","Conference Paper"
"Design Thinking for the Construction of Technological Solutions in a Science Course in a Virtual Environment","The trend of curricular reforms in recent years has been to promote the scientific learning of students, the Peruvian curriculum, through the curricular area of ​​Science and Technology, poses as one of the skills that must be developed in students is the so-called “Design and build technological solutions to solve problems in your environment”, whose products are evaluated at an institutional level for the Eureka Science and Technology Fair contest, however many of these need to be strengthened with aspects of creativity at the design level of the technologies, therefore, we set as an objective, to implement Design Thinking to develop competence in the design and construction of technological solutions to solve problems in their environment in female secondary school students in the Science and Technology course, during remote classes. Applying the intervention based on design thinking from the IDEO proposal, considering functional creativity and various cognitive scaffolds developed in electronic learning, the results were favorable, achieving significant differences in the evaluation scores obtained before and after in the first and second phase of the execution of the intervention achieving a Level of significance = 1%, the students were able to identify an alternative technological solution to the problem presented, design the alternative technological solution, implement it and go through the validation process to comply with the specifications of design and operation and evaluates and communicates the operation and impacts of its technological solution alternative.","","Arbulú Pérez Vargas CG,Gómez Fuertes A,Reyes Pérez MD,Espino Carrasco DK,Rojas Palacios LE","","2022","3–13","10.1007/978-3-031-05675-8_1","https://doi-org.proxy.bnl.lu/10.1007/978-3-031-05675-8_1;http://dx.doi.org/10.1007/978-3-031-05675-8_1","Conference Paper"
"MotionTalk: Personalized Home Rehabilitation System for Assisting Patients with Impaired Mobility","Physical injury, stroke, trauma, traumatic brain injury and spinal cord injury rank among the top causes of disability. There are a total of 54 million people in the US requiring rehabilitative assistance of which 15.3 million people are in the age groups of 18-44. However, the compliance rate for patients performing rehabilitation exercises in the home environment is poor. In this paper, we design and prototype a personalized home rehabilitation system, MotionTalk, for the real time quantitative assessment of mobility. Performance of rehabilitation is designed to be assessed using the changes in mobility, reflected in the exercises performed by patients at home with respect to the same exercises performed in the clinic. Our system is capable of capturing motion using Microsoft Kinect and analyzing the position and rotation information to give scores for assessing rehabilitation progress. In comparison to conventional rehabilitation systems, MotionTalk is an inexpensive ($1000), less intrusive and personalized home rehabilitation system, which was developed and tested using data from able-bodied volunteers at Georgia Institute of Technology.","","Venugopalan J,Cheng CW,Wang MD","","2014","455–463","10.1145/2649387.2649430","https://doi-org.proxy.bnl.lu/10.1145/2649387.2649430;http://dx.doi.org/10.1145/2649387.2649430","Conference Paper"
"Evaluating a Mobile Tablet Project in Rural South Africa against Criteria to Comply with Being an Innovative Educational Ecosystem","The purpose of this paper is to evaluate a specific mobile technology rural schools project known as ICT4E in South Africa to determine if it complies to be regarded as an innovative educational ecosystem. The criteria that were used were sourced from the literature. The project was explained and why it is regarded as a rural school mobile tablet project in education. Some high-level results and lessons learnt from this project are also provided that was used to evaluate whether it can be regarded as an instantiation of an innovative educational ecosystem. The evaluation methodology was applied to do the evaluation. The main results were that based on the criteria and the findings from the ICT4E project it could be regarded as an instantiation of an innovative educational ecosystem as it complied to most of the criteria except for two where it only partially complied. The project was also seen as a good example of how a country's system of innovation can be supported from a socio-cultural context-specific perspective.","","Herselman M,Botha A,Maremi K","","2019","215–220","10.1145/3345120.3355422","https://doi-org.proxy.bnl.lu/10.1145/3345120.3355422;http://dx.doi.org/10.1145/3345120.3355422","Conference Paper"
"Adapting Motorbikes for Independent Use by People with Disability","In much of the world motorbikes are the dominant means of transportation. In the developing world motorbikes are often the only form of motorized transportation affordable to the majority of the population. Unfortunately this method of transportation has not been widely exploited anywhere in the world for use by people with severe mobility impairments, especially those who must use wheelchairs. To provide affordable transport for a wide range of mobility-impaired people I have developed an inexpensive sidecar adaptation for motorbikes, capable of transporting a wheelchair user (Figure 1). This adaptation is referred to as the SideScooter. The SideScooter can be operated independently with hand controls from the sidecar or from the motorbike seat, depending on the needs of the operator. Given the vast number of motorbikes in the world and the scarcity of independent transportation for wheelchair users this device has the potential to improve the quality of life for many disabled people in developing as well as the more affluent regions of the world.","","Owens J","","2009","","10.1145/1592700.1592704","https://doi-org.proxy.bnl.lu/10.1145/1592700.1592704;http://dx.doi.org/10.1145/1592700.1592704","Conference Paper"
"Blood Pressure Concerns: Findings from a Usability Study of Culturally Infused MHealth Design","High blood pressure BP (i.e., hypertension) is a chronic condition and risk factor for cardiovascular disease, stroke, and heart failure, occurring in populations across the globe. Currently, smart phones and applications are developing rapidly, and mobile health applications are being used to manage hypertension. The goal of this study was to understand the usability findings from an iterative cross-cultural mHealth application to identify the perceived usefulness among African migrant adopters in Maryland, United States. Qualitative and quantitative statistical method were used to collect participants’ data. Usability findings reported that the behavioral intention of using the recommended features was influenced by the perceived usefulness of the AfriBP. The cultural dimensions were rated as the most preferred recommended features, followed by the health management feature. The perceived usefulness had a strong significant effect on attitude in adopting the AfriBP. Female participants adopted the AfriBP more than the male participants. The results regarding ethnicity found that the Nigerian participants considered the perceived usefulness of the AfriBP more than the Ghanaian participants. Few participants owned and or publicly used BP machines to monitor their BP. Few number of participants were less likely to use a smartphone health application to monitor their BP for health. The health status of the participants for BP readings and body mass index (BMI) was of great concern which supported prior research on Africans ancestry having the highest concern for BP.","","Oladapo H,Chakraborty J","","2022","296–305","10.1007/978-3-031-05028-2_20","https://doi-org.proxy.bnl.lu/10.1007/978-3-031-05028-2_20;http://dx.doi.org/10.1007/978-3-031-05028-2_20","Conference Paper"
"Information Operations in Africa: An Overlooked Opportunity","With last year's activation of us African Command (AFRICOM), the United States will now address its security concerns for that turbulent continent with operations realigned under one command instead of three. Information operations will necessarily dominate the Department of Defense's activities in Africa genocide, poverty, famine, epidemic and civil war are rarely if ever amenable to solution by direct armed intervention. Information Operations (IO) involves more than network and cyber operations, which is just one of its five core elements. IO also includes psychological operations, electronic warfare, operations security, and military deception. All of these will be important in AFRICOM, both in terms of their effectiveness and in their utility in the economy of force considerations that will be a permanent part of the security environment for the foreseeable future. This presentation considers the challenges and opportunities of IO in Africa from the point of view of culture, security, infrastructure, and level of development.","","McKinney JR,Westphal M","","2009","698–703","","","Conference Paper"
"Scalable Non-Invasive Pediatric Cerebral Visual Impairment Screening with the Higher Visual Function Question Inventory (HVFQI)","Cerebral Visual Impairment (CVI), vision loss due to brain injury in early childhood, is the leading cause --- approximately 40% --- of bilateral visual impairment in children from industrialized countries and is the most rapidly growing cause among children in developing countries. Typical causes of CVI include abnormal brain development or brain damage, often consequential to birth-related complications such as hypoxic ischemic encephalopathy, meningitis, hydrocephalus, and head injury. The current gold standard for clinical diagnosis require a trained clinician to administer visual-motor integration tests in conjunction with a thorough review of a patient's clinical history. This approach does not scale to meet the needs of undiagnosed children with CVI. Recently, non-invasive screening methods such as administering a higher visual function question inventory (HVFQI), have been shown to accurately capture the observations of teachers and guardians of children. Analysis of those observations has been shown to have very high correlation with visual-motor integration tests (p values < 0.01). In this poster, we present a clinical database and information system, the HVFQI web app, which delivers a scalable, non-invasive pediatric CVI screening that is currently administered by a clinician, but has the potential to be self-administered in the near future, with follow-up clinical consultation for participants that screen positive or near-positive.The HVFQI web app is an online clinical diagnostic tool and database system designed to gather participant responses to over 50 questions and follow-up questions. No personally identifying information is stored in the database. The web app provides three critical functions: (1) scalable and accurate administration of the HVFQI; (2) global coordination of screening efforts; and (3) a consolidated database for efficacy analysis studies and rapid iteration of the HFVQI to maximize impact, accuracy, and accessibility.The HVFQI consists of a question inventory, a scoring rubric, and a conditional intervention strategy list. The question inventory is carefully curated and designed to capture observations from teachers and guardians that may indicate specific pediatric higher visual function deficits (HVFDs). In many instances HVFDs are accompanied by normal visual acuity, making diagnosis difficult, and requiring multiple questions to elicit HVFDs. These questions are presented at random to avoid leading the participant. The responses are scored according to the HVFQI scoring rubric, which indicates which HVFDs may be present, and relevant intervention strategies. The rubric responds to varying degrees of affirmative responses in a 5-category Likert scale, which includes 3 non-applicable responses with different causes. The rubric also responds to categorical responses for multiple-choice and multiple-answer questions. The web app prepares a report of relevant intervention strategies for the participant, along with the questions and responses as context.The web app is also designed to coordinate international clinical efforts. The web application administrators, led by a superadministrator, can create, manage, and remove centers and staff corresponding to physical (or virtual) locations as demand grows. Each center has a local administrator that can authorize staff to administer the HVFQI, interpret and discuss the results and relevant strategies with participants.The data is stored in a central secure database, accessible only to authorized researchers, and the site administrator. All data are anonymous and non-personally identifying. Authorized researchers can analyze the results for their local centers to estimate efficacy and submit suggestions to update the HVFQI to meet the needs of local participants. Researchers authorized by the super-administrator have full access to the entire database and can perform global analysis for rapid improvement.The HVFQI web app is the result of a collaboration between the SeeLab of the Smith-Kettlewell Eye Research Institute, and the Kulkarni Group of the Computer Science Department at San Francisco State University.","","Wong M,Ghahghaei S,Chandna A,Kulkarni A","","2021","","10.1145/3459930.3469495","https://doi-org.proxy.bnl.lu/10.1145/3459930.3469495;http://dx.doi.org/10.1145/3459930.3469495","Conference Paper"
"Flexicurity for Investment Reimbursement of Micro Renewable Electric Energy Systems","Even the most affordable renewable energy installation still needs an investment that is significant for local people, so that a co-financing party is often indispensable. This article investigates through field research in Tanzania and a technology survey, whether technology could be able to support such investment schemes. It would secure reimbursements in the same flexible and secure way people now pay for mobile communication services, thereby applying the success factors of mobile communications in Africa to micro renewable electric energy systems. Further areas for investigation are identified.","","Van Acker B,Van Acker C,Van Acker V","","2012","149–154","10.1109/GHTC.2012.32","https://doi-org.proxy.bnl.lu/10.1109/GHTC.2012.32;http://dx.doi.org/10.1109/GHTC.2012.32","Conference Paper"
"A Roadmap to Proliferate Open Source Software Usage within SA Government Servers","Open Source software (OSS) is increasingly being recognized by the government sector around the world as a viable choice to proprietary software, particularly in a number of areas of information technology (IT) such as on the network servers. In the OSS domain, it is perceived that OSS has the potential to deliver better value for money, high quality software, secure, flexible, stable and reliable network applications. The South African (SA) government acknowledges that OSS is a viable alternative to proprietary software especially on the servers. According to the data collected (survey) from various SA government departments and agencies, indications are that OSS is not fully implemented on the network servers, although the global trends indicate high usage of OSS within the network environment. The main aim of this paper is to propose a roadmap that can be used to aid SA ministries to increase OSS usage.","","Mtsweni J,Biermann E","","2008","430–436","10.1109/BROADCOM.2008.82","https://doi-org.proxy.bnl.lu/10.1109/BROADCOM.2008.82;http://dx.doi.org/10.1109/BROADCOM.2008.82","Conference Paper"
"Decrease the Number of Patients Lost to Follow-up in the Monitoring of PLHIV in Cross-Border Areas between The Gambia, Senegal and Guinea Bissau","The fight against AIDS in West Africa is a big challenge of public health. The main difficulties are related to the availability of antiretrovirals (AVR) and mainly to the observance of the treatment. In the cross-borderland areas of the Gambia, Senegal and Guinea Bissau, these difficulties of the observance of the treatment are amplified by the vulnerability, the high mobility of the populations and the problems of communication between the actors of the monitoring of PLHIV who speak three different languages. That's what makes difficult the fight against AIDS in those areas and justify the phenomenon of the patients lost to follow-up, which is a great indicator for the following of the People Living with HIV-virus (PLHIV). This paper presents the decrease of the number of patients lost to follow-up in the monitoring of the PLHIV in the cross-borderland areas of the Gambia, Senegal and Guinea Bissau by a multilingual semantic web platform of reference, counter reference and auto reference.","","Diop I,Dieng Y,Faye Y,Malack CA,Cisse O,Diouf B","","2019","","10.1145/3361570.3361596","https://doi-org.proxy.bnl.lu/10.1145/3361570.3361596;http://dx.doi.org/10.1145/3361570.3361596","Conference Paper"
"Admixture Aberration Analysis: Application to Mapping in Admixed Population Using Pooled DNA","Admixture mapping is a gene mapping approach used for the identification of genomic regions harboring disease susceptibility genes in the case of recently admixed populations such as African Americans We present a novel method for admixture mapping, called admixture aberration analysis (AAA), that uses a DNA pool of affected admixed individuals We demonstrate through simulations that AAA is a powerful and economical mapping method under a range of scenarios, capturing complex human diseases such as hypertension and end stage kidney disease The method has a low false-positive rate and is robust to deviation from model assumptions Finally, we apply AAA on 600 prostate cancer-affected African Americans, replicating a known risk locus Simulation results indicate that the method can yield over 96% reduction in genotyping Our method is implemented as a Java program called AAAmap and is freely available.","","Bercovici S,Geiger D","","2010","31–49","10.1007/978-3-642-12683-3_3","https://doi-org.proxy.bnl.lu/10.1007/978-3-642-12683-3_3;http://dx.doi.org/10.1007/978-3-642-12683-3_3","Conference Paper"
"Baby Boomers’ Intention to Use Branch or Digital Banking Channels in South Africa: An Exploratory Study","With Baby Boomers comprising a significant and profitable segment of the South African population, understanding the banking behaviour of seniors becomes an important task for banking institutions. With minimal literature dedicated to the banking behaviour of seniors, this study aimed to outline aspects which influenced Boomer's intention to use branch or digital channels and identify reasons for this. Literature highlighted the significant role of behavioural beliefs, trust, normative beliefs, perceived usefulness, perceived secureness and perceived control in banking intention, with gender, computer literacy, banking institution and banking channel used, being the major differences when choosing to walk into a branch or bank electronically. By applying the Kruskal-Wallis test on data collected from 281 Boomers across Gauteng, it was found that the gender of Boomers did not have any differences across branch and digital channels. By applying banking channel split, differences were found among the branch, digital and both channel groups for all six variables for both branch and DB intention. Reasons for these differences were also outlined within. Based on these findings, recommendations for the banking institutions of SA have been provided. Suggestions on future research initiatives are included, with linking banking intention to banking behaviour and conducting comparisons to other generational groups being notable topics.","","Ramlall S,Hattingh M,Van Deventer P","","2020","74–84","10.1145/3410886.3410915","https://doi-org.proxy.bnl.lu/10.1145/3410886.3410915;http://dx.doi.org/10.1145/3410886.3410915","Conference Paper"
"Comparing Type 2 Diabetes Self-Management Apps Against the Needs of Low-Income Minority Patients: Is There An Implicit Functionality Bias?","Background: Diabetes Mellitus is a chronic disease affecting 30 million in the US. It is a leading cause of death and a major risk factor for severe COVID-19. More than 90% of cases are Type 2 (T2DM), which has adult onset and has risk factors that are behavioral (e.g., smoking) or environmental (e.g., poor nutrition, decreased physical activity). Self-management is critical to long-term treatment of T2DM. It includes adherence to medication regimens, constant nutritional and physical activity management, blood glucose monitoring, and behavioral changes (e.g., smoking cessation). Many mobile computing health (mHealth) apps have been developed to support TM self-management.Problem: US T2DM rates among non-Hispanic whites and the well-educated have leveled off, but diagnoses continue to increase disproportionately among low-income populations, particularly African-American, Latino, and Native American minorities. This has created a growing health disparity associated with social and economic factors that include differential access to healthcare, healthy food, occupational opportunities and physical activity options. (termed Social Determinants of Health or SDOH [1]. Recent public health research [2,3] has begun to identify unique SDOH challenges faced by one such population, low-income African Americans. This poster examines the degree to which the existing T2DM mHealth apps are able to address the self-management needs exposed in this emerging research, versus the more widely studied needs and issues associated with more affluent and largely white population of persons with T2DM.Methods: Seventeen positively assessed T2DM apps were selected from recent review articles. Separately, two sets of functional features were compiled. First, from the T2DM literature, a set of 23 categories and sub-categories was compiled of general features that were identified as desirable to support the T2DM self-management process. Second, a set of eleven functional features and sub-features was developed from the research on the SDOH challenges of low income African American persons with T2DM. The T2DM apps were then compared in a two-stage process using the two sets of criteria. Because many of the criteria in the second set involved social support, only those apps that have some form of social functionality were included in the second stage comparison.Results. The results of the two comparisons are presented as two matrices comparing each app with each criterion and sub-criterion. None of the apps in stage one contained all the general functions suggested in the literature, though several come close. In stage two, most apps had few or none of the focused forms of social support for self-management capabilities of interest.Conclusions. Social capabilities of existing T2DM apps seemed based on the unconstrained social network models used in general social network media (e.g., Facebook, Twitter, Instagram). However, the needs expressed from the low-income communities focused on first order geospatially-local networks that could provide pragmatic help in self-management activities. Additionally, existing apps relied on Premium versions and in-app sales for revenue models, but such features are not accessible to low-income users. Such design decisions suggest an implicit design bias toward more affluent user populations, which also sociologically tend to be more White. Participatory design is recommended as a method that could help avoid such implicit design biases.","","Zachary W,Gupta H","","2020","","10.1145/3388440.3414913","https://doi-org.proxy.bnl.lu/10.1145/3388440.3414913;http://dx.doi.org/10.1145/3388440.3414913","Conference Paper"
"A Critical Discourse Analysis of Governance Issues Affecting Public Private Partnership Contracting for Information Systems Implementations: A South African Case Study","Public Private Partnership (PPP) contracts have drawn considerable media interest due to a number of problems such as cost overruns, mismanagement and failure. The purpose of this paper is to critically analyse media discourse relating to the failure of a PPP contract between the South African Department of Labour (DOL) and Siemens Information Services (SIS). The contract pertained to the provision and implementation of Information and Communication Technology (ICT) services for the DOL. The theoretical foundation for this research is Habermas' theory of communicative action which focuses on normative standards for communication and implications of public speech. Our research builds on a growing literature on critical discourse analysis (CDA) that systematically applies Habermas' validity claims to empirical research on public communication focused on revealing distortions concerning claims of truth, sincerity, legitimacy and comprehensibility. Our study contributes to understanding issues of public accountability of PPP contracts and extends the reach of critical research into PPP contracting for information systems (IS) services and highlights key challenges of the lack of public sector management competences in securing the public interest in PPP engagements.","","Albertus R,Ngwenyama O,Brown I","","2015","","10.1145/2815782.2815800","https://doi-org.proxy.bnl.lu/10.1145/2815782.2815800;http://dx.doi.org/10.1145/2815782.2815800","Conference Paper"
"Macroscopic Traffic Stream Variables Prediction with Weather Impact Using Hybrid CNN-LSTM Model","Accurate prediction of the macroscopic traffic stream variables such as speed and flow is important for traffic operation and management in an intelligent transportation system. Adverse weather conditions like fog, snow, and rainfall affect the driver’s visibility, road capacity, and mobility. The accurate prediction of the traffic stream variables in adverse weather conditions is challenging because of the non-linear and complex characteristics of the traffic stream and spatiotemporal correlation between traffic and weather variables. Prolonged heavy rain causes massive waterlogging in developing countries due to weak drainage systems, narrow streets, and encroachment, further affecting these traffic stream variables. Snow reduces the road capacity as much as waterlogging does. Prolonged snowfall creates a thick layer on the road, which affects the traffic stream variables. Traffic data has a high spatial and temporal resolution compared to weather data, which makes the problem more challenging. In this paper, we define a soft temporal threshold to capture the prolonged impact of weather variables. To capture the traffic and weather data’s spatiotemporal and temporal features, we propose a hybrid CNN-LSTM model. To validate model performance, data from San Diego and Minneapolis Minnesota Twin city are used. The test experiments show that the hybrid CNN-LSTM model learns spatiotemporal and temporal features accurately compared to other deep learning models.","","Nigam A,Srivastava S","","2021","1–6","10.1145/3427477.3429780","https://doi-org.proxy.bnl.lu/10.1145/3427477.3429780;http://dx.doi.org/10.1145/3427477.3429780","Conference Paper"
"Public Perception of Mental Illness: Opportunity for Community-Based Collaborative Intervention","We explore factors contributing to poor mental healthcare, treatments and help-seeking behaviors among communities in Nigeria and across Africa. The findings from the interview of 25 stakeholders reveal some socio-cultural factors such as negative perceptions, stigmatizations, religious beliefs, and absence of automated supports, which hinder mental healthcare and help-seeking. Also, delays in seeking appropriate medical attention and intake of untested local herbs could lead to severe depressive symptoms, suicidal risks, and adversely affect the mental health of clients. Based on our findings, and in collaboration with the stakeholders, we designed ""Gwam-Okwu"" [Talk to Me]; a culturally-appropriate interactive app that is hyper-localized, safe and secured, and tailored to support communication and collaboration between health workers and clients/relations, personalized self-monitoring, and guided self-learning for the clients.","","Nkwo M,Suruliraj B,Orji R","","2020","1–7","10.1145/3334480.3383023","https://doi-org.proxy.bnl.lu/10.1145/3334480.3383023;http://dx.doi.org/10.1145/3334480.3383023","Conference Paper"
"Making a Community Network Legal within the South African Regulatory Framework","Community networks often operate at the fringe of legality with respect to spectrum, network infrastructure and providing services. We have been involved with such a network in a rural community, and together with them, have devised a way to become legal within the South African regulatory framework. A not-for-profit co-operative was formed and successfully applied for license exemption to operate the network infrastructure and offer services. Revenue is used to sustain the network and can also be used for other community needs. The network has equipment that is not 100% type-approved, and operates at a higher output power than is allowed. However, we have a simple plan to comply with such regulations. This paper offers our experience as a precedent for how to go about making a community network completely legal in South Africa and other countries that have a similar regulatory environment.","","Rey-Moreno C,Tucker WD,Cull D,Blom R","","2015","","10.1145/2737856.2737867","https://doi-org.proxy.bnl.lu/10.1145/2737856.2737867;http://dx.doi.org/10.1145/2737856.2737867","Conference Paper"
"The Still Untapped Potential of Social Media for Health Promotion: The WHO Example","Social media platforms are a network and a communication tool for populations and a powerful marketing channel for the private sector. But are public health organizations taking advantage of its full potential to reach communities directly, influence their (un)healthy behaviors and reduce inequities? Performance indicators of World Health Organization (WHO) Facebook pages were monitored over 5 months in 2019. Simple and multivariate statistics were applied to identify patterns of social media performance, limitations and improvement opportunities. The WHO global page has a totally different profile than the other WHO pages, being by far the most successful: 4.132.925 followers, average of 3 posts per day posts and average of 2.429 total reactions, comments, shares per post. However, one could expect an even better performance given the number of followers. Performance of regional offices pages (Western, Pacific, South-East Asia, Pan American, Europe, Eastern Mediterranean and African Regional Offices) is more worrisome: 14.149 to 309.104 followers per page, quite irrelevant interaction indicators (30 to 208 total reactions, comments, shares per post, 16 to 106 likes per post, 2 to 6 comments per post and 8 to 133 shares per post). Pan American Regional Offices strategy to create different countries and themed Facebook pages doesn't seem to work out. Posts are mainly published in a neutral way, compliant with a traditional public health institutional approach to disseminate health information. However, nowadays fake and erroneous news dissemination take a more sensationalist, sentimental approach, more in tune with a social media environment. One could wonder if WHO's more traditional way to transmit health information is indeed still the key to changing health behaviors. The existence of several WHO pages could be an opportunity to segment audiences, adjust the message to particular needs and thus improve the equity gap, since smaller, more at risk groups could be targeted. However, the current fragmentation of WHO approach isn't inducing a better social media performance. Our analysis was based on publicly available information (organic not payed reach). Owners of pages though have the exact return of health promotion investments in social media. Practice shows that social media investments necessary are much more cost effective than regarding other media (press, television among others). International institutions with a public health motivation such as WHO should rethink their social media strategies. A traditional and institutional approach of publishing information online isn't the more effective way to reach populations through this channel and spun behavior changes. Additionally, adequately done social media communication represents an easy and effective way to reach out to communities and accurately calculate the return on investment of these health promotion actions.","","Bacelar-Nicolau L","","2019","125","10.1145/3357729.3357755","https://doi-org.proxy.bnl.lu/10.1145/3357729.3357755;http://dx.doi.org/10.1145/3357729.3357755","Conference Paper"
"Towards a Unified Trust Model for M-Commerce Systems","M-commerce has become one of the most evolutionary fields not only in the developed countries but also in the developing countries. It facilitates transactional procedures using mobile devices that are being enhanced rapidly to become simpler and more secured. Currently users can make any monetary transaction such as booking tickets or buying goods online anywhere anytime. One of the most challenging concerns in developing m-commerce systems and applications is trustworthiness, because trust is very hard to gain and very easy to lose. Trust is a fuzzy concept as it is defined differently in each discipline even within each, it's perceived in a subjective way. A key step to incorporate trust in m-commerce is to acquire an in-depth understanding of the trustworthiness. This paper presents an attempt to develop a unified trust model for m-commerce. To achieve unification and abstraction, the proposed unified trust model for m-commerce separates changeable and endurable aspects of trustiness. In addition, the proposed model is validated through the demonstration of how existing trust models are embedded within the proposed unified model.","","Hamed WS,Hamza HS,Saroit IA","","2011","992–997","10.1109/ITNG.2011.170","https://doi-org.proxy.bnl.lu/10.1109/ITNG.2011.170;http://dx.doi.org/10.1109/ITNG.2011.170","Conference Paper"
"Secure Mobile Code Execution Service","Mobile code refers to programs that come into a host computer over the network and start to execute with or without a user's knowledge or consent. Because these programs run in the execution context of the user that downloads them, they can issue any system calls that the user is allowed to make, and thus pose a serious security threat when they are malicious. Although many solutions have been proposed to solve the malicious mobile code problem, none of them are truly effective at striking a good balance between defeating zero-day attacks and minimizing disruption to the execution of legitimate applications.This paper describes a commercial system called SEES that secures the execution of mobile code that comes into a host computer as an email attachment or as a web document downloaded through an anchor link by running them on a separate guinea pig machine rather than on the user machine. Effectively, it takes an isolation approach to the secure mobile code execution problem. As a result, SEES guarantees that no malicious email attachments or web documents that act on behalf of the user that downloads them, can damage the resources of the user machine, or can leak any confidential information. In particular, even zero-day virus cannot cause any harms. We present the design, implementation and evaluation of SEES on the Windows platform, and contrast it with other existing approaches to the same problem.","","Lam LC,Yu Y,Chiueh TC","","2006","5","","","Conference Paper"
"A Structured Demonstration of Five Program Comprehension Tools: Lessons Learnt","The purpose of this panel is to report on a structured demonstration for comparing program comprehension tools. Five teams of program comprehension tool designers applied their tools to a set of maintenance tasks on a common subject system. By applying a variety of reverse engineering techniques to a predefined set of tasks, the tools can be compared using a common playing field. A secondary topic of discussion will address the development of guinea pig systems and how to use them in a structured demonstration for evaluating software tools.","","Sim SE,Storey MA,Winter A","","2000","210","","","Conference Paper"
"Transportation Planning Based on GSM Traces: A Case Study on Ivory Coast","In this work we present an analysis process that exploits mobile phone transaction trajectory data to infer a transport demand model for the territory under monitoring. In particular, long-term analysis of individual call traces are performed to reconstruct systematic movements, and to infer an origin-destination matrix. We will show a case study on Ivory Coast, with emphasis on its major urbanization Abidjan. The case study includes the exploitation of the inferred mobility demand model in the construction of a transport model that projects the demand onto the transportation network obtained from open data, and thus allows an understanding of current and future infrastructure requirements of the country.","","Nanni M,Trasarti R,Furletti B,Gabrielli L,Mede P,Bruijn J,Romph E,Bruil G","","2013","15–25","10.1007/978-3-319-04178-0_2","https://doi-org.proxy.bnl.lu/10.1007/978-3-319-04178-0_2;http://dx.doi.org/10.1007/978-3-319-04178-0_2","Conference Paper"
"Universities of the Kyrgyz Republic on the Web: Accessibility and Usability","Today the Internet is the easiest way to find information about any kind of organization, and the first impression about an organization is almost always based on its Web site. This study investigated whether the Web sites of the universities in the Kyrgyz Republic comply with prevailing standards of accessibility and usability and whether these qualities depend on location and type of ownership of the universities. The analysis was conducted using online evaluation tools. Based on the data collected, the hypotheses were further tested using the SPSS statistical package. The results show a low usability rating for the vast majority of the universities' Web sites. For 90.47 % of the Web sites upload time exceeds 30 s; 52.38 % of the Web sites have broken links; and 100 % have browser compatibility problems. The results of accessibility tests show low compliance with W3C-WCAG 1.0: error rates for Priority 1, 2, and 3 checkpoints of 83.33, 92.85, and 95.24 %, respectively. The results obtained and the results of an independent t test indicate that most of the issues of all Web sites tested are not of a technical nature, and occur mainly due to human factors related to Web application development.","","Ismailova R,Kimsanova G","","2017","1017–1025","10.1007/s10209-016-0481-0","https://doi-org.proxy.bnl.lu/10.1007/s10209-016-0481-0;http://dx.doi.org/10.1007/s10209-016-0481-0","Journal Article"
"Design of Enterprise Employee Pension Platform Based on Complex Embedded System","","","Jiang L","","2021","","10.1016/j.micpro.2020.103783","https://doi-org.proxy.bnl.lu/10.1016/j.micpro.2020.103783;http://dx.doi.org/10.1016/j.micpro.2020.103783","Journal Article"
"Prediction of Wheat Production Using Machine Learning Algorithms in Northern Areas of Pakistan","","","Ahmed MU,Hussain I","","2022","","10.1016/j.telpol.2022.102370","https://doi-org.proxy.bnl.lu/10.1016/j.telpol.2022.102370;http://dx.doi.org/10.1016/j.telpol.2022.102370","Journal Article"
"Commercial-Off-the-Shelf-Technology in UK Military Training","Aim. This article gives an overview of how commercial computer game technology was introduced for training, education and decision support within the British Army. Value of the article. It records the narrative of the introduction and development of first person shooter computer games into the British Army; an area where developments are not routinely reported outside the closed world of defence training. Methodology. The research was based on interviews of key staff who worked in procurement at the Defence Academy of the UK and for the MoD during 2002 to 2012. The interviewees included two officers, an experienced defence contractor and a senior civil servant. These interviews were given on the understanding that the views expressed would not be individually attributable as they might not represent those of their current employers. The authors were also given access to a unique collection of documents, some of which were not publically available, but are held in the archives of the UK Defence Academy. These are cited in the bibliography. Limitations of the article. This article cites the evidence from the time that supported the continued use of what was a radical and contentious new way of training. Since the introduction of Virtual Battle Space 2 into the British Army, further research into the effectiveness of games based training in the military has been published. Analysis. Games based training has become a significant part of the training cycle for many parts of the British Army. These games have limitations, but are the only alternative to real operations for some types of training. However, the difficult topic of what is the correct proportion of games based training to other types__ __ is a contested area within defence training in the UK. Conclusions. Initial evaluations on the effectiveness of the use of computer games in preparing UK forces for operations in Iraq and Afghanistan showed they had a significant positive impact. The first experience of the British Army with these games has secured the long-term application of this technology and it is unrealistic to imagine future military training without some degree of games technology.","","Curry J,Price T,Sabin P","","2016","7–30","10.1177/1046878115600578","https://doi-org.proxy.bnl.lu/10.1177/1046878115600578;http://dx.doi.org/10.1177/1046878115600578","Journal Article"
"Dynamics of the Relationship between NDVI and SWIR32 Vegetation Indices in Southern Africa: Implications for Retrieval of Fractional Cover from MODIS Data","Fractional cover of photosynthetic vegetation FPV, non-photosynthetic vegetation FNPV, and bare soil FBS has been retrieved for Australian tropical savannah based on linear unmixing of the two-dimensional response envelope of the normalized difference vegetation index NDVI and short wave infrared ratio SWIR32 vegetation indices VI derived from Moderate Resolution Imaging Spectroradiometer MODIS reflectance data. The approach assumes that cover fractions are made up of a simple mixture of green leaves, senescent leaves, and bare soil. In this study, we examine retrieval of fractional cover using this approach for a study area in southern Africa with a more complex vegetation structure. Region-specific end-members were defined using Hyperion images from different locations and times of the season. These end-members were applied to a 10-year time series of MODIS-derived NDVI and SWIR32 from 2002 to 2011 to unmix FPV, FNPV, and FBS. Results of validation with classified high-resolution imagery indicated major bias in estimation of FNPV and FBS, with regression coefficients for predicted versus observed data substantially less than 1.0 and relatively large intercept values. Examination with Hyperion images of the inverse relationship between the MODIS-equivalent SWIR32 index and the Hyperion-derived cellulose absorption index CAI to which it nominally approximates revealed: 1 non-compliant positive regression coefficients for certain vegetation types; and 2 shifts in slope and intercept of compliant regression curves related to day of year and geographical location. The results suggest that the NDVI–SWIR32 response cannot be used to approximate the NDVI–CAI response in complex savannah systems like southern Africa that cannot be described as simple mixtures of green leaves, dry herbaceous material high in cellulose, and bare soil. Methods that use a complete set of multispectral channels at higher spatial resolution may be needed for accurate retrieval of fractional cover in Africa.","","Hill MJ,Zhou Q,Sun Q,Schaaf CB,Southworth J,Mishra NB,Gibbes C,Bunting E,Christiansen TB,Crews KA","","2016","1476–1503","10.1080/01431161.2016.1154225","https://doi-org.proxy.bnl.lu/10.1080/01431161.2016.1154225;http://dx.doi.org/10.1080/01431161.2016.1154225","Journal Article"
"On the Convergence of Newton-Type Methods Using Recurrent Functions","We introduce the new idea of recurrent functions to provide a new semilocal convergence analysis for Newton-type methods. It turns out that our sufficient convergence conditions are weaker, and the error bounds are tighter than in earlier studies in many interesting cases [X. Chen, On the convergence of Broyden-like methods for nonlinear equations with nondifferentiable terms, Ann. Inst. Statist. Math. 42 (1990), pp. 387-401; X. Chen and T. Yamamoto, Convergence domains of certain iterative methods for solving nonlinear equations, Numer. Funct. Anal. Optim. 10 (1989), pp. 37-48; Y. Chen and D. Cai, Inexact overlapped block Broyden methods for solving nonlinear equations, Appl. Math. Comput. 136 (2003), pp. 215-228; J.E. Dennis, Toward a unified convergence theory for Newton-like methods, in Nonlinear Functional Analysis and Applications, L.B. Rall, ed., Academic Press, New York, 1971, pp. 425-472; P. Deuflhard, Newton Methods for Nonlinear Problems. Affine Invariance and Adaptive Algorithms, Springer Series in Computational Mathematics, Vol. 35, Springer-Verlag, Berlin, 2004; P. Deuflhard and G. Heindl, Affine invariant convergence theorems for Newton's method and extensions to related methods, SIAM J. Numer. Anal. 16 (1979), pp. 1-10; Z. Huang, A note of Kantorovich theorem for Newton iteration, J. Comput. Appl. Math. 47 (1993), pp. 211-217; L.V. Kantorovich and G.P. Akilov, Functional Analysis, Pergamon Press, Oxford, 1982; D. Li and M. Fukushima, Globally Convergent Broyden-like Methods for Semismooth Equations and Applications to VIP, NCP and MCP, Optimization and Numerical Algebra (Nanjing, 1999), Ann. Oper. Res. 103 (2001), pp. 71-97; C. Ma, A smoothing Broyden-like method for the mixed complementarity problems, Math. Comput. Modelling 41 (2005), pp. 523-538; G.J. Miel, Unified error analysis for Newton-type methods, Numer. Math. 33 (1979), pp. 391-396; G.J. Miel, Majorizing sequences and error bounds for iterative methods, Math. Comp. 34 (1980), pp. 185-202; I. Moret, A note on Newton type iterative methods, Computing 33 (1984), pp. 65-73; F.A. Potra, Sharp error bounds for a class of Newton-like methods, Libertas Math. 5 (1985), pp. 71-84; W.C. Rheinboldt, A unified convergence theory for a class of iterative processes, SIAM J. Numer. Anal. 5 (1968), pp. 42-63; T. Yamamoto, A convergence theorem for Newton-like methods in Banach spaces, Numer. Math. 51 (1987), pp. 545-557; P.P. Zabrejko and D.F. Nguen, The majorant method in the theory of Newton-Kantorovich approximations and the Ptak error estimates, Numer. Funct. Anal. Optim. 9 (1987), pp. 671-684; A.I. Zinc˘enko, Some approximate methods of solving equations with non-differentiable operators, (Ukrainian), Dopovidi Akad. Nauk Ukrain. RSR (1963), pp. 156-161]. Applications and numerical examples, involving a nonlinear integral equation of Chandrasekhar-type, and a differential equation are also provided in this study.","","Argyros IK,Hilout S","","2010","3273–3296","10.1080/00207160903023557","https://doi-org.proxy.bnl.lu/10.1080/00207160903023557;http://dx.doi.org/10.1080/00207160903023557","Journal Article"
"Reducing Over-Dispersion by Generalized Degree of Freedom and Propensity Score","Assume y is a response variable, x is a risk factor of interest, and z's are covariates, or sometime called ""confounders of x"" if they are correlated with both x and y. If the covariates are numerous, then model selection procedures are applied on z's while x is usually forced into the model before or after the selection. In this situation, over-dispersion will occur to bias the inference on the relation between x and y. In a linear model, the over-dispersion comes from two sources: an underestimation of the mean-squared error, and a dependency between the estimator of the x-effect and its standard error. The author proposed a method that incorporates the ideas of Ye's generalized degree of freedom and Rosenbaum and Rubin's propensity score. The method reduces the bias and over-dispersion effect to acceptable levels. Data from the Georgia capital charging and sentencing study, which included 1077 observations and 295 covariates, were analyzed as an illustration.","","Lian IB","","2003","197–214","10.1016/S0167-9473(02)00223-2","https://doi-org.proxy.bnl.lu/10.1016/S0167-9473(02)00223-2;http://dx.doi.org/10.1016/S0167-9473(02)00223-2","Journal Article"
"An Evolved VIKOR Method for Multiple-Criteria Compromise Ranking Modeling under T-Spherical Fuzzy Uncertainty","","","Chen TY","","2022","","10.1016/j.aei.2022.101802","https://doi-org.proxy.bnl.lu/10.1016/j.aei.2022.101802;http://dx.doi.org/10.1016/j.aei.2022.101802","Journal Article"
"Assessment of Third-Party Logistics Providers by Introducing a New Stochastic Two-Phase Compromise Solution Model with Last Aggregation","","","Mohammadkhani A,Mousavi SM","","2022","","10.1016/j.cie.2022.108324","https://doi-org.proxy.bnl.lu/10.1016/j.cie.2022.108324;http://dx.doi.org/10.1016/j.cie.2022.108324","Journal Article"
"A Role-Playing Virtual World for Web-Based Application Courses","With the rapid development of the information communication and technology (ICT) infrastructure in the Caribbean, there is an increasing demand for skilled software developers to meet the ICT needs of the region. Consequently, the web-based applications course offered at the University of the West Indies, has been redeveloped. One major part of its upgrading is the use of virtual worlds, such as the negotiate and deal environment (NADE) system, to bridge the disconnect that can occur between the technical/academic skills and the issues associated with developing software in a competitive business environment. NADE is a role-playing virtual environment for teaching the art of creating secure, Java, web-based systems for information processing and backend applications. The system provides an environment where group interactivity and strategic planning are key success factors.","","Depradine C","","2007","1081–1096","10.1016/j.compedu.2006.01.002","https://doi-org.proxy.bnl.lu/10.1016/j.compedu.2006.01.002;http://dx.doi.org/10.1016/j.compedu.2006.01.002","Journal Article"
"A Framework to Study the Emergence of Non-Communicable Diseases","Objective: To design a framework for creating computational models that support the understanding of emergent mechanisms for non-communicable diseases.Scope: The national and global burden of Non-Communicable Diseases (NCDs) represent a major public health challenge that undermines the social and economic development in countries with limited resources. For instance, Cardiovascular Diseases (CVDs) accounted for four out of five deaths in Jamaica and it was the most significant contributor to non-communicable diseases. CVDs are caused by a cluster of comorbidities and lifestyle behaviors that interact to promote a vascular risk. However, their combined effect on CVDs have not been established because of interdependency, nonlinearity and feedback loops. In this research, we developed a computational model based on the Overview, Design concepts, and Details (OOD) protocol to understand the emergence of CVDs in the population. The pattern of this behavior is determined by the interaction of causal relationships among the risk factors. This work has inspired a framework that can be used to model the emergence of non-communicable diseases as complex systems.Results: Understanding the behavior of the Jamaican system provided insights to the creation of a novel framework for NCD emergent patterns. The framework could potentially reduce development cost and time of NCD management systems, since it supports an iterative modeling paradigm. The framework is dynamic enough to be applied in different populations, health states, and various NCDs.","","Simpson O,Camorlinga SG","","2017","116–125","10.1016/j.procs.2017.09.026","https://doi-org.proxy.bnl.lu/10.1016/j.procs.2017.09.026;http://dx.doi.org/10.1016/j.procs.2017.09.026","Journal Article"
"Picture Fuzzy Extension of the CODAS Method for Multi-Criteria Vehicle Shredding Facility Location","","","Simic V,Karagoz S,Deveci M,Aydin N","","2021","","10.1016/j.eswa.2021.114644","https://doi-org.proxy.bnl.lu/10.1016/j.eswa.2021.114644;http://dx.doi.org/10.1016/j.eswa.2021.114644","Journal Article"
"The Cloud Computing Adoption in Higher Learning Institutions in Kenya: Hindering Factors and Recommendations for the Way Forward","","","Njenga K,Garg L,Bhardwaj AK,Prakash V,Bawa S","","2019","225–246","10.1016/j.tele.2018.10.007","https://doi-org.proxy.bnl.lu/10.1016/j.tele.2018.10.007;http://dx.doi.org/10.1016/j.tele.2018.10.007","Journal Article"
"Detection of Stored-Grain Insects Using Deep Learning","","","Shen Y,Zhou H,Li J,Jian F,Jayas DS","","2018","319–325","10.1016/j.compag.2017.11.039","https://doi-org.proxy.bnl.lu/10.1016/j.compag.2017.11.039;http://dx.doi.org/10.1016/j.compag.2017.11.039","Journal Article"
"Virtual Currency as an Inclusive Monetary Innovation for the Unbanked Poor","","","Chipere M","","2018","37–43","10.1016/j.elerap.2018.01.004","https://doi-org.proxy.bnl.lu/10.1016/j.elerap.2018.01.004;http://dx.doi.org/10.1016/j.elerap.2018.01.004","Journal Article"
"Land Records on Blockchain for Implementation of Land Titling in India","","","Thakur V,Doja MN,Dwivedi YK,Ahmad T,Khadanga G","","2020","","10.1016/j.ijinfomgt.2019.04.013","https://doi-org.proxy.bnl.lu/10.1016/j.ijinfomgt.2019.04.013;http://dx.doi.org/10.1016/j.ijinfomgt.2019.04.013","Journal Article"
"Use of Jordan Forms for Convection-Pressure Split Euler Solvers","","","Garg NK,Maruthi NH,Rao SV,Sekhar M","","2020","","10.1016/j.jcp.2020.109258","https://doi-org.proxy.bnl.lu/10.1016/j.jcp.2020.109258;http://dx.doi.org/10.1016/j.jcp.2020.109258","Journal Article"
"Determining Antecedents of Intention to Adopt Goods and Service Tax Network","With the changing worldwide economic scenario, there occurs a need to structure new tax reforms especially for a developing country like India. With this ideation, the Indian government introduced the goods and service tax (GST) in order to conceptualise a common tax system. However, with digitalization transforming every service from offline to online mode, the government developed a not-for-profit website, GST network (GSTN), where citizens can smoothly and securely file their returns. Since the concept is new, studying the GSTN adoption by considering technology acceptance model (TAM) and unified theory of adoption and use of technology (UTAUT) variables becomes a novel approach. The article considers perceived ease of use, perceived usefulness, perceived risk, social influence, and facilitating conditions as exogenous variables whereas intention to adopt GSTN is considered as endogenous one. A partial least square (PLS) path modelling approach is applied on a survey data in order to validate the hypothesised model.","","Guleria N","","2020","30–41","10.4018/IJEA.2020010103","https://doi-org.proxy.bnl.lu/10.4018/IJEA.2020010103;http://dx.doi.org/10.4018/IJEA.2020010103","Journal Article"
"Blind Signature and Ring Signature Schemes: Rehabilitation and Attack","Blind signature and ring signature are two signature schemes with privacy concern. Zhang [Jianhong Zhang, Linkability analysis of some blind signature schemes, In International Conference on Computational Intelligence and Security 2006, IEEE, vol. 2, 2006, pp. 1367-1370, (Available at http://dx.doi.org.proxy.bnl.lu/10.1109/ICCIAS.2006.295283.)] analyzed the unlinkability of Zhang and Kim [Fangguo Zhang, Kwangjo Kim, ID-based blind signature and ring signature from pairings, in: Yuliang Zheng (Ed.), Advances in Cryptology - ASIACRYPT 2002, 8th International Conference on the Theory and Application of Cryptology and Information Security, Queenstown, New Zealand, December 1-5, 2002, Proceedings, Lecture Notes in Computer Science, vol. 2501, Springer, 2002, pp. 533-547], Huang et al. [Zhenjie Huang, Kefei Chen, Yumin Wang, Efficient identity-based signatures and blind signatures, in: Yvo Desmedt, Huaxiong Wang, Yi Mu, Yongqing Li (Eds.), Cryptology and Network Security, 4th International Conference, CANS 2005, Xiamen, China, December 14-16, 2005, Proceedings, Lecture Notes in Computer Science, vol. 3810, Springer, 2005, pp. 120-133] and Wu et al. [Qianhong Wu, Willy Susilo, Yi Mu, Fangguo Zhang, Efficient partially blind signatures with provable security, in: Osvaldo Gervasi, Marina L. Gavrilova, (Eds.), Computational Science and Its Applications - ICCSA 2007, International Conference, Kuala Lumpur, Malaysia, August 26-29, 2007. Proceedings. Part III, Lecture Notes in Computer Science, vol. 4707, Springer, 2007, pp. 1096-1105] and claimed that they are indeed linkable. On the other hand, Gamage et al. [Chandana Gamage, Ben Gras, Bruno Crispo, Andrew S. Tanenbaum, An identity-based ring signature scheme with enhanced privacy, Securecomm and Workshops 2006, IEEE, 2006, pp. 1-5, (Available at http://dx.doi.org.proxy.bnl.lu/10.1109/SECCOMW.2006.359554)] claimed that the scheme of Chow et al. [Sherman S.M. Chow, Siu-Ming Yiu, Lucas Chi Kwong Hui, Efficient identity based ring signature, in: John Ioannidis, Angelos D. Keromytis, Moti Yung (Eds.), Applied Cryptography and Network Security, Third International Conference, ACNS 2005, New York, NY, USA, June 7-10, 2005, Proceedings, Lecture Notes in Computer Science, vol. 3531, 2005, pp. 499-512] is vulnerable to key exposure attack. This paper shows that all these claims are incorrect. Furthermore, we show that the scheme proposed by Gamage et al. [Chandana Gamage, Ben Gras, Bruno Crispo, Andrew S. Tanenbaum, An identity-based ring signature scheme with enhanced privacy, Securecomm and Workshops 2006, IEEE, 2006, pp. 1-5, (Available at http://dx.doi.org.proxy.bnl.lu/10.1109/SECCOMW.2006.359554)] which aimed to provide enhanced privacy actually has privacy level reduced. We hope this work can pinpoint the standard one should use when analyzing the unlinkability of blind signatures and the anonymity of ring signatures.","","Chow SS","","2009","707–712","10.1016/j.csi.2008.09.002","https://doi-org.proxy.bnl.lu/10.1016/j.csi.2008.09.002;http://dx.doi.org/10.1016/j.csi.2008.09.002","Journal Article"
"The Use of Data Mining to Assist Crop Protection Decisions on Kiwifruit in New Zealand","A method is developed to predict insecticide spray decisions using machine learning.Spray diary data are used to predict the outcome of spray monitoring decisions.Using a naive Bayes model 70% of no-spray decisions were made to accuracy of 95%.The method provides new insights into factors affecting pest incidence and control.The method has wide application if linked with on-orchard data capture measures. Data mining algorithms were used to develop models to forecast the outcome of leafroller pest monitoring decisions on 'Hayward' kiwifruit crops in New Zealand. Using industry spray diary and pest monitoring data gathered at an orchard block level for compliance purposes, 80 attributes (independent variables) were created in three categories from the spray diary data: (1) individual insecticide applications applied during 2-week time windows, (2) groups of insecticide applications within time periods prior to or after fruit set and (3) orchard management attributes. Five machine learning algorithms (Decision Tree, Naïve Bayes, Random Forest, AdaBoost, Support Vector Machine) and one statistical method (Logistic regression) (classifiers) were used to develop models to forecast insecticide application decisions for leafroller control, by predicting whether pest monitoring results were above or below a spray threshold. Models to forecast 2011 spraying decisions were trained on 2008 and 2009 data and tested on 2010 data. Forecasts were made for spray and no-spray decisions based upon pre-determined acceptable rates of precision (proportion of correct decisions in test results). Orchard blocks in which a forecast could not be made to a prescribed degree of precision were recommended to be monitored, which is the normal practice. Spray decisions could not be forecast to an acceptable degree of precision, but decisions not to spray were successfully forecast for 49% of the blocks to a precision of 98% (AdaBoost) and 70% of the blocks to a precision of 95% (Naïve Bayes). Models with as few as four attributes gave useful forecasts, and orchard management attributes were the most important determinants of model forecasting accuracy. The potential for this methodology to assist with pest spray forecasting using customised data sets is discussed.","","Hill MG,Connolly PG,Reutemann P,Fletcher D","","2014","250–257","10.1016/j.compag.2014.08.011","https://doi-org.proxy.bnl.lu/10.1016/j.compag.2014.08.011;http://dx.doi.org/10.1016/j.compag.2014.08.011","Journal Article"
"A Systematic Review of IoT in Healthcare: Applications, Techniques, and Trends","","","Haghi Kashani M,Madanipour M,Nikravan M,Asghari P,Mahdipour E","","2021","","10.1016/j.jnca.2021.103164","https://doi-org.proxy.bnl.lu/10.1016/j.jnca.2021.103164;http://dx.doi.org/10.1016/j.jnca.2021.103164","Journal Article"
"Low-Latency Perception in off-Road Dynamical Low Visibility Environments","","","Ferreira Neto NA,Ruiz M,Reis M,Cajahyba T,Oliveira D,Barreto AC,Simas Filho EF,de Oliveira WL,Schnitman L,Monteiro RL","","2022","","10.1016/j.eswa.2022.117010","https://doi-org.proxy.bnl.lu/10.1016/j.eswa.2022.117010;http://dx.doi.org/10.1016/j.eswa.2022.117010","Journal Article"
"The Indirect Carbon Emission from Household Consumption in China between 1995–2009 and 2010–2030: A Decomposition and Prediction Analysis","","","Xia Y,Wang H,Liu W","","2019","264–276","10.1016/j.cie.2018.12.031","https://doi-org.proxy.bnl.lu/10.1016/j.cie.2018.12.031;http://dx.doi.org/10.1016/j.cie.2018.12.031","Journal Article"
"The 2-Dimensional Rigidity of Certain Families of Graphs","Laman's characterization of minimally rigid 2-dimensional generic frameworks gives a matroid structure on the edge set of the underlying graph, as was first pointed out and exploited by L. Lovász and Y. Yemini. Global rigidity has only recently been characterized by a combination of two results due to T. Jordán and the first named author, and R. Connelly, respectively. We use these characterizations to investigate how graph theoretic properties such as transitivity, connectivity and regularity influence (2-dimensional generic) rigidity and global rigidity and apply some of these results to reveal rigidity properties of random graphs. In particular, we characterize the globally rigid vertex transitive graphs, and show that a random d-regular graph is asymptotically almost surely globally rigid for all d ≥ 4. © 2006 Wiley Periodicals, Inc. J Graph Theory 54: 154–166, 2007","","Jackson B,Servatius B,Servatius H","","2007","154–166","","","Journal Article"
"Detecting Multiple Mean Breaks at Unknown Points in Official Time Series","In this paper, we propose a computationally effective approach to detect multiple structural breaks in the mean occurring at unknown dates. We present a non-parametric approach that exploits, in the framework of least squares regression trees, the contiguity property of data generating processes in time series data. The proposed approach is applied first to simulated data and then to the Quarterly Gross Domestic Product in New Zealand to assess some of anomalous observations indicated by the seasonal adjustment procedure implemented in X12-ARIMA are actually structural breaks.","","Cappelli C,Penny RN,Rea WS,Reale M","","2008","351–356","10.1016/j.matcom.2008.01.041","https://doi-org.proxy.bnl.lu/10.1016/j.matcom.2008.01.041;http://dx.doi.org/10.1016/j.matcom.2008.01.041","Journal Article"
"The Adoption of ECommerce Communications and Applications Technologies in Small Businesses in New Zealand","This research investigates the impact of 10 factors, extended from the technological innovation literature, on the adoption of different eCommerce communications and applications technologies (EC) in small businesses (SMEs) in New Zealand (NZ). The research results showed that the CEO's innovativeness was the only determinant of external-email adoption. CEO's involvement was found to be the only determinant of Intranet adoption. Relative advantage and competition were found to influence Extranet/VPN adoption significantly and positively. However, support from technology vendors appeared to violate its hypothesised effect on Extranet/VPN adoption. Regression analysis found that pressure from suppliers was the only determinant of Internet-EDI adoption. The adoption of Web sites was influenced by the information intensity of products and the CEO's innovativeness. The significant factors suggested the uniqueness of the adoption phenomenon in SMEs in NZ. However, the factors that appeared to be significant and the ones that appeared to be insignificant factors and the implications arising from these factors led to a conclusion which suggested the weakness of the EC adoption phenomenon in SMEs in NZ. The research discusses theoretical implications emerging from the research factors and portrays a path for future research.","","Al-Qirim N","","2007","462–473","10.1016/j.elerap.2007.02.012","https://doi-org.proxy.bnl.lu/10.1016/j.elerap.2007.02.012;http://dx.doi.org/10.1016/j.elerap.2007.02.012","Journal Article"
"A Digital Rock Density Map of New Zealand","Digital geological maps of New Zealand (QMAP) are combined with 9256 samples with rock density measurements from the national rock catalogue PETLAB and supplementary geological sources to generate a first digital density model of New Zealand. This digital density model will be used to compile a new geoid model for New Zealand. The geological map GIS dataset contains 123 unique main rock types spread over more than 1800 mapping units. Through these main rock types, rock densities from measurements in the PETLAB database and other sources have been assigned to geological mapping units. A mean surface rock density of 2440kg/m^3 for New Zealand is obtained from the analysis of the derived digital density model. The lower North Island mean of 2336kg/m^3 reflects the predominance of relatively young, weakly consolidated sedimentary rock, tephra, and ignimbrite compared to the South Island's 2514kg/m^3 mean where igneous intrusions and metamorphosed sedimentary rocks including schist and gneiss are more common. All of these values are significantly lower than the mean density of the upper continental crust that is commonly adopted in geological, geophysical, and geodetic applications (2670kg/m^3) and typically attributed to the crystalline and granitic rock formations. The lighter density has implications for the calculation of the geoid surface and gravimetric reductions through New Zealand.","","Tenzer R,Sirguey P,Rattenbury M,Nicolson J","","2011","1181–1191","10.1016/j.cageo.2010.07.010","https://doi-org.proxy.bnl.lu/10.1016/j.cageo.2010.07.010;http://dx.doi.org/10.1016/j.cageo.2010.07.010","Journal Article"
"The Study of Expanded Polytetrafluoroethylene New Material in Dural Repair","Dural defect is a common problem in neurosurgery, and the emergence of expanded polytetrafluoroethylene material provides an effective solution for the rehabilitation of artificial blood vessels, heart patches, and other fields. However, studies on the repair of expanded polytetrafluoroethylene in the dura have reported the occurrence of adverse events of cerebrospinal fluid leakage. Therefore, the task of improving expanded polytetrafluoroethylene materials cannot be delayed. In this study, a new composite dural repair material based on expanded polytetrafluoroethylene and polylactic acid-glycolic acid (expanded polytetrafluoroethylene/polylactic acid-glycolic acid) was designed and synthesized. The results of in vivo experiments confirmed that the material can fully meet the requirements of repairing the integrity of the dura mater, providing protection for the intracranial structure and rebuilding the extracellular matrix. More importantly, the new composite dural repair material can greatly reduce the incidence of cerebrospinal fluid leakage and inhibit inflammation. Therefore, the application data of this study on New Zealand rabbit species will lay an important foundation for the development of dural repair technology.","","Xu YQ,Gao WB,Xing MY,Gao Y,Zhang HT,Chen W,Liu PF,Velmurugan P","","2022","","10.1155/2022/4143413","https://doi-org.proxy.bnl.lu/10.1155/2022/4143413;http://dx.doi.org/10.1155/2022/4143413","Journal Article"
"Measuring the Organizational Resilience of Critical Infrastructure Providers","Modern societies are becoming increasingly dependent on critical infrastructure services. This dependence is not only on the technology used in infrastructures, but also on the organizations that manage the infrastructures. Initiatives that assess infrastructure resilience often concentrate on strengthening the physical infrastructure through robustness and redundancy. Few studies recognize the important role of critical infrastructure providers. This study presents a method for assessing the organizational resilience of critical infrastructure providers. The method is demonstrated using data from a group of critical infrastructure providers in New Zealand. The application of the Benchmark Resilience Tool developed by Resilient Organisations reveals that the surveyed organizations are strong in effective partnerships, but are weak in breaking silos and in conducting stress testing plans. The results also indicate that senior managers have much more positive views of the resilience of their organizations compared with other staff members.","","Brown C,Seville E,Vargo J","","2017","37–49","10.1016/j.ijcip.2017.05.002","https://doi-org.proxy.bnl.lu/10.1016/j.ijcip.2017.05.002;http://dx.doi.org/10.1016/j.ijcip.2017.05.002","Journal Article"
"Information Security Vulnerability Prediction Based on Business Process Model Using Machine Learning Approach","","","Hariyanti E,Djunaidy A,Siahaan D","","2021","","10.1016/j.cose.2021.102422","https://doi-org.proxy.bnl.lu/10.1016/j.cose.2021.102422;http://dx.doi.org/10.1016/j.cose.2021.102422","Journal Article"
"Digital Literacy and Knowledge Societies","With a structurally entrenched digital divide on the one hand, and increasing ubiquity of the Internet in a techno-centric world on the other, the imperative to exploit information and knowledge for development remains a significant driver for equitable growth. It is posited that the silver-bullet for reducing this gap lies in increasing digital literacies within a society in order integrate segments who may be marginalized into the inclusive mainstream. In enabling greater and wider participation of digital citizens in their countries' socio-economic activities, the opportunities of a sustainable economy arise. This article is a study of ICT policies, applications and the resulting transformations in five mature economies committed to the vision of knowledge-based development with high levels of digital participation among their citizens. Specifically, using a multi-dimensional scorecard derived from prior work, we conduct a grounded theory investigation of how the five societies have applied digital literacies in knowledge-intensive public services such as education, healthcare and e-government, to derive best practices as well as lessons learned. This study investigates the significance of digital literacy programmes on sustainable development in a knowledge society.Specifically, the notion of digital entitlements that promote the inclusion and participation of the community is seen as an effective motivation for exploiting the opportunities that are available over the Internet and new media.A Constructivist Grounded Theory approach was taken to examine the track-record of five successful knowledge societies - Finland, Hong Kong, Qatar, New Zealand and Singapore - in the areas of providing education, health and government services over digital platforms.While our analysis and findings reveal some interesting ""best practices"" as well as caveats, it is clear that digital literacy initiatives are not ends by themselves but means to an end.If the desired outcome of digital policies in knowledge societies is sustainable growth and development; we theorise that policies must focus on effective digital entitlements such as infrastructure, governance, human development and innovation.","","Sharma R,Fantin AR,Prabhu N,Guan C,Dattakumar A","","2016","628–643","10.1016/j.telpol.2016.05.003","https://doi-org.proxy.bnl.lu/10.1016/j.telpol.2016.05.003;http://dx.doi.org/10.1016/j.telpol.2016.05.003","Journal Article"
"Efficient Mining of the Multidimensional Traffic Cluster Hierarchy for Digesting, Visualization, and Anomaly Identification","Mining traffic to identify the dominant flows sent over a given link, over a specified time interval, is a valuable capability with applications to traffic auditing, simulation, visualization, as well as anomaly detection. Recently, Estan advanced a comprehensive data mining structure tailored for networking data-a parsimonious, multidimensional flow hierarchy, along with an algorithm for its construction. While they primarily targeted offline auditing, use in interactive traffic visualization and anomaly/attack detection will require real-time data mining. We suggest several improvements to Estan's algorithm that substantially reduce the computational complexity of multidimensional flow mining. We also propose computational and memory-efficient approaches for unidimensional clustering of the IP address spaces. For baseline implementations, evaluated on the New Zealand (NZIX) trace data, our method reduced CPU execution times of the Estan method by a factor of more than eight. We also develop a methodology for anomaly/attack detection based on flow mining, demonstrating the usefulness of this approach on traces from the Slammer and Code Red worms and the MIT Lincoln Laboratories DDoS data","","Wang J,Miller DJ,Kesidis G","","2006","1929–1941","10.1109/JSAC.2006.877216","https://doi-org.proxy.bnl.lu/10.1109/JSAC.2006.877216;http://dx.doi.org/10.1109/JSAC.2006.877216","Journal Article"
"Ensemble Method Based on Artificial Neural Networks to Estimate Air Pollution Health Risks","","","Araujo LN,Belotti JT,Alves TA,Tadano YS,Siqueira H","","2020","","10.1016/j.envsoft.2019.104567","https://doi-org.proxy.bnl.lu/10.1016/j.envsoft.2019.104567;http://dx.doi.org/10.1016/j.envsoft.2019.104567","Journal Article"
"Privacy Laws and Privacy by Design Schemes for the Internet of Things: A Developer’s Perspective","Internet of Things applications have the potential to derive sensitive information about individuals. Therefore, developers must exercise due diligence to make sure that data are managed according to the privacy regulations and data protection laws. However, doing so can be a difficult and challenging task. Recent research has revealed that developers typically face difficulties when complying with regulations. One key reason is that, at times, regulations are vague and could be challenging to extract and enact such legal requirements. In this article, we have conducted a systematic analysis of the privacy and data protection laws that are used across different continents, namely (i) General Data Protection Regulations, (ii) the Personal Information Protection and Electronic Documents Act, (iii) the California Consumer Privacy Act, (iv) Australian Privacy Principles, and (v) New Zealand’s Privacy Act 1993. Then, we used framework analysis method to attain a comprehensive view of different privacy and data protection laws and highlighted the disparities to assist developers in adhering to the regulations across different regions, along with creating a Combined Privacy Law Framework (CPLF). After that, the key principles and individuals’ rights of the CPLF were mapped with Privacy by Design (PbD) schemes (e.g., privacy principles, strategies, guidelines, and patterns) developed previously by different researchers to investigate the gaps in existing schemes. Subsequently, we have demonstrated how to apply and map privacy patterns into IoT architectures at the design stage and have also highlighted the complexity of doing such mapping. Finally, we have identified the major challenges that should be addressed and potential research directions to take the burden off software developers when applying privacy-preserving techniques that comply with privacy and data protection laws. We have released a companion technical report [3] that comprises all definitions, detailed steps on how we developed the CPLF, and detailed mappings between CPLF and PbD schemes.","","Aljeraisy A,Barati M,Rana O,Perera C","","2021","","10.1145/3450965","https://doi-org.proxy.bnl.lu/10.1145/3450965;http://dx.doi.org/10.1145/3450965","Journal Article"
"The State-of-the-Art Technology of Currency Identification: A Comparative Study","The security issue of currency has attracted awareness from the public. De-spite the development of applying various anti-counterfeit methods on currency notes, cheaters are able to produce illegal copies and circulate them in market without being detected. By reviewing related work in currency security, the focus of this paper is on conducting a comparative study of feature extraction and classification algorithms of currency notes authentication. We extract various computational features from the dataset consisting of US dollar USD, Chinese Yuan CNY and New Zealand Dollar NZD and apply the classification algorithms to currency identification. Our contributions are to find and implement various algorithms from the existing literatures and choose the best approaches for use.","","Yan W,Wang G,Wu X","","2017","58–72","10.4018/IJDCF.2017070106","https://doi-org.proxy.bnl.lu/10.4018/IJDCF.2017070106;http://dx.doi.org/10.4018/IJDCF.2017070106","Journal Article"
"Weakly Homogeneous Variational Inequalities and Solvability of Nonlinear Equations over Cones","","","Gowda MS,Sossa D","","2019","149–171","10.1007/s10107-018-1263-7","https://doi-org.proxy.bnl.lu/10.1007/s10107-018-1263-7;http://dx.doi.org/10.1007/s10107-018-1263-7","Journal Article"
"Analysing the Factors Affecting the Selection of ERP Package: A Fuzzy AHP Approach","","","Bhatt N,Guru S,Thanki S,Sood G","","2021","641–682","10.1007/s10257-021-00521-8","https://doi-org.proxy.bnl.lu/10.1007/s10257-021-00521-8;http://dx.doi.org/10.1007/s10257-021-00521-8","Journal Article"
"Leveraging Deep Learning and SNA Approaches for Smart City Policing in the Developing World","","","Hassan SU,Shabbir M,Iqbal S,Said A,Kamiran F,Nawaz R,Saif U","","2021","","10.1016/j.ijinfomgt.2019.102045","https://doi-org.proxy.bnl.lu/10.1016/j.ijinfomgt.2019.102045;http://dx.doi.org/10.1016/j.ijinfomgt.2019.102045","Journal Article"
"Bracken Fern Frond Status Classification in the Andes of Southern Ecuador: Combining Multispectral Satellite Data and Field Spectroscopy","In the anthropogenic fire-disturbed ecosystem of the San Francisco Valley in the Andes of southeastern Ecuador, dense stands of an aggressive invasive weed, the southern bracken fern Pteridium arachnoideum and Pteridium caudatum, dominate the landscape. To secure sustainable land management in the region, a comprehensive understanding of bracken spatial-distribution patterns and life cycle dynamics is crucial. We investigated the possibility of detecting bracken-infested areas and frond status live, fungi-infected, and dead by means of a high-resolution QuickBird scene from October 2010 and spectral signatures based on field spectroscopy. After image pre-processing, a two-step classification procedure first delineates the bracken-infested area by means of a maximum-likelihood hard classification. The probability-guided unmixing classifier with field-derived end-members is applied in the second step to obtain the fractional cover of the different frond statuses per pixel. The results showed that the areas infested by bracken could be distinguished from the other land-cover classes with high accuracy overall accuracy of 0.9973. Also, the three frond statuses could be accurately classified at the sub-pixel level. The ‘dead’ class was the dominant frond status at the time of image acquisition October 2010. We conclude that the extreme dry spell in October 2010 was particularly responsible for this dominance.","","Curatola Fernández GF,Silva B,Gawlik J,Thies B,Bendix J","","2013","7020–7037","10.1080/01431161.2013.813091","https://doi-org.proxy.bnl.lu/10.1080/01431161.2013.813091;http://dx.doi.org/10.1080/01431161.2013.813091","Journal Article"
"Context-Aware Middleware for Anytime, Anywhere Social Networks","Recent advances in wireless technologies and mobile devices let users form opportunistic social networks of interests with nearby users. However, anytime, anywhere social networks raise several technological issues, including the detection of user location; the modeling, acquisition, and analysis of a user's characterizing properties; and the dynamic extraction of social networks. SAMOA, a semantic context-aware middleware approach, lets you create anytime, anywhere social networks among users in physical proximity. SAMOA separates social-network management from application logic by providing reusable middleware support for various social application scenarios. In addition, SAMOA exploits semantic-based context modeling and matching algorithms for social-network extraction. This article is part of a special issue on social computing.","","Bottazzi D,Montanari R,Toninelli A","","2007","23–32","","","Journal Article"
"Fast Asymmetric Encryption and Decryption of SimpleMatrix Scheme for Internet of Things","","","Yi H","","2022","145–153","10.1016/j.comcom.2022.04.013","https://doi-org.proxy.bnl.lu/10.1016/j.comcom.2022.04.013;http://dx.doi.org/10.1016/j.comcom.2022.04.013","Journal Article"
"Measuring the Effects of Risk and Cultural Dimensions on the Adoption of Online Stock Trading: A Developing Country Perspective","Online stock trading OST is a growing phenomenon across countries, yet there is a sparse literature focusing on the negative utilities risks that causing the low adoption. Drawing from perceived risk theory, this article attempts to fill the gap by identifying the influential risk factors that impede the acceptance of OST in a developing country, Pakistan. The study also applies the Hofstede cultural theory to ascertain the effects of cultural moderators on investors' usage behavior UB. Based on structured questionnaire, 443 valid responses were received from current and potential investors. The model was tested using structural equation modeling through Smart-PLS. The results validate a negative and significant relationship between risk dimensions and investors' behavioral intentions BI to use OST. Especially time, financial, performance, privacy and opportunity cost risks are found having a negative impact on investors' BI. Moreover, the study finds that cultural dimensions, collectivism, and uncertainty avoidance, moderate the relationship between BI and UB.","","Khan SU,Liu X,Khan IU,Liu C,Hameed Z","","2018","106–127","10.4018/IJEIS.2018070106","https://doi-org.proxy.bnl.lu/10.4018/IJEIS.2018070106;http://dx.doi.org/10.4018/IJEIS.2018070106","Journal Article"
"Prediction of Risk Takers in Arterial Hypertension Patients with Data Mining Application","Hyper arterial pressure (HAP) is a disease that kills silently because it does not produce symptoms in the early stages, making it difficult to diagnose. When it is detected, its treatment is not accessible to everyone, which affects the disease’s long-term development. Hypertension affects a large portion of the Iraqi population. In the current research paper, we have discussed how data mining can be applied to identify the status of the risk factors that affect arterial hypertension due to I10-I15 causes, evaluating the context variables disability, overwork, high-risk pregnancy, stress, high diets, and poor nutrition in the population between 50 and 64 years in the city of Baghdad. It is possible to see how data mining in large volumes of health data can generate new knowledge and thus uncover hidden patterns in the data through the development of this research. Attributes directly linked to disease prevalence can be found in data from Baghdad, Iraq, even if they are not directly linked to a specific cause. This shows that some variables are transversal to the development of the disease regardless of its categorization. Cluster analysis revealed that, even though these diseases are categorized as having different causes, they have a degree of incorrect classification of 40.71% because they present attributes with a similar behavior transversal to the disease and not the disease-specific cause for which it is categorized.","","Alhazmi L,Alassery F,Rosales HG","","2022","","10.1155/2022/5093049","https://doi-org.proxy.bnl.lu/10.1155/2022/5093049;http://dx.doi.org/10.1155/2022/5093049","Journal Article"
"Robust Spatial Fuzzy GMM Based MRI Segmentation and Carotid Artery Plaque Detection in Ultrasound Images","","","Hassan M,Murtza I,Hira A,Ali S,Kifayat K","","2019","179–192","10.1016/j.cmpb.2019.04.026","https://doi-org.proxy.bnl.lu/10.1016/j.cmpb.2019.04.026;http://dx.doi.org/10.1016/j.cmpb.2019.04.026","Journal Article"
"Enhancing Intraday Stock Price Manipulation Detection by Leveraging Recurrent Neural Networks with Ensemble Learning","","","Wang Q,Xu W,Huang X,Yang K","","2019","46–58","10.1016/j.neucom.2019.03.006","https://doi-org.proxy.bnl.lu/10.1016/j.neucom.2019.03.006;http://dx.doi.org/10.1016/j.neucom.2019.03.006","Journal Article"
"Landslide Detection Based on Contour-Based Deep Learning Framework in Case of National Scale of Nepal in 2015","","","Yu B,Chen F,Xu C","","2020","","10.1016/j.cageo.2019.104388","https://doi-org.proxy.bnl.lu/10.1016/j.cageo.2019.104388;http://dx.doi.org/10.1016/j.cageo.2019.104388","Journal Article"
"A Data Mining Approach for Risk Assessment in Car Insurance: Evidence from Montenegro","This paper has proposed a data mining approach for risk assessment in car insurance. Standard methods imply classification of policies to great number of tariff classes and assessment of risk on basis of them. With application of data mining techniques, it is possible to get functional dependencies between the level of risk and risk factors as well as better results in predictions. On the case study data it has been proved that data mining techniques can, with better accuracy than the standard methods, predict claim sizes and occurrence of claims, and this represents the basis for calculation of net risk premium and risk classification. This paper, also, discusses advantages of data mining methods compared to standard methods for risk assessment in car insurance, as well as the specificities of the obtained results due to small insurance market, such is the one in Montenegro.","","Kašćelan L,Kašćelan V,Novović-Burić M","","2014","11–28","10.4018/ijbir.2014070102","https://doi-org.proxy.bnl.lu/10.4018/ijbir.2014070102;http://dx.doi.org/10.4018/ijbir.2014070102","Journal Article"
"Running, Sweating, and Persistence Hunting [Numbers Don't Lie]","During the two years of its monthly appearance, this column has looked at many objects–cars, turbines, airplanes, windows, mobile phones, and nuclear reactors–made by humans. Todayźs focus is on the human body, specifically the way it keeps itself cool. Before the development of long-range projectile weaponry some tens of thousands of years ago, in Africa, our ancestors had only two ways to secure meat: by scavenging the leftovers of mightier beasts or by running down their own prey. Humans were able to occupy the second of those ecological niches thanks, in part, to two great advantages of bipedalism.","","Smil V","","2016","26","10.1109/MSPEC.2016.7607022","https://doi-org.proxy.bnl.lu/10.1109/MSPEC.2016.7607022;http://dx.doi.org/10.1109/MSPEC.2016.7607022","Journal Article"
"Applying Intrusion Detection and Response Systems for Securing the Client Data Signals in the Egyptian Optical Network","","","Rahouma K,Ali A","","2019","538–549","10.1016/j.procs.2019.12.136","https://doi-org.proxy.bnl.lu/10.1016/j.procs.2019.12.136;http://dx.doi.org/10.1016/j.procs.2019.12.136","Journal Article"
"Short PCPs with Polylog Query Complexity","We give constructions of probabilistically checkable proofs (PCPs) of length $n cdot polylog n$ proving satisfiability of circuits of size $n$ that can be verified by querying $polylog n$ bits of the proof. We also give analogous constructions of locally testable codes (LTCs) mapping $n$ information bits to $ncdot polylog n$ bit long codewords that are testable with $polylog n$ queries. Our constructions rely on new techniques revolving around properties of codes based on relatively high-degree polynomials in one variable, i.e., Reed-Solomon codes. In contrast, previous constructions of short PCPs, beginning with [L. Babai, L. Fortnow, L. Levin, and M. Szegedy, Checking computations in polylogarithmic time, in Proceedings of the 23rd ACM Symposium on Theory of Computing, ACM, New York, 1991, pp. 21-31] and until the recent [E. Ben-Sasson, O. Goldreich, P. Harsha, M. Sudan, and S. Vadhan, Robust PCPs of proximity, shorter PCPs, and applications to coding, in Proceedings of the 36th ACM Symposium on Theory of Computing, ACM, New York, 2004, pp. 13-15], relied extensively on properties of low-degree polynomials in many variables. We show how to convert the problem of verifying the satisfaction of a circuit by a given assignment to the task of verifying that a given function is close to being a Reed-Solomon codeword, i.e., a univariate polynomial of specified degree. This reduction also gives an alternative to using the “sumcheck protocol” [C. Lund, L. Fortnow, H. Karloff, and N. Nisan, J. ACM, 39 (1992), pp. 859-868]. We then give a new PCP for the special task of proving that a function is close to being a Reed-Solomon codeword. The resulting PCPs are not only shorter than previous ones but also arguably simpler. In fact, our constructions are also more natural in that they yield locally testable codes first, which are then converted to PCPs. In contrast, most recent constructions go in the opposite direction of getting locally testable codes from PCPs.","","Ben-Sasson E,Sudan M","","2008","551–607","10.1137/050646445","https://doi-org.proxy.bnl.lu/10.1137/050646445;http://dx.doi.org/10.1137/050646445","Journal Article"
"Critical Risk Path Method: A Risk and Contingency-Driven Model for Construction Procurement in Complex and Dynamic Projects","Existing approaches to risk management in construction procurement primarily dwell on strategies designed for commonly identifiable risk factors in typical project environments. Commonly identifiable risk factors would include too early or late material delivery-a condition typically ameliorated by implementing a Just In Time JIT plan; inferior construction materials typically mitigated by employing trusted vendors; or ineffective contractors primarily avoided by the use of experienced contractors. The purpose of this paper is to present a coherent model for procurement risk management for construction and infrastructure development projects within the context of dynamic project environments-complex, or chaotic. For the purpose of this study, a critical risk path activity is one in which a delay of activity completion not only leads to project delay, but does so in a manner that may be fatal to project or at best, far greater than the actual delay. The study incorporates observations and theory with practical application for improving initiatives by emergency infrastructure development response organizations such as FEMA Federal Emergency Management Agency and USACE US Army Corps of Engineers in the United States, the NEMA National Emergency Management Agency in Nigeria, or ANDMA Afghanistan National Disaster Management Authority etc. This study presents risk response plans aimed at improving the potential occurrence of positive risk aspects while reducing, or eliminating the same for negative risk occurrences. This study explored material, equipment, and skilled labor procurement strategies related to project risk management from the perspectives of scheduling, cost, and quality-three factors often referred to as the triple project constraints. It identified gaps within specific national and multinational organizations' approaches, and provided detailed recommendations for process improvements from the procurement management perspective to ensure the potential for successful project outcomes in unstable project conditions.","","Howard C,Iromuanya C,Hargiss KM","","2013","61–73","10.4018/jsita.2013040105","https://doi-org.proxy.bnl.lu/10.4018/jsita.2013040105;http://dx.doi.org/10.4018/jsita.2013040105","Journal Article"
"Development of a Mobile Application Platform for Self-Management of Obesity Using Artificial Intelligence Techniques","Obesity is a major global health challenge and a risk factor for the leading causes of death, including heart disease, stroke, diabetes, and several types of cancer. Attempts to manage and regulate obesity have led to the implementation of various dietary regulatory initiatives to provide information on the calorie contents of meals. Although knowledge of the calorie content is useful for meal planning, it is not sufficient as other factors, including health status (diabetes, hypertension, etc.) and level of physical activity, are essential in the decision process for obesity management. In this work, we present an artificial intelligence- (AI-) based application that is driven by a genetic algorithm (GA) as a potential tool for tracking a user’s energy balance and predicting possible calorie intake required to meet daily calorie needs for obesity management. The algorithm takes the users’ input information on desired foods which are selected from a database and extracted records of users on cholesterol level, diabetes status, and level of physical activity, to predict possible meals required to meet the users need. The micro- and macronutrients of food content are used for the computation and prediction of the potential foods required to meet the daily calorie needs. The functionality and performance of the model were tested using a sample of 30 volunteers from the University of Ghana. Results revealed that the model was able to predict both glycemic and non-glycemic foods based on the condition of the user as well as the macro- and micronutrients requirements. Moreover, the system is able to adequately track the progress of the user’s weight loss over time, daily nutritional needs, daily calorie intake, and predictions of meals that must be taken to avoid compromising their health. The proposed system can serve as a useful resource for individuals, dieticians, and other health management personnel for managing obesity, patients, and for training students in fields of dietetics and consumer science.","","Sefa-Yeboah SM,Osei Annor K,Koomson VJ,Saalia FK,Steiner-Asiedu M,Mills GA,Hu F","","2021","","10.1155/2021/6624057","https://doi-org.proxy.bnl.lu/10.1155/2021/6624057;http://dx.doi.org/10.1155/2021/6624057","Journal Article"
"Safety Evaluation and Consideration of 4 Pin Multi-Needle for Meso-Therapy","This study was conducted according to the method presented in the Republic of Korea Pharmacopoeia 11th Revision, aseptic test method to evaluate the suitability of sterilization for a sterile needle (4 Pin Multi-needle). In this study, four tests were conducted: sterility test, cytotoxicity test, acute toxicity test, skin sensitization test. First, in the aseptic test, the microorganism was not proliferated in the aseptic test of the medium. As a result of the performance test of the medium, it was confirmed that the microorganism developed within 3 days and the fungus was evident within 5 days. Based on this, it was confirmed that the medium was suitable, and as a result of the aseptic test, the development of microorganisms was not observed during the total culture period. Based on these results, tests were conducted which were confirmed to be suitable for aseptic testing because the development of bacteria on the provided samples was not recognized. For cytotoxicity tests ISO10993-5; 2009 (Biological Evaluation of Medical Devices, Part 5: Test for in vitro Cytotoxicity). As a result, the MEM eluate of the test substance caused very slight cytotoxicity to the fibroblasts of the mouse and was judged to be Grade 1 (Slightly cytotoxic) according to the judgment standard of ISO 10993-5. On the other hand, solvent control, negative control and positive control showed the expected results on the test. Acute Toxicity Test Results: It was judged that there was no systemic toxicity change when ICR mice were treated with 50 mL/kg B.W. of the eluate of sterile injectable needle for 72 hours. Skin sensitization test result: The Hartley guinea pig was evaluated as a substance which is evaluated as a substance which does not induce any skin reaction when skin sensitization is applied to the dissected material of the sterile injectable needle and is weak in skin sensitivity. Based on the above tests, we will study the stability and efficacy of more reliable medical devices based on the verification and performance of medical devices.","","Kim JT,Choi A,Jeong JH,Jo JH,Ryu OS,Kim EJ,Kim KY,Song MH,Song YH,Shin WS,Lee SS,Gómez C,Schwarzacher SP,Zhou H","","2018","291–306","10.3233/THC-174624","https://doi-org.proxy.bnl.lu/10.3233/THC-174624;http://dx.doi.org/10.3233/THC-174624","Journal Article"
"Leveraging Artificial Intelligence Techniques for Smart Palm Tree Detection: A Decade Systematic Review","","","Hajjaji Y,Boulila W,Farah IR","","2022","2823–2832","10.1016/j.procs.2022.09.340","https://doi-org.proxy.bnl.lu/10.1016/j.procs.2022.09.340;http://dx.doi.org/10.1016/j.procs.2022.09.340","Journal Article"
"An Improved Marine Predators Algorithm for the Optimal Design of Hybrid Renewable Energy Systems","","","Houssein EH,Ibrahim IE,Kharrich M,Kamel S","","2022","","10.1016/j.engappai.2022.104722","https://doi-org.proxy.bnl.lu/10.1016/j.engappai.2022.104722;http://dx.doi.org/10.1016/j.engappai.2022.104722","Journal Article"
"The Nature of Security: A Conceptual Framework for Integral-Comprehensive Modeling of IT Security and Cybersecurity","","","Villalón-Fonseca R","","2022","","10.1016/j.cose.2022.102805","https://doi-org.proxy.bnl.lu/10.1016/j.cose.2022.102805;http://dx.doi.org/10.1016/j.cose.2022.102805","Journal Article"
"Gabor Filter Bank with Deep Autoencoder Based Face Recognition System","","","Hammouche R,Attia A,Akhrouf S,Akhtar Z","","2022","","10.1016/j.eswa.2022.116743","https://doi-org.proxy.bnl.lu/10.1016/j.eswa.2022.116743;http://dx.doi.org/10.1016/j.eswa.2022.116743","Journal Article"
"Modelling Mixed Crop-Livestock Farms for Supporting Farmers’ Strategic Reflections: The CLIFS Approach","","","Le Gal PY,Andrieu N,Bruelle G,Dugué P,Monteil C,Moulin CH,Penot E,Ryschawy J","","2022","","10.1016/j.compag.2021.106570","https://doi-org.proxy.bnl.lu/10.1016/j.compag.2021.106570;http://dx.doi.org/10.1016/j.compag.2021.106570","Journal Article"
"ICT Use Patterns, Mental Health Symptoms and the Well-Being of the Open Distance Learning Student: A Replication Study with Historically Advantaged Students","In addressing an area of research that has not received any attention, a recent study conducted in the South African context of disparities concluded that medium ICT use patterns hold no risk factors for the mental health and well-being of the historically disadvantaged open distance learning student. To determine if the basic findings can be applied to a different subgroup of students who are known to have better access to ICT resources, a replication study with historically advantaged students was done. Key findings from data collected from 699 students revealed no significant relationships between total ICT use scores, mental health and psychological and emotional well-being. Other than facets of social well-being, results were relatively consistent with the original study. In the context studied, it was concluded that ICT use patterns hold no risk factors for the mental health and well-being of the open distance learning student in general.","","Merwe TM","","2020","360–383","10.1504/ijlt.2020.113884","https://doi-org.proxy.bnl.lu/10.1504/ijlt.2020.113884;http://dx.doi.org/10.1504/ijlt.2020.113884","Journal Article"
"Optimal Multimedia Transport on the Internet","Delivering events in a distributed system needs special attention in cases with large numbers of receivers. With traditional solutions, an event producer needs to know all of his event consumers. To deliver an event, the producer has to issue a remote method invocation on a consumer. Alternatively, the consumers periodically have to poll the producer for new events. Both solutions are inefficient; they require the implementation of registration logic, and do not address partial failure adequately. The most efficient approach consists of pushing the event onto the wire just once and all interested remote listeners automatically pick up the event while it passes by. We have developed a quality of service framework where applications only pay for services they need: programmers can request qualities of service such as reliable multicast, virtual synchrony, encrypted communication and a protocol composition framework that extends to incorporate yet unsupported communication protocols and qualities of service. This paper presents the real time wide area network dissemination architecture protocol (RWANDA) which overcomes synchronous limitations by providing an asynchronous group communication model where applications only pay for the required quality of service (QoS) such as multicast, virtual synchrony and encrypted communication. In RWANDA, information sources use channels to disseminate information to a potentially large and changing set of channel subscribers. RWANDA is a Java architecture and it recognises the differing media characteristics and transport requirements of multimedia by providing a protocol composition framework that extends to incorporate yet unsupported communication protocols, qualities of service and optimised multimedia stacks. RWANDA provides an asynchronous foundation necessary for developing large-scale wide-area network continuous media applications.1998 Academic Press","","Parr G,Curran K","","1998","149–161","10.1006/jnca.1998.0070","https://doi-org.proxy.bnl.lu/10.1006/jnca.1998.0070;http://dx.doi.org/10.1006/jnca.1998.0070","Journal Article"
"The Impact of Information Lifecycle Management Process in the Nigerian Financial Sector","The main objective of this paper focuses on the theoretical and practical approaches in the banking sector, with emphasis being placed on financial service operations of cheque processing and securities trading, and in managing financial information. The banking sector was identified as it is presently the most vibrant and emerging sector in the financial services in Nigeria, which was mentioned in the Financial Times. In 2007, the banking sector has been the driving force behind Nigeria's equity, which is in excess of $3.3bn in equity capital market transactions. The banks that were investigated in this research paper included banks that incorporate functions in the equity market as part of their daily operations and in the possession of relevant information on securities trading as well as information on cheque processing procedures. The paper concludes by suggesting that, there is above average knowledge and understanding of ILM within the financial sector in Nigeria. Therefore, it was recommended that the application of ILM techniques should be improved upon in the management of information in the Nigerian financial sector and to obtain the best results at every stage of the information lifecycle.","","Al-Karaghouli W,Fadare EB","","2010","111–132","10.1504/IJBIS.2010.034008","https://doi-org.proxy.bnl.lu/10.1504/IJBIS.2010.034008;http://dx.doi.org/10.1504/IJBIS.2010.034008","Journal Article"
"Information Technology in Nigerian Banks: The Limits of Expectations","In the last ten years, banks in developed countries have been investing more and more in information technology (IT) as a means to reduce costs and improve operational efficiency. An investigation of the application of IT in Nigerian banks was carried out in order to determine the expectations and success of IT implementations in the sector. The data were generated from a survey of randomly selected branches of 56 banks in Lagos, the commercial capital of Nigeria. Almost all the banks had an IT policy, the main thrusts of which where to achieve full application of IT, to be able to meet organisational goals, to secure competitive advantage, and to be up to date. Only 54.6% of them actually achieved some measure of successful implementations. The expected benefits of investment in IT were realised in only a relatively few number of banks. The consequence was that less than 40% of the banks were poised to maximise the benefits of IT through major investments, especially in the areas of online access and transactions, electronic commerce, and electronic publishing. It is estimated that at least 60% of the branches of these banks are spending less than $150,000 annually on IT. An upsurge of investment is, however, expected, first by the banks that style themselves as progressive and have already made some success in IT implementations, and later by the other banks.","","Ehikhamenor FA","","2003","13–24","10.1002/itdj.1590100103","https://doi-org.proxy.bnl.lu/10.1002/itdj.1590100103;http://dx.doi.org/10.1002/itdj.1590100103","Journal Article"
"Professional Mobile Radio — the BT Airwave Public Safety Service and the Path for Technology and Service Evolution","Professional mobile radio (PMR) has often been perceived as the 'Cinderella' of the mobility market; however, a wide range of corporate mobile business communications people use PMR intensively, because both its unique functionality and its performance match their requirements bettern than other mobile technologies.Although there are several new digital PMR technologies, the new ETSI TETRA (terrestrial trunked radio) standard, which offers enhanced speech and data facilities, is a major factor in the quiet revolution in which more and more business users are adopting PMR to meet their mobile communications needs. This market is estimated to be worth over £ 10bn by 2004.TETRA is also receiving global acceptance outside Europe with contracts and/or commitments already in Asia Pacific, Latin America, Africa, the Middle East and China, with interest being shown in North America (Com-Net Ericsson/Marconi contract for Florida).BT Quadrant and BT Airwave have been very successful in capturing a significant part of the UK 'public safety' (police, fire, ambulance, etc) market. A Public Private Partnership (PPP) contract worth £2.5bn was secured at the beginning of this year for the supply of PMR communications to the police and other 'blue light' services. This contract has a lifetime of over 15 years and it is therefore important to look ahead at how the present capabilities may be evolved to enhance the service, at a time when the capabilities of public cellular networks will be enhanced by new 3rd generation developments.This paper reviews the BT Airwave service for public safety users and discusses how it may be developed to provide users with greater flexibility and increased working effectiveness.","","Tattersall PR","","2001","142–148","10.1023/A:1009677432169","https://doi-org.proxy.bnl.lu/10.1023/A:1009677432169;http://dx.doi.org/10.1023/A:1009677432169","Journal Article"
"Challenges and Solutions Implementing an SMS Text Message-Based Survey CASI and Adherence Reminders in an International Biomedical HIV PrEP Study (MTN 017)","","","Brown W,Giguere R,Sheinfil A,Ibitoye M,Balan I,Ho T,Brown B,Quispe L,Sukwicha W,Lama JR,Carballo-Diéguez A,Cranston RD","","2018","78–86","10.1016/j.jbi.2018.02.018","https://doi-org.proxy.bnl.lu/10.1016/j.jbi.2018.02.018;http://dx.doi.org/10.1016/j.jbi.2018.02.018","Journal Article"
"The Use of Artificial Intelligence in Migration-Related Procedures in the European Union - Opportunities and Threats","","","Szwed A","","2022","3645–3651","10.1016/j.procs.2022.09.424","https://doi-org.proxy.bnl.lu/10.1016/j.procs.2022.09.424;http://dx.doi.org/10.1016/j.procs.2022.09.424","Journal Article"
"PTZ-Surveillance Coverage Based on Artificial Intelligence for Smart Cities","","","Eldrandaly KA,Abdel-Basset M,Abdel-Fatah L","","2019","520–532","10.1016/j.ijinfomgt.2019.04.017","https://doi-org.proxy.bnl.lu/10.1016/j.ijinfomgt.2019.04.017;http://dx.doi.org/10.1016/j.ijinfomgt.2019.04.017","Journal Article"
"Towards a Theoretical Understanding of Workarounds Emerging from Use of a Referral Mobile Application: A Developing Country Context","","","Kapepo MI,Van Belle JP,Weimann E","","2022","533–541","10.1016/j.procs.2021.12.046","https://doi-org.proxy.bnl.lu/10.1016/j.procs.2021.12.046;http://dx.doi.org/10.1016/j.procs.2021.12.046","Journal Article"
"Multi-Modal Biometric Fusion Based Continuous User Authentication for E-Proctoring Using Hybrid LCNN-Salp Swarm Optimization","In Covid 19, pandemic remote proctoring of the employee or human being is evolved as a big challenge for the information retrieval process. On the other side, memory-based system access authentication is becoming outdated and less preferred for live applications, especially where data security and customer privacy are crucial. Multi-modal authentication has outperformed the unimodal process with high accuracy and improved security in the user authentication field. Multi-modal biometric verification includes user attributes such as keystrokes, iris, speech, face, etc. For real-time execution of multi-modal biometric fusion-based live tracking for compatible applications. The study proposes an efficient continuous biometric user authentication system for a new challenge of pandemic time, a live online authentication of the evaluation process (CBUA-OE). The proposed CBUA-OE system can address the challenges associated with live proctoring and is also compatible with real-time implementation, deployment of authentication systems. The modified wolf optimization algorithm and CUBA-OE's optimal feature fusion algorithm give an edge over the other contemporary methods and make it more robust. In modern forms of authentication, the classification stage affects the overall outcome of the system, and the model's performance is also a factor of varying quality of datasets. In contrast, a hybrid LCNN-Salp swarm optimization-based classifier is more efficient and consistent in continuous user authentication. Here the performance of the proposed hybrid LCNN-Salp swarm optimization classifier is analyzed with different standard datasets. The results are compared with the existing state-of-art classifiers regarding the accuracy, precision, recall, and F-measure. This projected work is novel in terms of usability factors and scalability to live tracking systems.","","Purohit H,Ajmera PK","","2022","827–846","10.1007/s10586-021-03450-w","https://doi-org.proxy.bnl.lu/10.1007/s10586-021-03450-w;http://dx.doi.org/10.1007/s10586-021-03450-w","Journal Article"
"Fractional Optimal Control with Fish Consumption to Prevent the Risk of Coronary Heart Disease","According to the World Health Organization (WHO), Chronic Heart Disease (CHD) is one of the greatest defies currently confronting humankind which is sweeping the whole globe, with an expanding trend in developing countries. In this paper, a mathematical model (MM) was proposed to study the connection between fish consumption and CHD mortality in Egypt, by considering a system of ordinary differential equations (ODEs) involving time-fractional derivative (FD). We considered here the study on Egypt for the ease of obtaining real data, but the method and approach adopted here is not limited to Egypt only and can be applied to any country in the world with the information of the real data related to the subject of the study. Additionally, the control function which represents the metabolic and the behavioural risk factors of CHD that help to reduce the number of mortality due to CHD is incorporated in the proposed MM. A fractional optimal control problem (FOCP) with a proposed control is formulated and studied theoretically using the Pontryagin maximum principle, to minimize the susceptible population and also to decrease the mortality rate of CHD. Moreover, firstly we discussed the positivity and boundedness of solutions; then, the model equilibria are determined and their local stability analysis was investigated; furthermore, we use the improved forward-backward sweep method (FBSM) based on the predictor-corrector method (PCM) in order to obtain the solution of proposed FOCP. In addition, some numerical simulations were performed to show the effect of the proposed optimal control (OC) besides the impact of fish consumption on the mortality of CHD.","","Ameen I,Hidan M,Mostefaoui Z,Ali HM,Guo X","","2020","","10.1155/2020/9823753","https://doi-org.proxy.bnl.lu/10.1155/2020/9823753;http://dx.doi.org/10.1155/2020/9823753","Journal Article"
"The Relative Importance of Monetary and Non-Monetary Drivers for Information and Communication Technology Acceptance in Rural Agribusiness","Traditionally the information and communication technology for development ICT4D literature assessed technology interventions in developing countries from an economic viewpoint, typically measuring income increases or other economic gains. However numerous ICT4D studies revealed that technology adopters only secure a small, single-digit monetary benefit, thus suggesting the importance of other i.e. non-monetary drivers of information and communication technology ICT acceptance. Seeking to address the issue and to identify the relative importance of monetary vs. non-monetary drivers for the acceptance of ICT in rural agribusiness, this study investigates the key motivational drivers monetary vs. non-monetary for the acceptance of a digital procurement e-purjee system by sugarcane growers in rural Bangladesh. The e-purjee system is a simple SMS-based purchase order system that replaces a paper-based procurement order system. Treating the acceptance of e-purjee system as sugarcane growers’ decision-problem, and applying a multi-criteria decision-making approach [e.g. Zionts & Wallenius. 1976. An interactive programming method for solving the multiple criteria problem. Management Science, 226, 652–663] to that problem, the study identifies the trade-offs growers appear to make between non-monetary and monetary decision criteria. In addition, by analyzing interviews with local growers from the perspective of the human capability approach [Sen. 1999. Development as freedom. New York, NY: Oxford University Press], this study offers new explanations for their preferences and reasoning. The findings indicate that non-monetary incentives, namely procedural fairness and uncertainty reduction, can be more important than positive monetary benefits. Interview responses also suggest that non-monetary benefits affect small-scale growers more than the large-scale growers. Considering growers’ preferences related to non-monetary incentives, the e-purjee system appears to affect three out of five types of instrumental freedoms postulated by Sen [1999. Development as freedom. New York, NY: Oxford University Press]. The study offers several practical and theoretical recommendations about the structuring of incentive systems for rural technology-based development projects, and about decision modeling for a relatively untrained informant group.","","Alam MM,Wagner C","","2016","654–671","10.1080/02681102.2016.1155142","https://doi-org.proxy.bnl.lu/10.1080/02681102.2016.1155142;http://dx.doi.org/10.1080/02681102.2016.1155142","Journal Article"
"Mapping Twenty Years of Antimicrobial Resistance Research Trends","","","Luz CF,van Niekerk JM,Keizer J,Beerlage-de Jong N,Braakman-Jansen LM,Stein A,Sinha B,van Gemert-Pijnen JE,Glasner C","","2022","","10.1016/j.artmed.2021.102216","https://doi-org.proxy.bnl.lu/10.1016/j.artmed.2021.102216;http://dx.doi.org/10.1016/j.artmed.2021.102216","Journal Article"
"Multi-Objective Cluster Head Using Self-Attention Based Progressive Generative Adversarial Network for Secured Data Aggregation","","","Sindhuja M,Vidhya S,B S J,Shajin FH","","2023","","10.1016/j.adhoc.2022.103037","https://doi-org.proxy.bnl.lu/10.1016/j.adhoc.2022.103037;http://dx.doi.org/10.1016/j.adhoc.2022.103037","Journal Article"
"A Framework for Integrating Geospatial Information Systems and Hybrid Cloud Computing","","","Helmi AM,Farhan MS,Nasr MM","","2018","145–158","10.1016/j.compeleceng.2018.03.027","https://doi-org.proxy.bnl.lu/10.1016/j.compeleceng.2018.03.027;http://dx.doi.org/10.1016/j.compeleceng.2018.03.027","Journal Article"
"Of Milk and Mobiles: Assessing the Potential of Cellphone Applications to Reduce Cattle Milk Yield Gaps in Africa Using a Case Study","","","A. Bateki C,Daum T,Salvatierra-Rojas A,Müller J,Birner R,Dickhoefer U","","2021","","10.1016/j.compag.2021.106516","https://doi-org.proxy.bnl.lu/10.1016/j.compag.2021.106516;http://dx.doi.org/10.1016/j.compag.2021.106516","Journal Article"
"Plagiarism Detection in Armenian Texts Using Intrinsic Stylometric Analysis","","","Yeshilbashian YM,Asatryan AA,Ghukasyan TG","","2022","435–444","10.1134/S0361768822070039","https://doi-org.proxy.bnl.lu/10.1134/S0361768822070039;http://dx.doi.org/10.1134/S0361768822070039","Journal Article"
"The Urgency for Investment on Local Data for Advancing Food Assessments in Africa: A Review Case Study for APSIM Crop Modeling","","","Carcedo AJ,Vieira Junior N,Marziotte L,Correndo AA,Araya A,Prasad PV,Min D,Stewart ZP,Faye A,Ciampitti IA","","2023","","10.1016/j.envsoft.2023.105633","https://doi-org.proxy.bnl.lu/10.1016/j.envsoft.2023.105633;http://dx.doi.org/10.1016/j.envsoft.2023.105633","Journal Article"
"African Buffalo Algorithm: Training the Probabilistic Neural Network to Solve Classification Problems","","","Alweshah M,Rababa L,Ryalat MH,Al Momani A,Ababneh MF","","2022","1808–1818","10.1016/j.jksuci.2020.07.004","https://doi-org.proxy.bnl.lu/10.1016/j.jksuci.2020.07.004;http://dx.doi.org/10.1016/j.jksuci.2020.07.004","Journal Article"
"Characterizing the Input-Output Function of the Olfactory-Limbic Pathway in the Guinea Pig","Nowadays the neuroscientific community is taking more and more advantage of the continuous interaction between engineers and computational neuroscientists in order to develop neuroprostheses aimed at replacing damaged brain areas with artificial devices. To this end, a technological effort is required to develop neural network models which can be fed with the recorded electrophysiological patterns to yield the correct brain stimulation to recover the desired functions. In this paper we present a machine learning approach to derive the input-output function of the olfactory-limbic pathway in the in vitro whole brain of guinea pig, less complex and more controllable than an in vivo system. We first experimentally characterized the neuronal pathway by delivering different sets of electrical stimuli from the lateral olfactory tract (LOT) and by recording the corresponding responses in the lateral entorhinal cortex (l-ERC). As a second step, we used information theory to evaluate how much information output features carry about the input. Finally we used the acquired data to learn the LOT-l-ERC ""I/O function,"" by means of the kernel regularized least squares method, able to predict l-ERC responses on the basis of LOT stimulation features. Our modeling approach can be further exploited for brain prostheses applications.","","Breschi GL,Ciliberto C,Nieus T,Rosasco L,Taverna S,Chiappalone M,Pasquale V","","2015","","10.1155/2015/359590","https://doi-org.proxy.bnl.lu/10.1155/2015/359590;http://dx.doi.org/10.1155/2015/359590","Journal Article"
"A Study on the Determinants of Ethiopian Minibus Taxi Drivers’ Speeding Behaviour: An Application of the ‘Major Theorists’ Model","","","Mamo WG,Ross V,Alhajyaseen WK,Reinolsmann N,Brijs K","","2022","189–196","10.1016/j.procs.2022.03.027","https://doi-org.proxy.bnl.lu/10.1016/j.procs.2022.03.027;http://dx.doi.org/10.1016/j.procs.2022.03.027","Journal Article"
"Wind Energy Resource Prediction and Optimal Storage Sizing to Guarantee Dispatchability: A Case Study in the Kenyan Power Grid","Kenya is experiencing a fast increase in grid-connected intermittent renewable energy sources (RESs) to meet its increased power demand, and at the same time be able to fulfill its Paris Agreement obligations of abating greenhouse gas emissions. For instance, Kenya has 102 MW of grid-tied solar power and 410 MW of grid-tied wind power. However, these sources are very intermittent with low predictability. Thus, after their installation and integration into the grid, they impose a new challenge for the secure, reliable, and economic operation of the system. To mitigate these and to ensure proper planning of the system operations, accurate and faster prediction of the generation output of the wind energy resources and optimal design and sizing of storage for the large-scale wind energy integration into the grid are of paramount importance. Artificial intelligence (AI) and metaheuristic techniques have proven to be efficient and robust in offering solutions to complex nonlinear prediction and optimization problems. Therefore, this study aims to utilize backpropagation neural network (BPNN) algorithm to conduct hourly prediction of the generation output of Lake Turkana Wind Power Plant (LTWPP), a 310 MW plant connected to the Kenyan power grid, and optimally size its battery energy storage system (BESS) using genetic algorithm (GA) to guarantee its dispatchability. The historical weather data, namely wind speed, ambient temperature, relative humidity, wind direction, and generation output from LTWPP, are employed in the training, testing, and validation of the neural network. LTWPP and BESS are modelled in MATLAB R2016a software. Thereafter, the developed BPNN and GA algorithms are applied to the modelled systems to predict the wind output and optimize the storage system, respectively. BESS optimization with neural prediction reduces the BESS capacity and investment costs by 59.82%, while the overall dispatchability of LTWPP is increased from 73.36% to 90.14%, hence enabling the farm to meet its allowable loss of power supply probability (LPSP) index of 0.1 while guaranteeing its dispatchability.","","Odero H,Wekesa C,Irungu G,Vallée F","","2022","","10.1155/2022/4044757","https://doi-org.proxy.bnl.lu/10.1155/2022/4044757;http://dx.doi.org/10.1155/2022/4044757","Journal Article"
"The Making of KECCAK","The sponge function KECCAK is the versatile successor of SHA-1 and the SHA-2 series of hash functions. Its structure and components are quite different from its predecessors, and at first sight it seems like a complete break with the past. In this article, researchers show that KECCAK is the endpoint of a long learning process involving many intermediate designs, mostly gradual changes, but also some drastic changes of direction. Researchers take off from their attempts at fixing PANAMA [26], resulting in RADIOGATÚN [4], and their insights on trail backtracking applied to generalizations of PANAMA and RADIOGATÚN, known as alternating-input and belt-and-mill structures. They explain how they originally proposed the sponge construction to compactly express security claims for their designs and how they finally decided to use it in an actual design which would become KECCAK. Then, they explain the design choices made in KECCAK and how some of its building blocks can be traced back to its predecessor, RADIOGATÚN, and even earlier.","","Bertoni G,Daemen J,Peeters M,Van Assche G","","2014","26–60","10.1080/01611194.2013.856818","https://doi-org.proxy.bnl.lu/10.1080/01611194.2013.856818;http://dx.doi.org/10.1080/01611194.2013.856818","Journal Article"
"Complex Systems Analysis of Hybrid Warfare","","","Nadolski M,Fairbanks J","","2019","210–217","10.1016/j.procs.2019.05.072","https://doi-org.proxy.bnl.lu/10.1016/j.procs.2019.05.072;http://dx.doi.org/10.1016/j.procs.2019.05.072","Journal Article"